ON THE NOTION OF A BASIS OF A FINITE DIMENSIONAL
VECTOR SPACE
ALEXANDER GAMKRELIDZE AND GRIGORI GIORGADZE

Abstract
In this Note, we show that the notion of a basis of a finite-dimensional vector
space could be introduced by an argument much weaker than Gauss’ reduction
method. Our aim is to give a short proof of a simply formulated lemma, which in
fact is equivalent to the theorem on frame extension, using only a simple notion of
the kernel of a linear mapping, without any reference to special results, and derive
the notions of basis and dimension in a quite intuitive and logically appropriate
way, as well as obtain their basic properties, including a lucid proof of Steinitz’s
theorem.
1. Introduction
To indroduce the notion of a basis of a finite dimensional vector space the
following Proposition or its equivalent should be proved:
Given two n−frames (sequence of linearly independent vectors) kej kn , kfj kn in
a vector space, the vector fj contained in the linear span of kej kn , fj ∈ [kej kn ], j =
1, . . . , n, there exists a uniquely defined invertible n×n-matrix of scalars A, satisfying
the equations
kfj kn = kej kn A ⇐⇒ kej kn = kfj kn A−1 .
Existence and uniqueness of the matrix A is evident, but proving its invertibility is
always a delicate pedagogical problem for every author of an introductory text on
Linear Algebra, since it should be given right at the beginning of the exposition,
after the vector space axioms are listed.
A standard argument of proving the Proposition is based (explicitly or implicitly)
on Gauss’ reduction process of transforming a square matrix to a triangular form,
often combined with the Steinitz’s theorem on frame extension.
In this Note we suggest, instead of solving the above equations, to solve the system
of inclusions
ei ∈ [kfj kn ], i = 1, . . . , n,
which is equivalent under given conditions to the above equations. The proof
is short and based on an argument much weaker than the reduction process additionally to the list of axioms we only need the notion of the kernel of a linear
mapping, without any special constructions performed on the data.
The authors thank Prof. Revaz V. Gamkrelidze for drawing our attention to the
problem and stimulating discussions during the preparation of this manuscript.
1

2

ALEXANDER GAMKRELIDZE AND GRIGORI GIORGADZE

2. Preliminary remarks
The logical procedure of introducing a basis of a finite dimensional vector space is
completely equivalent to that of inverting a nondegenerate square matrix of scalars
and is reduced to proving the following proposition or its equivalent, after which
the path to the notions of a basis and dimension are almost uniquely determined
and short.
Proposition. If two n-frames of a vector space (not necessarily finite dimensional),
kej kn and kfj kn , are given, where the vectors fj , j = 1, . . . , n, are contained in the
linear span [kej kn ], then there exists an invertible n × n matrix of scalars A such
that
(1)

kfj kn = kej kn A ⇐⇒ kej kn = kfj kn A−1 .

The existence and uniqueness of A are evident since the sequences kej kn , kfj kn are
linearly independent, but proving its invertibility is always a delicate pedagogical
problem for every author of an introductory text on Linear Algebra, since the proof
should be given right at the beginning of the exposition, after the vector space
axioms are listed, very often even before linear mappings are introduced.
A standard way of solving the problem is to apply to A (implicitly or explicitly)
Gauss’ method of reduction of a square matrix to a triangular form, often combined
with Steinitz’s theorem on a frame extension. In this respect, it is instructive to
compare expositions of the corresponding material in four texts [1], [2], [3] and [4],
the last three published after [1] with the time lag of more than 50 years.
In this note, instead of solving equations (1), we prove the system of inclusions
(2)

ei ∈ [kfj kn ], i = 1, . . . , n,

which is equivalent to (1) since kej kn , kfj kn are linearly independent. The proof is
much shorter and based on an argument much weaker than the reduction process.
Additionally to the list of axioms we only need the notion of the kernel of a linear
mapping, without any special constructions performed on the data.
In section 3, inclusions (2) are presented and discussed as a short and simply
formulated Basic Lemma, from which, in sections 4 - 6, the notions of a basis and
dimension of a finite dimensional vector space along with their basic properties
(including a lucid proof of the frame extension theorem) are derived in a quite
intuitive and logically proper way. Finally, in Section 7, the Basic Lemma is proved.
In the next Section 2 we list several necessary initial notions used in this note.
To conclude the section, we should remark that in most texts on introductory Linear
Algebra, linear mappings are introduced too late, contrary to a well known motto,
according to which “morphisms in a category are at least as useful as the objects
are”. We think that linear mappings and their basic properties should be exposed
in introductory texts right after the vector space axioms are listed and properly
discussed, and consider this Note as a proper example supporting our opinion.
3. A short list of necessary initial notions
Together with the standard general set-theoretic notions related to a mapping
L,
dom L = E, codom L = F, im L = L(E),

ON THE NOTION OF A BASIS OF A FINITE DIMENSIONAL VECTOR SPACE

3

it is useful to have at the disposal from the very beginning specifical linear notions
of a (linear) subspace F ⊂ E and the factor E /F, in particular, the notions of the
kernel ker L and factor E/ker L.
For an adequate definition of the basis and its appropriate discussion, we should
have a certain freedom in handling finite sequences of vectors in E. An arbitrary
sequence of length n of vectors in E is presented as an n-row matrix,
||x1 , . . . , xn || = kxj kn = kxj k, xj ∈ E, j = 1, . . . , n.
Every sequence of vectors could be extended by ascribing to it new vectors from
the space. It is useful to remember that a sequence of length n of vectors in E is
not a subset of E, but rather a function to E on the ordered set of first n naturals,
where imkxj k ⊂ E. If imkxj k is a subset of a subspace F ⊂ E we say that the
sequence kxj k belongs to F and write kxj k ≺ F.
The initial list of basic items should also contain the following notions: linear
combination of vectors of a sequence, linearly independent and dependent sequences
of vectors of E, n - frames — linearly independent sequences of length n, or rank
n,
kej k = kej kn , rank kej kn = n.
We also need the following notions: the rank of an arbitrary sequence,
rank kxj k, kxj k ≺ E, defined as the maximal rank of frames contained (as subsequences) in kxj k, the linear span [kxj k] ⊂ E of an arbitrary sequence of vectors
kxj k ≺ E, linear span of an arbitrary subset A ⊂ E — minimal subspaces in E (with
respect to the set-theoretic inclusion) containing, respectively, subsets imkxj k and
A.
4. The basic lemma. Formulation and a preliminary discussion
A frame kej k ≺ F ⊂ E is maximal in a subspace F if the rank of an arbitrary
sequence kxj k ≺ F is bounded by the rank of kej k,
kxj k ≺ F =⇒ rank kej k ≥ rank kxj k.
A frame kej kn ≺ F could be extended (is extendable) in F, if there exists a vector
f ∈ F such that the extended sequence e1 , . . . , en , f is again a frame (of rank n + 1).
Intuitively, maximality of a frame could be considered as a “generalized version” of
the “individual property” of a frame to be non-extendable. Every maximal frame
in F is evidently not extendable. The inversion of the assertion is also true —
every non-extendable frame in F is maximal in F (Steinitz’s extension theorem),
but the proof is not trivial and in fact belongs right to the core of the problem
under discussion — of giving proper definitions of a basis and dimension of a finite
dimensional vector space.
Now we shall formulate a simple lemma, which easily clears up all interrelations
between the notions of maximality of a frame and its ability “to be extendable”,
and suggests natural intuitive definitions of a basis and dimension.
The Basic Lemma. Every frame kej k ≺ E is maximal in its linear span [kej k]
and extendable in every subspace F ⊃ [kej k], if the inclusion is strong.
The ability of being “extendable” under the given conditions is evident — it is
achieved by ascribing to kej k an arbitrary vector f ∈ F, f ∈
/ [kej k], the maximality
of kej k in the linear span [kej k] is equivalent to each of the following two assertions.

4

ALEXANDER GAMKRELIDZE AND GRIGORI GIORGADZE

1. Every frame kfj kn of rank n in the linear span [kej kn ] is not extendable there,
or, equivalently, the following system of n inclusions is valid,
ei ∈ [kfj kn ], i = 1, . . . , n.

(3)

2. The rank of an arbitrary sequence in E consisting of linear combinations of a
fixed sequence of n vectors from E does not exceed n.
A simple inductive proof of the system of inclusions (3), based on the notion of the
kernel of a linear mapping, is given (as already stated) in the final Section 6. Before,
in next two Sections, we shall derive simple and intuitive definitions of a basis and
dimension of a finite dimensional vector space from the formulated lemma, as well
as give a lucid proof of Steinitz’s theorem on the frame extension.
5. Definition of a basis and dimension of a finite dimensional vector
space
A vector space E is finite dimensional if it contains a finite set of generators —
a finite subset G ⊂ E with the linear span coinciding with E. Since G is finite, it
contains a frame kej kn ≺ G (of maximal rank in G), which spans the whole space
E = [kej kn ], hence, according to the lemma, the frame is maximal in E. Hence
every finite dimensional vector space contains maximal frames — the bases of the
space. Their common rank n is the dimension of the space, and every vector x ∈ E
is uniquely represented as
x=

n
X

λ α eα ,

λj ∈ Λ, j = 1, . . . , n.

1

Thus, every basis of a finite dimensional vector space is an irreducible system of
generators of the space.
Conversely, if a sequence kxj kn in a vector space E is given such that every
vector x ∈ E is uniquely represented as
x=

n
X

λ α xα ,

λj ∈ Λ,

1

then, according to the lemma, kxj kn is a maximal frame of rank n, or a basis in E.
6. The Steinitz’ theorem on the frame extension
In k + l-dimensional vector space Ek+l a basis B = kej kk+l and an arbitrary
k-frame kfj kk are given. From general considerations it easily follows by induction
that B contains a subsequence ei1 , . . . , eir of a certain length r ≤ k + l such that
the frame kfj kk extended by the subsequence is a frame of length k + r,
B 0 = kf1 , . . . , fk ; ei1 , . . . , eir k ≺ Ek+l ,
containing the linear span of B, which is the whole space Ek+l , hence
[B 0 ] = Ek+l .
According to the lemma, the obtained frame B 0 is maximal in Ek+l , i. e. is a basis
of the k + l-dimensional vector space Ek+l , hence r = l, and we have extended the
initial k-frame kfj kk by a subsequence of length r = l of a preassigned basis B to
a new basis B 0 of the space Ek+l .

ON THE NOTION OF A BASIS OF A FINITE DIMENSIONAL VECTOR SPACE

5

7. The basic lemma. Proof
We shall prove the system of inclusions (2) by induction performed on the rank
n of the frame kej kn . The assertion is evident for n = 1 since in this case the linear
span coincides with the family of vectors
[kej k1 ] = {λe1 | λ ∈ Λ} .
Assuming that the assertion is proved for all natural k ≤ n − 1, consider the case
k = n. Introduce n linear mappings


Li ∈ Hom [kej kn ], [kf1 , . . . , fˆi , . . . , fn k] , i = 1, . . . , n,
by defining Li on vectors e1 , . . . , en according to the equations
Li ej = fj , i 6= j, Li ei = 0,

i, j = 1, . . . , n.

The kernel of Li coincides with the subspace

kerLi = {λei λ ∈ Λ},
and the image — with the linear span
im Li = [kf1 , . . . , fˆi , . . . fn k].
The restriction of Li on the subspace [kfj kn ] ⊂ [kej kn ] has a nonzero kernel since
otherwise the n-frame kLi fj k, j = 1, . . . , n would be embedded in the linear span of
an (n − 1)-frame kf1 , . . . , fˆi , . . . , fn k, which contradicts the inductive assumption.
Hence,


λei ∈ kerLi 
∀λ ∈ Λ, i = 1, . . . , n,
[kfj kn ]

or
ei ∈ [kfj kn ] ∀i = 1, . . . , n.
This proves the Lemma.
References
[1] G. Schreier, E. Sperner. Einführung in die Analytische Geometrie und Algebra,
Bd. 1 B.G. Teubner, Leipzig, 1931
[2] Renè Deheuvels. Formes quadratiques et groupes classiques
Presses Universitaires de France, 1981
[3] László Babai and Péter Frankl. Linear Algebra Methods in Combinatorics,
Dept. of Computer Science, The University of Chicago,
Preliminary Version, 1992
[4] Sheldon Axler. Linear Algebra Done Right
Springer Verlag, 2015
Department of Computer Science, I. Javakhishvili Tbilisi State University, Georgia
E-mail address: alexander.gamkrelidze@tsu.ge
Department of Mathematics, I. Javakhishvili Tbilisi State University, Georgia
E-mail address: gia.giorgadze@tsu.ge

