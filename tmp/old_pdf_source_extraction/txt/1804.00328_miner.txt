***

Problem 1.1. Given a hypergraph H ⊆ (cid:0)V
family in(cid:0)[n]
(cid:1).

k

(cid:1), determine the value ex (n,H) of the largest H-free

k

***
Deﬁnition 1.2. A hypergraph is said to be (h, d)-expanded if it has at most h edges and the
intersection of each two of its edges is of size at most d.

***
Deﬁnition 1.3. Let H be a hypergraph. The k-expansion of H is the k-uniform hypergraph H+
obtained from H by enlarging each of its edges with distinct new vertices. We denote by exk (n,H+)

the problem of determining the largest size of a family F ⊆(cid:0)[n]

(cid:1) free of the k-expansion of H.

k

***

Deﬁnition 1.4. A family F ⊆ (cid:0)[n]
A, B ∈(cid:0)[n]

(cid:1) is said to depend on the set of coordinates J if for each sets
(cid:1) that satisfy A ∩ J = B ∩ J we have A ∈ F ⇐⇒ B ∈ F. A family F is said to be a

k

j-junta if it depends on a set J of size at most j. We say that a family F1 is -essentially contained
in F2 if

k

|F1\F2| ≤ 

(cid:18)n

(cid:19)

.

k

***
Theorem 1.5. [Dinur–Friedgut [15]] For each r ∈ N, there exist C > 0, j ∈ N, such that any

(cid:1)r-essentially contained in an intersecting j-junta.

intersecting family F ⊆(cid:0)[n]

(cid:1) is C(cid:0) k

k

n

***
Theorem 1.6. [[43]] For each  > 0, h, d ∈ N, there exist C > 0, j ∈ N, such that the following
C , and let H be a k-uniform (h, d)-expanded hypergraph. Then any H-free family
holds. Let C < k < n

(cid:1) is -essentially contained in an H-free j-junta.

F ⊆(cid:0)[n]

k

n ≤ k ≤ (cid:0) 1

k

***
Theorem 1.7. For each  > 0, d, h ∈ N, there exists j > 0, such that the following holds. Let
-essentially contained in an H-free j-junta.

h − (cid:1) n, and let H be an (h, d)-expanded hypergraph. Then any H-free F ⊆(cid:0)[n]
(cid:1) is

***
Deﬁnition 1.8. Let H be a hypergraph and let v be a vertex of H. The resolution of H at v, denoted
by res (H, v), is the hypergraph obtained from H by taking v out of each edge of H that contains v,
and by replacing it with a new vertex that belongs only to this edge. The resolution of H at a set of
vertices S, denoted by res (H, S), is the hypergraph obtained by resolving H at the vertices of S one
after the other. Any hypergraph of the form res (H, S) will be called a resolution of H.

***
Example 1.9. Any hypergraph H is a resolution of itself since res (H, ∅) = H. Deﬁning the center
of a hypergraph H to be the set of its vertices that belong to at least two of its edges, the k-uniform
h-matching Mh := M +
h is the resolution of any k-uniform hypergraph with h edges at its center.
Another simple example is the hypergraph I2,d: its resolutions are the hypergraphs of the form I2,d(cid:48)
for d(cid:48) ≤ d.

***

Deﬁnition 1.10. Let δ > 0 and let H be a k-uniform hypergraph. We say that a family F ⊆(cid:0)[n]
(cid:1)
is δ-almost H-free if a random copy of H in(cid:0)[n]

(cid:1) lies within F with probability at most δ.

k

k

h − (cid:1) n, and let H be a k-uniform (h, d)-expanded hypergraph, then we have the following.

***
Theorem 1.11. For each h, d ∈ N,  > 0 there exists C, δ > 0 such that the following holds. Let
(1) If the family F is δ-almost H-free, then F is -essentially contained in an Mh-free family.
(2) Conversely, if the family F is δ-essentially contained in an Mh-free family, then F is -almost

C ≤ k ≤(cid:0) 1

H-free.

(cid:110)
A ∈(cid:0) [n]

(cid:1) : 1 ∈ A

(cid:111)

n/3

***
is o (1)-almost free of the hypergraph I2,1, which
Example 1.12. The star
consists of two edges that intersect in a singleton {i}. Indeed, the probability that a random copy of
n, as it is the probability that a random injection from the vertices
this hypergraph lies in the star is 1
of I2,1 to [n] sends the vertex i to 1. As Theorem 1.11 guarantees, the star is o (1)-essentially
contained in an M2-free family as it is in itself M2-free. However, the star is not o (1)-essentially
contained in any family free of the hypergraph I2,1.
More generally, suppose that G is a j-junta depending on a set J and that H is an (h, d)-expanded
hypergraph. Then the center of a random copy of H most likely does not intersect J. So from the
‘point of view’ of the junta G, a random copy of H and a random copy of Mh look the same. It is
therefore easy to see that

Pr [a random copy of H lies in G] = Pr [a random copy of Mh lies in G] + o (1) .

***
Theorem 1.13. For each h, d, s ∈ N,  > 0 there exist δ > 0, j ∈ N, such that the following holds.
Let H be an (h, d)-expanded hypergraph. Let 1
ns -almost H-free
family. Then F is -essentially contained in an (H, s)-free j-junta.

h − (cid:1) n, and let F be a δ

δ ≤ k ≤ (cid:0) 1

holds. Let H be a hypergraph with h edges whose center is of size c. Let C ≤ k ≤(cid:0) 1

***
Proposition 1.14. For each h, c, j, s ∈ N, there exists a constant C > 0, such that the following
J be an (H, s)-free j-junta. Then J is C

ns+1 -almost H-free.

h − (cid:1) n, and let

***
Problem 2.1. Which monotone Boolean functions f : {0, 1}n → {0, 1} exhibit a coarse threshold?

***
Theorem 2.2. [Friedgut–Kalai] For each  > 0 there exists n0 = n0 () such that the following
holds. Let n > n0 and let f : {0, 1}n → {0, 1} be a monotone transitive symmetric function satisfying
 < pc (f ) < 1 − . Then f exhibits an -sharp threshold.

***
Theorem 2.3. [Corollary of Friedgut’s Junta Theorem] For each  > 0, there exists j ∈ N, such
that the following holds. Let f : {0, 1}n → {0, 1} be a Boolean function, and let q, p be numbers in
the interval (0, 1) that satisfy p > q + . Then there exists some r in the interval [q, p] , such that f
is (µr, )-close to a j-junta.

***
Deﬁnition 2.4. Let q < p. The (q, p)-biased distribution, denoted by D (q, p),
probability distribution on elements (x, y) ∈ {0, 1}n × {0, 1}n that satisﬁes the following.

is the unique

(1) The pairs (xi, yi) are independent random variables.
(2) We have xi ≤ yi with probability 1.
(3) We have Pr [xi = 1] = q and Pr [yi = 1] = p.

We write x, y ∼ D (q, p) to denote that they are chosen according to this distribution. We say that
f : {0, 1}n → {0, 1} is (q, p, δ)-almost monotone if

Pr

x,y∼D(q,p)

[f (x) > f (y)] < δ.

***
Theorem 2.5. For each  > 0, there exists j ∈ N, δ > 0, such that the following holds. Let p, q be
numbers in the interval (, 1 − ) that satisfy p−q >  and let f : {0, 1}n → {0, 1} be a (q, p, δ)-almost
monotone function. Then there exists a monotone j-junta g, such that

Pr
x∼µq

[f (x) > g (x)] <  and Pr
x∼µp

[f (x) < g (x)] < .

***
Example 2.6. Fix some numbers q, p in the interval (0, 1) that satisfy q < p. Let fn : {0, 1}n →
{0, 1} be the function deﬁned by

1 x1 = 1, and (cid:80)n
1 x1 = 0, and (cid:80)n

0 Otherwise

i=2 xi > qn
i=2 xi > pn

.

f (x) =

The Central Limit Theorem implies that

µq (f ) =

q
2

+ o (1) and µp (f ) =

(1 + p)

2

+ o (1) .

(cid:16)

(cid:17)

Since both µq (f ) and µp (f ) are bounded away from 0 and 1, we obtain that f has an -coarse
threshold for some constant  independent of n. On the other hand, it is easy to see that f is not
µp, (1−p)
-close to an O (1)-junta and is not (µq, q (1 − q))-close to an O (1)-junta, provided that n
is suﬃciently large. However, if we take g to be the dictator function deﬁned by g (x) = x1, then we
have

4

Pr
x∼µq

[f (x) > g (x)] = o (1) and Pr
x∼µp

[f (x) < g (x)] = o (1) ,

as Theorem 2.5 guarantees.

***
Deﬁnition 2.7. A function f : {0, 1}n → [0, 1] is said to be (r, , µp)-regular if

for each set J ⊆ [n] of size at most r and each y ∈ {0, 1}J.

|µp (fJ→y) − µp (f )| < 

***
Theorem 2.8. For each  > 0, there exists δ > 0, such that the following holds. Let q, p ∈ (, 1 − )
and suppose that p > q + . Let f, g : {0, 1}n → [0, 1]. Suppose that
E(x,y)∼D(q,p) [(1 − g (y)) f (x)] < δ,

(cid:1)-regular. Then either µq (f ) < , or µp (g) > 1 − .

δ

and that the function f is(cid:0)(cid:6) 1

(cid:7) , δ, µq

***
Remark 2.9. While Theorem 2.8 is more general than the Friedgut–Kalai Theorem, we remark that
the Friedgut–Kalai Theorem is better in the quantitative aspects that we have not addressed. We
would also like to remark that the proof of Theorem 2.5 is very diﬀerent than the standard proofs
of Theorems 2.2 and 2.3 . While the traditional proofs are based on the hypercontractivity theorem
of Bonami, Gross, and Beckner [8, 38, 5] and on Russo’s Lemma [55], our proof of Theorem 2.8 is
based instead on the invariance principle of O’Donnell, Mossel, and Oleszkiewicz [50].

***
Deﬁnition 3.1. Let i ∈ [n]. The Fourier character corresponding to the singleton {i} is the function
i ∈ L2 ({0, 1}n , µp) deﬁned by the formula
χp

More generally, let S be a subset of [n]. The Fourier character corresponding to the set S ⊆ [n] is
the function χp

i∈S χp
i .

S :=(cid:81)

−(cid:113) 1−p
(cid:113) p

p
1−p

xi = 1

xi = 0

.

χp

i (x) :=

***
Fact 3.2. Let f ∈ L2 ({0, 1}n , µp) be a function that has the Fourier expansion

Then

f =

ˆf (S) χp
S.

(cid:88)
(cid:88)

S⊆[n]

S⊆[n]\T

AT [f ] =

ˆf (S) χp
S

***
Deﬁnition 3.3. The p-biased ith inﬂuence of a function f : {0, 1}n → R whose Fourier expansion

is(cid:80)

(3.1)

S⊆[n]

ˆf (S) χp

S is deﬁned by setting

i [f ] = E(cid:104)(cid:0)f − A{i} [f ](cid:1)2(cid:105)

Inf p

(cid:88)

S(cid:51)i

=

ˆf (S)2 .

***
Deﬁnition 3.4. Given x ∈ {0, 1}n the (ρ, p)-noisy distribution of x denoted by Nρ,p (x) is a
probability distribution on elements y ∈ {0, 1}n, where we set each coordinate yi independently
to be xi with probability ρ, and to a new p-biased element of {0, 1} with probability 1 − ρ.
The noise operator Tρ,p on the space L2 ({0, 1}n , µp) is the operator that associates to each f ∈
L2 ({0, 1}n , µp) the function

E

y∼Nρ,p(x)

Tρ,p [f ] :=

[f (y)] .

***
Fact 3.5. Let ρ, p ∈ (0, 1), and let

f =

be a function in L2 ({0, 1}n , µp). Then

(cid:88)
(cid:88)

S⊆[n]

ˆf (S) χp
S

ρ|S| ˆf (S) χp
S.

Tρ,p [f ] =

S⊆[n]

Lemma 3.6. Let p > q, and set ρ =
L2 ({0, 1}n , µq). Then Tq→p (f ) has the p-biased Fourier expansion:

S⊆[n]

ˆf (S) χq

S be a function in

S⊆[n] ˆg (S) χp

S is a function in L2 ({0, 1}n , µp), then the function Tp→q (g) has the

***

Similarly, if g =(cid:80)

q-biased Fourier expansion

(cid:113) q(1−p)
p(1−q) . Let f = (cid:80)
(cid:88)
(cid:88)

ρ|S| ˆf (S) χp
S.

S⊆[n]

ρ|S|ˆg (S) χq
S.

Tq→p (f ) =

Tp→q (g) =

S⊆[n]

***
Claim 3.7. Let x, y be elements of {0, 1}n , let p > q ∈ (0, 1) , and let ρ =
(3.4)
and
(3.5)

Ex,y∼D(q,p)| y=y [χq

Ex,y∼D(q,p)| x=x [χp

i (xi)] = ρχp

i (yi) ,

i (yi)] = ρχq

i (xi) .

(cid:113) q(1−p)

p(1−q) . Then

***

Example 3.8. Let f : {0, 1}n → [0, 1] be a transitive symmetric function. Then f is (cid:0)r,(cid:112) r
Fourier regular for any r and p. Indeed, let S ∈(cid:0)[n]

r

n , µp

(cid:1)-
(cid:1), then the fact that f is transitive symmetric
(cid:108) n

r (cid:101), such that ˆf (Si) = ˆf (S) for each i.

(cid:1)-Fourier regular, so it is in fact (r, δ, µp)-Fourier

(cid:109) ˆf (S)2 .

r

ˆf (Si)2 =

n , µp

implies that there exist distinct r-subsets of [n], S1, . . . , S(cid:100) n
By Parseval’s identity, we have

r (cid:101)(cid:88)
After rearranging, we obtain that f is(cid:0)r, 2r(cid:112) r

1 ≥ (cid:107)f(cid:107)2

(cid:100) n

≥

i=1

µp

regular, provided that n > 4r
δ2 .

***
Deﬁnition 3.9. Let δ > 0, ρ, p ∈ [0, 1] . A function f : {0, 1}n → R is said to have (ρ, δ, µp)-small
noisy inﬂuences if Inf (ρ,p)

[f ] < δ for every i ∈ [n] .

i

***
Theorem 3.10. For each  > 0 there exists j ∈ N such that the following holds. Let p ∈ (, 1 − )
and let f ∈ L2 ({0, 1} , µp) be a function. Then there exists a set J of size at most j, such that if
, then the functions fJ→x has (1 − , , µp)-small noisy inﬂuences with

we choose x ∼(cid:16){0, 1}J , µp

(cid:17)

probability at least 1 − .

***
Remark 3.11. Jones [40] proved Theorem 3.10 only for the case where p = 1
2 . However, as in most
of the results in the area, their proof can be extended verbatim to the p-biased distribution, for any
p bounded away from 0 and 1.

***
Theorem 3.12. [ [17, Theorem 1.7]] For each δ,  > 0, there exists j ∈ N, such that the following
holds. Let δ < k
and a family G ⊆ P (J), such that:
(1) We have µ (F \ (cid:104)G(cid:105)) < .
(2) For each B ∈ G the family F B

(cid:1) be a family. Then there exists a set J of size at most j
(cid:7) , δ(cid:1)-regular and µ(cid:0)F B

(cid:1) > 

n < 1 − δ, and let F ⊆(cid:0)[n]
J is(cid:0)(cid:6) 1

k

δ

J

2.

***
Deﬁnition 3.13. Let ρ ∈ (0, 1), and let x ∈ Rn, the ρ-noisy distribution of x is the distribution

Nρ,γ (x), where we choose y by setting each coordinate yi independently to be ρxi +(cid:112)1 − ρ2zi, where

z is a new independent γ-distributed element of R. The noise operator Tρ on the space L2 (Rn, γ) is
the operator that associates to each f ∈ L2 (Rn, γ) the function
[f (y)] .

Tρ [f ] (x) :=

E

y∼Nρ,γ (x)

***
Remark 3.14. The analogy between the distribution Nρ,p, and Nρ,γ stems from the fact if we choose
x ∼ γ, and y ∼ Nρ,γ (x) , then we have the following properties.

• x, y ∼ γ.
• ∀i : E [xiyi] = ρ.
• The R2-valued random variables(xi, yi) are independent of each other.

These properties are similarly satisﬁed when we choose x ∼µp and then choose y ∼ Nρ,p (x) .

***
Theorem 3.15. [Borell 1985] Let f, g ∈ L2 (Rn, γ) be two [0, 1]-valued functions. Then

(cid:2)FE[f ]

(cid:3) , FE[g]

(cid:104)Tρ [f ] , g(cid:105) ≤(cid:10)Tρ

(cid:11) .

***
Lemma 3.16. For each  > 0, there exists δ > 0, such that the following holds. Let µ ∈ (, 1) and
let ρ, ν ∈ (0, 1 − ). Then

Λρ (µ, ν) ≤ µ − δ.

***
Lemma 3.17. [[49, Lemma 2.5]] Let ρ1 < ρ2. Then

|Λρ1 (µ, ν) − Λρ2 (µ, ν)| ≤ 10 (ρ2 − ρ1)
1 − ρ2

.

***

Fact 3.18. Let f =(cid:80)

S⊆[n] ai

(cid:81)

(cid:88)

S⊆[n]

Tρ [f ] =

i∈S zi be a multilinear polynomial. Then

aiρ|S|(cid:89)

i∈S

zi.

***
Deﬁnition 3.19. Let f ∈ L2 ({0, 1}n , µp) be some function with Fourier expansion

We let the Gaussian analogue of it be the multilinear polynomial ˜f ∈ L2 (Rn, γ) deﬁned by

(cid:88)
(cid:88)

S⊆[n]

S⊆[n]

(cid:89)

i∈S

f =

ˆf (S) χp
S.

˜f (z) =

ˆf (S)

zi.

***
Corollary 3.20. [Corollary of the invariance principle] For each , η > 0, there exists δ > 0, such
that the following holds. Let p ∈ (, 1 − ), let f : {0, 1}n → [0, 1] be a function, and suppose that f
is (δ, 1 − η, µp)-smooth. Then

(cid:16) ˜f
(cid:17)(cid:107) < .

(cid:107) ˜f − Chop

***
Proposition 4.1. For each  > 0, there exists δ > 0, such that the following holds. Let ρ ∈ (0, 1 − ) ,
and suppose that p − q > . Let f, g : {0, 1}n → [0, 1] be some functions, and suppose that

(cid:110)

min

Inf (1−δ,q)

i

[f ] , Inf (1−δ,q)

i

(cid:111)

[g]

< δ.

Then
(4.1)

ρ|S| ˆf (S) ˆg (S) < Λρ (µq (f ) , µp (g)) + .

max
i∈[n]

(cid:88)

S⊆[n]

***
Lemma 4.2. For each  > 0, there exists δ > 0 such that the following holds. Let q, p ∈ (, 1 − ),
S be a

S be a (δ, 1 − , µq)-smooth function, and let g = (cid:80) ˆg (S) χp

let ρ ∈ (0, 1) , let f = (cid:80) ˆf (S) χq
(δ, 1 − , µp)-smooth function. Then(cid:88)

ρ|S| ˆf (S) ˆg (S) < Λρ (µq (f ) , µp (g)) + .

S⊆[n]

***
Claim 4.3. Provided that δ is suﬃciently small we have 1 < /2.

***
Claim 4.4. Provided that δ is suﬃciently small, we have 2 < /2.
Choose X ∼ (R, γ) , Y ∼ Nρ (X) . Then Λρ
is the probability of the event X < t1, Y <
t2 for the proper values of t1, t2. Similarly, Λρ
is the probability of the
event X < t3, Y < t4 for the proper values of t3, t4. These events diﬀer either if X is in the interval
whose endpoints are t1, t3 or if Y is in the interval whose endpoints are t2, t4. The Probability of the
former event is
Therefore, a union bound implies that:

(cid:16) ˜f
(cid:17)(cid:105) − E(cid:104) ˜f

(cid:16)E(cid:104) ˜f
(cid:105)
(cid:16)E(cid:104)

(cid:17)
(cid:16) ˜f
(cid:17)(cid:105)

, E [Chop (˜g)]

(cid:12)(cid:12)(cid:12)E(cid:104)

, E [˜g]

Chop

Chop

(cid:17)

(cid:105)(cid:12)(cid:12)(cid:12), and the probability of the latter event is |E [Chop (˜g)]−E [˜g]|.
(cid:12)(cid:12)(cid:12)Λρ
≤(cid:12)(cid:12)(cid:12)E(cid:104)

(cid:16)E(cid:104)
(cid:17) − Λρ
(cid:16)E(cid:104) ˜f
(cid:105)
(cid:16) ˜f
(cid:17)(cid:105)
(cid:105)(cid:12)(cid:12)(cid:12) + |E [Chop (˜g)] − E [˜g]|
(cid:16) ˜f
(cid:17)(cid:105) − E(cid:104) ˜f
(cid:17) − ˜f(cid:107) + (cid:107)Chop (˜g) − ˜g(cid:107) <
(cid:16) ˜f

, E [Chop (˜g)]

(cid:17)(cid:12)(cid:12)(cid:12)

, E [˜g]

Chop

Chop

.

2 =


2

(By Cauchy-Schwarz and (??)) ≤ (cid:107)Chop

***
Lemma 4.5. For each  > 0, there exists δ > 0 such that the following holds. Let q, p ∈ (, 1 − ),

(cid:110)

S be a function and suppose that
[f ] , Inf (1−δ,p)
[g]

Inf (1−δ,q)

max

i

(cid:111)

i

< δ.

let ρ ∈ (0, 1), let f =(cid:80) ˆf (S) χq
(cid:88)

Then

max
i∈[n]

S⊆[n]

ρ|S| ˆf (S) ˆg (S) < Λρ (µq (f ) , µp (g)) + .

***
Theorem. For each  > 0, there exists j ∈ N, δ > 0, such that the following holds. Let p, q be
numbers in the interval (, 1 − ) that satisfy p − q >  and let f : {0, 1}n → {0, 1} be a (q, p, δ)-
almost monotone function. Then there exists a monotone j-junta g, such that

Pr
x∼µq

[f (x) > g (x)] <  and Pr
x∼µp

[f (x) < g (x)] < .

***
Lemma 5.1. For each  > 0, j ∈ N there exists δ > 0, such that the following holds. Let
f, g : {0, 1}n → [0, 1] be functions, let J be a set of size at most j, and let p, q ∈ (, 1 − ), be
with p − q > . Suppose that (cid:104)Tq→pf, 1 − g(cid:105) < δ, and let x, y ∈ {0, 1}J be with ∀i : xi ≤ yi. Suppose
additionally that fJ→x has (1 − , , µq)-small noisy inﬂuences. Then we either have µq (fJ→x) < 
or we have µp (gJ→y) > 1 − .

***
Theorem. For each  > 0, there exists δ > 0, such that the following holds. Let q, p ∈ (, 1 − ) and
suppose that p > q + . Let f, g : {0, 1}n → [0, 1], and suppose that
Ex,y∼D(q,p) [(1 − g (y)) f (x)] < δ,

(cid:1)-regular. Then either µq (f ) < , or µp (g) > 1 − .

δ

and that the function f is(cid:0)(cid:6) 1

(cid:7) , δ, µq

***
Theorem 6.1. For each h ∈ N,  > 0, there exists δ > 0, such that the following holds. Let

k1, . . . , kh ≤ (cid:0) 1
. Suppose that for each i ∈ [n], such that ki ≥ δn the family Fi is (cid:0)(cid:6) 1

(cid:1) be families whose measure is at least
(cid:1), . . . ,Fh ⊆ (cid:0)[n]
s − (cid:1) n, and let F1 ⊆ (cid:0)[n]
(cid:7) , δ(cid:1)-regular, and choose
(cid:18)[n]
(cid:18)[n]
(cid:19)
(cid:19)

uniformly at random a matching {A1, . . . , Ah} , such that
, . . . , Ah ∈

A1 ∈

δ

k1

kh

k1

.

kh

Then

Pr [A1 ∈ F1, . . . , Ah ∈ Fh] > δ.

***

Deﬁnition 6.2. Let F ⊆(cid:0)[n]

(cid:1), we associate to F the function fF deﬁned by

k

(cid:40)

fF (x) =

0
PrA∼(x

k) [A ∈ F]

|x| < k
|x| ≥ k

.

***
Deﬁnition 6.3. Given a function f : {0, 1}n → R, and a δ ∈ R, we deﬁne the function Cutδ (f ) by
setting:

(cid:40)

1
0

Cutδ (f ) (x) =

if f (x) ≥ δ
if f (x) < δ

.

***
Deﬁnition 6.4. Let p ∈ (0, 1) , and let k ∈ [n] .

• We write µ≥k

• We write(cid:0)µ≥k

for the conditional probability distribution on x ∼ ({0, 1}n , µp) given that
given that A∩ J =

p , J → B(cid:1) for the conditional distribution on sets A ∼ µ≥k

are deﬁned accordingly.)

p , µ<k

|x| ≥ k. (The distributions µ>k

p

B. The distributions (µp, J → B) ,

p

p , µ≤k

(cid:16)(cid:0)[n]
(cid:1), J → B

(cid:17)

k

are deﬁned accordingly.

p

***
Deﬁnition 6.5. Choose uniformly and independently [0, 1]-valued random variables X1, . . . , Xn. For

each i ∈ {1, . . . , h} we let Bi be the set of all j ∈ [n] , such that Xj is in the interval(cid:2) j−1
Given a (cid:0) 1

(cid:3). We call
h-biased matching (B1, . . . , Bh) given that |Bi| ≥ k for each i a(cid:0) 1
h , k(cid:1)-biased matching.
h , k(cid:1)-biased matching (B1, . . . , Bh), we obtain that B1 is distributed according to some

the sets (B1, . . . , Bh) a random 1
a random 1

h , j

h

h-biased matching. Let k ≤ n

h we call the conditional distribution on

distribution that we denote by µ

matching
1
h ,k

.

***
Lemma 6.6. For each  > 0, there exists n0 > 0, such that the following holds. Let n > n0, let
q ∈ (0, 1) , k ≤ n satisfy q ≥ k
(6.1)

n + , and let F ⊆(cid:0)[n]

(cid:1) be some family. Then

µq (fF ) ≤ µ (F) ≤ µq (fF ) (1 + ) .

k

***
Lemma 6.7. For each  > 0 there exists n0, such that the following holds. Let n > n0, let k ≤ n

and let q be a number in the interval(cid:0) k

n + , 1(cid:1), and set λ = k

qn . Then

µq ((fF )J→x) (1 − ) ≤

E

C∼(P(x),µλ)

[µ (FJ→C)] ≤ µq ((fF )J→x) (1 + ) .

***

Lemma 6.8. For each  < 0, there exists n0, such that the following holds. Let n > n0, let F ⊆(cid:0)[n]
be a(cid:0)(cid:6) 1

(cid:7) , 2(cid:1)-regular family, and let q ≥ k

(cid:1)-regular.

n + . Then the function fF is(cid:0)(cid:6) 1



(cid:7) , , µq

2

(cid:1)

k

***
Lemma 6.9. For each  > 0, there exists δ > 0 such that the following holds. Let k

(cid:1) be some family. Then the function fF is(cid:0)(cid:6) 1

and let F ⊆(cid:0)[n]

k

(cid:7) , , µq

(cid:1)-regular.



n < δ, let q ≥ ,

***
Lemma 6.10. Let δ > 0, let p > q > k

(cid:1) we have

n. For any F ⊆(cid:0)[n]

k

Ex,y∼D(q,p) [fF (x) (1 − Cutδ (fF ) (y))] ≤ δ.

let F ⊆(cid:0)[n]
family F is(cid:0)(cid:6) 1

k

δ

***
Lemma 6.11. For each  > 0, there exists δ > 0, such that the following holds. Let p ≥ k

(cid:1) be some family whose measure is at least . Suppose that we either have k ≤ δn or the
(cid:7) , δ(cid:1)-regular. Then

n + , and

µp (Cutδ (fF )) > 1 − .

***
Corollary 6.12. For each  > 0, h there exists δ > 0, such that the following holds. Let k

(cid:1) be some family whose measure is at least . Suppose that we either have k ≤ δn or
(cid:7) , δ(cid:1)-regular. Then

and let F ⊆(cid:0)[n]
the family F is(cid:0)(cid:6) 1

n ≤ 1

h − ,

k

δ

µmathching

1
h ,k

(Cutδ (fF )) ≥ 1 − .

1

***
Theorem 7.1. For each c, h ∈ N,  > 0 there exists δ > 0, such that the following holds. Let

h − (cid:1) n be some numbers, and let Ai ∈ (cid:0)[n]
δ ≤ k1, . . . , kh ≤ (cid:0) 1
(cid:1) be sets, such that the hypergraph
H = {A1, . . . , Ah} has center of size at most c. Let F1 ⊆(cid:0)[n]
(cid:1), . . . ,Fh ⊆(cid:0)[n]
(cid:1) be some families of
(cid:7) , δ(cid:1)-regular.
n ≤ δ or the family Fi is(cid:0)(cid:6) 1
(cid:1) of H. Then
(cid:1) × ··· ×(cid:0)[n]
Choose uniformly at random a copy (A1, . . . , Ah) ∈(cid:0)[n]

measure at least . Suppose that for each i, we either have ki

ki

k1

kh

Pr [A1 ∈ F1, . . . , Ah ∈ Fh] > δ.

k1

kh

δ

***
Deﬁnition 7.2. A set J is -fair for F if

(cid:1) ≥ (1 − ) µ (F)

for any B ⊆ J.

µ(cid:0)F B

J

***
Proposition 7.3. For each , s > 0, there exists m > 0 such that the following holds. Let m < k <

(cid:1) be some family of measure at least , and let J ∼(cid:0)[n]

(cid:1). Then

n − m, let F ⊆(cid:0)[n]

k

Pr [J is -fair for F] ≥ 1 − .

s

***
Lemma 8.1. For each h, c, s, j ∈ N,  > 0 there exists δ > 0, such that the following holds. Let H be
a hypergraph with h edges whose center is of size c, and let G ⊆ P (J). Let 1
the following are equivalent.

h − (cid:1) n. Then

(1) The junta (cid:104)G(cid:105) is (H, s)-free.
(2) There exists no copy of a trace of H in G, whose center is of size at most s.

δ ≤ k ≤(cid:0) 1

Lemma 8.2. Let  > 0, s ≤ c, h ∈ N be some constants. Let n ≤ k ≤(cid:0) 1
the probability that Ai ∩ J = Bi for each i is Θ(cid:0)(cid:0) 1

hypergraph whose center is of size c. Let {A1, . . . , Ah} be a uniformly random copy of H, let J ⊆ [n]
 , and let {B1, . . . , Bh} ⊆ P (J) be a trace of H of center of size s. Then
be some set of size at most 1

h − (cid:1) n, let H be a k-uniform

***

(cid:1)s(cid:1) .

n

***
Theorem. For each h, c, , s ∈ N, there exists δ, j > 0, such that the following holds. Let H be a
hypergraph with h edges whose center is of size c. Let

(cid:19)

− 

n,

(cid:18) 1

h

≤ k ≤

1
δ

and let F be a δ

ns -almost H-free family. Then F is -essentially contained in an (H, s)-free j-junta.

holds. Let H be a hypergraph with h edges whose center is of size c. Let n ≤ k ≤ n(cid:0) 1

***
Proposition. For each constants h, c, j, s ∈ N, there exists a constant C > 0, such that the following
J be some (H, s)-free j-junta. Then J is C

ns+1 -almost H-free.

h − (cid:1) , and let

h − (cid:1) n, and let H be a k-uniform (h, d)-expanded hypergraph, then we have the following.
(cid:0) 1

***
Theorem. For each h, d ∈ N,  > 0 there exists C, δ > 0 such that the following holds. Let C ≤ k ≤
(1) If the family F is δ-almost H-free, then F is -essentially contained in an Mh-free family.
(2) Conversely, if the family F is δ-essentially contained in an Mh-free family, then F is -almost

H-free.

