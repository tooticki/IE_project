***
Theorem 1.1. (Main Theorem) Let (F, G) ∈ C[x, y]2 be a Jacobian pair. Then the Keller map
σ is injective. In particular, the 2-dimensional Jacobian conjecture holds, i.e., F, G are generators
of C[x, y].

***
Theorem 1.2.
(i) There exist ξ0 , ξ1 ∈ C such that Vξ0 ,ξ1 = ∅.

(ii) Fix any ξ0 , ξ1 ∈ C satisfying (i). Denote, for (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V ,
dp0 ,p1 = |x0 − ξ0 |2 + |x1 − ξ1 |2 .

(1.9)


Then for any (p0 , p1 ) ∈ V , there exists (q0 , q1 ) = (ẋ0 , ẏ0 ), (ẋ1 , ẏ1 ) ∈ V such that
dq0 ,q1 < dp0 ,p1 .

(1.10)

***

Theorem 1.3. Denote, for (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V ,

	
hp0 ,p1 = max |x1 |, |y1 |, |x0 |, |y0 | ,

(1.11)

and call hp0 ,p1 the height of (p0 , p1 ). There exists s0 ∈ R>0 (depending on m = deg F,
 deg G and
coefficients of F and G ) satisfying the following: For any (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V with
hp0 ,p1 ≥ s0 ,
we must have
In particular if hp0 ,p1

m
m+1

(1.12)
m
m+1

|x0 + y0 | < hp0 ,p1 ,
|x1 + y1 | < hp0 ,p1 .

	
= max |xt |, |yt | (for some t ∈ {0, 1} ), then
m+1
m+2

|a − b| < nt

	
where nt = min |xt |, |yt | .


	
for any a, b ∈ |xt |, |yt |, hp0 ,p1 ,

(1.13)

(1.14)

***
Theorem 1.4. Under the assumption (??), we have the following.
(i) The following subset of V is a nonempty closed bounded subset of C4 for any k0 , k1 ∈ R≥0 ,



	
Ak0 ,k1 = (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V  |x0 | = k0 , |x1 | = k1 .
(1.16)
(ii) The following is a well-defined function on k0 , k1 ∈ R≥0 ,



γ
= max |y1 |  (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ Ak
k0 ,k1

0 ,k1

	
.

(1.17)

(iii) The γ k0 ,k1 is an “almost strictly” increasing function on both variables k0 , k1 ∈ R≥0 in the
following sense,
(a) γ k0 ,k1 > γ k0 ,k1 if k00 > k0 ≥ 0, k1 ≥ 0,
0

(b)

γ k0 ,k10 > γ k0 ,k1

if k0 > 0, k10 > k1 ≥ 0.

(1.18)

***
Theorem 1.5.
(1) There exist κi ∈ R>0 such that the following hold.

(i) Denote by V0 the subset of V such that all its elements (p0 , p1 ) = (x0 , y0 ), (x1 , y1 )
simultaneously satisfy one of (1.19) or (1.20) [cf. (??) ]. Then V0 6= ∅.
(a) κ0 ≤ |x1 | ≤ κ1 |x0 |κ2 + κ3 ≤ κ4 |x1 | + κ5 , (b) `p0 ,p1 :=

|y1 |
≥ κ7 ,
|x1 |κ6

(1.19)

(a) 1 ≤ κ1 |x30 x1 y1 |κ2 ≤ κ3 |x0 x31 y12 | ≤ κ4 |x30 x1 y1 |κ5 ≤ κ6 ,
 |x3 y |κ9

1 1
(b) κ7 ≤ |x1 | ≤ κ8 ,
(c) `p0 ,p1 := |x1 |2
+
κ
≥ κ12 ,
(1.20)
11
|x0 |κ10
where we require
κ4 < 1, κ3 < min{κ0 , κ5 } in case (1.19),
(1.21)
and in any case, κi will be chosen such that there exists θi ∈ R>0 satisfying: when
conditions hold, we have
θ0 ≤ |x0 |, |x1 | ≤ θ1 , and |y1 | ≥ θ0 .
(1.22)
(ii) For any (p0 , p1 ) ∈ V0 , at most only one equality can hold in (1.19) (a) or (1.20) (a);
furthermore, none of the first or last equality of (1.20) (a) or any equalities of
(1.20) (b) can occur.

(2) For any (p0 , p1 ) ∈ V0 , there exists (q0 , q1 ) = (ẋ0 , ẏ0 ), (ẋ1 , ẏ1 ) ∈ V0 such that
`q0 ,q1 > `p0 ,p1 .

(1.23)

***
Remark 1.6.
(1) We wish to mention that Theorem 1.5 is the most important and difficult
part of the paper. Throughout the paper we will frequently use the local bijectivity of
Keller maps. Theorem 1.5 (2) says that [assume for example, we have case (1.19) ]
(a) κ0 ≤ |ẋ1 | ≤ κ1 |ẋ0 |κ2 + κ3 ≤ κ4 |ẋ1 | + κ5 ,

(b)

|y1 |
|ẏ1 |
>
,
κ
|ẋ1 | 6
|x1 |κ6

(1.24)

(c) σ(q0 ) = σ(q1 ),
(d) q0 6= q1 .
(1.25)
If we regard ẋ0 , ẏ0 , ẋ1 , ẏ1 as 4 free variables, then the local bijectivity always allows us to
obtain (1.24) (c), which imposes two restrictions on 4 variables. We can impose at most
two more “nontrivial” restrictions on them [we regard (1.24) (d) as a trivial restriction, see
below]. The main difficulty for us is how to impose two more “solvable” restrictions on
variables [see (3) below] to control ẋ0 , ẏ0 , ẋ1 , ẏ1 in order to achieve our goal of “deriving a
contradiction”. However, it seems to us that two more restrictions are always insufficient
to achieve the goal. Here, condition (1.24) (b) imposes one more restriction, and we have
one free variable left. However there are 3 restrictions in (1.24) (a), thus in general there
will be no solutions. Thanks to Theorem 1.5 (1) (ii) [see (2) below], we only need to take
care of one restriction in (1.24) (a) each time [cf. (??) ] since we are always under a “local”
situation (i.e., we are only concerned with a small neighborhood of some points each time),
and thus the inequation in (1.24) (a) is solvable [we do not need to consider condition
(1.24) (d) under the “local” situation, we only need to take care of it when we take some
kind of “limit”, cf. (??) ].
(2) Condition (1.24) (b) is not only used to control |ẋ1 | and |ẏ1 |, but also used to take the
“limit”; while (1.24) (a) is used to control |ẋ0 | and |ẋ1 |. We remark that the requirement
“ κ3 < κ5 ” in (1.19) (a) or respectively κ11 > 0 in (1.20) (c) will guarantee the correspondent
inequation
κ1 |ẋ0 |κ2 + κ3 ≤ κ4 |ẋ1 | + κ5 , or respectively,
 |ẋ3 ẏ |κ9

 3 κ9

2 |x1 y1 |
1 1
|ẋ1 |2
+
κ
>
|x
|
+
κ
,
(1.26)
11
1
11
|ẋ0 |κ10
|x0 |κ10
is solvable [see (3) below, Remark 6.2 and (??) ]. Finally we would like to mention that
to find conditions like the ones in (1.19) or (1.20) satisfying Theorem 1.5 (1) (ii) has been
extremely difficult for us, we achieve this by using Theorem 1.4 to prove several technical
lemmas (cf. Assumption 5.1 and Lemmas 5.2 –5.13 ).
(3) One may expect to have some statements such as one of the following:
(i) For any (p0 , p1 ) ∈ V with |x0 |θ0 + |x1 |θ1 ≤ s (for some θi , s ∈ R>0 ), there exists
(q0 , q1 ) ∈ V such that
(a) |ẋ0 |θ0 + |ẋ1 |θ1 ≤ s,
(ii) For any (p0 , p1 ) ∈ V with |x1

|θ1

≤ |y1

(b) |ẏ1 |θ2 > |y1 |θ2 .
|θ2

(1.27)

+ s, there exists (q0 , q1 ) ∈ V such that

(a) |ẋ1 |θ1 ≤ |ẏ1 |θ2 + s,
(b) |ẏ0 |θ3 − |ẋ0 |θ4 > |y0 |θ3 − |x0 |θ4 .
(1.28)
If a statement such as one of the above could be obtained, then a proof of Theorem 1.1
would be easier. At a first sight, the condition (1.27) (a) [or (1.10) ] only imposes one
restriction on variables, however it in fact contains 2 hidden restrictions [see arguments
after (??) ] simply because the left-hand side of “ < ” has 2 positive terms with absolute
values containing variables. The second condition in (1.28) is unsolvable as will be explained
in Remark 6.2 . We would also like to point out that to obtain Theorem 1.1 , we always
need to take some kind of “limit” [cf. (??) ] to derive a contradiction. Thus some condition
such as (1.10), (1.24) (b), (1.27) (b) or (1.28) (b) is necessary in order to take the “limit”.

***
Convention 2.1. √ (1) A complex number is written as a = are + aim i for some are , aim ∈ R,
where i = −1. If ab appears in an expression, then we assume b ∈ R, and in case a 6= 0,
we interpret ab as the unique complex number rb ebθi by writing a = reθi for some r ∈ R>0 ,
−π < θ ≤Pπ and e is the natural number.
(2) Let P = i∈Z≥0 pi y α+i ∈ C(x)((y)) with α ∈ Z, pi ∈ C(x).
(i) Assume p0 = 1. For any β ∈ Q with αβ ∈ Z, we always interpret P β as
 

j 
∞
P
P
β
β
αβ
P =y
1+
pi y i
∈ C(x)((y)),
(2.1)
j=1 j
i∈Z>0

1 +λ2 +···+λi )+1)
.
where in general, λ1 ,λ2k,...,λi is the multi-nomial coefficient k(k−1)···(k−(λ
λ1 !λ2 !···λi !
Then
0
0
(P β )β = P ββ for any β, β 0 ∈ Q with αβ, αββ 0 ∈ Z.
(2.2)
If p0 6= 1, then pβ0 is in general a multi-valued function, and if we fix a choice of pβ0 ,
then (2.2) only holds when β 0 ∈ Z [fortunately we will only encounter this situation,
cf. (??) and statements after it].
(ii) For Q1 , Q2 ∈ C(x)((y)), we use the following notation [as long as it is algebraically a
well-defined element in C(x)((y)) ]
P
P (Q1 , Q2 ) = P |(x,y)=(Q1 ,Q2 ) = pi (Q1 )Qα+i
(2.3)
2 .
i

(iii) If Q1 , Q2 ∈ C with Q2 6= 0, we also use (2.3) to denote a well-defined complex number
as long asPpi (Q1 ) exists for all posible i and the series (2.3) converges absolutely.
(iv) For Q = i∈Z≥0 qi y β+i ∈ C(x)((y)), by comparing coefficients of y β+i for i ≥ 0, there
exists uniquely bi ∈ C(x) such that
∞
P
β+i
(2.4)
Q=
bi P α .
i=0
β+i
α

β+i

We call bi the coefficient of P
in Q, and denote by Coeff (Q, P α ). If Q =
P
i
j
i j
i,j qij x y with qij ∈ C, we also denote Coeff (Q, x y ) = qij .
(3) Throughout the paper, we need two independent parameters k  1 (i.e., k → ∞) and
E → 0. We use the following convention: Symbols s, s j for j ≥ 0 always denote some
(sufficiently large) numbers independent of E , k . We use O(E i ) for i ∈ Q≥0 to denote any
element P in C(x)((y)) (or especially in C) such that P (ẋ, ẏ) converges absolutely and
|E −i P (ẋ, ẏ)| < s for some fixed s, where (ẋ, ẏ) is in some required region which will be
specified in the context.

***
Definition 2.2.
exists and

(1) Let P be as above and Q =

P

i qi y

i

∈ C((y)), qi ∈ R≥0 , x0 ∈ C. If pi (x0 )

|pi (x0 )| ≤ qi for all possible i,
then we say Q is a controlling function for P on y at point x0 , and denote
P Exy 0 Q or Q Dxy 0 P ,

(2.5)
(2.6)

or P Ey Q or Q Dy P when there is no confusion. In particular if P, Q do not depend on
y then we write P Ex0 Q or Q Dx0 P (thus a E b for a, b ∈ C simply means |a| ≤ b).
(2) An element in C((y)) with non-negative coefficients (such as Q above) is called a controlling
function on y. P
(3) If Q = q0 y α + j>0 qj y α+j ∈ C((y)) is a controlling function on y with qi ∈ R≥0 and
q0 > 0, then we always use the same symbol with subscripts “ igo ” and “ neg ” to denote
the elements


P
P
Qigo = q0−1
qj y j , Qneg = q0 y α 1 − q0−1
qj y j = q0 y α (1 − Qigo ).
(2.7)
j>0

j>0

We call Qigo the ignored part of Q, and Qneg the negative correspondence of Q [in sense of
(2.9) and (2.10), where a, −k are nonpositive].

***
Lemma 2.3.

(1) If
P = p0 y α +

P

pj y α+j ∈ C(x)((y)),

Q = q0 y α +

j>0

P

qj y α+j ∈ C((y)),

(2.8)

j>0

with P Exy 0 Q, x0 ∈ C and |p0 (x0 )| = q0 ∈ R>0 , then
dQ
∂P
Exy 0 ±
,
∂y
dy

(b) P a Exy 0 Qaneg Ey (q0 y α )−b Qa+b
neg for a, b ∈ Q− ,

(2.9)

Qk Ey (q0 y α )2k Q−k
neg Ey


(q0 y α )k



if k ∈ Z≥1 ,
 1 − kQ
igo



 (q y α )k 1 + kQigo

if k ∈ Q≥0 with k < 1.
 0
1 − Qigo

(2.10)

(a)

where (2.9) (a) holds under the condition: either both P and Q are power series of y (in
this case the sign is “ + ”), or else both are polynomials on y −1 (in this case the sign is
“ − ”).
(2) If x0 , y0 ∈ C with y0 6= 0, and P1 Exy 0 Q1 , P2 Exy 0 Q2 , then
A(x0 ,y0 ) (P1 P2 ) ≤ A(y0 ) (Q1 )A(y0 ) (Q2 ) = Q1 (|y0 |)Q2 (|y0 |).

(2.11)

***
Lemma 2.4. Let (with âi ∈ R≥0 , â1 > 0 ),
∞
∞
P
P
F̂ = â1 y +
âi y i ∈ C[[y]] and F̂ neg = â1 y −
âi y i ,
i=2

(2.15)

i=2

be a controlling function on y and its negative correspendence [cf. (2.7) ], and let
∞
P
i
y = ŷneg (F̂ neg ) = b̂1 F̂ neg +
b̂i F̂ neg ,

(2.16)

i=2
i

be the formal inverse function of F̂ neg , where b̂1 = â−1
1 and b̂i = Coeff (y, F̂ neg ) ∈ C. Then
(1) ŷneg (F̂ neg ) is a controlling function on F̂ neg , i.e.,
i

b̂i = Coeff (y, F̂ neg ) ≥ 0 for i ≥ 1.

(2.17)

(2) If F̃ Exy 0 F̂ with F̃ as in (??) and f˜i (x0 ) exists for all possible i and |f˜1 (x0 )| = â1 , then
y = yF̃ (F̃ ) ExF̃0 ŷneg (F̃ ), i.e.,
bi Ex0 b̂i ,

(2.18)

where bi = Coeff (y, F̃ i ) is as in (??), and bi Ex0 b̂i means that |bi (x0 )| ≤ b̂i . In particular
y Ey ŷneg (F̂ ),

(2.19)

where the right side of “ Ey ” is regarded as a function of y by substituting F̂ by (2.15).

***
Remark 3.1. Before continuing, we would like to remark that our idea is to take some variable
change [cf. (??) ] to send the leading part FL of F to a “leading term” [cf. (??) ], which has the
highest absolute value when (x, y) is set to p0i or p1i [cf. (??) ] so that when we expand it as a
power series of y, it converges absolutely [cf. (??) ], and further, the inverse function converges
absolutely (cf. Lemma 3.3 ). Then we can derive a contradiction [cf. (??) ].

***
Lemma 3.2. There exists some δ > 0 independent of E such that
|u1 (a)| > δ for 0 ≤ a ≤ 1 (when i  1).

(3.15)

***
Lemma 3.3.

(1) The series in (??) converges absolutely when setting (x, P ) to (a, P0 ), and
Y0 (a) := y|(x,P )=(a,P0 ) = u1 (a) + O(E 1 ).

∂ F̂ −1

(2) Regarding ∂y
Furthermore,

(3.29)

as a series of P , it converges absolutely when setting (x, P ) to (a, P0 ).

 ∂ F̂ −1 

= −m−1 u1 (a) + O(E 1 ).

∂y
(x,P )=(a,P0 )
(3) The series in (??) converges absolutely when setting (x, P ) to (a, P0 ).

(3.30)

***
Remark 3.4. By (??),
F̂ = the leading term + O(E 1 ),
(3.37)
1
±1
where O(E ) is a finite combination of powers of y . In this case, we can in fact easily choose a
simpler controlling function P̂ for P [cf. (??) ]:
P̂ = |u1 (a)|−1 y

∞
P
i=0

E δ1 i y i

=

|u1 (a)|−1 y
,
1 − E δ1 y

where δ1 ∈ R>0 is some fixed sufficiently small number. Then

 |u(a)|−1 y(1 − 2E δ1 y)
E δ1 y
P̂ neg = |u(a)|−1 y 1 −
=
,
1 − E δ1 y
1 − E δ1 y

(3.38)

(3.39)

and we can explicitly write down the inverse function of P̂ neg by solving y from (3.39) to obtain
yneg (P̂ neg ) [which, by Lemma 2.4 (1), must be a controlling function on P̂ neg (although it is not
obvious to see)]
1 + E δ1 |u(a)|P̂ neg − A
, where
4E δ 1

1
2
2
A = 1 − 6E δ1 |u(a)|P̂ neg + E 2δ1 |u(a)|2 P̂ neg .
yneg (P̂ neg ) =

(3.40)

From this, one easily sees that the right-hand side of (??) converges when P is set to |P0 |, i.e.,
(3.40) converges when P̂ neg is set to |P0 | [if we expand A as a power series of P̂ neg , it converges
absolutely when P̂ neg is set to |P0 | simply because there appear the factors E δ1 and E 2δ1 ]. Thus
the proof of Lemma 3.3 (1) is easier (we have used the above proof as it can be adapted in some
more general situation).

***
Remark 4.1. When we consider the local bijectivity of Keller maps, we always assume u, v ∈ C
are bounded by some fixed s ∈ R>0 (which is independent of E , and we can assume E as small as
s
we wish, for instance E < s −s ).

***
Remark 4.2. Before continuing, we remark that the proof of (1.18) (a) is easier: in that case
condition (??) (I) should be replaced by the condition |x̃1 + uE | = |x̃1 |, which can be easily satisfied
even in case k1 = 0 (i.e., x̃1 = 0). Thus (1.18) (a) holds.

***
Assumption 5.1. Assume Theorem 1.5 (1) is not true.

***
Lemma 5.2. For any δ, k, k0 , k1 ∈ R>0 with k > 1, δ <

1
m,

we have γ k1+δ k0 ,kk1 < kγ k0 ,k1 .

***
Remark 5.3. Note that when we design the system (??), k is simply some fixed positive real
number. When we say k  1, it means that we may need to choose sufficiently large k such that
the system (??) can satisfy our requirement. This will also apply to some similar situations later.

***
Lemma 5.4. For any k0 , k1 ∈ R>0 , we have γ k0 ,k1 > k1 .

***
Lemma 5.5. We have ak > 0, bk > 0.

***
Lemma 5.6. For any fixed δ ∈ R>0 , we have k < γ k,k < (1 + δ 4 )k.

***
Lemma 5.7. For any fixed δ ∈ R>0 with δ <

1
m,

we have bk ≥ 1 + δ + ak for all k > 0.

***
Remark 5.8. Recall from statements inside the bracket before (??) and Remark 4.1 that when
k is fixed, E can be fixed, and we can assume E < k −k . We here emphasis that the E used in the
above design of the system of inequations in (??) is exactly the same as that used in the local
bijectivity of Keller maps in (??). There is no any problem in doing this since our design does not
need to use the local bijectivity of Keller maps, we only use the local bijectivity of Keller maps to
show that the set V0 is nonempty [in the sense of defining the system (??), `, k , E are simply some
chosen positive real numbers, cf. Remark 5.3 ].

***
Lemma 5.9. For any fixed δ ∈ R>0 , we have (1 − δ 5 )bk ≤ 1 + ak for all k  1.

***
Remark 5.10.
(i) We wish to emphasis that the following design (??) has been the hardest
part for us to obtain [from the proof below we will see why we have to design such a
complicated system of inequations in (??) ].
(ii) From our proof above, one can see that in order to achieve our task, we must choose the
power (denoted as α0 ) of |x1 | in (??) (b), (??) (ii) and (??) (ii) to be different from one,
and in case α0 < 1 we must choose α0 to be independent of k as in (??) (ii), and therefore
we have to choose v to be different from u [as in (??) and (??) ] so that (??) (ii) and
(??) (ii) can hold. However because of (??), our task becomes extremely difficult, simply
because of the fact that any choice of v 6= u (and in case α0 < 1, v, u must be negative),
with v to be differ from u by a number which is independent of k , will possibly force
s = −ak u + bk v + O(E 1 ) to be too large [by (??) ]; thus we have to try in some other way
as shown below.
(iii) We wish to mention that in C5 of (??) (iii), we add the term E 4 in order for the technical
reason that the inequation corresponding to (1.23) is solvable [cf. (??) (i) ].

***
Remark 5.11. We emphasis once again (cf. Remarks 5.3 and 5.8 ) that there is no problem to
use the k , E in our design of the system (??). In the sense of defining the system (??), k , E are
only some chosen numbers (however in order for the system to satisfy our requirement, we may
need to choose these numbers to satisfy the condition E −1  k  1 ).

***
Lemma 5.12. When conditions (??) hold we have the following [in particular we have (1.22) ].
(a) E ≤ |X1 | ≤ E −1 , (b) E ≤ |X0 | ≤ E −1 , (c) (1−δ 5 )|X1 | ≤ |Y1 | ≤ (1+δ 5 )|X1 |.

(5.28)

***
Lemma 5.13. Theorem 1.5 (1) holds.

***
Remark 6.1. We remark that the E here shall be regarded to be different from that in the
previous results, here E may be much smaller than the previous E . If we denote the previous E as
E

−1

whenever necessary we can assume our new E satisfies that E < k −k , `−` , E 11 , where k , ` are
as before (cf. Remark 4.1 ).
E 1,

***
Remark 6.2. (cf. Remark 1.6 ) Assume that we have the following inequation on variable u,
where α1 , α2 , β1 , β2 ∈ R>0 , and a1 , a2 , a3 ∈ C are some unknown complex numbers:
α1 |1 + a1 uE + a2 u2 E 2 + a3 E 2 |β1 < α2 |1 + uE |β2 + α1 − α2 + O(E 3 ).

(6.20)

Then from the proof of (??), one can see that this inequation is solvable for any unknown
a1 , a2 , a3 ∈ C if and only if α1 > α2 [the reason that (??) (i) is solvable is that we have designed
(??) (i) to be compatible with (??) (ii) ].

