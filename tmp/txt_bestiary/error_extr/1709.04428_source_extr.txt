BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Let $u_1,u_2, \cdots , u_n$ be an ordering of the vertices of the digraph and let $\mathbb {A}$ correspond to this ordering. Pick any $u_i$. Then we have \[ \sum _{j=1}^{n} \mathbb {A}_{ij} \chi (u_j)= \sum _{u_{i} \rightarrow u_{j}} \chi (u_{j})=\sum _{s \in S} \chi (u_{i}+s)= \sum _{s \in S} \chi (u_{i})\chi (s)=\left [\sum _{s \in S} \chi (s)\right ]\chi (u_{i}).\] Thus \[ \mathbb {A} \chi = \left [\sum _{s \in S} \chi (s)\right ] \chi .\]
END Proof
 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Let $u_1,u_2, \cdots , u_n$ be an ordering of the vertices of $Cay(H,S)$ and let $\mathbb {A}$ be the adjacency matrix corresponding to this ordering. By Theorem~\ref {character theory} each $\chi _i$ gives us an eigenvector for $\mathbb {A}$ with an eigenvalue $\sum _{s \in S} \chi _{i}(s) $. We can normalize $\chi _i$ for each $i \in \{1,2, \cdots , n \}$ and get $v_i$'s so that $v_1, \cdots , v_n$ is an orthonormal basis for $\mathbb {C}^n$. Therefore, any complex $n$-dimensional vector $v$ can be written as $v= \sum ^n_{j=1} \langle v,v_j\rangle v_j$ where $\langle -,-\rangle $ denotes the Hermitian inner product in $\mathbb {C}^n$. Notice \begin {equation} \label {Planch} \langle v,v \rangle = \left \langle \sum ^n_{j=1} \langle v, v_j \rangle v_j , v \right \rangle =\sum ^n_{j=1} \langle v, v_j \rangle \langle v_j , v \rangle =\sum _{j=1}^{n} \|\langle v,v_j\rangle \|^2 \end {equation} which is also known as the Plancherel identity. \par Define $\boldsymbol {1_{X}}$ as the $0$-$1$ column vector whose $i^{\text {\tiny th}}$ entry is $1$ when $u_{i} \in X$ and $0$ otherwise. Define $\boldsymbol {1_{Y}}$ similarly. If we calculate \[\mathbb {A}\boldsymbol {1_{Y}}=\begin {bmatrix} a_1\\ a_2\\ \vdots \\a_n \end {bmatrix}\] then each $a_i$ denotes the number of directed edges from $u_{i}$ to the vertices of $Y$. If we multiply both sides of the equation with $\boldsymbol {1^T_{X}}$ from the left, we get \[\boldsymbol {1^T_{X}} \mathbb {A} \boldsymbol {1_{Y}}= \boldsymbol {1^T_{X}} \begin {bmatrix} a_1\\ a_2\\ \vdots \\a_n \end {bmatrix}= \sum _{u_i \in X} a_{i}\] which is indeed exactly the number of edges from the vertices of $X$ to the vertices of $Y$. This calculation shows that as long as $\boldsymbol {1^T_{X}} \mathbb {A} \boldsymbol {1_{Y}} > 0$ there will be a directed edge from a vertex in $X$ to a vertex in $Y$. \par On the other hand we also have \begin {align} \boldsymbol {1^T_{X}} \mathbb {A} \boldsymbol {1_{Y}}&= \langle \boldsymbol {1_{X}},\mathbb {A} \boldsymbol {1_{Y}} \rangle = \left \langle \boldsymbol {1_{X}}, \mathbb {A} \left ( \sum _{j=1}^n \langle \boldsymbol {1_{Y}}, v_{j} \rangle v_{j} \right ) \right \rangle = \left \langle \boldsymbol {1_{X}}, \left ( \sum _{j=1}^n \langle \boldsymbol {1_{Y}}, v_j \rangle \lambda _{j} v_{j} \right ) \right \rangle \nonumber \\ &=\sum _{j=1}^n \left \langle \boldsymbol {1_{X}}, \langle \boldsymbol {1_{Y}}, v_{j} \rangle \lambda _{j} v_{j} \right \rangle = \sum _{j=1}^n \langle \boldsymbol {1_{X}},\lambda _{j} v_j \rangle \overline {\langle \boldsymbol {1_{Y}}, v_{j} \rangle } =\sum _{j=1}^n \overline {\lambda _{j}} \langle \boldsymbol {1_{X}}, v_{j} \rangle \langle v_{j}, \boldsymbol {1_{Y}} \rangle \label {eqn1} \end {align} \par By Theorem~\ref {character theory} we know one of the eigenvalues of $Cay(H,S)$ is $\lambda _1=|S|$ with eigenvector $v_1= \frac {1}{\sqrt {n}}\boldsymbol {1}$ and by substitution in \eqref {eqn1} we get \[\boldsymbol {1^T_{X}} \mathbb {A} \boldsymbol {1_{Y}} = \frac {|X||Y||S|}{n} + \sum _{j=2}^n \overline {\lambda _{j}} \langle \boldsymbol {1_{X}}, v_j \rangle \langle v_{j} , \boldsymbol {1_{Y}} \rangle .\] Let \[E = \sum _{j=2}^n \overline {\lambda _j} \langle v_j , \boldsymbol {1_{Y}} \rangle \langle \boldsymbol {1_{X}}, v_j \rangle .\] We will show if $\sqrt {|X||Y|} > n_{\ast }$ then $\dfrac {|X||Y||S|}{n} > |E|$, and the result will follow. \par By the Cauchy-Schwarz inequality we have \[ |E| \leqslant ( \max _{2 \leqslant j \leqslant n} \| \lambda _j \| ) \left (\sum _{j=1}^n \| \langle \boldsymbol {1_{Y}} ,v_j \rangle \|^2 \right )^{1/2} \left (\sum _{j=1}^n \| \langle \boldsymbol {1_{X}} ,v_j \rangle \|^2 \right )^{1/2} \] \par Moreover by Plancherel's equality we have \[ \lvert E \rvert \leqslant \left ( \max _{2 \leqslant j \leqslant n} \| \lambda _j \| \right ) \sqrt {\lvert X \rvert \lvert Y \rvert }.\] Hence, the result follows as long as \[ \frac {|S| \lvert X \rvert \lvert Y\rvert }{n} > \left ( \max _{2 \leqslant j \leqslant n} \| \lambda _j \| \right ) \sqrt {\lvert X \rvert \lvert Y \rvert } \] holds. The only thing left to point out is that in the statement of the theorem we substituted $\lambda _j$'s using Theorem~\ref {character theory}.
END Proof
 
BEGIN Corollary \protect \let \reserved@d = *\def \par 
BEGIN Corollary \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Corollary \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Since $R$ is finite, the following chain has to stop for some $l \in \mathbb {Z}_{+}$ \[J \supseteq J^2 \supseteq J^3 \supseteq \cdots \supseteq J^l =J^{l+1} = J^{l+2} = \cdots .\] If $J^l=0$, we are done. Otherwise, let $I_{1}=J$, $I_{2}= J^{l}$ and apply Nakayama's lemma.
END Proof
 
BEGIN Lemma \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 If $a+J$ is a left unit in $\bigslant {R}{J}$, then there exists some $u \in R$ such that $(u+J)(a+J)=1+J$. That means there exists some $u \in R$ and $j \in J$ such that $ua=1+j$. This implies that there exists some $y \in R$ such that $yua=1$, which says $yu$ is a left inverse of $a$.\\ Also notice that $(yu+J^i)(a+J^i):=yua+J^i=1+J^i$ which means $a+J^i$ is a left unit in $\bigslant {R}{J^i}$.
END Proof
 
BEGIN Lemma \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Let $p(x)=\sum a_{n}x^{n}$. Then, \[ p(x+y)=\sum a_{n}(x+y)^{n}=\sum a_{n}(x^n+nx^{n-1}y+y^2(\cdots ))=\sum a_{n}x^n+y\sum na_{n}x^{n-1}+y^2p_2(x,y).\]
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Notice that the existence of $\dfrac {1}{p'(a_0)}$ follows from Lemma~\ref {Small Fact} and from the assumptions. Suppose we have a root of $p(x)$ in $\bigslant {R}{J^2}$, let's denote it with $r+J^2$. If we send $r+J^2$ using the canonical reduction map from $\bigslant {R}{J^2}$ to $\bigslant {R}{J}$, the image of $r+J^2$ should also be a root i.e. \[p(r+J^2) \equiv 0 \pmod {J^2} \ \ \implies \ \ p(r+J) \equiv 0 \pmod {J}. \] If $r+J^2$ is a lift of $a_0+J$ then we should have $r+J=a_0+J$ in $\bigslant {R}{J}$ i.e. $r=a_0+j$ for some $j \in J$. By Lemma~\ref {Taylor}, we have \[ p(r)= p(a_0+j)=p(a_0) +p'(a_0) j + j^2 b \] for some $b \in R$. We need $p(a_0+j) \equiv 0 \pmod {J^2}$ that means we need \[p(a_0)+p'(a_0).j \equiv 0 \pmod {J^2}. \] So, if we let $j=-\dfrac {p(a_0)}{p'(a_0)}$ from the beginning, everything works out in these equations and the claims follow.
END Proof
 
BEGIN Corollary \protect \let \reserved@d = *\def \par 
BEGIN Corollary \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Let $p(x)= x^k+B_2^k + \cdots + B_m^k-\alpha $ and apply the previous corollary.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 By setting $Q(g+f^{n}t) \equiv 0 \pmod {f^{n+m}}$, we can solve for $t$. By applying Lemma~\ref {Taylor} on $Q$ we know that \begin {align*} Q(g+f^{n}t) &= Q(g)+f^{n}t Q'(g)+(f^{n}t)^2 \tilde {Q}(g,f^nt) \ \ \ \ \ \text { for some polynomial } \tilde {Q} \\ &\equiv Q(g)+f^{n}t Q'(g) \pmod {f^{n+m}} \ \ \ \ \ \text {since } n \geqslant m. \end {align*} By assumption $Q(g) \equiv 0 \pmod {f^n}$ i.e. $Q(g)= f^nh$ for some $h \in \Bbb F_q[x]$. So, we should have \begin {align*}Q(g+f^{n}t) &\equiv f^nh+f^ntQ'(g) \pmod {f^{n+m}} \\ &\equiv f^n(h+tQ'(g)) \pmod {f^{n+m}}. \end {align*} Moreover, \begin {align*} Q(g+f^{n}t) \equiv 0 \pmod {f^{n+m}} &\iff f^n(h+tQ'(g))=f^{n+m}v \ \ \ \ \text { for some } v \in \Bbb F_q[x]\\ &\iff f^n(h+tQ'(g)-f^{m}v)=0 \ \ \ \ \text { for some } v \in \Bbb F_q[x]. \end {align*} To have this, since $\Bbb F_q[x]$ is an integral domain, we need $h+tQ'(g)-f^{m}v$ to be zero, that means we need $h+tQ'(g)=f^{m}v$ which is the same with $t \equiv \dfrac {-h}{Q'(g)} \pmod {f^{m}}$. So, if we define $g_{2}=g-f^n \dfrac {h}{Q'(g)}=g- \dfrac {Q(g)}{Q'(g)}$ from the beginning, we are all set. \par The only point we did not justify here is why $Q'(g)^{-1}$ makes sense in $\bmod {f^m}$. Remember $Q'(g) \in \Bbb F_q[x]$. $\Bbb F_q[x]$ is a PID, that means we have B\'ezout's identity in $\Bbb F_q[x]$. By assumption we have $Q'(g) \not \equiv 0 \pmod {f}$, which means $f$ doesn't divide $Q'(g)$. Since $f$ is irreducible, the only divisors of $f$ are $1$ and itself. So, $\gcd (Q'(g),f)=1$ and this implies $\gcd (Q'(g),f^m)=1$. By B\'ezout, we have $AQ'(g)+Bf^m=1$ for some $A,B \in \Bbb F_q[x]$ which shows $Q'(g)^{-1}$ exits in $\bmod {f^m}$ for any $m \geqslant 1$.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Since $Q(g) \equiv 0 \pmod {f^n}$, there exists an $h_1 \in \Bbb F_q[x]$ such that $Q(g)=f^{n} h_1$. Similarly since $\nu (Q'(g))=m$, there exists an $h_2 \in \Bbb F_q[x] $ such that $Q'(g)=f^{m}h_2$ and $h_2 \not \equiv 0 \pmod {f}$, which implies $h_2$ is a unit in $\bmod {f^i}$ for any $i$. \par To prove \eqref {item1} by applying Lemma~\ref {Taylor} on $Q$ we have \begin {align*} Q(g_2) &= Q\left (g-\frac {Q(g)}{Q'(g)}\right ) \\ &= Q(g)+\left [\frac {-Q(g)}{Q'(g)}\right ]Q'(g)+\left [\frac {Q(g)}{Q'(g)}\right ]^2 \hat {Q}(\cdots ) \ \ \ \ \ \text { for some polynomial } \hat {Q} \\ &= (f^{n-m} h_1h_2^{-1})^2 \ \hat {Q}(\cdots ) \\ &\equiv 0 \pmod {f^{n+1}} \ \ \ \ \ \text {since } n > 2m. \end {align*} \par \eqref {item2} follows from \[g_{2} - g = \frac {-Q(g)}{Q'(g)} = \frac {-f^{n}h_1}{f^{m}h_2} = -f^{n-m}h_1h_2^{-1} \equiv 0 \pmod {f^{n-m}}.\] \par To prove \eqref {item3} by applying Lemma~\ref {Taylor} on $Q'$ we have \begin {align*} Q'(g_2) &= Q' \big ( g+(g_2-g) \big ) \\ &= Q'(g)+(g_2-g)Q''(g)+(g_2-g)^2 \check {Q}(\cdots ) \ \ \ \ \ \text { for some polynomial } \check {Q} \\ &= Q'(g) - \bigg [ \frac {Q(g)}{Q'(g)} \bigg ] Q''(g) + \bigg [ \frac {Q(g)}{Q'(g)} \bigg ]^2 \check {Q}(\cdots ) \\ &= f^{m}h_2-f^{n-m}h_1h_2^{-1} Q''(g) + (f^{n-m}h_1h_2^{-1})^2 \check {Q}(\cdots ) \\ &=f^m \big [ h_2- f^{n-2m}h_1h_2^{-1} Q''(g) + f^{2n-3m} (h_1h_2^{-1})^2 \check {Q}(\cdots )\big ] \\ &\equiv 0 \pmod {f^{m}} \ \ \ \ \ \text {since } n > 2m. \end {align*} Since $\big [h_2- f^{n-2m}h_1h_2^{-1} Q''(g) + f^{2n-3m} (h_1h_2^{-1})^2 \check {Q}(\cdots )\big ] \not \equiv 0\pmod {f}$ we have $\nu \big ( Q'(g_2) \big )=m$.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 We have $R_k \subseteq 2R_k \subseteq \cdots \subseteq mR_k= (m+1)R_k=\cdots $ for some $m$ since $\Bbb F_q$ is finite. We assumed $\Bbb F_q$ is coverable this implies $mR_k=\Bbb F_q$. If $nR_k \neq (n+1)R_k$ for some $n$, that means there exists a nonzero element $\alpha $ in $(n+1)R_k$ but not in $nR_k$. Let $R_k^{\ast }:= R_k \setminus \{ 0 \} $. $R_k^{\ast }$ is a group under multiplication and it is a subgroup of $\Bbb F_q^{\ast }$. Notice that if we can write $\alpha $ as a sum of $n+1$ many $k^{\text {\tiny th}}$ powers, then any element in the coset of $\alpha $, i.e. in $\alpha R_k^{\ast }$, can be written as a sum of $n+1$ many $k^{\text {\tiny th}}$ powers. This implies if $\alpha \in (n+1)R_k^{\ast }$, then $\alpha R_k^{\ast } \subseteq (n+1)R_k^{\ast }$. This means the number of the strict inclusions in $R_k \subseteq 2R_k \subseteq \cdots \subseteq mR_k$ is at most one less than the number of cosets of $R_k^{\ast }$ inside $\Bbb F_q^{\ast }$. Moreover, since $\Bbb F_q^{\ast }$ is cyclic of order $q-1$ and $R_k^{\ast }$ is a subgroup of $\Bbb F_q^{\ast }$, $R_k^{\ast }$ has to be a cyclic group. Let $\Bbb F_q^{\ast }=\langle \gamma \rangle $, then $R_k^{\ast } = \langle \gamma ^{k} \rangle $ and $ | R_k^{\ast } | = \frac {q-1}{\gcd (k,q-1)}$. So, the number of cosets is $\gcd (k,q-1)$. Also, it is clear that $\Bbb F_q^{\ast }=R_k^{\ast }$ if and only if $\gcd (k,q-1) =1$.
END Proof
 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 We will use the spectral gap theorem to prove the result. Since $v=0$ is already a sum of two $k^{\text {\tiny th}}$ powers, let $v \in \Bbb F_q^{\ast }$. We have $d=\gcd (k,q-1)$ many cosets of $R_k^{\ast }$ inside $\Bbb F_q^{\ast }$ and $v \in vR_k^{\ast }$. The plan is to take $X=R_k^{\ast }$, $Y=vR_k^{\ast }$ and apply the spectral gap theorem. When we apply it, the theorem will guarantee the existence of a directed edge from $X$ to $Y$ under the assumption $q>k^4$. This means there exists some $u^k \in X$ and $vw^k \in Y$ for some $u,w,z \in \Bbb F_q^{\ast }$ such that $u^k+z^k=vw^k$ i.e. $v=(\frac {u}{w})^{k}+(\frac {z}{w})^{k}$, and the result follows. The only thing left is to figure out when the spectral gap theorem applies. \par First, define a Cayley digraph $Cay(\Bbb F_q,R_k^{\ast })$ whose vertices are the elements of $\Bbb F_q$, and there exists a directed edge from $u$ to $v$ if and only if $v-u \in R_k^{\ast }$. Since $R_k^{\ast }$ does not contain $0$, $Cay(\Bbb F_q,R_k^{\ast })$ is loopless. We know every character on $\Bbb F_q$ corresponds to an eigenvector of the adjacency matrix, $\mathbb {A}$ of $Cay(\Bbb F_q,R_k^{\ast })$ by Theorem~\ref {character theory}. For instance if $\Bbb F_q^{\ast }=\langle \gamma \rangle $ we have $\Bbb F_q=\{0, \gamma , \gamma ^2, \cdots , \gamma ^{q-1}=1\}$, and any character $\chi $ gives us a unique eigenvector such that the first entry of the corresponding eigenvector is $\chi (0)$, the second entry of the eigenvector is $\chi (\gamma )$, the third entry is $\chi (\gamma ^2)$ etc. We can even find the eigenvalues corresponding to those eigenvectors using the same theorem. Recall that we proved every character on $\Bbb F_q$ should be in the form of $\chi _{1} \circ \phi _{\alpha }$ for some $\alpha \in \Bbb F_q$ where $\phi _{\alpha }(x) = \operatorname {tr}(\alpha x)$ and $\chi _{1}(x)=e^{\frac {2\pi i x}{p}}$ for every $x \in \Bbb F_q$. Let $\lambda _{\alpha }$ denote the eigenvalue of $\mathbb {A}$ corresponding to the eigenvector induced from $\chi _{1} \circ \phi _{\alpha }$. By Theorem~\ref {character theory} we have \[ \lambda _{\alpha } = \sum _{x \in R_k^{\ast }} \chi _{1} \circ \phi _{\alpha }(x)= \sum _{x \in R_k^{\ast }} e^{\frac {2\pi i (\operatorname {tr}(\alpha x))}{p}}.\] Notice if $\alpha R_k^{\ast }=\beta R_k^{\ast }$ we have \[ \sum _{x \in R_k^{\ast }} e^{\frac {2\pi i ( \operatorname {tr}(\alpha x))}{p}} = \sum _{x \in R_k^{\ast }} e^{\frac {2\pi i ( \operatorname {tr}(\beta x))}{p}}= \lambda _{\beta }.\] This calculation shows us if $\alpha $ and $\beta $ are in the same coset of $R_k^{\ast }$ inside $\Bbb F_q^{\ast }$, the eigenvectors induced by $\chi _{1} \circ \phi _{\alpha }$ and $\chi _{1} \circ \phi _{\beta }$ correspond to the same eigenvalue. We also have the trivial character which induces $\boldsymbol {1}$ as an eigenvector with eigenvalue $|R_k^{\ast }|$, this means we have at most $\frac {|\Bbb F_q^{\ast }|}{|R_k^{\ast }|}+1$ many distinct eigenvalues. Thus the spectrum of $\mathbb {A}$ contains the largest eigenvalue $|R_k^{\ast }|$ with multiplicity $1$ and other eigenvalues, $ \lambda _{\alpha _{i}}$'s each with multiplicity $|R_k^{\ast }|$, since $|\alpha _{i} R_k^{\ast }|=|R_k^{\ast }|$. Therefore, we have \begin {equation} \label {lambda sum one} \sum _{\alpha \in \Bbb F_q} \| \lambda _{\alpha } \|^2=|R_k^{\ast }|^2 + \sum _{i=1}^{d} \| \lambda _{\alpha _{i}} \|^2 |R_k^{\ast }|. \end {equation} At the same time we know \begin {equation} \label {lambda sum two} \sum _{\alpha \in \Bbb F_q} \| \lambda _{\alpha } \|^2=\operatorname {tr}(\mathbb {A}^{\ast } \mathbb {A}) \end {equation} from basic linear algebra. Notice that we also have \begin {equation} \label {lambda sum three} \operatorname {tr}(\mathbb {A}^{\ast } \mathbb {A})=\operatorname {tr}(\mathbb {A}^{T} \mathbb {A})=\operatorname {tr}(\mathbb {A} \mathbb {A}^{T})=\sum _{\alpha \in \Bbb F_q} d^{+}(\alpha ) \end {equation} as $\mathbb {A}$ is real $\mathbb {A}^{\ast }=\mathbb {A}^{T}$, and the last equality holds since $Cay(\Bbb F_q,R_k^{\ast })$ is a simple digraph. By Equations~\eqref {lambda sum one}, \eqref {lambda sum two} and \eqref {lambda sum three} we have \[ |R_k^{\ast }|^2 + \sum _{i=1}^{d} \| \lambda _{\alpha _{i}} \|^2 |R_k^{\ast }|= q |R_k^{\ast }|.\] Hence \[ \sum _{i=1}^{d} \| \lambda _{\alpha _{i}} \|^2 = q- |R_k^{\ast }| \] which implies \[ \max _{1 \leqslant i \leqslant d} \| \lambda _{\alpha _{i}} \| \leqslant \sqrt {q- |R_k^{\ast } |} \ .\] It follows that \[ n_{\ast }= \frac {q}{|R_k^{\ast }|}\big ( \max _{1 \leqslant i \leqslant d} \| \lambda _{\alpha _{i}} \| \big ) \leqslant \frac {q \sqrt {q- |R_k^{\ast } |} }{ |R_k^{\ast }|}.\] \par Now, let $x=d=\gcd (k,q-1)$ and $y=q$ in Lemma~\ref {induction1} in Appendix~\ref {Lemmata}. Notice that since $y$ is the order of the finite field, it is already in $\mathbb {Z}_{+} \setminus \{1\}$. Besides, there is no harm assuming $x \neq 1$, since we already handled $x=1$ case before in Proposition~\ref {gamma1 case}. By the lemma, we have $(y-1)^4-x^4y^3+(y-1)y^2x^3>0$, by dividing it with $x^4$ we get $\dfrac {(y-1)^4}{x^4}+\dfrac {(y-1)y^2}{x}>y^3$. This means $\lvert R_k^{\ast } \rvert ^{4}+\lvert R_k^{\ast } \rvert q^2 >q^3$ which is to say $\lvert R_k^{\ast } \rvert ^{4} >q^3-\lvert R_k^{\ast } \rvert q^2$ i.e. $\lvert R_k^{\ast } \rvert ^{4} > q^2 (q-\lvert R_k^{\ast } \rvert )$. So $q>k^4$ implies $\lvert R_k^{\ast } \rvert > n_{\ast }$ and the result follows.
END Proof
 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 We will use Corollary~\ref {fancy spectral gap theorem} and the discussion provided right after that. We define a new digraph using the Cayley digraph in the previous theorem's proof. The vertices of the new digraph are the elements of $\Bbb F_q$, and there exists a directed edge from $u$ to $v$ if and only if there is a $2$-walk from $u$ to $v$ in the original graph. Since $v=0$ is already a sum of three $k^{\text {\tiny th}}$ powers, let $v \in \Bbb F_q^{\ast }$. Let $X=R_k^{\ast }$, $Y=vR_k^{\ast }$ and apply Corollary~\ref {fancy spectral gap theorem}. It will guarantee the existence of a directed $2$-walk from $X$ to $Y$ under the assumption $q>k^3$ and the result will follow. \par Let $x=d=\gcd (k,q-1)$ and $y=q$ in Lemma~\ref {induction2} in Appendix~\ref {Lemmata}. By the lemma, we have $(y-1)^3-x^{2}y(xy-y+1)>0$, by dividing it with $x^3$ we get $\frac {(y-1)^3}{x^3} > y \Big ( \frac {xy-y+1}{x} \Big )$. This means $\lvert R_k^{\ast } \rvert ^{3} > q (q-\lvert R_k^{\ast } \rvert )$ i.e. $\lvert R_k^{\ast } \rvert > \frac {q (q-\lvert R_k^{\ast } \rvert )}{\lvert R_k^{\ast } \rvert ^{2}}$ and the result follows.
END Proof
 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 As in the last two theorems, again we want to apply the spectral gap theorem. Our calculations in the proof of Theorem~\ref {Main Theorem} showed that $n_{\ast } \leqslant \dfrac {q \sqrt {q- |R_k^{\ast } |} }{ |R_k^{\ast }|}$. We have \[\frac {q \sqrt {q- |R_k^{\ast } |} }{ |R_k^{\ast }|} = \frac {q \sqrt {q- \frac {q-1}{d}} }{\frac {q-1}{d}}=\frac {q}{q-1}\sqrt {d} \sqrt {qd-q+1}. \] Since $d= \gcd (k,q-1) \leqslant q-1$ i.e. $d+1 \leqslant q$ we have \[ \frac {q}{q-1}\sqrt {d} \sqrt {qd-q+1} \leqslant \frac {q}{q-1}\sqrt {d} \sqrt {d(q-1)} = \frac {qd}{\sqrt {q-1}} \leqslant \frac {qk}{\sqrt {q-1}}.\] If $\frac {qk}{\sqrt {q-1}}< |E|$, by Theorem~\ref {SGT} there is an edge from a vertex in $E$ to a distinct vertex in $E$ and the result follows.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 We denote $f(x)$ with $f$ in this proof. Take any element from $\bigslant {\Bbb F_q[x]}{\langle f^2 \rangle }$. Using division algorithm we can write an equivalence class representative of this element as $r_1+r_2f$ where $r_1,r_2 \in \Bbb F_q[x]$ and $\deg (r_1), \deg (r_2)< n$. It follows from the assumption that there exist some $B_1, B_2, \cdots , B_m \in \Bbb F_q[x]$ such that $r_1 \equiv B_1^k+B_2^k+ \cdots +B_m^k \pmod {f}$. \par If some of $B_i $'s are zeros modulo $f$, we can erase them from the list of $ B_i $'s, and use the ones which are not zero modulo $f$ for the next step. We can erase them, because if $B_i \equiv 0 \pmod {f}$, $B_i^k \equiv 0 \pmod {f}$ so the summation of the $k^{\text {\tiny th}}$ powers of the reduced list will still be $r_1$. If all of the $B_i $'s are zeros modulo $f$, then we need to be a little bit careful. If $k$ is odd, or if $k$ is even and $-1$ is a $k^{\text {\tiny th}}$ power in $\Bbb F_q$, simply take $B_{i_1}=1$ and $B_{i_2}=-1$ and proceed to the next step. If $k$ is even and $-1$ is not a $k^{\text {\tiny th}}$ power in $\Bbb F_q$, then we can write $0 \equiv B_{i_1}^k+ (-1) \pmod {f}$ for $B_{i_1}=1$, and we know $-1$ can be written as a sum of $m$ many $k^{\text {\tiny th}}$ powers by assumption. So we can assume $B_{i_1}, \cdots , B_{i_j} $ are all nonzero in $\bmod {f}$ and their summation is equivalent to $r_1$ in $\bmod {f}$. \par Define the polynomial $Q(t)=t^k+B_{i_1}^k+ \cdots +B_{i_{j-1}}^k-r_1-r_2f$ over $\Bbb F_q[x]$, use Hensel's lemma for the polynomial rings (Proposition~\ref {Hensel for poly-strong version}) for $Q(t)$ to conclude there exists a $g_2 \in \Bbb F_q[x]$ such that $ g_2^k+B_{i_1}^k+ \cdots + B_{i_{j-1}}^k= r_1+r_2f \pmod {f^2}$ and the result for $i=2$ follows. Here, we are allowed to use Hensel's lemma, since $B_{i_j}$ is a root of $Q(t)$ in $\bmod {f}$ and $\nu (Q'(B_{i_j}))=0 < \frac {1}{2}$. $\nu (Q'(B_{i_j}))=0$ since $Q'(t)=k t^{k-1}$ and $Q'(B_{i_j})= k B_{i_j}^{k-1} \not \equiv 0 \pmod {f}$. This follows from $ f \nmid k$, $ p \nmid k $, $f \nmid B_{i_j}$ and $f$ being irreducible. \par Once we lift a solution from $\bigslant {\Bbb F_q[x]}{\langle f(x) \rangle }$ to $\bigslant {\Bbb F_q[x]}{\langle f^2(x) \rangle }$, it is easy. Third condition in Proposition~\ref {Hensel for poly-strong version} allows us to apply Hensel's lemma again and again, and get a solution in each $\bigslant {\Bbb F_q[x]}{\langle f^i(x) \rangle }$ for any $i \in \mathbb {Z}_{+}$.
END Proof
 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 To explain the process, we will only do for the first row. Let $k=3$. By Section~\ref {fields section} we know that every element of a finite field can be written as a sum of three cubes as long as $q \neq 4$. Let $A \in \operatorname {Mat}_n(\Bbb F_q)$. By the discussion prior to Proposition~\ref {fancy Henseling}, we know that $\Bbb F_q[A] \cong \bigslant {\Bbb F_q[x]}{\langle p_1^{i_1} \rangle } \times \cdots \times \bigslant {\Bbb F_q[x]}{\langle p_j^{i_j} \rangle }$ for some $p_1,p_2, \cdots , p_j$ distinct irreducible polynomials over $\Bbb F_q$. We first exclude all of the subfields of $\Bbb F_4$ from our list so that none of the $\bigslant {\Bbb F_q[x]}{\langle p_r\rangle }$ will be isomorphic to $\Bbb F_4$. So, $\bigslant {\Bbb F_q[x]}{\langle p_r \rangle }$ will be different than $\Bbb F_4$, as long as $\Bbb F_q \neq \Bbb F_2, \Bbb F_4$. This guarantees that every element of $\bigslant {\Bbb F_q[x]}{\langle p_r \rangle }$ can be written as a sum of three cubes. Then, we want to lift the $k^{\text {\tiny th}}$ powers from $\bigslant {\Bbb F_q[x]}{\langle p_r \rangle }$ to $\bigslant {\Bbb F_q[x]}{\langle p_r^{i_r} \rangle }$. We will use Proposition~\ref {fancy Henseling}. To use this proposition we need the characteristic of the finite field not to divide $k$. That is why we need to exclude $p=3$ cases. Once we guarantee that three cubes is enough for $\bigslant {\Bbb F_q[x]}{\langle p_r^{i_r} \rangle }$ for every $1 \leqslant r \leqslant j$, then Chinese remainder theorem guarantees that three cubes is enough for $\bigslant {\Bbb F_q[x]}{\langle p_1^{i_1} \rangle } \times \cdots \times \bigslant {\Bbb F_q[x]}{\langle p_j^{i_j} \rangle }$. One last thing to note is that when we determine $m$, if $-1$ is a $k^{\text {\tiny th}}$ power (in particular if $k$ is odd) we can use the same $m$ from the downstairs $\left (\bigslant {\Bbb F_q[x]}{\langle p_r \rangle }\right )$; but if $-1$ is not a $k^{\text {\tiny th}}$ power (for example in some cases when $k$ is even) we need to increase $m$ by $1$ when we do the lifting using Proposition~\ref {fancy Henseling}. That is why in the table when $k$ is even, we increased $m$ by $1$ just to be safe without paying any attention to $-1$ being a $k^{\text {\tiny th}}$ power or not.
END Proof
 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 \textbf {Case 1:} Let $R$ be commutative. Then we have $\bigslant {R}{J} \cong \Bbb F_{q_1} \times \cdots \times \Bbb F_{q_r}$ for some finite fields, $\Bbb F_{q_i}$'s. Let $\alpha \in R$. Since we assumed every element of $\bigslant {R}{J}$ can be written as a sum of $m$ many $k^{\text {\tiny th}}$ powers in $\bigslant {R}{J}$, we know $\alpha \equiv B_1^k + \cdots + B_m^k$ $\bmod \ J$ for some $B_1, \cdots , B_m \in R$. We can send $\alpha $ from $R$ to $\bigslant {R}{J}$ with the reduction $\bmod \ J$, and denote it with $\bar {\alpha }$ so that $\bar {\alpha }=(\alpha _1,\alpha _2,\cdots , \alpha _r)$ for some $\alpha _i \in \Bbb F_{q_i}$ where $1 \leqslant i \leqslant r$. Similarly, we will use $\bar {B}_j$ to denote $B_j$ $\bmod \ J$ for every $B_j \in R$. \par \textbf {Case 1.a:} If $\bar {\alpha }$ is a unit in $\bigslant {R}{J}$ that means each entry of $\bar {\alpha }$ (i.e. $\alpha _i$ for every $1 \leqslant i \leqslant r$) is nonzero. Then we can arrange $\bar {B}_j$'s (by shuffling the entries of $\bar {B}_j$'s) such that $\bar {B}_1$ does not have any zero entry, so that $\bar {B}_1$ is a unit in $\Bbb F_{q_1} \times \cdots \times \Bbb F_{q_r}$. Since we have $\gcd (|R|,k)=1$ by assumption, $\bar {k}=(k_1, k_2, \cdots , k_r)$ that is the image of $k$ under reduction $\bmod \ J$ is a unit in $\Bbb F_{q_1} \times \cdots \times \Bbb F_{q_r}$. This implies $\bar {k} \bar {B}_1^{k-1}$ is a unit, and the result follows from Corollary~\ref {Hensel2}. \par \textbf {Case 1.b:} If $\bar {\alpha }$ is not a unit in $\bigslant {R}{J}$, that means at least one of the entries of $\bar {\alpha }$ is zero. Assume only one of them equals $0$, say $\alpha _1$. We have $\alpha \equiv B_1^k + \cdots + B_m^k$ $\bmod \ J$ by assumption. We can shuffle the entries of $\bar {B}_j$'s such that the $i^{\text {\tiny th}}$ entry of $\bar {B}_1$ is nonzero for every $2 \leqslant i \leqslant r$. If the first entry of one of the $\bar {B}_j$'s is nonzero, then we can shuffle the nonzero entry to $\bar {B}_1$ and $\bar {B}_1$ becomes again a unit, we are back in case 1.a. If the first entries of all of the $\bar {B}_j$'s are zero for $1 \leqslant j \leqslant m$, then we can do the following trick. We can replace $0$ in the first entry of $\bar {B}_1$ with $1$, so that $\bar {B}_1$ becomes a unit. But then the first entry of $\bar {B}_1^k$ also becomes $1$ and we need to destroy the effect of $1$ in the summation ($\bar {B}_{1}^k+\bar {B}_{2}^k+ \cdots + \bar {B}_{m}^k=\bar {\alpha }$). Therefore, we have to change the first entries of $\bar {B}_j$'s for $2 \leqslant j \leqslant m$ such that the first entry of the summation $\bar {B}_2^k + \cdots + \bar {B}_m^k$ will be $-1$. If $k$ is odd, then simply replace $0$ in the first entry of $\bar {B}_2$ with $-1$, leave the other $\bar {B}_j$'s as they are and the problem is solved since $(-1)^k=-1$. If $k$ is even, by assumption $(-1,0,\cdots ,0)$ can be written as a sum of $m$ many $k^{\text {\tiny th}}$ powers in $\bigslant {R}{J}$, this implies for some $x_j \in \Bbb F_{q_1}$ we have $(-1,0,\cdots ,0)= (x_1,0,\cdots ,0)^k+(x_2,0,\cdots ,0)^k+\cdots +(x_m,0,\cdots ,0)^k$. Let $\bar {B}_{new}=(x_1,0,\cdots ,0)$, and replace the first entries of $\bar {B}_j$'s with $x_j$'s for $2 \leqslant j \leqslant r$, so that the first entry of the summation $\bar {B}_{new}^k+\bar {B}_2^k + \cdots + \bar {B}_m^k$ will be $-1$ and $\bar {\alpha }$ will be equal to $\bar {B}_{1}^k+ \bar {B}_{new}^k +\bar {B}_{2}^k+ \cdots + \bar {B}_{m}^k$. We again have $\bar {k} \bar {B}_1^{k-1}$ is a unit, since $\gcd (|R|,k)=1$ and $\bar {B}_1$ is a unit. Corollary~\ref {Hensel2} implies that $\alpha $ can be written as a sum of $m+1$ many $k^{\text {\tiny th}}$ powers. \par \textbf {Case 2:} Let $R$ be noncommutative. To reduce this case to the commutative case, we use the following trick. Let $\alpha \in R$. Consider the subring generated by $\alpha $, i.e. $\mathbb {Z}[\alpha ]= \left \{ a_{0}.1+a_{1}\alpha +\cdots +a_{l}\alpha ^{l} \mid a_0, a_1 \cdots a_l \in \mathbb {Z} \right \}.$ It is a subring but it is a commutative finite ring with identity by itself. Moreover, since the order of $\mathbb {Z}[\alpha ]$ has to divide $|R|$, $\gcd (|R|,k)=1$ implies $\gcd (|\mathbb {Z}[\alpha ]|,k)=1$ and we are again in case $1$. Note that this approach enables us to write every element of $\mathbb {Z}[\alpha ]$ as a sum of $k^{\text {\tiny th}}$ powers from $\mathbb {Z}[\alpha ]$ instead of $R$, which means when $R$ is not commutative the $n$ value (i.e. the number of $k^{\text {\tiny th}}$ powers needed to write $\alpha $ as a sum) we find with this approach can be bigger than the actual $n$ value.
END Proof
 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Given a $k$ value, we want to find an integer $n$ with the property that every element of $R$ can be written as a sum of at most $n$ many $k^{\text {\tiny th}}$ powers in $R$. We want to use the previous theorem. One of the assumptions in that theorem is $\gcd (|R|,k)=1$. In the table, notice that $q$-column always has the divisors of $k$. So when we say $q$ does not divide $|R|$ in the statement, it is guaranteed that $\gcd (|R|,k)=1$. \par If $R$ is commutative, then $\bigslant {R}{J}$ is isomorphic to the direct product of some finite fields as we discussed earlier. If $R$ is not commutative, then let $\alpha \in R$. Since $\mathbb {Z}[\alpha ]$ is a commutative finite ring with identity, we have $\bigslant {\mathbb {Z}[\alpha ]}{J \left ( \mathbb {Z}[\alpha ] \right )} \cong \Bbb F_{q_1} \times \cdots \times \Bbb F_{q_r}$ for some finite fields $\Bbb F_{q_1}, \cdots , \Bbb F_{q_r}$. That means to find $m$ in the previous theorem, first we need to find how many $k^{\text {\tiny th}}$ powers is necessary to write every element of $\Bbb F_{q_i}$ as a sum of $k^{\text {\tiny th}}$ powers in $\Bbb F_{q_i}$. We denote this number with $m_i$ for each $\Bbb F_{q_i}$, i.e. every element of $\Bbb F_{q_i}$ can be written as a sum of $m_i$ many $k^{\text {\tiny th}}$ powers in $\Bbb F_{q_i}$. Then, every element of $\bigslant {R}{J}$ $\left ( \text {or resp. } \bigslant {\mathbb {Z}[\alpha ]}{J \left ( \mathbb {Z}[\alpha ] \right )}\right )$ can be written as a sum of $m=\max _{1 \leqslant i \leqslant r} m_i$ many $k^{\text {\tiny th}}$ powers in $\bigslant {R}{J}$ $\left ( \text {or resp. in } \bigslant {\mathbb {Z}[\alpha ]}{J \left ( \mathbb {Z}[\alpha ] \right )}\right )$. Therefore, building on our results in Section~\ref {fields section} we can determine $m$, and using the previous theorem we can let $n=m$ or $n=m+1$ depending on the parity of $k$.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Lemma \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Step $1$: Pick any $x \in \mathbb {Z}_{+} \setminus \{1\}$ and fix it.\\ We will prove $F(x,y)=(y-1)^4-x^4y^3+(y-1)y^2x^3>0$ when $y=x^4+1$. \begin {align*} F(x,x^4+1) &=x^{16}-x^4(x^4+1)^3+x^4(x^4+1)^2x^3\\ &=x^4(x^3-x-1)(x^8+x^6-2x^5+3x^4-x^3+x^2-x+1). \end {align*} $x^4 \geqslant 0$ for every $x \in \mathbb {R}$.\\ $x^3-x-1$ has only one real root in the interval $(1,2)$ and two complex conjugate roots, as the first derivative test and sign chart illustrates it. We have $x^3-x-1>0$ when $x \in \mathbb {Z}_{+} \setminus \{1\}$.\\ Also, $x^8+x^6-2x^5+3x^4-x^3+x^2-x+1>0$ as $x^8+x^6> 2x^5$ and $2x^4>x^3+x$ when $x \in \mathbb {Z}_{+} \setminus \{1\}$.\\ As a result, we proved $F(x,y)>0$ when $y=x^4+1$ and $x \in \mathbb {Z}_{+} \setminus \{1\}$.\\ Step $2$: Pick any $x \in \mathbb {Z}_{+} \setminus \{1\}$. Now, we will prove by induction that $F(x,y)>0$ for any $y>x^4$. We already showed in Step $1$ that $F(x,y)>0$ when $y=x^4+1$. We assume this holds for $y=x^4+C$ for any $C \in \mathbb {Z}_{+}$, and we demonstrate below $F(x,y)>0$ also holds when $y=x^4+C+1.$\\ We have \[F(x,x^4+C)=(x^4+C-1)^4-x^{4}(x^4+C)^3+(x^4+C-1)(x^4+C)^{2}x^{3}>0\] by assumption, and \[F(x,x^4+C+1)=(x^4+C+1-1)^4-x^4(x^4+C+1)^3+(x^4+C+1-1)(x^4+C+1)^{2}x^3.\] Notice that if we show $B=[F(x,x^4+C+1)-F(x,x^4+C)]>0$, then we are done.\\ We have \[B= 4 C^{3} + 9 C^{2} x^{4} + \underbrace {3 C^2 x^3 - 6 C^2} + 6 C x^8 + \underbrace {6 C x^7 - 15 C x^4} + C x^3 + 4 C + x^{12} + \underbrace {3 x^{11} - 9 x^8} + x^7 + \underbrace {3 x^4 - 1}.\] Notice that we have \[3 C^2 x^3 - 6 C^2=3C^2(x^3-2)>0\] \[6 C x^7 - 15 C x^4=3Cx^4(2x^3-5)>0\] \[3 x^{11} -9 x^8=3x^8(x^3-3)>0 \text { \ \ \ and \ \ \ } 3 x^4 - 1>0\] since $x \in \mathbb {Z}_{+} \setminus \{1\}$. These calculations show $B>0$, and the result follows.
END Proof
 
BEGIN Lemma \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 We again use induction to prove the claim.\\ Step $1$: Pick any $x \in \mathbb {Z}_{+} \setminus \{1\}$ and fix it.\\ We need to show $F(x,y)=(y-1)^3-x^{2}y(xy-y+1)>0$ holds when $y=x^3+1$.\\ We have $F(x,x^3+1)=x^8-2x^6+x^5-x^3$ is clearly bigger than zero as $x \in \mathbb {Z}_{+} \setminus \{1\}$.\\ Step $2$: Pick any $x \in \mathbb {Z}_{+} \setminus \{1\}$. We assume the claim holds for $y=x^3+C$ for any $C \in \mathbb {Z}_{+}$, and we demonstrate below $F(x,y)>0$ holds also when $y=x^3+C+1.$\\ We have \[F(x,x^3+C)=(x^{3}+C-1)^3-x^2(x^3+C) [x(x^3+C)-(x^3+C)+1]>0\] by assumption, and \[F(x,x^3+C+1)=(x^{3}+C+1-1)^3-x^{2}(x^3+C+1)[x(x^{3}+C+1)-(x^{3}+C+1)+1].\] Notice that if we show $B=[F(x,x^3+C+1)-F(x,x^3+C)]>0$, then we are done.\\ We have \[B= 3 C^{2} + 4 C x^{3} + \underbrace {2 C x^2 - 3 C} + x^6 + \underbrace {2 x^5 - 4 x^3}+1.\] Notice that both $2 C x^2 - 3 C>0$ and $2 x^5 - 4 x^3>0$ as $x \in \mathbb {Z}_{+} \setminus \{1\}$. So, we have $B>0$ and the result follows.
END Proof
 
