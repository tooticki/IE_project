BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Theorem~\ref {t.multi_szem_ab_gr}] Consider the abelian group $P=G^m$, $X_i=S\subset P$, for $i\in [1,m+1]$. Let $\mathbf {x}_i=(x_{i,1},\ldots ,x_{i,m})$, $i\in [1,m+1]$, be the variables of the homomorphism system that can be derived from the following linear equations: \begin {equation}\label {eq.system_multidim} \left \{\begin {array}{cl} x_{1,1}-x_{2,1}= x_{1,j}-x_{j+1,j} & \text { for } j\in [2,m] \\ x_{1,j}=x_{i,j} & \text { for all }(i,j)\in [1,m+1]\times [1,m], i\neq j+1.\\ \end {array}\right . \end {equation} Indeed, $\mathbf {x}_1$ is thought of as the centre of the configuration. The first equations state that the difference between the $j$-th coordinate of $\mathbf {x}_{j+1}$ and the $j$-th coordinate of $\mathbf {x}_1$ is the same regardless of $j$; this is achieved by setting all the differences to be equal to the difference between the first coordinate of $\mathbf {x}_2$ and the first coordinate of $\mathbf {x}_1$. The second set of equations treat the other coordinates, imposing that all the other coordinates of $\mathbf {x}_{j+1}$, except the $j$-th, should be equal to those of $\mathbf {x}_1$. Therefore, $(\mathbf {x_1},\ldots ,\mathbf {x}_{m+1})$ is a solution to the system defined by (\ref {eq.system_multidim}) if and only if $\mathbf {x}_1=(y_1,\ldots ,y_m)$, $\mathbf {x}_2=(y_1+a,\ldots ,y_m)$, \ldots , $\mathbf {x}_{m+1}=(y_1,\ldots ,y_m+a)$ for some $y_1,\ldots ,y_m,a\in G$. \par By adding some trivial equations, like $0=0$, the system induces a homomorphism $A:P^{m+1} \to P^{m}$, with $S(A,P)\cong G^{m+1}$. Observe that $S_i(A,P)\cong G^m$ as any point in $P=G^m$ can be the $i$-th element in the configuration. \par Consider the $\delta =\delta _{\text {Theorem~\ref {t.rem_lem_ab_gr}}}(m+1,\varepsilon /(m+1))$ coming from Theorem~\ref {t.rem_lem_ab_gr} applied with $\varepsilon /(m+1)$ and $m+1$. Let us proceed by contradiction and assume that the number of solutions is less than $\delta S(A,P)=\delta |G|^{m+1}$. Now we apply Theorem~\ref {t.rem_lem_ab_gr} and find sets $X_1',\ldots ,X_{m+1}'$ with $|X_i'|<|G^m|\varepsilon /(m+1)$ such that the sets $X_i=S\setminus X_i'$ bear none of the desired configurations. \par Observe that any point $\mathbf {x}\in S\subset G^m$ generates a solution to the linear system as $(\mathbf {x},\ldots ,\mathbf {x})\in P^{m+1}$ is a valid configuration with $a=0_{G}$. Consider $S'=S\setminus (\cup X_i')$. Since $|S|>\varepsilon |G^m|$ and $|X_i'|<|G^m|\varepsilon /(m+1)$, there exists an element $\mathbf {s}$ in $S'$, as $S'$ is non-empty. Therefore $\mathbf {s}\in X_i$ for every $i\in [1,m+1]$. Thus $(\mathbf {s},\ldots ,\mathbf {s})\in P^{m+1}$ is a solution that still exists after removing the sets $X_i'$ of size at most $\varepsilon /(m+1)$ from $S$. This contradicts Theorem~\ref {t.rem_lem_ab_gr}. Therefore, we conclude that at least $\delta |G|^{m+1}$ solutions exist.
END Proof
 
BEGIN Corollary \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 We proceed by contradiction. Choose $\delta =\delta _{\text {Theorem~\ref {t.rem_lem_ab_gr}}}(m,\varepsilon /(m+1)$ and assume that $\left |S(A,G,S^m)\right |<\delta \left |S(A,G)\right |$. Then there are sets $X_i'$, with $|X_i'|< \varepsilon /(m+1)$, such that $S(A,G,\prod _{i=1}^m S\setminus X_i')=\emptyset $. However, by $(i)$ and $(ii)$ we delete at most $\epsilon \frac {m}{m+1}|R|$ hence $R\cap \prod _{i=1}^m S\setminus X_i'\neq \emptyset $, thus $S(A,G,\prod _{i=1}^m S\setminus X_i')\neq \emptyset $ reaching a contradiction.
END Proof
 
BEGIN Corollary \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Consider $R=\{(x,\ldots ,x)\}_{x\in G}$. Observe that the configuration set $\{x\in G, \mathbf {x}\in \prod _{i=1}^s G_i \;|\; (x+\Phi _1(\mathbf {x}), \ldots ,x+\Phi _t(\mathbf {x}))\in G^t\}$ is a subgroup of $G^t$, whence there exists a homomorphism $A$ such that $S(A,G)$ is the configuration set and, in this case, $S_i(A,G)=G=\pi _i(R)$ for all $i$. Thus the hypotheses of Corollary~\ref {c.homotetic_solutions2} are fulfilled and the result follows.
END Proof
 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Definition \protect \let \reserved@d = *\def \par 
BEGIN Theorem \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Theorem~\ref {t.rep_sys_rem_lem}] Let $(K,H)$ be the hypergraph pair that $\gamma $-represents the system $(A,G)$, with $\gamma =(\gamma _1,\ldots ,\gamma _m)$. Let us denote the labelling by $l:E(K)\to G$ and the representation function by $r:C(H,K)\to S(A,G)\times Q$. The components of $r$ are given by $r_0:C(H,K)\to S(A,G)$ and $r_q:C(H,K)\to Q$. Recall that, by Definition~\ref {d.rep_sys}, if $H_0=\{e_1,\ldots ,e_m\}$ is a copy of $H$ in $K$, then $r_0(H)=(l(e_1),\dots ,l(e_m))$. Let $K_X$ be the subhypergraph of $K$ with the same vertex set as $K$ and the edges belonging to $r_0^{-1}(S(A,G,X))$. In other words, $K_X\subset K$ is the hypergraph containing only the edges whose labels belong to the restricted solution set. \par \par By the property RP\ref {prop_rep2} of the $\gamma $-representability of the system, the total number of copies of $H$ in $K$ is, for the $c$ and $p$ provided by the representation, at most $$ c\frac {|K|^s}{ |G|} p |Q||S(A, G)| \prod _{i=1}^m \gamma _i. $$ Let $\lambda =c\frac {|K|^s}{ |G|}$. Since $H$ has $h$ vertices, it follows that $$ \lambda p |Q| |S(A, G)| \prod _{i=1}^m \gamma _i<|K|^h. $$ On the other hand, the hypothesis $|S(A,G,X)|<\delta |S(A,G)|$, $\delta $ to be determined later, implies that the total number of copies of $H$ in $K_X$ is at most $$ \lambda p |Q| |S(A, G, X)| \prod _{i=1}^m \gamma _i < \delta \lambda p|Q| |S(A, G)| \prod _{i=1}^m \gamma _i < \delta |K|^h. $$ We apply the Removal Lemma for colored hypergraphs, Theorem~\ref {t.rem_lem_edge_color_hyper}, with $\varepsilon '=c\varepsilon /m$. By setting $\delta $ according to $\varepsilon '$ and $H$ in Theorem~\ref {t.rem_lem_edge_color_hyper}, we obtain a set of edges $E'\subset E(K_X)$ with cardinality at most $\varepsilon '|K|^s$ such that $K_X \setminus E'$ has no copy of $H$. We note that $\delta $ depends on $s,h,m$ and $\varepsilon '$, which in our context and by the representability, all depend on $m$ and $\varepsilon $. \par We next define the sets $X'_i\subset X_i$ as follows. The element $x$ is in $X_i'$ ($x$ is removed from $X_i$) if $E'$ contains at least $\lambda \gamma _i /m $ edges labelled $x$ and colored $i$. We observe that \begin {displaymath} |X'_i|\le \frac {|E'|}{(\lambda \gamma _i/m)} =\frac {m|G|}{c|K|^s}|E'| \frac {1}{\gamma _i}\le \varepsilon \frac {|G|}{\gamma _i}. \end {displaymath} \par We claim that $S(A,G,X\setminus X')$, with $X\setminus X'=\prod _{i=1}^m X_i\setminus X_i'$, is empty. Indeed, pick one element $\mathbf {x}=(x_1,\ldots ,x_m)\in S(A,G,X)$ and $q\in Q$. By RP\ref {prop_rep2} there are $p\lambda \prod _{i=1}^m \gamma _i$ copies of $H$ in $r^{-1}(\mathbf {x},q)$. Since $\mathbf {x}\in S(A,G,X)$, all these copies belong to $K_X$. On the other hand, by RP\ref {prop_rep3}, every edge of $K$ coloured $i$ is contained in at most $p\prod _{j\in [1,m]\setminus \{i\}} \gamma _j$ copies of $H$ in $r^{-1}(\mathbf {x},q)$. Let $E'_{i,x_i}$ denote the set of edges in $E'$ labelled with $x_i$ and colored $i$. Then \begin {displaymath} \sum _{i=1}^m \left [|E'_{i,x_i}| p\prod _{j\in [1,m]\setminus \{i\}} \gamma _j \right ]\geq p \lambda \prod _{j\in [1,m]} \gamma _j \end {displaymath} as there are no copies related to $(\mathbf {x},q)$ after $E'$ has been removed. By the pigeonhole principle, at least one of the sets $E'_{i,x_i}$ is such that $|E'_{i,x_i}|>\lambda \gamma _i/m$. By the definition of $X'_i$, the element $x_i$ belongs to $X'_i$ and thus $\mathbf {x}\not \in X\setminus X' \supset S(A,G,X\setminus X')$. This proves the claim and finishes the proof of the result.
END Proof
 
BEGIN Claim \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 The map $f$ must be bijective. Indeed, since $G_{\tau }$ is a complete graph if $f$ were not bijective, then the graph induced by $V(H_0)$ would contain a loop as $f$ is a homomorphism, but $G_{\sigma }$ is loopless. \par If $f$ is not the map $f(i)=x_i$, then there exist a pair $i,j\in [1,t-1]$ with $i<j$ but $f(i)>f(j)$. If the edge between $i$ and $j$ is $e=\{i\to j\}$, then $f(e)=\{f(i)\to f(j)\}$. In such case, $e$ is painted blue as $i<j$ and $f(e)$ is painted red as $f(i)>f(j)$, hence $f$ is not an homomorphism. If the edge between $i$ and $j$ is $e'=\{j\to i\}$, then $e$ is coloured red but $f(e')$ is blue. Therefore, if $f$ is a homomorphism, it has to be the isomorphism with $f(i)=x_i$.
END Proof
 
BEGIN Claim \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Let $e=\{x_i\to x_j\}$ be an edge in $G_{\sigma }$, then $\sigma (x_i)<\sigma (x_j)$. Since $H_0$ is a copy of $G_{\tau }$ where $x_i$ corresponds to the $i$-th vertex of $G_{\tau }$, $e'=\{i\to j\}$ is an edge in $G_{\tau }$ meaning that $\tau (i)<\tau (j)$ as wanted. Since the reverse implication also holds, the result is shown.
END Proof
 
BEGIN Claim \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 Assume the pair $\{i,j\}\in {[0,t-1]\choose 2}$, with $i<j$, is such that $\sigma (x_i)<\sigma (x_j)$. By the construction of $G_{\sigma }$ we have the edge $\{x_i\to x_j\}$ and is painted blue (as $x_i<x_j$). Since $\{x_0<\cdots <x_{t-1}\}\in \Lambda ^{\tau }(\sigma )$, then $\tau (i)<\tau (j)$. Hence $G_\tau $ has the edge $\{i\to j\}$ coloured blue (as $i<j$). \par Assume now that the pair $\{i,j\}\in {[0,t-1]\choose 2}$, with $i<j$, is such that $\sigma (x_i)>\sigma (x_j)$. $G_{\sigma }$ contains the edge $\{x_j\to x_i\}$ painted red (as $x_j>x_i$). On the other side we have $\tau (i)>\tau (j)$ as $\{x_0<\cdots <x_{t-1}\}\in \Lambda ^{\tau }(\sigma )$. Hence $G_\tau $ has the edge $\{j\to i\}$ coloured red (as $j>i$). \par Therefore, the map $i\mapsto x_i$, for $i\in [0,t-1]$, is a graph homomorphism preserving the colours and the directions of the edges as claimed.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Proposition~\ref {p.1-auto-equiv-rep}] Let $\phi $ be the map that defines the $1$-auto-equivalence $\phi : S(A_2,G) \to S(A_1,G)$ with $\phi (x_1,\ldots ,x_{m_2})=\left (\phi _1(x_{\sigma (1)}),\ldots ,\phi _{m_1}(x_{\sigma (m_1)})\right )$. Let $(K',H', \gamma ',\linebreak [1] l', r', Q', p', c')$ be the vector defining the $\gamma '$-representation for $(A_2,G)$. Let $s$ be the uniformity of the edges of $H'$. \par The vector $(K,H,\gamma ,l,r,Q',p',c')$ defines the $\gamma $-representation of $((A_1,\mathbf {b}_1),G)$ as follows. $\gamma _i=\gamma '_{\sigma (i)}$ for $i\in [1,m_1]$. $H$ and $K$ are the hypergraph on the same vertex set of $H'$ and $K'$ respectively, and with the edges given by the colours $\sigma (1),\ldots ,\sigma (m_1)$. Repaint the edge coloured $\sigma (i)$ with colour $i$. If $e=\{v_1,\ldots ,v_s\}$ is an edge coloured $\sigma (i)$ in $K'$ and labelled $l'(e)$, then $e$ is an edge coloured $i$ in $K$ and labelled $l(e)=\phi _i(l'(e))$. $r_q(H_0)=r_q'(H_0')$ where $H_0'$ is the unique copy of $H'$ in $K'$ spanned by the vertices of $H_0$ seen as vertices of $K'$. \par \par \par Each copy of $H$ in $K$ induces a unique copy of $H'$ in $K'$ and vice-versa. Moreover, $\phi $ is a bijection between the solution sets and $(K',H',\gamma ',l',r',Q',p',c')$ is a $\gamma '$-representation for $((A_2,\mathbf {b}_2),G)$. Therefore, $(K,H,\gamma ,l,r,Q,p,c)$ as defined above induces a $\gamma $-representation for $((A_1,\mathbf {b}_1,G)$ and have the same constants $\chi _1$ and $\chi _2$ as $(K',H',\gamma ',l',r,Q',p',c')$. Since $\phi _i$ are affine automorphisms, if the representation for $((A_2,\mathbf {b}_2),G)$ is strong, the so is the representation for $((A_1,\mathbf {b}_1,G)$ here presented.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Proposition~\ref {p.mu-auto-equivalent}] \par Let $\iota $ be a map from $S((A_2,\mathbf {b}_2),G)$ to $[1,\mu ]$ where, given $\mathbf {x}_1, \mathbf {x}_2\in S((A_2,\mathbf {b}_2),G)$ such that $\phi (\mathbf {x}_1)=\phi (\mathbf {x}_2)$ and $\mathbf {x}_1\neq \mathbf {x}_2$, then $\iota (\mathbf {x}_1)\neq \iota (\mathbf {x}_2)$. If $\phi $ is a $\mu $-to-$1$ map, such $\iota $ exist, is exhaustive and induces an equipartition in $S((A_2,\mathbf {b}_2),G)$. \par Let $(K',H',\gamma ',l',r',Q',p',c')$ be the vector defining the $\gamma '$-representation for $((A_2,\mathbf {b}_2),G)$. Let $s$ be the uniformity of the edges of $H'$. The candidate vector $(K,H,\gamma ,l,r,Q,p,c)$ is defined as follows. \begin {itemize} \item $Q=Q'\times [1,\mu ]$, $p=p'\prod _{i=m_1+1}^{m_2} \gamma '_i$, $c=c'$, $\gamma $ is such that $\gamma _i=\gamma '_i $ for $i\in [1,m_1]$. \item $H$ and $K$ are the hypergraphs on the vertex sets of $H'$ and $K'$ respectively. $e=\{v_1,\ldots ,v_s\}$ is an edge in $K$ coloured $i\in [1,m_1]$ if and only $e$ is an edge coloured $i\in [1,m_1]$ in $K'$. \item $l$ is defined by $l(e)=l'(e)$ for $e$ an edge coloured $i\in [1,m_1]$. \item If $H_0\in C(H,K)$, then $r_q(H_0)=(r_q'(H_0'),\iota (r_0'(H_0')))$ where $H_0'$ is the unique copy of $H'$ in $K'$ spanned by the vertices of $H_0$, seen as vertices of $K'$. \end {itemize} \par \par Selecting $\mathbf {x}\in S((A_1,\mathbf {b}_1),G)$ and $q=(q',j)\in Q=Q'\times [1,\mu ]$ is equivalent to select the $\mathbf {y}\in S((A_2,\mathbf {b}_2),G)$, with $\mathbf {y}\in \phi ^{-1}(\mathbf {x})$ such that $\iota (\mathbf {y})=j$, and $q'\in Q'$, first coordinate of $q$. Moreover, each copy of $H$ in $K$ induces a unique copy of $H'$ in $K'$ and vice-versa. Therefore, the class of copies of $H$ related to $(\mathbf {x},q)$ is the same as the copies of $H'$ related to $(\mathbf {y},q')$. \par Since each edge $e_i\in E(K')$, $i\in [1,m_1]$, is contained in $p'\frac {\prod _{j=1}^{m_2}\gamma '_j}{\gamma '_i}$ copies of $H'$ related to $(\mathbf {y},q')$, then it also contains, seen as an edge in $K$, $p'\frac {\prod _{j=1}^{m_2}\gamma '_j}{\gamma '_i}=p\frac {\prod _{j=1}^{m_1}\gamma '_j}{\gamma _i}$ copies of $H$ related to $(\mathbf {x},q)$. Therefore, $(K,H,\gamma ,l,r,Q,p,c)$ as defined above induces a $\gamma $-representation for $(A_1,G)$ and have the same constants $\chi _1$ and $\chi _2$ as $(K',H',\gamma ',l',r',Q',p',c')$. Moreover, since $\phi _i$ is the identity map for each $i$, if the representation for $((A_2,\mathbf {b}_2),G)$ is strong, then so is the presented representation for $((A_1,\mathbf {b}_1),G)$.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Proposition~\ref {p.mu-equivalent_1}] \par \par Observe that, for $i\in [1,m_1]$, $\phi _1(S_i((A_2,\mathbf {b}_2),G_2))=S_i((A_1,\mathbf {b}_1),G_1)$ as $\phi $ is surjective. Since $\phi _1$ is affine, $|\{y_i\in S_i((A_2,\mathbf {b}_2),G_2) : \phi _1(y_i)=x_i\}|$ is the same for each $x_i\in S_i((A_1,\mathbf {b}_1),G_1)$. Since $\phi ^{-1}(\mathbf {x})=\prod _{i=1}^{m_1} \phi _1^{-1}((\mathbf {x})_i)$ and $\phi _1$ is affine, then we can let $\beta =|S_i((A_2,\mathbf {b}_2),G_2)|/|S_i((A_1,\mathbf {b}_1),G_1)|$, as its value is independent of $i\in [1,m_1]$. Therefore, $\mu =\beta ^{m_1}$. Additionally, since $\phi _1$ is surjective, $\beta =|G_2|/|G_1|$. \par \par Let $\iota $ be a map from $G_2$ to $\Z _{\beta }$ such that, if $y_1,y_2\in G_2$ with $\phi _1(y_1)=\phi _1(y_2)$ and $y_1\neq y_2$, then $\iota (y_1)\neq \iota (y_2)$. Since $\phi _1$ is a $\beta $-to-$1$ map between $G_2$ and $\phi _1(G_2)=G_1$, then such $\iota $ exist, is exhaustive and induces an equipartition of $G_2$ in $\beta $ classes. Moreover, $\iota $ induces the bijections \begin {displaymath} \begin {array}{cl} G_2 &\longrightarrow \phi _1(G_2)\times \Z _{\beta } \\ y &\longmapsto (\phi _1(y),\iota (y)) \end {array} \text { and } \begin {array}{cl} S((A_2,\mathbf {b}_2),G_2) &\longrightarrow S((A_1,\mathbf {b}_1),G_1)\times \Z _{\beta }^{m_1} \\ \mathbf {y} &\longmapsto (\phi (\mathbf {y}),\iota (\mathbf {y})) \end {array} \end {displaymath} where $\iota ((\mathbf {y}_1,\ldots ,\mathbf {y}_{m_1}))=(\iota (\mathbf {y}_1),\ldots ,\iota (\mathbf {y}_{m_1}))$. Let $\pi :\Z _{\beta }^{m_1}\to \Z _{\beta }^{m_1}/\langle 1,\ldots ,1\rangle $ be the quotient map. \par \par Let $(K',H',\gamma ',l',r',Q',p',c')$ be the vector defining the $\gamma '$-representation for $((A_2,\mathbf {b}_2),G_2)$. Let $s$ be the uniformity of the edges of $H'$. The candidate vector $(K,H,\gamma ,l,r,Q,p,c)$ is defined as follows. \begin {itemize} \item $Q=Q'\times \left [\Z _{\beta }^{m_1}/\langle 1,\ldots ,1\rangle \right ]$, $p=p'$, $c=c'$, $\gamma _i=\gamma '_i $ for $i\in [1,m_1]$. \item $H$ and $K$ are the hypergraphs on the same vertex sets and edge sets as $H'$ and $K'$ respectively. $e=\{v_1,\ldots ,v_s\}$ is an edge in $K$ coloured $i\in [1,m_1]$ if and only $e$ is an edge coloured $i\in [1,m_1]$ in $K'$. \par \item $l(e)=\phi _1(l'(e))$ if $e$ is an edge coloured $i\in [1,m_1]$ as an edge in $K'$. \item Given $H_0\in C(H,K)$, let $H_0'$ be the unique copy of $H'$ in $K'$ spanned by the vertices of $H_0$ and let $\mathbf {y}=(\mathbf {y}_1,\ldots ,\mathbf {y}_{m_1})=r_0'(H_0')\in S((A_2,\mathbf {b}_2),G_2)$ the solution spanned by $H_0'$. Then $r_q(H_0)=(r_q'(H_0'),\pi (\iota (\mathbf {y})))$. \end {itemize} \par \par Property RP\ref {prop_rep1} is fulfilled with the same parameters and each edge bears a label given by $l$. The function $r=(r_0,r_q)$ goes from $C(H,K)$ to $S((A_1,\mathbf {b}_1),G_1)\times Q$ by the definition of $r'=(r_0',r_q')$, $\iota $, $\phi _1$ and $\pi $. $r$ is surjective because $r'$ is surjective and $S((A_2,\mathbf {b}_2),G_2)$ is in bijection with $S((A_1,\mathbf {b}_1),G_1)\times \Z _{\beta }^{m_1}$. Observe that $r^{-1}(\mathbf {x},q)$ is the union of those $r'^{-1}(\mathbf {y},q')$, with $\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2)$, such that $\phi (\mathbf {y})=\mathbf {x}$ and $q=(q',\pi (\iota (\mathbf {y})))$. This union has $\beta $ elements, as this is the size of each class in the quotient $\Z _\beta ^{m_1}/\langle (1,\ldots ,1)\rangle $. Therefore, \begin {align} \left |r^{-1}(\mathbf {y},q)\right |=\beta \left |r'^{-1}(\mathbf {x},q')\right |=\beta p'c' \frac {|K'|^s}{|G_2|} \prod _{i=1}^{m_1} \gamma _i' =p c \frac {|K|^s}{|G_1|} \prod _{i=1}^{m_1} \gamma _i, \nonumber \end {align} which shows RP\ref {prop_rep2}. \par All the solutions $(\mathbf {y}_1,\ldots ,\mathbf {y}_m)=\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2)$ that conform the union just mentioned have the property that any component $\mathbf {y}_i$ takes all the possible $\beta $ values of $\phi _1^{-1} ((\mathbf {x})_i)$. Indeed, from all the solutions $(\mathbf {y}_1,\ldots ,\mathbf {y}_m)=\mathbf {y}$ that, along with the $q'$, conform the sets of copies of $H$ given by $r^{-1}(\mathbf {x},q)$, there is only one solution $\mathbf {y}$ with $\mathbf {y}_i$ having a particular value in $\phi _1^{-1}((\mathbf {x})_i)$. Therefore, if two copies of $H$ in $K$ share an edge $e_i\in H_0\in r^{-1}(\mathbf {x},q)$, then they belong to the same set $r'^{-1}(\mathbf {y},q')$ if seen as copies of $H'$ in $K'$. Thus, there are $p'\frac {\prod _{j=1}^m \gamma '_j}{\gamma '_i}=p\frac {\prod _{j=1}^m \gamma _j}{\gamma _i}$ copies of $H$ in $K$ sharing $e_i$. This shows RP\ref {prop_rep3}. \par \par Let $\mathbf {x}\in S((A_1,\mathbf {b}_1),G_1)$ and $q=(q',j)\in Q$. Pick $e_i$ with $l(e_i)=(\mathbf {x})_i$ for some $i\in [1,m_1]$. Let $y_i=l'(e_i)$ by seen $e_i$ as an edge in $K'$. Let $\mathbf {y}$ be the unique solution to $S((A_2,\mathbf {b}_2),G_2)$ such that $\phi (\mathbf {y})=\mathbf {x}$, $(\mathbf {y})_i=y_i$, and $\pi (\iota (\mathbf {y}))=j$. If $((A_2,\mathbf {b}_2),G_2)$ is strongly representable, there exists a $H_0'$, $H_0'\in r'^{-1}(\mathbf {y},q')$, with $e_i\in H_0'$. If $H_0$ is the unique copy of $H$ in $K$ on the vertices of $H_0'$, then $e_i\in H_0$ and $H_0\in r^{-1}(\mathbf {x},q)$. This shows RP\ref {prop_rep4} for the system $((A_1,\mathbf {b}_1),G_1)$ when $((A_2,\mathbf {b}_2),G_2)$ is strongly representable and finishes the proof of the proposition.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Proposition~\ref {p.mu-equivalent_2}] Since $\phi $ is surjective, so is $\phi _i:S_i((A_2,\mathbf {b}_2),G_2)\to S_i((A_1,\mathbf {b}_1),G_1)$ for $i\in [1,m_1]$. Since $\phi _i$ is affine, $|\{y_i\in S_i((A_2,\mathbf {b}_2),G_2) : \phi _i(y_i)=x_i\}|$ is the same for each $x_i\in S_i((A_1,\mathbf {b}_1),G_1)$. As $\phi $ and $\phi _i$ are affine homomorphisms, given $\mathbf {x}\in S((A_1,\mathbf {b}_1),G_1)$, the solutions $\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2)$ such that $\phi (\mathbf {y})=\mathbf {x}$ can be partitioned into \begin {multline} \label {e.union} \left \{\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2) : \phi (\mathbf {y})=\mathbf {x}\right \}= \\ \bigcup _{\substack {y_i \in S_i((A_2,\mathbf {b}_2),G_2)\\ \phi _i(y_i)=(\mathbf {x})_i}} \left \{\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2)\; :\; \phi (\mathbf {y})=\mathbf {x} \text { and } (\mathbf {y})_i=y_i \right \}. \end {multline} By the assumptions, the size of the sets $\left \{\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2)\; :\; \phi (\mathbf {y})=\mathbf {x} \text { and } (\mathbf {y})_i=y_i \right \}$ is independent of each $y_i$ with $\phi _i(y_i)=(\mathbf {x})_i$ and we denote it by $\mu _i$. Therefore (\ref {e.union}) is an equipartition. Let $\beta _i=|S_i((A_2,\mathbf {b}_2),G_2)|/|S_i((A_1,\mathbf {b}_1),G_1)|$ be the number of preimages by $\phi _i$ of each $x_i\in S_i((A_1,\mathbf {b}_1),G_1)$ in $S_i((A_2,\mathbf {b}_2),G_2)$. Then $\mu _i$ is such that $\mu _i\beta _i=\mu $. \par \par Let $(K',H',\gamma ',l',r',Q',p',c')$ be the vector defining the $\gamma '$-strong-representation for $((A_2,\mathbf {b}_2),G_2)$. Let $s$ be the uniformity of the edges of $H'$. The candidate vector $(K,H,\gamma ,l,r,Q,p,c)$ is defined as follows. \begin {itemize} \item $Q=Q'$, $c=c'$, \item $\gamma _i=\gamma '_i \frac {|S_i((A_2,\mathbf {b}_2),G_2)|}{|S_i((A_1,\mathbf {b}_1),G_1)|}\frac {|G_1|}{|G_2|}$ for $i\in [1,m_1]$. $p=\mu p'\frac {|G_2|^{m_1-1}}{|G_1|^{m_1-1}}\left [\prod _{i=m_1+1}^{m_2}\gamma _i'\right ] \left [\prod _{i=1}^{m_1} \frac {|S_i((A_1,\mathbf {b}_1),G_1)|}{|S_i((A_2,\mathbf {b}_2),G_2)|}\right ]$. \par \item $H$ and $K$ are hypergraphs on the same vertex sets as $H'$ and $K'$ respectively. $e=\{v_1,\ldots ,v_s\}$ is an edge in $K$ (respectively $H$) coloured $i\in [1,m_1]$ if and only if $e$ is an edge coloured $i\in [1,m_1]$ in $K'$ (respectively $H'$.) \item $l(e)=\phi _i(l'(e))$ if $e$ is an edge coloured $i\in [1,m_1]$ as an edge in $K'$. \item Given $H_0\in C(H,K)$, let $H_0'$ be the unique copy of $H'$ in $K'$ spanned by the vertices of $H_0$. Then $r_q(H_0)=r_q'(H_0')$. \end {itemize} \par RP\ref {prop_rep1} is satisfied for $(K,H)$ with the same bounds and the labelling function $l'$. By the hypothesis (\ref {h.1}), each copy of $H'$ in $K'$ spans a unique copy of $H$ in $K$ and vice-versa. Since \begin {equation} \label {e.345} r^{-1}(\mathbf {x},q)=\bigcup _{\mathbf {y}\in \phi ^{-1}(S((A_1,\mathbf {b}_1),G_1))\cap S((A_2,\mathbf {b}_2),G_2)} r'^{-1}(\mathbf {y},q) \end {equation} and there are $\mu $ different $\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2)$ with $\phi (\mathbf {y})=\mathbf {x}$, then the union (\ref {e.345}) is disjoint and \begin {displaymath} |r^{-1}(\mathbf {x},q)|=\mu |r'^{-1}(\mathbf {y},q)|=\mu p' c\frac {|K'|^s}{|G_2|}\prod _{i=1}^{m_2} \gamma _i'. \end {displaymath} as each set $r'^{-1}(\mathbf {y},q)$ contains $p' c\frac {|K'|^s}{|G_2|}\prod _{i=1}^{m_2} \gamma _i'$ copies of $H'$ in it. \par \par \par By the definition of $\gamma $ and $p$ we have \begin {multline} |r^{-1}(\mathbf {x},q)|=\mu p' c\frac {|K'|^s}{|G_2|}\prod _{i=1}^{m_2} \gamma _i'= \\ \mu p' \frac {|K|^{s}}{|G_2|} \left [\prod _{i=m_1+1}^{m_2} \gamma _i' \right ] \left [\prod _{i=1}^{m_1}\gamma _i\frac {|S_i((A_1,\mathbf {b}_1),G_1)|}{|S_i((A_2,\mathbf {b}_2),G_2)|} \right ] \frac {|G_2|^{m_1}}{|G_1|^{m_1}} =p c\frac {|K|^s}{|G_1|}\prod _{i=1}^{m_1} \gamma _i. \end {multline} Since $r'$ is a $\gamma '$-representation function and $\phi =(\phi _1,\ldots ,\phi _{m_1})$ defines the $\mu $-equivalence between systems (in particular, is surjective), RP\ref {prop_rep2} is satisfied for $r$. \par Given $\mathbf {x}\in S((A_1,\mathbf {b}_1),G_1)$ and $q\in Q$, let $e_i$ be an edge coloured $i$ and with $l(e_i)=(\mathbf {x})_i$. $H_0$, a copy of $H$ in $K$, belongs to $r( \mathbf {x},q)$ and contains $e_i$ if and only if $H_0$, as a copy of $H'$ in $K'$, contains $e_i$ and belongs to one of the $r'^{-1}(\mathbf {y},q)$ with $\phi (\mathbf {y})=\mathbf {x}$. Since $((A_2,\mathbf {b}_2),G_2)$ is $\gamma '$-strongly-represented, each set $r'^{-1}(\mathbf {y},q)$ with $(\mathbf {y})_i=l'(e_i)$ contains an $H_0'$, a copy of $H'$ in $K'$, with $e_i\in H_0'$. By RP\ref {prop_rep3}, there are $p' \frac {\prod _{j=1}^{m_2} \gamma _j'}{\gamma _i'}$ copies of $H'$ containing $e_i$ in any set $r'^{-1}(\mathbf {y},q)$ whenever $(\mathbf {y})_i=l'(e_i)$. \par \par There are $\mu _i=\mu /\beta _i$ solutions $\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2)$ such that $\phi (\mathbf {y})=\mathbf {x}$ with $(\mathbf {y})_i=l'(e_i)$. Therefore, there is a total of \begin {align} \mu _i &p' \frac {\prod _{j=1}^{m_2} \gamma _j'}{\gamma _i'} =\frac {\mu }{\beta _i} p' \left [\prod _{j=m_1+1}^{m_2} \gamma _j' \right ]\frac {\prod _{j=1}^{m_1} \gamma _j'}{\gamma _i'}\nonumber \\ &= \mu {p'} \left [\prod _{j=m_1+1}^{m_2} \gamma _j'\right ] \frac {\left [\prod _{j=1}^{m_1} \gamma _j' \right ] \left [\prod _{j=1}^{m_1}\frac { |S_j((A_2,\mathbf {b}_2),G_2)|}{ |S_j((A_1,\mathbf {b}_1),G_1)|}\right ] \frac {|G_1|^{m_1}}{|G_2|^{m_1}}}{\gamma _i' \beta _i \frac {|G_1|}{|G_2|} } \frac {|G_2|^{m_1-1}}{|G_1|^{m_1-1}} \prod _{j=1}^{m_1} \frac { |S_j((A_1,\mathbf {b}_1),G_1)|}{ |S_j((A_2,\mathbf {b}_2),G_2)|} \nonumber \\ &= p \frac {\prod _{j=1}^{m_1} \gamma _j}{\gamma _i} \nonumber \end {align} copies of $H'$ in $K'$ through $e_i$ that, seeing as copies of $H$ in $K$, belong to $r^{-1}(\mathbf {x},q)$. Hence, the vector $(K,H,\gamma ,l,r,Q,p,c)$ fulfills RP\ref {prop_rep3}. \par To show RP\ref {prop_rep4}, choose $q$ and let $e_i$ be an edge in $K$ and let $\mathbf {x}$ be a solution to $((A_1,\mathbf {b}_1),G_1)$ such that $(\mathbf {x})_i=l(e_i)$. By the surjectivity of $\phi $ there exists a $\mathbf {y}\in S((A_2,\mathbf {b}_2),G_2)$ with $\phi (\mathbf {y})=\mathbf {x}$. By the assumption (\ref {h.2}), we can choose the solution $\mathbf {y}$ such that $(\mathbf {y})_i=l'(e_i)$. Since $r'^{-1}(\mathbf {y},q)$ contains a copy $H_0'$ of $H'$ with $e_i\in H_0'$, then $r^{-1}(\mathbf {x},q)$ contains $H_0$, the copy of $H$ over the vertices of $H_0'$, and satisfies $e_i\in H_0$. This shows RP\ref {prop_rep4} and finishes the proof of Proposition~\ref {p.mu-equivalent_2}.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Proposition~\ref {p.hom_to_all}] Assume that $A\mathbf {x}=\mathbf {b}$ has a solution $\mathbf {y}=(\mathbf {y}_1,\ldots ,\mathbf {y}_m)$. The map $\phi : S((A,\mathbf {0}),G) \to S((A,\mathbf {b}),G)$ with $\phi ((\mathbf {x}_1,\ldots ,\mathbf {x}_m))=(\mathbf {x}_1+\mathbf {y}_1,\ldots ,\mathbf {x}_m+\mathbf {y}_m)$ defines a $1$-auto-equivalence.
END Proof
 
BEGIN Observation \protect \let \reserved@d = *\def \par 
BEGIN Remark \protect \let \reserved@d = *\def \par 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Proposition~\ref {p.union_systems_d_k}] Let $S=U^{-1}AV^{-1}$ be the Smith Normal Form of $A$, where $U$ and $V$ are integer unimodular matrices that convey, respectively, the row and column operations that transform $A$ into $S$. We have $S=\left (D|0\right )$, where $D$ is a $k\times k$ diagonal integer matrix with $\det (D)=D_k(A)$ and $0$ is an all--zero $k\times (m-k)$ matrix. $d_i$ is the $i$-th element in the main diagonal of $D$. Let $A^{\text {\tiny {(1)}}}=U^{-1}A=SV$. Notice that the system $A^{\text {\tiny {(1)}}}\textbf {x}=\mathbf {0}$ is equivalent to $A\textbf {x}=\mathbf {0}$. \par As $A^{\text {\tiny {(1)}}}$ has been obtained from $S$ by column operations using integer coefficients, the $j$-th row $A_j^\text {\tiny {(1)}}$ is formed by integer multiples of $d_j$. Since $V$ is unimodular, then \[\gcd \left (\left \{A_{j,i}^{\text {\tiny {(1)}}}\right \}_{i\in [1,m]}\right )=d_j,\] which proves the first part of the statement. Let $A^{\text {\tiny {(2)}}}$ be the matrix obtained by dividing each row $A_j^{\text {\tiny {(1)}}}$ by $d_j$. We have $A^{\text {\tiny {(2)}}}=S^{\text {\tiny {(2)}}}V$, where $S^{\text {\tiny {(2)}}}=\left (I_k|0\right )$ is the Smith Normal Form of $A^{\text {\tiny {(2)}}}$ and $I_k$ is the $k\times k$ identity matrix. This completes the proof.
END Proof
 
BEGIN Observation \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Observation~\ref {o.sol_set}] Let $\textbf {x}\in G^m$ be a solution to $A\mathbf {x}=\mathbf {0}$, or, equivalently, $A^{\text {\tiny {(1)}}}\mathbf {x}=\mathbf {0}$. Observe the $j$-th equation for $A^{\text {\tiny {(1)}}}$: \begin {displaymath} A^{\text {\tiny {(1)}}}_{j,1}x_1 + \cdots + A^{\text {\tiny {(1)}}}_{j,m} x_m=0 \iff d_j\left (A^{\text {\tiny {(2)}}}_{j,1}x_1+ \cdots + A^{\text {\tiny {(2)}}}_{j,m} x_m\right )=0. \end {displaymath} Thus, $A^{\text {\tiny {(2)}}}_{j,1}x_1+ \cdots + A^{\text {\tiny {(2)}}}_{j,m} x_m$ is an element of $\mathcal {P}_{d_j}(G)$. Doing the same for all the rows (equations) of the system gives us that $A^{\text {\tiny {(2)}}}\mathbf {x}=\mathbf {b}$ for some independent vector $\mathbf {b}$ in $\prod _{i=1}^k \mathcal {P}_{d_i}(G) \subset G^k$. Also, any solution to $A^{\text {\tiny {(2)}}}\mathbf {x}=\mathbf {b}$ for some $\mathbf {b}\in \prod _{i=1}^k \mathcal {P}_{d_i}(G)$ is a solution to $A^{\text {\tiny {(1)}}}\mathbf {x}=\mathbf {0}$ by multiplying the $i$-th equation by $d_i$.
END Proof
 
BEGIN Observation \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Observation~\ref {o.simul_small_tor_p-groups}] Since $G=\mathbb {Z}_{n}^{s}$ then $\mathcal {P}_{d_j}(G)\cong \mathbb {Z}_{\gcd (n,d_j)}^{s}$. Observe that the introduction of $\overline {y}_j$ in \begin {displaymath} A_{j,1}^{\text {\tiny {(2)}}}x_1+\cdots +A_{j,m}^{\text {\tiny {(2)}}}x_m -\overline {y}_j=0 \end {displaymath} with $\overline {y}_j\in \mathbb {Z}_{\gcd (n,d_j)}^{s}$ simulates the independent vector. \par As $\frac {n}{\gcd (n,d_j)}: \mathbb {Z}_{n}^{s} \to \mathbb {Z}_{\gcd (n,d_j)}^{s}$ with $\frac {n}{\gcd (n,d_j)}(g)=\frac {n}{\gcd (n,d_j)}g$ is a $|\mathcal {P}_{n/\gcd (n,d_j)}(G)|$-to-$1$ surjective homomorphism, we can replace the variable $\overline {y}_j\in \mathbb {Z}_{\gcd (n,d_j)}^{s}$ by the variable $y_j\in \mathbb {Z}_{n}^{s}$ multiplied by $\frac {n}{\gcd (n,d_j)}$ and obtain the two parts of the observation.
END Proof
 
BEGIN Remark \protect \let \reserved@d = *\def \par 
BEGIN Lemma \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Lemma~\ref {lem:ext-mat}] Let $S=UAV=(D|0)$ be the Smith Normal Form of $A$, where $U$ and $V$ are unimodular matrices and $D$ is a $k\times k$ diagonal matrix. Consider \begin {displaymath} S'=\begin {pmatrix} D & 0\\ 0 & I_{m-k}\\ \end {pmatrix}\; \text { and }\; U'=\begin {pmatrix} U & 0 \\ 0 & I_{m-k} \\ \end {pmatrix}. \end {displaymath} Then $N=U'^{-1} S' V^{-1}$ is an integer matrix as $U'$ is unimodular and satisfy the thesis of the lemma.
END Proof
 
BEGIN Remark \protect \let \reserved@d = *\def \par 
BEGIN Observation \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Observation~\ref {o.number_of_solutions}] Extend the matrix $A$ with Lemma~\ref {lem:ext-mat} to a $1$-auto-equivalent system \begin {displaymath} A'= \begin {pmatrix} A' & B & 0\\ 0 & M & I_{m-k}\\ \end {pmatrix} \text { with } \gcd \left (\det \begin {pmatrix} B \\ M \end {pmatrix},n\right )=1. \end {displaymath} Select a value for $x_1,\ldots ,x_k$ and any value for the last $m-k$ variables of $A'$. Then the value of the variables $x_{k+1},\ldots ,x_{k+m}$ in $\Z _n$ is uniquely determined as the determinant is coprime with $n$.
END Proof
 
BEGIN Remark \protect \let \reserved@d = *\def \par 
BEGIN Remark \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Remark~\ref {r.prop.G3}] The variables with indices $[k^{\text {\tiny {(6)}}}+1,m^{\text {\tiny {(6)}}}]$ from $(A^{\text {\tiny {(6)}}},G_{\kappa }^t)$ parameterize the solution set $(A^{\text {\tiny {(6)}}},G_{\kappa }^t)$. This is, any choice of $x_{(k^{\text {\tiny {(6)}}}+1,\cdot )},\ldots ,x_{(m^{\text {\tiny {(6)}}},\cdot )}\in G_{\kappa }^t$ provide a unique solution to $(A^{\text {\tiny {(6)}}},G_{\kappa }^t)$. The same holds true for the variables indexed by $[k^{\text {\tiny {(J)}}}+1,m^{\text {\tiny {(J)}}}]$ in the system $(J_{\kappa },G_\kappa ^t)$. \par Assume $(i,j)\in \Upsilon \setminus \{(1,0)\}$. The $(i,j)$-th equation for $(A^{\text {\tiny {(6)}}},G_{\kappa }^t)$ can be written as \begin {displaymath} x_{(i,j)}+d_{i,j} B_{[(i-1)t+j]}^{\text {\tiny {(2)}}}\cdot \left (x_{(k^{\text {\tiny {(6)}}}+1,j)},\ldots ,x_{(m^{\text {\tiny {(6)}}},j)}\right )^{\top }=0 \end {displaymath} On the other hand, the $(i,j)$-th equation in $(J_{\kappa },G_{\kappa }^t)$ is \begin {displaymath} \left \{\begin {array}{cr} \left .\begin {array}{c} y_{(i,j)} + B_{\kappa ,[(i-1)t+j]}^{\text {\tiny {(3)}}}\cdot \left (y_{(k^{\text {\tiny {(J)}}}+1,j)},\ldots ,y_{(m^{\text {\tiny {(J)}}},j)}\right )^{\top }= \\ =y_{(i,j)} + B_{[(i-1)t+j]}^{\text {\tiny {(2)}}}\cdot \left (y_{(k^{\text {\tiny {(J)}}}+1,j)},\ldots ,y_{(m^{\text {\tiny {(J)}}}-1,j)}\right )^{\top } =0 \end {array}\right \} & \text { if } (i,j)\neq \kappa \\ \par \left .\begin {array}{c} y_{(i,j)} + B_{\kappa ,[(i-1)t+j]}^{\text {\tiny {(3)}}}\cdot \left (y_{(k^{\text {\tiny {(J)}}}+1,j)},\ldots ,y_{(m^{\text {\tiny {(J)}}},j)}\right )^{\top }= \\ y_{(i,j)} + d_{i,j} B_{[(i-1)t+j]}^{\text {\tiny {(2)}}}\cdot \left (y_{(k^{\text {\tiny {(J)}}}+1,j)},\ldots ,y_{(m^{\text {\tiny {(J)}}}-1,j)}\right )^{\top }-y_{(m^{\text {\tiny {(J)}}},j)}=0 \end {array}\right \} & \text { if } (i,j)= \kappa . \\ \end {array}\right . \end {displaymath} Therefore, if we let $\left (x_{(k^{\text {\tiny {(6)}}}+1,\cdot )},\ldots ,x_{(m^{\text {\tiny {(6)}}},\cdot )}\right )=\left (y_{(k^{\text {\tiny {(J)}}}+1,\cdot )},\ldots ,y_{(m^{\text {\tiny {(J)}}}-1,\cdot )}\right )$, the variables $y_{(i,j)}$ and $x_{(i,j)}$ are such that $d_{i,j}y_{(i,j)}=x_{(i,j)}$ for $(i,j)\neq \kappa $. If $(i,j)=\kappa $, then $d_{i,j}G_{\kappa }=0$ and $(\mathbf {x})_{\kappa }=0=d_{i,j} (\mathbf {y})_{\kappa }$ for any pair of solutions $\mathbf {x}\in S(A^{\text {\tiny {(6)}}},G_{\kappa }^t)$ and $\mathbf {y}\in S(J_{\kappa },G_{\kappa }^t)$. This shows that the map $f_{\kappa }$ exists. \par \par Since $f_{\kappa }$ maps the subset of parameterizing variables $(y_{(k^{\text {\tiny {(J)}}}+1,\cdot )},\ldots ,y_{(m^{\text {\tiny {(J)}}}-1,\cdot )})$ to the parameterizing variables $(x_{(k^{\text {\tiny {(6)}}}+1,\cdot )},\ldots ,x_{(m^{\text {\tiny {(6)}}},\cdot )})$ using the identity map, $f_{\kappa }$ is surjective. Moreover, since the image by $f_{\kappa }$ is independent of the variable $y_{(m^{\text {\tiny {(J)}}},\cdot )}$, the map is $|G_{\kappa }^t|$-to-$1$.
END Proof
 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Proposition~\ref {p.constr_c}] Consider the square matrix formed by the column blocks $A^{[i,i+k-1]}=(A^{[i]},\linebreak [1]\ldots ,\linebreak [1]A^{[i+k-1]})$ with $i\in [1,m]$. By assumption $A^{[i,i+k-1]}$ is a square non-singular matrix as it has non-zero determianant. For the $j$-th vector in the column block $A^{[i+k]}$, $A^{[i+k],j}$, with $j\in [1,t]$, we can find rational coefficients $b_{(i-1)t+w,(i+k-1)t+j}$, $w\in [1,kt]$, with \begin {displaymath} A^{[i+k],j}=\sum _{w\in [1,kt]} b_{(i-1)t+w,(i+k-1)t+j}\; A^{[i,i+k-1],w} \end {displaymath} where $A^{[i,i+k-1],w}$ stands for the $w$-th column in $A^{[i,i+k-1]}$ and corresponds to the $((i-1)t+w)$-th column in $A$. Moreover, since the determinant is coprime with $n$, there exists an integer $c_{(i+k-1)t+j,(i+k-1)t+j}$, coprime with $n$, such that \begin {equation}\label {e.coeff_C} -c_{(i+k-1)t+j,(i+k-1)t+j}\; A^{[i+k],j}=\sum _{w\in [1,kt]} c_{(i-1)t+w,(i+k-1)t+j}\; A^{[i,i+k-1],w} \end {equation} where, for $w\in [1,kt]$, $c_{(i-1)t+w,(i+k-1)t+j}=-c_{(i+k-1)t+j,(i+k-1)t+j} \; b_{(i-1)t+w,(i+k-1)t+j}$ are integers. \par The coefficients of the matrix $C$ are \begin {enumerate}[(a)] \item $c_{w_1,w_2}$ whenever the subscripts $(w_1,w_2)$ coincide with one the $c$'s found in the relations given by (\ref {e.coeff_C}) for the $mk$ column vectors of $A$. \item \label {c.matrix_c.2} $0$ otherwise. \end {enumerate} Consider the matrix $C$ as divided into $t\times t$ blocks $\mathcal {C}_{\cdot ,\cdot }\;$. $C$ satisfy property \ref {p.p1}. Indeed, given a column of $C$ indexed by $j=j_1t+j_2$, with $j_1\in [0,m-1]$ and $j_2\in [1,t]$, the indices $i$ of the rows involved in the relations given by (\ref {e.coeff_C}) satisfy $i\in [(j_1-k)t,(j_1+1)t]$. \par The relation (\ref {e.coeff_C}) can be rearranged as \begin {displaymath} 0=c_{(i+k-1)t+j,(i+k-1)t+j} A^{[i+k],j}+\sum _{w\in [1,kt]} c_{(i-1)t+w,(i+k-1)t+j} A^{[i,i+k-1],w} \end {displaymath} and can be extended to $\sum _{w\in [1,tm]} c_{w,(i+k-1)t+j} A^l$ considering that all the other $c$'s that appear in the sum are zero by (\ref {c.matrix_c.2}). Thus \ref {p.p0} is satisfied. \par Observe that $\mathcal {C}_{i,i}$ is a diagonal matrix where all the elements in the diagonal are coprime with $n$. Hence the first part of property \ref {p.p2} is satisfied. To show the second part observe that, for each $i\in [1,m]$, indices modulo $m$, \begin {displaymath} \begin {pmatrix} A^{[i-k]} & \cdots & A^{[i-1]} \end {pmatrix} \begin {pmatrix} 0 & 0 & \cdots & 0 & \mathcal {C}_{i-k,i} \\ & & I_{t(k-1)} & & \vdots \\ & & & & \mathcal {C}_{i-1,i} \\ \end {pmatrix} = \begin {pmatrix} A^{[i-k+1]} & \cdots & A^{[i-1]} & \overline {A}^{[i]} \end {pmatrix} \end {displaymath} where the columns of $\overline {A}^{[i]}$ are multiples of the columns of $A^{[i]}$ by (\ref {e.coeff_C}). Indeed, $\overline {A}^{[i],j}= -c_{(i-1)t+j,(i-1)t+j} A^{[i],j}$. Therefore \begin {displaymath} \det \begin {pmatrix} A^{[i-k+1]} & \cdots & A^{[i-1]} & \overline {A}^{[i]} \end {pmatrix} = \det \begin {pmatrix}A^{[i-k+1]} & \cdots & A^{[i-1]} & A^{[i]}\end {pmatrix} \prod _{j\in [1,t]}c_{(i-1)t+j,(i-1)t+j} \end {displaymath} which is a product of integers coprime with $n$. Since \begin {displaymath} \det \begin {pmatrix} 0 & 0 & \cdots & 0 & \mathcal {C}_{i-k,i} \\ & & I_{t(k-1)} & & \vdots \\ & & & & \mathcal {C}_{i-1,i} \\ \end {pmatrix}= \pm \det (\mathcal {C}_{i-k,i}) \end {displaymath} and $(\pm \det (\mathcal {C}_{i-k,i}))\cdot \det \begin {pmatrix} A^{[i-k]} & \cdots & A^{[i-1]} \end {pmatrix} =\det \begin {pmatrix} A^{[i-k+1]} & \cdots & A^{[i-1]} & \overline {A}^{[i]} \end {pmatrix}$, then $\det (\mathcal {C}_{i-k,i})$ is an integer coprime with $n$. This proves the second part of \ref {p.p2} and finalizes the proof of the proposition.
END Proof
 
BEGIN Lemma \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Lemma~\ref {lem:ext3}] We detail the construction of $T$. Let us define the matrices $r-i\times r$ matrices \begin {displaymath} M^i=\begin {pmatrix} M^i_{i+1} \\ \vdots \\ M^i_r \\ \end {pmatrix},\; i\in [0,r-1], \end {displaymath} together with the rows $T_{i+1}$ inductively. Let $M^0=M$. Let $d_i=\gcd (M^{i-1}_{i,i},\ldots ,M^{i-1}_{r,i})$, $i\in [1,r]$, be the greatest common divisor of the column $M_{\cdot ,i}^{i-1}$. Let \begin {displaymath} T_{i}=\lambda _{i}^{i} M^{i-1}_{i}+ \cdots + \lambda _r^{i} M^{i-1}_{r} \end {displaymath} where $\lambda _{i}^{i}, \ldots ,\lambda _r^{i}$ are such that \begin {equation} \label {eq.6} \lambda _{i}^{i} M^{i-1}_{i,i}+ \cdots + \lambda _r^{i} M^{i-1}_{r,i}=d_{i} \end {equation} and where $\lambda _{i}^{i}$ is some prime, $p_{i}$, larger than $n$. This $p_{i}$ exists, subjected to the constrain (\ref {eq.6}), by the Dirichlet theorem regarding the containment of infinitely many primes in the arithmetic progressions $a+b\Z $ with $\gcd (a,b)=1$. Observe that \begin {displaymath} \det \begin {pmatrix} M^{i-1}_{i} \\ \vdots \\ M^{i-1}_r\\ T_1\\ \vdots \\ T_{i-1} \end {pmatrix} =p_{i} \det \begin {pmatrix} M^{i-1}_{i+1} \\ \vdots \\ M^{i-1}_r\\ T_1\\ \vdots \\ T_{i} \end {pmatrix} \end {displaymath} \par \par \par The rows of the matrix $M^i$, denoted by $M^i_j$, are $M^i_{j}=M^{i-1}_j - (M^{i-1}_{j,i}/d_i) T_i$, for $j\in [i+1,r]$ and with $T_0=\mathbf {0}$. The first $i$ columns of $M^i$ are the zero columns. \par Observe that $\gcd (d_i,n)=1$ as \begin {displaymath} \det \begin {pmatrix} M^{i-1}_{i+1}\\ \vdots \\ M^{i-1}_{r}\\ T_1\\ \vdots \\ T_i\\ \end {pmatrix}=\det \begin {pmatrix} M^i_{i+1} \\ \vdots \\ M^i_r\\ T_1\\ \vdots \\ T_i\\ \end {pmatrix} \end {displaymath} is coprime with $n$ and the original matrix $M$ has determinant coprime with $n$. Therefore the equivalent matrix \begin {displaymath} \begin {pmatrix} M^i_{i+1} \\ \vdots \\ M^i_r\\ T_1\\ \vdots \\ T_i\\ \end {pmatrix} \sim \begin {pmatrix} M_{i+1} \\ \vdots \\ M_r\\ T_1\\ \vdots \\ T_i\\ \end {pmatrix} \end {displaymath} also has a determinant coprime with $n$. This shows the property regarding the coprimality of the determinant of consecutive rows for the first $r$ rows constructed in this way, $T_1,\ldots ,T_r$. Observe that \begin {displaymath} T_i=(\overbrace {0 \; \cdots \; 0}^{i-1}\; d_i \; \ast \; \cdots \; \ast ). \end {displaymath} Since each $d_i$ is coprime with $n$, we can add the identity matrix after the matrix $T$ and the claimed properties are satisfied. The matrix $S$ is built similarly but we start from the last column and we construct a lower diagonal matrix $S$.
END Proof
 
BEGIN Remark \protect \let \reserved@d = *\def \par 
BEGIN Remark \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Remark~\ref {r.last}] The system $(A^{\text {\tiny {(7)}}},G^t)$ is formed by joining the systems $\{(\overline {J}_\kappa ,G_{\kappa }^t)\}_{\kappa \in \Upsilon }$ together. The $k^{\text {\tiny {(J')}}}\times m^{\text {\tiny {(J')}}}$ system $(\overline {J}_\kappa ,G_{\kappa }^t)$ is $1$-auto-equivalent to $(J_\kappa ,G_{\kappa }^t)$ by Remark~\ref {r.ext_matrix_auto} for any $\kappa \in \Upsilon $.\footnote { Indeed, $(\overline {J}_{\kappa },G_{\kappa }^t)$ is built from $(J_{\kappa },G_{\kappa }^t)$ by adding some variables and the same number of equations in a way that the new equations are: new variable equal linear equation involving old variables. Therefore, a projection onto the right variables using the identity as maps $\phi _i$ configure the application $\phi $ of the $1$-auto-equivalence.} Let $\phi '_{\kappa }$ be the map defining the $1$-auto-equivalence from $S(\overline {J}_{\kappa },G_{\kappa }^t)$ to $S(J_{\kappa },G_{\kappa }^t)$ \par \par \par \par \par Any solution $\mathbf {x}\in S(A^{\text {\tiny {(7)}}},G^t)$ induces $(mt+1)$ solutions $\overline {\mathbf {x}}_\kappa \in S(\overline {J}_{\kappa },G_{\kappa }^t)$ and vice-versa. By the $1$-auto-equivalence, these solutions can be seen in $(J_{\kappa },G_{\kappa }^t)$ considering $\mathbf {x}_\kappa =\phi _{\kappa }'(\overline {\mathbf {x}}_\kappa )\in S(J_{\kappa },G_{\kappa }^t)$. We use the maps $f_{\kappa }$ from Remark~\ref {r.prop.G3} to conclude that \begin {displaymath} \phi (\mathbf {x})=\sum _{\kappa \in \Upsilon } f_{\kappa }(\mathbf {x}_\kappa )\in S(A^{\text {\tiny {(6)}}},\Z _n^t) \end {displaymath} as $\phi $ is the sum over $\Upsilon $ of the compositions of the homomorphisms $f_{\kappa }$ with the $\phi _{\kappa }'$. \par Since the homomorphism $f_{(1,0)}$ associated to $(J_{(1,0)},\Z _n^t)=(J_{(1,0)},G_{(1,0)}^t)$ is surjective, so is $\phi $.\footnote {Observe that $S(J_{\kappa },G_{\kappa }^t)$ contains the trivial solution $\mathbf {0}$ and $\{f_{\kappa }\}_{\kappa \in \Upsilon }$ are homomorphisms.} As $\phi $ is a homomorphism, $\phi $ is $\mu $-to-$1$ for $\mu =|S(A^{\text {\tiny {(7)}}},G^t)|/|S(A^{\text {\tiny {(6)}}},\Z _n^t)|$. \par Let us show the second part of the result for $\mathbf {x}\in S(A^{\text {\tiny {(6)}}},\Z _n^t)$. Given $\mathbf {y}_{\kappa }\in S(J_{\kappa },G_{\kappa }^t)$, $(\mathbf {y}_{\kappa })_{i}\in G_{\kappa }^t$, $i\in [1,m^{\text {\tiny {(J)}}}]$, denotes the $i$-th coordinate of $\mathbf {y}_{\kappa }$ and $(\mathbf {y}_{\kappa })_{i,j}\in G_{\kappa }$ denotes the $(i,j)$-th coordinate of the solution with $(i,j)\in [1,m^{\text {\tiny {(J)}}}]\times [1,t]$. \par \par \par \par Any collection of solutions $\mathbf {y}_{\kappa }\in S(J_{\kappa },G_{\kappa }^t)$ induce a unique $\mathbf {y}\in (A^{\text {\tiny {(7)}}},G^t)$. The variables indexed in $[k^{\text {\tiny {(6)}}}+1,m^{\text {\tiny {(6)}}}]$ parameterize the solutions in $S(A^{\text {\tiny {(6)}}},\Z _n^t)$. Therefore, if we have \begin {equation}\label {eq.x_as_sum_y} (\mathbf {x})_i=\sum _{\kappa \in \Upsilon } (\mathbf {y}_{\kappa })_{i+1}, \text { for all } i\in [k^{\text {\tiny {(6)}}}+1,m^{\text {\tiny {(6)}}}] \end {equation} for our selected $\mathbf {x}$, then $\phi (\mathbf {y})=\mathbf {x}$. The condition (\ref {eq.x_as_sum_y}) is also necessary; if the collection of solutions $\{\mathbf {y}_{\kappa }\}_{\kappa \in \Upsilon }$ inducing $\mathbf {y}$ does not satisfy (\ref {eq.x_as_sum_y}) for some index $i\in [k^{\text {\tiny {(6)}}}+1,m^{\text {\tiny {(6)}}}]$, then $\phi (\mathbf {y})\neq \mathbf {x}$. The variables that parameterize the solutions for any system $(J_{\kappa },G_{\kappa }^t)$ are those indexed in $[k^{\text {\tiny {(J)}}}+1,m^{\text {\tiny {(J)}}}]$; once the value of $(\mathbf {y}_{\kappa })_i$ is selected for $i\in [k^{\text {\tiny {(J)}}}+1,m^{\text {\tiny {(J)}}}]$, the solution $\mathbf {y}_\kappa \in S(J_{\kappa },G_{\kappa }^t)$ exists and is unique. As the proof of Remark~\ref {r.prop.G3} highlights, the variable $m^{\text {\tiny {(J)}}}$ does not appear in (\ref {eq.x_as_sum_y}); the value of $\phi (\mathbf {y})$ is independent of the values $(\mathbf {y}_{\kappa })_{m^{\text {\tiny {(J)}}}}$ for $\kappa \in \Upsilon $. \par \par \par \par \par Pick an $i\in [k^{\text {\tiny {(6)}}}+1,m^{\text {\tiny {(6)}}}]$ and a value for $(\mathbf {y})_{i+1}\in G^t$ such that $\phi _i((\mathbf {y})_{i+1})=(\mathbf {x})_i$. All the solutions $\mathbf {y}\in S(A^{\text {\tiny {(7)}}},G^t)$ with $\phi (\mathbf {y})=\mathbf {x}$ can be found by selecting a value for the remaining parameterizing variables $(\mathbf {y})_{i_1}$ with $i_1\in [k^{\text {\tiny {(J)}}}+1,m^{\text {\tiny {(J)}}}]\setminus \{i+1\}$ appropriately to configure a solution in $S(A^{\text {\tiny {(7)}}},G^t)$ with $\phi (\mathbf {y})=\mathbf {x}$. For $i_1\in [k^{\text {\tiny {(J)}}}+1,m^{\text {\tiny {(J)}}}-1]\setminus \{i+1\}$, we can select any $(\mathbf {y})_{i_1}\in G^t$ as long as \begin {displaymath} (\mathbf {x})_{i_1-1}=\sum _{\kappa \in \Upsilon } (\mathbf {y}_{\kappa })_{i_1}=\phi _{i_1-1}((\mathbf {y})_{i_1}). \end {displaymath} Additionally, we can select any value for $(\mathbf {y})_{m^{\text {\tiny {(J)}}}}$. Observe that the number of choices is independent on the particular value $(\mathbf {y})_{l+1}$ with $\phi _l((\mathbf {y})_{l+1})=(\mathbf {x})_l$ we have picked. \par \par \par Given $\mathbf {x}\in S(A^{\text {\tiny {(6)}}},\Z _n^t)$, $i\in [1,k^{\text {\tiny {(6)}}}]$ and any $y^{(i)}\in G^t$ with $\phi _i(y^{(i)})=(\mathbf {x})_i$ we shall find all the solutions $\mathbf {y}\in S(A^{\text {\tiny {(7)}}},G^t)$ with $\phi (\mathbf {y})=\mathbf {x}$ and $(\mathbf {y})_i=y^{(i)}$. For $\kappa \in [1,m]\times [1,t]$, select any solution $\mathbf {y}_{\kappa }'''\in S(J_{\kappa },G_{\kappa }^t)$ such that \begin {equation}\label {eq.23} (\mathbf {y}_{\kappa }''')_{i}=y^{(i)}_{\kappa }. \end {equation} Pick an auxiliary solution $\mathbf {y}_{(1,0)}'\in S(J_{(1,0)},G_{(1,0)}^t)$, defined by the last $m^{\text {\tiny {(J)}}}-k^{\text {\tiny {(J)}}}$ variables, \begin {itemize} \item choosing a value for $(\mathbf {y}_{(1,0)}')_{m^{\text {\tiny {(J)}}}}$ in $\Z _n^t$ (any value.) \item $(\mathbf {y}_{(1,0)}')_{j+1}=(\mathbf {x})_{j}-\sum _{\kappa \in \Upsilon \setminus \{(1,0)\}}(\mathbf {y}_{\kappa }''')_{j+1}$ for $j\in [k^{\text {\tiny {(6)}}}+1,m^{\text {\tiny {(6)}}}]$. \end {itemize} Let $\mathbf {y}'$ be the solution in $S(A^{\text {\tiny {(7)}}},G^t)$ defined by the $mt+1$ solutions $\{\mathbf {y}_{(1,0)}',\{\mathbf {y}_{\kappa }'''\}_{\kappa \in \Upsilon \setminus \{(1,0)\}}\}$. Observe that $\phi (\mathbf {y}')=\mathbf {x}$. Indeed, for $j\in [k^{\text {\tiny {(6)}}}+1,m^{\text {\tiny {(6)}}}]$, \begin {displaymath} \phi _{j}(\mathbf {y}')=(\mathbf {y}_{(1,0)}')_{j+1}+\sum _{\kappa \in \Upsilon \setminus \{(1,0)\} } (\mathbf {y}_{\kappa }''')_{j+1}=(\mathbf {x})_{j} -\sum _{\kappa \in \Upsilon \setminus \{(1,0)\} } (\mathbf {y}_{\kappa }''')_{j+1}+\sum _{\kappa \in \Upsilon \setminus \{(1,0)\} } (\mathbf {y}_{\kappa }''')_{j+1}= (\mathbf {x})_{j}. \end {displaymath} Since $\phi (\mathbf {y}')\in S(A^{\text {\tiny {(6)}}},\Z _n^t)$ and $\mathbf {x}$ is unique given the value of its last $m^{\text {\tiny {(6)}}}-k^{\text {\tiny {(6)}}}$ variables, the claim follows and we have a solution $\mathbf {y}'\in S(A^{\text {\tiny {(7)}}},G^t)$ such that $\phi (\mathbf {y}')=\mathbf {x}$. \par However, it is not yet clear that $(\mathbf {y})_i=y^{(i)}$; by (\ref {eq.23}), we know this equality holds for all coordinates in $\Upsilon \setminus (1,0)$. If $\mathbf {y}_{(1,0)}'$ would be such that $(\mathbf {y}_{(1,0)}')_j=y^{(i)}_{(1,0)}$, then the solution $\mathbf {y}'\in S(A^{\text {\tiny {(7)}}},G^t)$ defined before satisfies the claims $\phi (\mathbf {y}')=\mathbf {x}$ and $(\mathbf {y}')_i=y^{(i)}$. Let us define $\epsilon _{i,j}=\epsilon _{i,j}(\mathbf {x},\{\mathbf {y}_{\kappa }'''\}_{\kappa \in \Upsilon \setminus \{(1,0)\}},y^{(i)})$, for $j\in [1,t]$, as the difference between the $j$-th components of the $i$-th coordinate of $\mathbf {y}_{(1,0)}'$ and its aimed value $(y^{(i)}_{(1,0)})_j$: \begin {displaymath} (\mathbf {y}_{(1,0)}')_{i,j}-(y^{(i)}_{(1,0)})_j=\epsilon _{i,j}(\mathbf {x},\{\mathbf {y}_{\kappa }'''\}_{\kappa \in \Upsilon \setminus \{(1,0)\}},y^{(i)}). \end {displaymath} Observe that $\epsilon _{i,j}\in G_{i,j}$. Indeed, \begin {displaymath} (\phi _i(y^{(i)}))_j=d_{i,j} \left (\sum _{\kappa \in \Upsilon } (y^{(i)}_{\kappa })_{j}\right )=(\mathbf {x})_{i,j}\stackrel {\phi (\mathbf {y}')=\mathbf {x}}{=}(\phi _i(\mathbf {y}'))_{j}=d_{i,j}\left ((\mathbf {y}'_{(1,0)})_{i,j}+\sum _{\kappa \in \Upsilon \setminus \{(1,0)\}} (y_{\kappa }^{(i)})_j\right ). \end {displaymath} Therefore $d_{i,j} \epsilon _{i,j}=d_{i,j} \left ((\mathbf {y}_{(1,0)}')_{i,j}-(y^{(i)}_{(1,0)})_j\right )=0$ as claimed. \par \par Using $\epsilon _{i,j}$ we pick, one for each $j\in [1,t]$, a total of $t$ auxiliary solutions $\mathbf {y}^{(j)}_{(1,0)}\in S(J_{(1,0)},G_{(i,j)}^t)\subset S(J_{(1,0)},G_{(1,0)}^t)$, such that \begin {itemize} \item $(\mathbf {y}_{(1,0)}^{(j)})_{m^{\text {\tiny {(J)}}}}=0$. \item $(\mathbf {y}_{(1,0)}^{(j)})_{i,j}=\epsilon _{i,j}$. \item $ (\mathbf {y}_{(1,0)}^{(j)})_{i,r}=0$ for $r\in [1,t]\neq j$.\footnote {There are $|G_{(i,j)}^t|^{m^{\text {\tiny {(J)}}}-k^{\text {\tiny {(J)}}}-2}$ such solutions for each $j\in [1,t]$ by Observation~\ref {o.number_of_solutions}. We only select one per each $j$.} \end {itemize} These $\{\mathbf {y}^{(j)}_{(1,0)}\}_{j\in [1,t]}$ exist because the greatest common divisor of the coefficients of the $((i-1)t+j)$-th row of $B^{\text {\tiny {(3)}}}_{(1,0)}$ from $J_{(1,0)}$, that define the $(i,j)$-th variable, is $1$. \par Consider the collection of $t$ solutions $\{\mathbf {y}_{(i,j)}''\}_{j\in [1,t]}$, $\mathbf {y}_{(i,j)}''\in S(J_{(i,j)},G_{(i,j)}^t)$, that are determined by sharing the last $m^{\text {\tiny {(J)}}}-k^{\text {\tiny {(J)}}}$ variables with $\mathbf {y}_{(1,0)}^{(j)}$: $(\mathbf {y}_{(i,j)}'')_r=(\mathbf {y}_{(1,0)}^{(j)})_{r}$ for $r\in [k^{\text {\tiny {(J)}}}+1,m^{\text {\tiny {(J)}}}]$. Observe that $(\mathbf {y}_{(i,j)}'')_i=0$ since \begin {itemize} \item $(\mathbf {y}_{(i,j)}'')_{i,j}=0$ as $(\mathbf {y}_{(i,j)}'')_{i,j}=(\mathbf {y}_{(i,j)}'')_{m^{\text {\tiny {(J)}}},1}=(\mathbf {y}_{(1,0)}^{j})_{m^{\text {\tiny {(J)}}},1}=0$. \item For $r\neq j$, the equations defining $(\mathbf {y}_{(i,j)}'')_{i,r}$ and $(\mathbf {y}_{(1,0)}^{(j)})_{i,r}$ from the last $m^{\text {\tiny {(J)}}}-k^{\text {\tiny {(J)}}}$ variables are the same. Since $(\mathbf {y}_{(1,0)}^{(j)})_{i,r}=0$, then so is $(\mathbf {y}_{(i,j)}'')_{i,r}$. \end {itemize} \par Let $\mathbf {y}$ be the solution in $S(A^{\text {\tiny {(7)}}},G^t)$ formed by \begin {itemize} \item $\mathbf {y}_{\kappa }=\mathbf {y}_{\kappa }'''$ for $\kappa \in ([1,m]\setminus \{i\})\times [1,t]$. \item $\mathbf {y}_{\kappa }=\mathbf {y}_{\kappa }''+\mathbf {y}_{\kappa }'''$ for $\kappa \in \{i\}\times [1,t]$. \item $\mathbf {y}_{(1,0)}=\mathbf {y}'_{(1,0)}-\sum _{j=1}^t \mathbf {y}_{(1,0)}^{(j)}$. \end {itemize} Observe that \begin {itemize} \item for $\kappa \in \Upsilon $, $\mathbf {y}_{\kappa }\in S(J_{\kappa },G_{\kappa }^t)$ as $\mathbf {y}_{(1,0)}^{(j)}\in S(J_{(1,0)},G_{(i,j)}^t)\subset S(J_{(1,0)},G_{(1,0)}^t)$ and $\mathbf {y}_{(i,j)}''\in S(J_{(i,j)},G_{(i,j)}^t)$ for all $j\in [1,t]$. \item $\phi (\mathbf {y})=\mathbf {x}$ as $\phi (\mathbf {y})\in S(A^{\text {\tiny {(6)}}},\Z _n^t)$ and, for $r\in [k^{\text {\tiny {(6)}}}+1,m^{\text {\tiny {(6)}}}]$, \begin {align} \phi _r(\mathbf {y})&=(\mathbf {y}_{(1,0)})_{r+1}+\sum _{\kappa \in ([1,m]\setminus \{i\})\times [1,t]} (\mathbf {y}_{\kappa })_{r+1}+\sum _{j\in [1,t]}(\mathbf {y}_{(i,j)})_{r+1} \nonumber \\ &= (\mathbf {y}_{(1,0)}')_{r+1}-\sum _{j=1}^t (\mathbf {y}_{(1,0)}^{(j)})_{r+1} +\nonumber \\ &\qquad +\sum _{\kappa \in ([1,m]\setminus \{i\})\times [1,t]} (\mathbf {y}_{\kappa }''')_{r+1}+\sum _{j\in [1,t]}\left ((\mathbf {y}_{(i,j)}'')_{r+1} + (\mathbf {y}_{(i,j)}''')_{r+1}\right ) \nonumber \\ &=(\mathbf {y}_{(1,0)}')_{r+1}+\sum _{\kappa \in \Upsilon \setminus \{(1,0)\}}(\mathbf {y}_{\kappa }''')_{r+1}=(\mathbf {x})_{r} \nonumber \end {align} \item $(\mathbf {y})_i=y^{(i)}$. Indeed, for $\kappa \in ([1,m]\setminus \{i\})\times [1,t]$, $(\mathbf {y}_{\kappa })_i=(\mathbf {y}_{\kappa }''')_i=y^{(i)}_{\kappa }$ by hypothesis. Since $(\mathbf {y}_{(i,j)}'')_i=0$, $(\mathbf {y}_{(i,j)})_i=(\mathbf {y}_{(i,j)}'')_i+(\mathbf {y}_{(i,j)}''')_i=y^{(i)}_{(i,j)}$ for $j\in [1,t]$. Additionally, for each $j\in [1,t]$, \begin {displaymath} (\mathbf {y}_{(1,0)})_{i,j}=(\mathbf {y}'_{(1,0)})_{i,j}-\sum _{r=1}^t (\mathbf {y}_{(1,0)}^{(r)})_{i,j}=(\mathbf {y}'_{(1,0)})_{i,j}-(\mathbf {y}_{(1,0)}^{(j)})_{i,j}=(\mathbf {y}'_{(1,0)})_{i,j}-\epsilon _{i,j}= (y^{(i)}_{(1,0)})_j. \end {displaymath} \end {itemize} \par Therefore, the set of solutions $\{\mathbf {y}_{\kappa }\}_{\kappa \in \Upsilon }$ provides a unique solution $\mathbf {y}$ with $\phi (\mathbf {y})=\mathbf {x}$ and $(\mathbf {y})_i=y^{(i)}$ as desired. Using Observation~\ref {o.number_of_solutions} on the matrices $J_{\kappa }$, the number of choices made to find $\mathbf {y}$ is independent of the particular $y^{(i)}$. Even more, the excesses $\epsilon _{i,j}$ define a quotient structure among the possible choices of $\{\mathbf {y}_\kappa '''\}_{\kappa \in \Upsilon \setminus \{(1,0)\}}$ and value for $(\mathbf {y}_{(1,0)}')_{m^{\text {\tiny {(J)}}}}$ (the other choices for the solutions $\mathbf {y}^{(j)}_{(1,0)}$ can be thought to be fixed depending on $\epsilon _{i,j}$.) This finishes the proof of the remark.
END Proof
 
BEGIN Remark \protect \let \reserved@d = *\def \par 
BEGIN Proposition \protect \let \reserved@d = *\def \par 
BEGIN Observation \protect \let \reserved@d = *\def \par 
BEGIN Proof 
 [Proof of Observation~\ref {lem:red2_ext_3}] Suppose $m\geq k+2$. By reordering the variables, assume that $I=[j,m]$ for some $j$. Represent the system $(A,G_0)$ by the $s$-uniform hypergraph pair $(K_0,H)$. By the construction in Section~\ref {s.final_composition} and Section~\ref {s.unwrap_const} and the comments in Section~\ref {s.adding_variables}, $H$ is connected and $K_0$ is $|H|$-partite. Let $V_1,\ldots ,V_{|H|}$ denote the stable sets in $K_0$ and recall that $|V_i|=|V_j|$ for $i,j\in [1,|H|]$. Let $K=K_0\left (\prod _{i=1}^m X_i\right )$ represent the hypergraph where only the edges labelled $x_i\in X_i$ and colored $i$ appear. Let $K'$ and $H'$ be the hypergraphs obtained by removing the edges colored $i\in [j,m]$ from $K$ and $H$ respectively. Assume $e_1=\{1,\ldots ,s\}\subset H$ is the edge related to $x_1$. \par \par Let $d$ be the number of vertices in $H'$ with no edges. By the construction of the representation from the $n$--circular matrix provided in the third part of Section~\ref {s.final_composition} and knowing that the deleted edges have the largest indices, the stable sets $V_i$ (clusters of vertices) of $K'$ with no edge incident with them are the consecutive ones $V_{|H|-d+1},\ldots ,V_{|H|}$. Since every subset of $s$ clusters from $K'$ span, at most, one color class of edges, the connected component of $H'$ has one vertex in each of the first $|H|-d$ clusters. The isolated vertices of $H'$ can be placed in any cluster $V_i, i\in [1,|H|]$. Thus, each copy of $H$ in $K\left (\prod _{i=1}^m X_i\right )$ generates ${|K|-(|H|-d) \choose d}\approx c'|K|^d$ copies of $H'$ in $K'$, for some constant $c'$. \par \par Let $H''$ be the hypergraph built from $H'$ by removing its isolated vertices. Let $K''$ be built from $K'$ by removing the isolated stables $V_{|H|-d+1},\ldots ,V_{|H|}$. Then $(K'',H'')$ is a representation of the system $(A,G_0)$ where $(x_1,\ldots ,x_{j-1})$ is a solution if and only if there is some $(x_j,\ldots ,x_m)\in G_0^{m-j+1}$ for which $(x_1,\ldots ,x_{j-1},x_j,\ldots ,x_m)$ is a solution. Indeed, we can extend any copy $H''$ in $K''$ to $\left |\prod _{i=|H|-d+1}^{|H|} V_i\right |=|V_i|^d=c|K|^d$ copies of $H$ in $K$ by selecting one additional vertex in each of the last $d$ clusters. Since $X_i=G_0$, $K$ has all the possible edges coloured $i\in I$ in the vertices $\{(\cdot ,j)\}_{j\in \{i_1,\ldots ,i_s\}}$, where $\{i_1,\ldots ,i_s\}$ is the support of the edge coloured $i$ in $H$. Therefore, any choice in $\prod _{i=|H|-d+1}^{|H|} V_i$ completes a copy of $H''$ in $K''$ to a copy of $H$ in $K$. On the other hand, any copy of $H$ in $K$ generates one copy of $H''$ in $K''$. Thus, \begin {displaymath} |C(H, K)|=|C(H'', K'')| \;|V_i|^d=|C(H'', K'')|\; c|K|^d \end {displaymath} and the proportions $|K|^{|H|}/|C(H, K)|$ and $|K''|^{|H''|}/|C(H'', K'')|$ are such that \begin {displaymath} \frac {|K|^{|H|}}{|C(H, K)|}=\frac {|K|^{|H|}}{c|K|^d |C(H'', K'')|}=c''\frac {|K''|^{|H''|}}{|C(H'', K'')|} \end {displaymath} where $c''$ only depends on $m$. \par Therefore, if $|S(A,G_0,\prod _{i=1}^{j-1} X_i\times G_0^{m-j+1})|<\delta |S(A,G_0)|$, then, by the representability for $(A,G_0)$ by $(K,H)$, $|C(H,K)|<\delta ' |K|^{|H|}$. Hence $|C(H'',K'')|<\delta '' |K''|^{|H''|}$. By applying the same procedure of Theorem~\ref {t.rep_sys_rem_lem} to $(K'',H'')$, we show a removal lemma by obtaining sets $X_i'\subset X_i$, $i\in [1,j-1]$, as those are the represented variables, such that $\prod _{i=1}^{j-1} X_i\setminus X_i'$ has no solution (for any value of the last variables.) Therefore, we obtain the additional property that $X_i'=\emptyset $ for $i\in [j,m]$.
END Proof
 
