arXiv:1711.11497v2 [math.OC] 12 Jan 2018

Exponential Lower Bounds on Spectrahedral Representations of
Hyperbolicity Cones ‚àó
Prasad Raghavendra
EECS
UC Berkeley

Nick Ryder
Mathematics
UC Berkeley

Nikhil Srivastava
Mathematics
UC Berkeley

Benjamin Weitz
Pinterest

January 15, 2018

Abstract
The Generalized Lax Conjecture asks whether every hyperbolicity cone is a section of a
semidefinite cone of sufficiently high dimension. We prove that the space of hyperbolicity cones
of hyperbolic polynomials of degree d in n variables contains (n/d)‚Ñ¶(d) pairwise distant cones
in the Hausdorff metric, and therefore that any semidefinite representation of such polynomials
must have dimension at least (n/d)‚Ñ¶(d) (even allowing a small approximation error). The cones
are perturbations of the hyperbolicity cones of elementary symmetric polynomials. Our proof
contains several ingredients of independent interest, including the identification of a large subspace in which the elementary symmetric polynomials lie in the relative interior of the set of
hyperbolic polynomials, and a quantitative generalization of the fact that a real-rooted polynomial with two consecutive zero coefficients must have a high multiplicity root at zero.

1

Introduction

A homogeneous polynomial p in R[x1 , . . . , xn ] is said to be hyperbolic with respect to a direction
e ‚àà Rn if p(e) 6= 0 and all its univariate restrictions along the direction e are real-rooted, i.e., for
every x ‚àà Rn , the polynomial px (t) = p(te + x) has all real roots. GaÃärding showed that every
hyperbolic polynomial p is associated with a closed1 convex cone Kp defined as follows,
Kp = {x ‚àà Rn | all roots of p(te + x) are non-positive}.
The cone Kp is referred to as the hyperbolicity cone associated with the polynomial p.
From the standpoint of convex optimization, hyperbolicity cones yield a rich family of convex
sets that one can efficiently optimize over ‚Äî in particular, interior point methods can be used to
efficiently optimize over the hyperbolicity cone Kp for a polynomial p, given an oracle to evaluate p
and its gradient and Hessian [GuÃàl97, Ren06]. This optimization primitive, referred to as hyperbolic
programming, captures linear and semidefinite programming
as special cases. Specifically, the
Q
hyperbolicity cone for the polynomial p(x1 , . . . , xn ) = ni=1 xi is the positive orthant Rn+ , which
corresponds to linear programming, while semidefinite programming arises from the symmetric
‚àó
This research was supported by NSF Grants CCF-1553751, NSF CCF-1343104 and NSF CCF-1407779, and a
Sloan Research Fellowship for NS.
1
The usual definition considers open cones, but we will work with their closures instead.

1

determinant polynomial det(X). Is hyperbolic programming as an algorithmic primitive strictly
more powerful than semidefinite programming? Can hyperbolicity cones other than these two be
harnessed towards obtaining better algorithms for combinatorial optimization problems? These
compelling questions remain open.
Lately, the relationship between hyperbolicity cones and the semidefinite cone has been a subject
of intense study. It is easy to see that every section of the semidefinite cone is a hyperbolicity cone,
so it is natural to ask whether the converse holds, i.e., if every hyperbolicity cone can be realized
as a section of the semidefinite cone. Formally, a spectrahedral cone K is specified by:
X
K = {x ‚àà Rn |
Ai xi  0},
i

for some matrices {Ai }i‚àà[n] ‚àà
dral cone.

RB√óB .

It is conjectured that every hyperbolicity cone is a spectahe-

Conjecture 1. (Generalized Lax Conjecture) Every hyperbolicity cone is a spectahedral cone, i.e.,
a linear section of the cone of positive semidefinite matrices in some dimension.
The Lax conjecture in its original stronger algebraic form asked whether every polynomial in
three variables hyperbolic with respect to the direction (1, 0, 0), could be written as det(xI + yB +
zC) for some symmetric matrices B, C (sometimes called a definite determinantal representation).
This immediately implies that all hyperbolicity cones in three dimensions are spectrahedral, and
was proved by Helton and Vinnikov and Lewis, Parrilo, and Ramana [HV07, LPR05]. The algebraic
conjecture is easily seen to be false for n > 3 by a count of parameters, since the set of hyperbolic
d
polynomials is known to have nonempty interior
 [Nui69] and is of dimension n , whereas the set of
d
n‚àítuples of d √ó d matrices has dimension n 2 . This led to the weaker conjecture that for every
hyperbolic p(x) there is an integer k such that p(x)k admits a definite determinantal representation,
which was disproved by BraÃànden in [BraÃà11]. The Generalized Lax conjecture, which is a geometric
statement, is equivalent to the yet weaker algebraic statement that for every hyperbolic p(x) there is
a hyperbolic q(x) such that Kp ‚äÜ Kq and p(x)q(x) admits a definite determinantal representation.
For several special classes of hyperbolic polynomials, the corresponding hyperbolicity cones
are known to be spectrahedral.
The
P
Q elementary symmetric polynomial of degree d in n variables
is given by ed (x) = S‚äÜ[n],|S|=d i‚ààS xi . BraÃànden [BraÃà14] showed that the hyperbolicity cones
of elementary symmetric polynomials are spectrahedral with matrices of dimension O(nd ). If a
polynomial p is hyperbolic with respect to a direction e ‚àà Rn , then its directional derivatives
along
Q
e are hyperbolic too [GaÃär59]. Directional derivatives of the polynomial p(x) = i‚àà[n] xi [Zin08,
San13, BraÃà14, COSW04] and the first derivatives of the determinant polynomial [Sau17] are also
known to satisfy the generalized Lax conjecture. Amini [Ami16] has shown that certain multivariate
matching polynomials are hyperbolic and that their cones are spectrahedral, of dimension n!.
Given the above examples, it is natural to wonder whether exponential blowup in dimension is
an essential feature of passing from hyperbolicity cones to spectrahedral representations, and even
assuming the generalized Lax conjecture to be true, the size of the spectrahedral representation of a
hyperbolicity cone is interesting from a complexity standpoint. In this paper, we obtain exponential
lower bounds on the size of the spectrahedral representation in general, even if the representation
is allowed to be approximate (up to an exponentially small error).
Recall that the Hausdroff distance between two cones K and K 0 is defined as
hdist(K, K 0 ) =

max

x‚ààB‚à©K,y‚ààB‚à©K 0

2

(d(x, K 0 ), d(y, K)),

where B is the unit ball in Rn . We say that a spectrahedral cone K 0 is an Œ∑-approximate spectrahedral
representation of another cone K if hdist(K, K 0 ) ‚â§ Œ∑. Our main theorem is the following.
Theorem 2 (Main Theorem). There exists an absolute constant Œ∫ > 0 such that for all sufficiently
large n, d, there exists an n-variate degree d hyperbolic polynomial p whose hyperbolicity cone Kp
does not admit an Œ∑‚àíapproximate spectrahedral representation of dimension B ‚â§ (n/d)Œ∫d , for
Œ∑ = 1/n4nd .
Our proof is analytic and does not rely on algebraic obstacles to representability; in fact the
polynomials we construct have very
 simple coefficients (they are essentially binary perturbations
of ed ). However, since there are nd coefficients, the examples require ‚Ñ¶(nd ) bits to write down. It
is still unknown whether ed itself admits a low dimensional spectrahedral representation, though
Saunderson and Parrilo [SP15] have shown that if one allows projections of sections of semidefinite
cones, then such a represntation exists with size poly(n, d).
Algebraically, the notion of (exact) spectrahedral representation of a hyperbolicity cone Kp for
a polynomial p corresponds to an algebraic identity of the form,
X
p(x) ¬∑ q(x) = det(
Ci x i ) ,
i‚àà[n]

where Kq contains Kp . Thus, our main theorem implies the existence of a degree d polynomial p
such that the degree of any identity of the above form is at least (n/d)Œ∫d .

1.1

Proof Overview

The starting point for our proof is the theorem of Nuij [Nui69], which says that the space of
hyperbolic polynomials of degree d in n variables has a nonempty interior, immediately implying
that it has dimension nd . The Generalized Lax Conjecture concerns the cones of these polynomials,
which are geometric rather than algebraic objects. If we could show that this space of cones also
has large ‚Äúdimension‚Äù in some appropriate quantitative sense, and that the maps between the
hyperbolicity cones and their spectrahedral representations are suitably well-behaved, then it would
rule out the existence of small spectrahedral representations for all of them uniformly, since such
representations are parameterized by tuples of n B √ó B matrices, which have dimension nB 2 .
The difficulties in turning this idea into a proof are: (1) There are no quantitative bounds on
Nuij‚Äôs theorem. (2) the space of hyperbolicity cones is hard to parameterize and it is not clear
how to define dimension. (3) the mapping from hyperbolicity cones to their representations can
be arbitrary, and needn‚Äôt preserve the usual notions of dimension anyway. We surmount these
difficulties by a packing argument, which consists of the following steps.
‚Ñ¶(d)

1. Exhibit a large family of hyperbolicity cones of size 2(n/d) , every pair of which are at least
 apart from each other in the Hausdroff metric between the cones.
2. Show that the spectrahedral representations of two distant cones K and K 0 are distant from
each other, once the representations are appropriately normalized. Formally, the matrices
{Ci }i‚àà[n] and {Ci0 }i‚àà[n] representing the two cones are at least 0 away in operator norm if
hdist(K, K 0 ) ‚â•  (see Lemma 14).
We work only with cones which contain the positive orthant in order to ensure that they have
normalized representations.
3

Figure 1: Outline of the Proof
2

3. By considering the volume, there is a (B/0 )nB upper bound on the number of pairwise
0 -distant spectrahedral representations in B √ó B matrices, thus giving the lower bound on
B.
By far, the most technical part of the proof is the first step exhibiting a large family of pairwise distant hyperbolicity cones. The set of hyperbolic polynomials is known to have a non-empty
interior in the set of all degree d homogenous polynomials. Although this implies the existence of
a full-dimensional family of hyperbolic polynomials, it is not clear how far apart they are quantitatively. Moreover, without any further understanding of the structure of the polynomials, it is
difficult to argue that their cones are far in the Hausdorff metric. To this end, we work with an
explicit family of hyperbolic polynomials which are all perturbations of the elementary symmetric
polynomials, whose cones we are able to understand. Specifically, we will show the following:
n

1. There exists an explicit
P of 2‚Ñ¶(( d )) perturbations of the degree d elementary symmetric
P familyQ
polynomial ed (x) = S,|S|‚â§d i‚ààS xi that are all hyperbolic, and pairwise distant from each

other. These perturabations are indexed by a hypercube of dimension ‚Ñ¶( nd ), as depicted in
Figure 1. The subspace of perturbations is carefully chosen to preserve real-rootedness of all
the restrictions, thereby preserving the hyperbolicity of the polynomial ed (x) (see Section 2),
as well as to yield perturbations of an especially simple structure.
2. The hyperbolicity cones for every pair of polynomials in P are far from each other. In order to

lower bound the Hausdroff distance between these cones, we identify an explicit set of ‚Ñ¶( nd )
points on the boundary of the hyperbolicity cone for ed (x) as markers. We will lower bound
the perturbation of these markers as the polynomial is perturbed, in order to argue that the
corresponding hyperbolicity cone is also perturbed (see Section 4). Again, the structure of
the chosen subspace ensures that there are no ‚Äúinteractions‚Äù between the markers, and the
analysis is reduced to understanding the perturbation of a single univariate Jacobi polynomial.

4

2

Many Hyperbolic Perturbations of ed

In this section we prove that even though ed (x1 , . . . , xn ) is not in the interior of the set of Hyperbolic
polynomials, there is a large subspace Œ†d of homogeneous polynomials of degree d in n variables
such that all sufficiently small perturbations of ed in this subspace remain hyperbolic.
The subspace will be spanned by certain homogeneous polynomials corresponding to matchings.
For any matching M containing d edges on {1, . . . , n}, define the polynomial
Y
qM (x1 , . . . , xn ) :=
(xi ‚àí xj ).
i<j‚ààM

We say that a d‚àímatching on [n] fully crosses a d‚àísubset S of [n] if every edge of M has exactly
one endpoint in S.
Lemma 3 (Many Uniquely Crossing Matchings). There is a set Md of d‚àímatchings on [n] of size
at least

n
|Md | =: N ‚â•

d

4 ¬∑ 2d
and a set of d‚àísubsets Sd such that for every S ‚àà Sd there is a unique matching M ‚àà Md which
fully crosses it, and for every M ‚àà Md there is at least one S ‚àà Sd which it fully crosses.
Moreover, for every indicator vector 1S , S ‚àà Sd there is a unique M ‚àà Md such that qM (1S ) 6=
0, so the dimension of the span of
Œ†d := {qM : M ‚àà Md }
is exactly N .
Proof. Let M denote the set of all d‚àímatchings on [n] and let S be the set of all d‚àísubsets of [n].
Let


n‚àíd
E :=
¬∑ d!
d
be the number of matchings fully crossing a fixed set S ‚àà S. Let Md be a random subset of M
in which each matching is included independently with probability Œ±/E for some Œ± ‚àà (0, 1) to be
determined later, and let XM be the indicator random variable that M ‚àà Md . For any set S,
define the random variable
X
deg(S) :=
XM ,
M fully crossing S

and observe that
Edeg(S) = Œ±.
Call a set S good if deg(S) = 1 and let G be the number of good S. Observe that
 
 
 
n
n
Œ±
n
EG =
¬∑ P[deg({1, . . . , d} = 1] =
¬∑ E ¬∑ (1 ‚àí (Œ±/E))E‚àí1 ¬∑
‚â•
Œ±(1 ‚àí Œ± ¬∑ (1 ‚àí 1/E)).
d
d
E
d
Setting Œ± = 1/2 we therefore have
 
n
EG ‚â•
/4,
d
5


so with nonzero probability there are at least nd /4 good subsets.
Let Sd be the set of good subsets. Finally, remove
 from Md all the matchings that do not fully
cross a good subset. Since there are at least (1/4) nd good subsets, every good subset fully crosses
at least one matching in Md , and at most 2d subsets cross any given matching, the number of
matchings whichremain in Md is at least
 
n
(1/4)
/2d ,
d
as desired.
The moreover part is seen by observing that qM (1S ) 6= 0 if and only if M fully crosses S.


n
,
Remark 4. In fact, the dimension of the span of all of the polynomials qM is exactly nd ‚àí d‚àí1
by properties of the Johnson Scheme, but in order to obtain the additional property above we have
restricted to Md .
Henceforth we fix {qM : M ‚àà Md } to be a basis of Œ†d and define the `1 norm of a polynomial
X
q=
sM qM ‚àà Œ†d
M ‚ààMd

as kqk1 := ksk1 . We will use the notation
md (x1 , . . . , xn ) = max

|S|=d

Y

|xi |,

i‚ààS

to denote the product of the d largest entries of a vector in absolute value, and occasionally we will
write ed (p) and md (p) for a real-rooted polynomial p, which means applying ed or md to its roots.
The operator D refers to differentiation with respect to t.
The main theorem of this section is:
Theorem 5 (Effective Relative Nuij Theorem for ed ). If q ‚àà Œ†d satisfies

n
kqk1 ‚â§

d

2n ¬∑ n(d+1)(n‚àíd)

=: R

then ed + q is hyperbolic with respect to 1.
Recalling the definition of hyperbolicity, our task is to show that all of the restrictions
t 7‚Üí ed (t1 + x),

x ‚àà Rn

remain real-rooted after perturbation by q. Many of these restrictions lie on the boundary of the
set of (univariate) real-rooted polynomials, or arbitrarily close to it, so it is not possible to simply
discretize the set of x by a net and choose q to be uniformly small on this net; one must instead
carry out a more delicate restriction-specific analysis which shows that for small R, the perturbation
q(t1+x) is less than the distance of ed (t1+x) to the boundary of the set of real-rooted polynomials,
for each x ‚àà Rn . Since we are comparing vanishingly small quantities, it is not a priori clear that
such an approach will yield an effective bound on R depending only on n and d; Lemma 6 shows
that this is indeed possible.
6

Proof of Theorem 5. Fix any nonzero vector x ‚àà Rn and perturbation q ‚àà Œ†d with kqk1 ‚â§ R and
consider the perturbed restriction:
r(t) := ed (t1 + x) + q(t1 + x).
Let p(t) := ed (t1 + x) and observe that since q is translation invariant, we have q(t1 + x) = q(x),
so in fact
r(t) = p(t) + q(x).
Let Œ≥ ‚â• 0 be the largest constant such that p(t) + Œ¥ is real-rooted for all Œ¥ ‚àà [‚àíŒ≥, Œ≥] (note that Œ≥
could be zero if p has a repeated root). It is sufficient to show that |q(x)| ‚â§ Œ≥. Observe that
Œ≥ = min |p(t)|,
t:p0 (t)=0

(1)

since the boundary of the set of real-rooted polynomials consists of polynomials with repeated
roots, and at any double root t0 of the p + Œ≥ we have p0 (t0 ) = (p + Œ≥)0 (t0 ) = (p + Œ≥)(t0 ) = 0. Let t0
be the minimizer in (1) and replace x by x ‚àí t0 1, noting that this translates r(t) to r(t ‚àí t0 ) and
does not change Œ≥ or q(x), so that we now have:
p0 (0) = d ¬∑ ed‚àí1 (x) = 0
and
Œ≥ = |p(0)| = |ed (x)|.
On the other hand, observe that:
|q(x)| ‚â§

X

Y

|sM |

M ‚ààMd

|xi ‚àí xj |

ij‚ààM

‚â§ kqk1 ¬∑ max

M ‚ààMd

Y

(|xi | + |xj |)

ij‚ààM

‚â§ kqk1 ¬∑ 2d ¬∑ md (x).
Thus we have Œ≥ ‚â• |q(x)| as long as md (x) = 0 or
kqk1 ‚â§
which is implied by

|ed (x)|
,
2d md (x)

n
d
2d (2nd+1 )(n‚àíd)



kqk1 ‚â§
by Lemma 6, as advertised.

The following lemma may be seen as a quantitative version of the fact that if a real-rooted polynomial has two consecutive zero coefficients ed = ed‚àí1 = 0 then it must have a root of multiplicity
d + 1 at zero.
Lemma 6. If x ‚àà Rn satisfies ed‚àí1 (x) = 0 then
n
d
|md (x)|.
(2nd+1 )(n‚àíd)



|ed (x)| ‚â•

7

Q
Proof. Let p(t) := ni=1 (t ‚àí xi ) and let qk (t) := Dn‚àík p, noting that qk is real-rooted of degree exactly k. Assume for the moment that all of the xi are distinct and that qk (0) 6= 0 for all k = n, . . . , d
(note that this is equivalent to assuming that the last d + 1 coefficients of p are nonzero). Note
that these conditions imply that all of the polynomials qk have distinct roots, since differentiation
cannot increase the multiplicity of a root.
If n = d then the claim is trivially true since
ed (x) = ed (qd ) = md (qd ) = md (x).

(2)

Observe that ed behaves predictably under differentiation:
ed (qd ) = ed (D

n‚àíd

(n ‚àí d)!
p) =
ed (p) =
n ¬∑ . . . ¬∑ (d + 1)

 ‚àí1
n
ed (qn ).
d

(3)

We will show by induction that:
md (qd ) ‚â•

1
1
1
md (qd+1 ) ‚â• . . . ‚â•
md (qk ) ‚â• . . . ‚â•
md (qn ),
2nd+1
(2nd+1 )k‚àíd
(2nd+1 )n‚àíd

which combined with (2) and (3) yields the desired conclusion.
Case k = d + 1. Let z‚àí and z+ be the smallest (in magnitude) negative and positive roots of
qd = Dqd+1 , respectively. Let w 6= 0 be the unique root of qd+1 between z‚àí and z+ ; assume
without loss of generality that w > 0 (otherwise consider the polynomial p(‚àíx)). Let x‚àí < z‚àí and
x+ < z+ be the smallest in magnitude negative and positive roots of qd+1 other than w, so that
x‚àí < 0 < w < x+ . There are two subcases, depending on whether or not w is close to zero ‚Äî if
it is, then it prevents any root from shrinking too much under differentiation, and if it is not, the
hypothesis ed‚àí1 (p) = 0 shows that |z‚àí | and |z+ | are comparable, which also yields the conclusion.
‚Ä¢ Subcase |w| ‚â§ |x‚àí |/2n. By Lemma 8, we have
|z‚àí | ‚â• |x‚àí | ‚àí (|x‚àí | + |w|)(1 ‚àí 1/n) ‚â• |x‚àí |(1 ‚àí (1 + 1/2n)(1 ‚àí 1/n)) ‚â• |x‚àí |/2n.
For every root of qd+1 other than x‚àí there is another root of qd+1 between it and zero, so
Lemma 8 implies that for every such root the neighboring (towards zero) root of Dqd+1 is
smaller by at most 1/n. Thus, we conclude that
md (qd ) = md (Dqd+1 ) ‚â•

md (qd+1 )
.
2nd

‚Ä¢ Subcase |w| > |x‚àí |/2n. In this case we may assume that md (qd+1 ) is witnessed by the d roots
of qd+1 excluding x‚àí , call this set W , losing a factor of at most 1/2n. Observe that every root
in W \ {w} is separated from zero by another root of qd+1 , so such roots shrink by at most
1/n under differentiation by Lemma 8. Noting that x‚àí ‚àà
/ W , we have by interlacing that:
Y

|z| ‚â•

qd (z)=0,z6=z‚àí

8

1
nd‚àí1

Y
x‚ààW \{w}

|x|,

and our task is reduced to showing |z‚àí | is not small compared to |w|
The hypothesis ed‚àí1 (qd+1 ) = 0 implies that qd0 (0) = 0; applying Lemma 8, we find that the
magnitudes of the innermost roots of qd must be comparable:
|z‚àí | ‚à® |z+ | ‚â§ d ¬∑ (|z‚àí | ‚àß |z+ |).
We now have
|z‚àí | > |z+ |/n > |w|/n,
so we conclude that
md (qd ) ‚â•

md (qd+1 )
,
2nd

as desired.
Case k ‚â• d + 2. We proceed by induction. Assume md (qk ) is witnessed by a set of d roots L ‚à™ R,
where L contains negative roots and R contains positive ones. If there is a negative root not in L
and a positive root not in R then as before every root in L ‚à™ R is separated from zero by another
root of qk , and by Lemma 7 we have
md (Dqk ) ‚â•

1
md (qk ),
nd

(4)

so we are are done. So assume all of the negative roots are contained in L; since |L ‚à™ R| = d this
implies that there are at least two positive roots not in R; let z‚àó be the largest positive root not
contained in R. Let z‚àí and z+ be the negative and positive roots of qk of least magnitude. There
are two cases:
‚Ä¢ |z+ | > |z‚àí |/2n. This means that we can delete z‚àí from L and add z‚àó to R, and reduce to the
previous situation, incurring a loss of at most 1/2n, which means by (4):
md (qk‚àí1 ) ‚â•

1 1
md (qk ).
2n nd

‚Ä¢ |z+ | ‚â§ |z‚àí |/2n. By Lemma 7, the smallest in magnitude negative root of Dqk has magnitude
at least
(1 ‚àí (1 ‚àí 1/n)(1 + 1/2n))|z‚àí | ‚â• |z‚àí |/2n,
and all the positive roots decrease by at most 1/n upon differentiating by Lemma 7, whence
we have
1
md (Dqk ) ‚â• d md (qk ).
2n
To finish the proof, the requirements that qk (0) 6= 0 for all k and that all coordinates of x are
distinct may be removed by a density argument, since the set of x for which this is true is dense in
the set of x ‚àà Rn satisfying ed‚àí1 (x) = 0.
Remark 7. We suspect that the dependence on n and d in the above lemma can be improved, and
it is even plausible that it holds with a polynomial rather than exponential dependence of R on n.
Since we do not know how to do this at the moment, we have chosen to present the simplest proof
we know, without trying to optimize the parameters.
9

The following lemma is a quantitative version of the fact that the roots of the derivative of a
polynomial interlace its roots.
Lemma 8 (Quantitative Interlacing). If p is real rooted of degree n then every root of p0 between
two distinct consecutive roots of p divides the line segment between them in at most the ratio 1 : n.
0
Proof. Begin by recalling that if p has distinct roots z1 < . . . < zn then the roots z10 < . . . < zn‚àí1
of p0 satisfy for j = 1, . . . , n ‚àí 1:

X
i‚â§j

X 1
1
=
.
zj0 ‚àí zi
zi ‚àí zj0
i>j

Note that the solution zj0 is monotone increasing in the zi on the LHS and monotone decreasing in
the zi on the RHS. Thus, zj0 is at least the solution to:
zj0
z

1
n
=
,
‚àí zj
zj+1 ‚àí zj0

‚àíz

which means that it is at least zj + j+1n j . A similar argument shows that it it at most zj + (1 ‚àí
1/n)(zj+1 ‚àí zj ). Adding the common roots of p and p0 back in, we conclude that these inequalities
are satisfied by all of the zj0 .

3

Separation in Restriction Distance

For a parameter  > 0 to be chosen later and s ‚àà {0, 1}Md let
X
ps (x1 , . . . , xn ) := ed (x1 , . . . , xn ) ‚àí 
sM qM (x1 , . . . , xn ).
M ‚ààMd

For any polynomial p hyperbolic with respect to 1, define the restriction embedding
Œõ(p) := (Œªmax (p(t1 + 1S )))S‚ààSd .
Lemma 9. If 0 <  < R/N and s, s0 ‚àà {0, 1}Md are distinct then both ps and p0s are hyperbolic
with respect to 1 and
  ‚àí1
n
kŒõ(ps ) ‚àí Œõ(ps0 )k‚àû ‚â• ‚àÜ := 
de
.
d
Proof. Since  < R/N , we have ked ‚àí ps k1 , ked ‚àí ps0 k1 ‚â§ R so by Theorem 5 both of them must be
hyperbolic with respect to 1.
Since s 6= s0 , suppose sM = 0 and s0M = 1 for some matching M ‚àà Md , and let S ‚àà Sd be a set
which fully crosses M . By Lemma 3, M is the only matching in Md which crosses S, so we have
qM (1S ) = 1 and qM 0 (1S ) = 0 for all other M 0 6= M ‚àà Md . Thus, along the restriction t1 + 1S , one
has
qs (t1 + 1S ) = ed (t1 + 1S ) =: J(t)
(5)
and
qs0 (t1 + 1S ) = ed (t1 + 1S ) ‚àí qM (1S ) = ed (t1 + 1S ) ‚àí  = J(t) ‚àí ,
10

where we have again used that the qM are translation invariant. Note that J(t) has positive leading
coefficient, so subtracting a constant from it increases its largest root. Thus, our task is reduced to
showing that
Œªmax (J(t) ‚àí ) ‚â• Œªmax (J(t)) + ‚àÜ.
To analyze the behavior of this perturbation, first we note that
J(t) = ed (t1, . . . , t1, t1 + 1, . . . , t1 + 1) =

1
1
Dn‚àíd eN (t1 + 1S ) =
Dn‚àíd tn‚àíd (t + 1)d .
(n ‚àí d)!
(n ‚àí d)!

Since tn‚àíd (t + 1)d has roots in [‚àí1, 0] and the roots of the derivative of a polynomial interlace its
roots, we immediately conclude that the zeros of J satisfy ‚àí1 ‚â§ z1 ‚â§ . . . ‚â§ zd ‚â§ 0. Again by
interlacing, we see that J 0 (z) ‚â• 0 and J 00 (z) ‚â• 0 for z ‚â• zd , whence J is monotone and convex
above zd . Thus, Œª := Œªmax (J(t) ‚àí ) is the least Œª > zd such that J(Œª) ‚â• . Let Œ∏ > 0 be a
parameter to be set later. Then either Œª ‚â• zd + Œ∏ or we have by convexity that
J(zd + Œ∏) ‚â§ J(zd ) + Œ∏J 0 (zd + Œ∏).
The first term is zero and we can upperbound the second term as:
 
 X Y
n
n
0
| (zd + Œ∏ ‚àí zi )| ‚â§
d ¬∑ (1 + Œ∏)n‚àí1 ,
|J (zd + Œ∏)| ‚â§
d
d
i‚â§d j6=i

since |zd ‚àí zi | ‚â§ 1 for every i ‚â§ d. Thus, we have
 
 
n
n
n‚àí1
J(zd + Œ∏) ‚â§
dŒ∏(1 + Œ∏)
‚â§
dŒ∏e
d
d

whenever Œ∏ < 1/n, which is less than  for Œ∏ = ( nd de)‚àí1 . This means that in either case we must
have
  ‚àí1
n
Œª ‚â• zd + 
de
,
d
as desired.

4

Separation in Hausdorff Distance

Lemma 10. For s, s0 ‚àà {0, 1}Md and
<

1

‚àö =: R2
n

4nd(n‚àíd) N d

we have
hdist(Kps , Kps0 ) >

kŒõ(ps ) ‚àí Œõ(p0s )k‚àû
18nd(n‚àíd) N n

Proof. Suppose kŒõ(ps ) ‚àí Œõ(p0s )k‚àû = ‚àÜ > 0. There must be some restriction t1 + 1S along which
the intersections with the boundaries of the cones differ by ‚àÜ. Moreover, this S must be fully
crossed by some matching M for which sM or sM 0 is nonzero, since otherwise we would have
ps (t1 + 1S ) = ps0 (t1 + 1S ) = ed (t1 + 1S ). By Lemma 3, there is a unique such M and we may
11

assume that sM = 0 and s0M = 1, and moreover qM 0 (t1 + 1S ) = 0 for all other M 0 ‚àà Md , so that
we have
ps (Œª1 + 1S ) = ed (Œª1 + 1S ) = 0
and
ps0 ((Œª + ‚àÜ)1 + 1S ) = ed ((Œª + ‚àÜ)1 + 1S ) ‚àí  = 0
where Œª ‚àà R is the largest root of the polynomial J(t) from (5).
Let
z = Œª1 + 1S
and
z 0 = (Œª + ‚àÜ)1 + 1S = z + ‚àÜ1
denote the corresponding points in Rn on the boundaries of Kps and Kps0 , respectively. Let H be
the hyperplane tangent to Kps at z. Let v be a unit vector normal to H. Since the hyperbolicity
cones are convex, the distance from z 0 to Kps is at least the distance to H, which is given by:
k‚àÜ1k ¬∑

|h1, vi|
|h1, vi|
=‚àÜ¬∑
.
k1kkvk
kvk

Normalizing so that z 0 is a unit vector, we obtain:
hdist(Kps , Kps0 ) ‚â• ‚àÜ

|h1, vi|
,
kvkkz 0 k

(6)

so if we can prove a uniform lower bound on this quantity over all v and z 0 corresponding to s, s0 ,
then we are done.
Computing the normal we find that
X
v = ‚àáps (z) = ‚àáed (z) + 
sM ‚àáqM (z) =: ‚àáed (z) + w,
M ‚ààMd

so that
|h1, vi| ‚â• |h1, ‚àáed (z)i| ‚àí k1kkwk.
The first inner product is just the directional derivative of ed (t1 + 1S ) along 1 at t = Œª, which is:
d
1
ed (t1 + 1S )|t=Œª = J 0 (Œª) ‚â• d(n‚àíd) ,
dt
n

(7)

by Lemma 11, proven below.
We now prove crude upper bounds on kz 0 k, kwk, kvk, which will be negligible when  is small.
First we have
‚àö
kz 0 k ‚â§ (Œª + ‚àÜ)k1k + k1S k ‚â§ 3 n,
(8)
since |Œª| ‚â§ 1 because J has roots in [‚àí1, 0] and |‚àÜ| < 1.
To control kwk, we compute the ith coordinate of ‚àáqM (x):
Y
‚àÇxi qM (x) = œÉi
(xk ‚àí xl ),
k<l‚ààM \{i}

12

where œÉi zero if i ‚àà
/ M and ¬±1 if i ‚àà M . Since z has coordinates in [‚àí1, 0], |‚àÇxi qM (z)| ‚â§ 1 for all
i ‚àà M and
‚àö
k‚àáqM (z)k ‚â§ 2d.
Applying the triangle inequality and noting that sM ‚àà {0, 1} gives
‚àö
kwk ‚â§ |Md | ¬∑ 2d ‚â§ 2N d.

(9)

Finally, we have
v
u n
uX
k‚àáed (z)k = t
ed‚àí1 (z‚àíi )2 ,
i=1

where z‚àíi is the vector obtained by deleting the ith coordinate of z. Since these coordinates are
bounded in magnitude by 1, the above norm is bounded by


‚àö
‚àö
n
n¬∑
‚â§ n ¬∑ N,
d‚àí1
and applying the triangle inequality once more we get
‚àö
‚àö
kvk ‚â§ n ¬∑ N + kwk ‚â§ 3N n,
since  < 1.
Combining (6), (7), (8),(9), and (10), we have:
‚àö
n‚àíd(n‚àíd) ‚àí  ¬∑ 2N d n
‚àÜ
‚àö
‚àö
hdist(Kps , Kps0 ) ‚â• ‚àÜ ¬∑
‚â•
,
d(n‚àíd)
3 n ¬∑ 3N n
18n
Nn
provided

‚àö
2N d n ‚â§ (1/2)n‚àíd(n‚àíd) ,

as desired.
Lemma 11 (Sensitivity of Jacobi Root). Let Œª be the largest root of J(t). Then
J 0 (Œª) ‚â•

1
nd(n‚àíd)

.
The proof is deferred to the appendix.

5

Separation of Matrix Parameterizations

Given C = {Ci }i‚àà[n] ‚äÇ Rk√ók , define the cone
KC = {x ‚àà Rn |

X

Ci xi  0}

i‚àà[n]

Here C is said to be a spectrahedral representation of the cone KC .
13

(10)

Figure 2: Proof of Lemma 14
Definition 12. A spectrahedral representation of a cone K ‚äÜ Rn as K = {x ‚àà Rn |
said to be a normalized if,
n
X
Ci = Idk

P

i Ci x i

 0},is

i=1

and Ci  0
Lemma 13. If a spectrahedral cone K contains the positive orthant Rn+ then K admits a normalized
representation.
Proof. Let C = {Ci }i‚àà[n] be a spectrahedral representation of K. Let U = ‚à©ni=1 Ker(Ci ) be the
subspace in the kernel of all the Ci , and let Œ†U ‚ä• denote the projection on to U ‚ä• . It is easy to
check that for all x ‚àà Rn ,
X
X
Ci xi  0 ‚áê‚áí
Œ†U ‚ä• Ci Œ†U ‚ä• xi  0.
i

i
0

0

By a basis change of Rn , that contains a basis for U ‚ä• , we obtain matrices C 0 = {Ci0 }i‚àà[n] in Rk √ók
where k 0 = dim(U ‚ä• ) such that K = KC 0 .
Furthermore, since the ith basis vector ei is in the non-negative orthant, ei ‚àà K. This implies
that Ci0  0 for each i. For each u ‚àà U ‚ä• , therePexists Ci such that uT Ci u > 0, which implies that
P
T 0
0
i u Ci u > 0. In other words, we have M =
i Ci  0 is positive definite.
The normalized representation ofP
K is given by C 00 = {M ‚àí1/2 Ci0 M ‚àí1/2 }i‚àà[n] . By definition, the
representation is normalized in that i‚àà[n] Ci00 = Idk0 .
For two spectrahedral representations given by matrices C = {Ci }i‚àà[n] and C 0 = {Ci0 }i‚àà[n] ,
define the distance between the representations as,
mdist(C, C 0 ) = max kCi ‚àí Ci0 k
i

Lemma 14. Suppose C, C 0 are normalized spectrahedral representations of KC and KC 0 respectively. Then, hdist(KC , KC 0 ) ‚â§ n3/2 ¬∑ mdist(C, C 0 )

14

Proof. Let B(0, 1) denote the `‚àû unit ball in Rn . For every x ‚àà KC ‚à© B(0, 1),
X
X
X
(Ci ‚àí Ci0 )xi
Ci x i +
Ci0 xi =
i‚àà[n]

i‚àà[n]

i‚àà[n]

 ‚àínmdist(C, C 0 ) ¬∑ Idk
P
0
0
where we are using the fact that i Ci xi  0. This implies that the point
Px =0 x+nmdist(C, C )¬∑1 ‚àà
KC 0 . To see this, recall that the representation is normalized in that i Ci = Idk . Therefore, we
get
X
X
X
Ci0 x0i =
Ci0 xi + n ¬∑ mdist(C, C 0 )
Ci0  0
i

i

i

The lemma follows by observing that kx ‚àí x0 k2 ‚â§ n3/2 ¬∑ mdist(C, C 0 ).

6

Proof of The Main Theorem

We restate the theorem for convenience.
Theorem 15 (Restatement of Main Theorem). There exists an absolute constant Œ∫ > 0 such
that for all sufficiently large n, d, there exists an n-variate degree d hyperbolic polynomial p whose
hyperbolicity cone Kp does not admit an Œ∑‚àíapproximate spectrahedral representation of dimension
B ‚â§ (n/d)Œ∫d , for Œ∑ = 1/n4nd .
Proof. Set  smaller than R and R2 . Theorem 5, Lemma 9 and Lemma 10 together imply a family
of hyperbolic polynomials P with the following properties:
1. |P| = 2|Md | where |Md | ‚â• (n/d)Œ∫d for some absolute constant Œ∫ > 0.
2. For all p 6= p0 ‚àà P, hdist(Kp , Kp0 ) ‚â• Œ≥ for Œ≥ >

1
.
n3nd

3. For every p ‚àà P, the positive orthant Rn+ is contained in Kp .
The last observation follows from the fact that positive orthant is contained in Ked , and the
perturbations of ed in P are small enough to keep all the coefficients non-negative.
Suppose each of the hyperbolicity cones Kp admitted a Œ≥/3‚àíapproximate spectrahedral representation in dimension B. By Lemma 13, for each cone in Kp , there exists a normalized Œ≥/3approximate spectrahedral representation Cp in dimension Bp ‚â§ B Further, by Lemma 14, for every
pair of polynomials p, p0 ‚àà P, their corresponding Œ≥/3-approximate spectrahedral representations
satisfy mdist(Cp , Cp0 ) ‚â• n‚àí3/2 Œ≥/3 := Œ∑.
Notice that in every normalized spectrahedral representation
‚àö Cp in dimension B, every matrix
C ‚àà Cp satisfies C  0 and C  IdB . This implies that kCkF ‚â§ B. By a simple volume argument,
for every Œ∑ > 0, the number of normalized spectrahedral representations in RB√óB whose pairwise
‚àö
nB 2
distances are ‚â• Œ∑ is at most
B/Œ∑
. Since every cone Kp for p ‚àà P admits a normalized
spectrahedral representation of dimension at most B, we get that
|P| ‚â§ t

‚àö

B/Œ∑

15

nB 2

,

which implies that
B 2 log B ‚â• |Md |/ log(n3/2 /Œ≥) ‚â•

1
¬∑ (n/d)Œ∫d .
n log n

0

which implies the lower bound of B ‚â• (n/d)Œ∫ d for some constant Œ∫0 > 0.

Acknowledgments
We thank Jim Renegar for pointing out a mistake in a previous version of the proof of Lemma
6. We thank the Simons Institute for the Theory of Computing and MSRI, where this work was
partially carried out, for their hospitality.

References
[Ami16]

Nima Amini, Spectrahedrality of hyperbolicity cones of multivariate matching polynomials, arXiv preprint arXiv:1611.06104 (2016).

[BraÃà11]

Petter BraÃàndeÃÅn, Obstructions to determinantal representability, Advances in Mathematics 226 (2011), no. 2, 1202‚Äì1212.

[BraÃà14]

, Hyperbolicity cones of elementary symmetric polynomials are spectrahedral,
Optimization Letters 8 (2014), no. 5, 1773‚Äì1782.

[COSW04] Young-Bin Choe, James G Oxley, Alan D Sokal, and David G Wagner, Homogeneous
multivariate polynomials with the half-plane property, Advances in Applied Mathematics
32 (2004), no. 1-2, 88‚Äì187.
[GaÃär59]

Lars GaÃärding, An inequality for hyperbolic polynomials, Journal of Mathematics and
Mechanics 8 (1959), no. 6, 957‚Äì965.

[GuÃàl97]

Osman GuÃàler, Hyperbolic polynomials and interior point methods for convex programming, Mathematics of Operations Research 22 (1997), no. 2, 350‚Äì377.

[HV07]

J William Helton and Victor Vinnikov, Linear matrix inequality representation of sets,
Communications on pure and applied mathematics 60 (2007), no. 5, 654‚Äì674.

[LPR05]

Adrian Lewis, Pablo Parrilo, and Motakuri Ramana, The lax conjecture is true, Proceedings of the American Mathematical Society 133 (2005), no. 9, 2495‚Äì2499.

[Nui69]

Wim Nuij, A note on hyperbolic polynomials, Mathematica Scandinavica 23 (1969),
no. 1, 69‚Äì72.

[Ren06]

James Renegar, Hyperbolic programs, and their derivative relaxations, Foundations of
Computational Mathematics 6 (2006), no. 1, 59‚Äì79.

[San13]

Raman Sanyal, On the derivative cones of polyhedral cones, Advances in Geometry 13
(2013), no. 2, 315‚Äì321.

[Sau17]

James Saunderson, A spectrahedral representation of the first derivative relaxation of
the positive semidefinite cone, arXiv preprint arXiv:1707.09150 (2017).
16

[SP15]

James Saunderson and Pablo A Parrilo, Polynomial-sized semidefinite representations
of derivative relaxations of spectrahedral cones, Mathematical Programming 153 (2015),
no. 2, 309‚Äì331.

[Zin08]

Yuriy Zinchenko, On hyperbolicity cones associated with elementary symmetric polynomials, Optimization Letters 2 (2008), no. 3, 389‚Äì402.

Appendix
Proof of Lemma 11. Let z1 ‚â§, . . . , ‚â§ zd = Œª be the roots of J(t). Observe that
Y
J 0 (Œª) =
(zd ‚àí zi ) ‚â• |zd ‚àí zd‚àí1 |d‚àí1 ,
i<d

so if we can prove a lowerbound on the spacing between zd and zd‚àí1 we are done.
We do this by recalling from Lemma 5 that:
J(t) =

1 n‚àíd n‚àíd
D
t
(1 + t)d .
d!

Let qk (t) := Dk tn‚àíd (1 + t)d and note that qk+1 interlaces qk , and all of these polynomials have real
roots in [‚àí1, 0]. Let yk be the largest root of qk that is strictly less than 0, noting that every qk for
k < n ‚àí d has a root at 0 because q0 has a root of multiplicity n ‚àí d at 0. By lemma 8, we have for
k = 1, . . . , n ‚àí d:
1
yk+1 ‚â§ 0 ‚àí |0 ‚àí yk | ‚â§ ‚àí|yk |/n.
n
Noting that y0 = ‚àí1 and iterating this bound n ‚àí d ‚àí 1 times we obtain
yn‚àíd‚àí1 ‚â§ ‚àí1/nn‚àíd‚àí1 ,
so that Dn‚àíd‚àí1 q0 has a root at zero and a root yn‚àíd‚àí1 ‚â§ ‚àí1/nn‚àíd . Since J(t) = Dqn‚àíd‚àí1 (t), we
must have zd‚àí1 ‚â§ ‚àíyn‚àíd‚àí1 by interlacing. However, applying Lemma 8 once more, we see that
zd ‚â• ‚àíyn‚àíd‚àí1 + |0 + yn‚àíd‚àí1 |/n = ‚àí(1 ‚àí 1/n)yn‚àíd‚àí1 ,
so the gap must be at least
zd ‚àí zd‚àí1 ‚â• yn‚àíd‚àí1 /n =

1
nn‚àíd

.

Thus, we conclude that
J 0 (Œª) ‚â•

1
n(d‚àí1)(n‚àíd)

as desired.

17

‚â•

1
nd(n‚àíd)

,

