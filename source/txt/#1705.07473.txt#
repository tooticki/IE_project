Nonautonomous Young differential equations revisited

arXiv:1705.07473v1 [math.PR] 21 May 2017

Nguyen Dinh Cong∗, Luu Hoang Duc†, Phan Thanh Hong

‡

Abstract
In this paper we prove that under weak conditions a nonautonomous Young differential equation
possesses a unique solution which depends continuously on initial conditions. The proofs use estimates in
p-variation norms, greedy time techniques, and Gronwall-type lemma with the help of Shauder theorem
of fixed points.

Keywords: stochastic differential equations (SDE), fractional Brownian motion (fBm), Young integral,
p-variation.

1

Introduction

This paper deals with the Young differential equation of the form
dxt = f (t, xt )dt + g(t, xt )dωt , t ≥ 0

(1.1)

where f : R × Rd → Rd and g : R × Rd → Rd×m are continuous functions, ω is a Rm -valued function of finite
p-variation norm for some 1 < p < 2. Such type of system is generated from stochastic differential equations
driven by fractional Brownian noises, as seen e.g. in [13]. Equation (1.1) is understood in the integral form
xt = x0 +

Z

t

f (s, xs )ds +
0

Z

t

g(s, xs )dωs , t ≥ 0,

(1.2)

0

where the first integral is of Riemannian type, meanwhile the second integral can be defined in the Young
sense [17]. The existence and uniqueness of the solution of (1.2) are studied by several authors. When f, g are
time-independent, system (1.2) is proved in [17] and [16] and [10] to have a unique solution in a certain space
of continuous functions with bounded p-variation. The result is then generalized for the case 2 < p < 3 by
[7] and [11] using rough path theory, see also recent work by [15] for rough differential equations. According
to their settings, g is often assumed to be infinitely differentiable and bounded in itself and its derivatives.
Another approach following Zähle [18] by using fractional derivatives can be seen in [14] which derives very
weak conditions for f and g in (1.1), in particular g need to be only C 1 with bounded and Hölder continuous
first derivative, to ensure the existence and uniqueness of the solution in the space of Hölder continuous
functions.
Our aim in this paper is to close the gap between the two methods by proving that, under similar assumptions
to those of Nualart and Rascanu [14], the existence and uniqueness theorem for system (1.1) still holds in
the space of continuous functions with bounded p-variation norm. For that to work, we construct a sequence
of the so-called greedy times (see e.g. [12]) such that the solution can be proved to exists uniquely in each
interval of the consecutive greedy times, and is then concatenated to form a global solution. It is remarkable
that since we are using estimates for p-variation norms, we do not apply the classical arguments of contraction
mappings, but use Shauder-Tychonoff fixed point theorem as seen in [10] and a Gronwall-type lemma.
The paper is organized as follows. In section 2, the Young integral is introduced and a greedy times analysis
is given. In Section 3, we prove the existence and uniqueness of the global solution of system (1.2) in Theorem
∗ Institute

of Mathematics, Vietnam Academy of Science and Technology, Vietnam E-mail: ndcong@math.ac.vn
of Mathematics, Vietnam Academy of Science and Technology, & Max-Planck-Institut für Mathematik in den
Naturwissenschaften, Leipzig, Germany E-mail: lhduc@math.ac.vn, duc.luu@mis.mpg.de
‡ Thang Long University, Hanoi, Vietnam E-mail: hongpt@thanglong.edu.vn
† Institute

1

3.6, for this we need to formulate a Gronwall-type lemma. Proposition 3.7 gives an estimate of q-var norm
of solution via p-var norm of the driver ω. We also prove the existence and uniqueness of the solution of
the backward equation (3.26) in Theorem 3.8. In Section 4, the fact in Theorem 4.1 that two trajectories do
not intersect help to conclude that the Cauchy operator or the Ito map of (1.2) generates a continuous two
parameter flow.

2
2.1

Preliminaries
Young integral

In this section we recall some facts about Young integral, more details can be seen in [7]. Let C([a, b], Rd )
denote the space of all continuous paths x : [a, b] → Rd equipped with sup norm k · k∞,[a,b] given by
kxk∞,[a,b] = supt∈[a,b] |xt |, where | · | is the Euclidean norm in Rd . For p ≥ 1 and [a, b] ⊂ R, a continuous
path x : [a, b] → Rd is of finite p-variation if
!1/p
n
X
< ∞,
(2.1)
|xti+1 − xti |p
|||x|||p-var,[a,b] := sup
Π(a,b) i=1

b p ([a, b], Rd ) ⊂
where the supremum is taken over the whole class of finite partition of [a, b]. The subspace C
d
C([a, b], R ) of all paths x with finite p-variation and equipped with the p-var norm
kxkp-var,[a,b]

:=

|xa | + |||x|||p-var,[a,b] ,

bp ([a, b], Rd ) then the mapping
is a nonseparable Banach space [7, Theorem 5.25, p. 92]. Notice that if x ∈ C
(s, t) → |||x|||p-var,[s,t] is continuous on the simplex ∆[a, b] := {(s, t)|a ≤ s ≤ t ≤ b}, see [7, Proposition 5.8, p.
80].
b p ([a, b], Rd ) is a separable Banach space denoted by
Furthermore, the closure of C ∞ ([a, b], Rd ) in C
0,p
d
b ([a, b], R ) which can be defined as the space of all continuous paths x such that
C
X
|xti+1 − hti |p = 0.
lim
sup
δ→0 Π(a,b),|Π|≤δ

i

It is easy to prove (see [7, Corollary 5.33, p. 98]) that for 1 ≤ p < p′ we have
bp ([a, b], Rd ) ⊂ C
b0,p′ ([a, b], Rd ).
C

Also, for 0 < α ≤ 1 denote by C α-Hol ([a, b], Rd ) the Banach space of all Hölder continuous paths x :
[a, b] → Rd with exponential α, equipped with the norm
kxkα-Hol,[a,b]

:=

|xa | + |||x|||α-Hol,[a,b]

=

|xa | +

|xt − xs |
< ∞.
α
(s,t)∈∆[a,b] (t − s)
sup

(2.2)

Clearly, if x ∈ C α-Hol ([a, b], Rd ) then for all s, t ∈ [a, b] we have
|||x|||α-Hol,[a,b] |t − s|α .

|xt − xs | ≤
Hence, for all p such that pα ≥ 1 we have
|||x|||p-var,[a,b]

≤

|||x|||α-Hol,[a,b] (b − a)α < ∞.

bp ([a, b], Rd ).
Therefore, C 1/p-Hol ([a, b], Rd ) ⊂ C
1/p,∞
As introduced in [14], the space Wb
([a, b], Rd ) of measurable functions g : [a, b] → Rd such that


Z t
|gy − gs |
|gt − gs |
+
dy < ∞
sup
1/p
1+1/p
a<s<t<b (t − s)
s (y − s)
1/p,∞

is a subspace of C 1/p-Hol ([a, b], Rd ). Hence Wb

b p ([a, b], Rd ).
([a, b], Rd ) ⊂ C
2

(2.3)

b p ([a, b], Rd ), p ≥ 1. If a = a1 < a2 < · · · < ak = b, then
Lemma 2.1 Let x ∈ C
k−1
X

p
|||x|||p-var,[ai ,ai+1 ]

≤

p
|||x|||p-var,[a1 ,ak ]

p−1

≤ (k − 1)

p

|||x|||p-var,[ai ,ai+1 ] .

i=1

i=1

Proof:
inequality

k−1
X

The proof is similar to the one in [7, p. 84], by using triangle inequality and power means
n

n

1X
zi ≤
n i=1

1X r
z
n i=1 i

!1/r

∀zi ≥ 0, r ≥ 1.

,

Definition 2.2 A continuous map ω : ∆[a, b] −→ R+ is called a control if it is zero on the diagonal and
superadditive, i.e
(i), For all t ∈ [a, b], ω t,t = 0,
(ii), For all s ≤ t ≤ u in [a, b], ω s,t + ωt,u ≤ ω s,u .
q

The functions (s, t) −→ (t − s)θ with θ ≥ 1, and (s, t) −→ |||x|||p-var,[s,t] , where x is of bounded p-variation
norm on [a, b] and q ≥ p are some examples of control function. The following lemma gives a useful property
of controls in relation with variations of a path (see [7] for more properties of control functions).
Lemma 2.3 Let ω j be a finite sequence of control functions on [0, T ], Cj > 0,
x : [0, T ] → Rd be a continuous path satisfying
|xt − xs | ≤

k
X

j = 1, k, p ≥ 1 and

Cj ω j (s, t)1/p , ∀s < t ∈ [0, T ].

i=j

Then
k
X

|||x|||p-var,[s,t] ≤

Cj ω j (s, t)1/p , ∀s < t ∈ [0, T ].

(2.4)

j=1

Proof: Consider an arbitrary finite partition Π = (si ), i = 0 . . . , n + 1, of [s, t]. By assumption and
Minskowski inequality we have
n
X
i=0

|xsi+1 − xsi |p

!1/p



≤ 
≤



n
X
i=0

n
X



k
X
j=1

p 1/p

Cj ω j (si , si+1 )1/p  
!1/p

C1p ω 1 (si , si+1 )

i=0

≤ C1

n
X

!1/p

1

ω (si , si+1 )

i=0

≤

k
X

+ ···+

n
X

!1/p

Ckp ω k (si , si+1 )

i=0

+ · · · + Ck

n
X
i=0

k

!1/p

ω (si , si+1 )

Cj ω j (s, t)1/p .

j=1

This implies the conclusion of the lemma.
bq ([a, b], Rd×m ) and ω ∈ C
b p ([a, b], Rm ), p, q ≥ 1, if Riemann-Stieltjes sums for finite
Now, consider x ∈ C
partition Π = {a = t0 < t1 < · · · < tn = b} of [a, b] and any ξi ∈ [ti , ti+1 ]
SΠ

:=

n
X

xξi (ωti+1 − ωti ),

i=1

3

(2.5)

converges as the mesh |Π| := min |ti+1 − ti | tends to zero, we call the limit is the Young integral of x
0≤i≤n−1
Rb
w.r.t ω on [a, b] denoted by a xt dωt . It is well known that if p, q ≥ 1 and p1 + 1q > 1, the Young integral
Rb
x dωt exists (see [17, p. 264–265]). Moreover, if xn and ω n are of bounded variation, uniformly bounded
a t
bq ([a, b], Rd×m ), C
bp ([a, b], Rd×m ) and converges uniformly to x, ω respectively, then the sequence of the
in C
Rb
Rb
Riemann-Stieljes integral a xnt dωtn approach a xt dωt as n → ∞ (see [7]). This integral satisfies additive
property by the construction, and the so-called Young-Loeve estimate [7, Theorem 6.8, p. 116]
Z t



xu dωu − xs [ωt − ωs ] ≤ K |||x|||q-var,[s,t] |||ω|||p-var,[s,t] ,


(2.6)

s

where

K := (1 − 21−θ )−1 ,

θ :=

1 1
+ > 1.
p q

(2.7)

bq ([a, b], Rd×m ), ω ∈ C
bp ([a, b], Rm ), the
Lemma 2.4 For 1 ≤ p, 1 ≤ q such that θ = 1p + 1q > 1 and x ∈ C
following estimates hold
Z .





 xu dωu 
≤
|||ω|||
|x
|
+
(K
+
1)
|
|x|||
(2.8)
a
p-var,[a,b]
q-var,[a,b] ,


a

p-var,[a,b]

where K is determined by (2.7).

Proof: To prove (2.8), we note that by virtue of (2.6) for all a ≤ s ≤ t ≤ b we have
Z t




xu dωu  ≤ |xs ||(ωt − ωs )| + K |||ω|||p-var,[s,t] |||x|||q-var,[s,t]

s


≤ |||ω|||p-var,[s,t] kxk∞,[a,b] + K |||x|||q-var,[a,b]


≤ |||ω|||p-var,[s,t] |xa | + (K + 1) ||x|||q-var,[a,b] .
p

Since ω̄(s, t) := |||ω|||p-var,[s,t] is a control on the simplex ∆[a, b] (see [7, Proposition 5.8, p. 80]),
is of bounded p-variation and
Z .





 xu dωu 
≤ |||ω|||p-var,[a,b] |xa | + (K + 1) ||x|||q-var,[a,b]


a

R.

a

xu dωu

p-var,[a,b]

due to [7, Proposition 5.10(i), p. 83].

Rt
Due to Lemma 2.4, the integral t 7→ a xs dωs is a continuous bounded p-variation path. Note that the
definition of Young integral does depend on the direction of integration in a simple way like the RiemannStieltjes integral. Namely, it is easy to see that
Z

b

2.2

a

xu dωu =

lim

Π(a,b),|Π|→0

n
X

xξi (ωti − ωti+1 ) = −

i=1

lim

Π(a,b),|Π|→0

n
X

xξi (ωti+1 − ωti ) = −

i=1

Z

b

xu dωu .

(2.9)

a

Greedy times analysis

ep (R, Rm ) the space of all continuous functions ω : R → Rm such that for any T > 0 the
Denote by C
bp ([−T, T ], Rm). Equip C
e p (R, Rm ) with the metric
restrictions of ω to [−T, T ] is of C
d(ω 1 , ω 2 ) :=

∞
X

n=1

2−n

kω 1 − ω 2 kp-var,[−n,n]
.
1 + kω 1 − ω 2 kp-var,[−n,n]

4

Let n ∈ N, observe that metric d satisfies
d(ω 1 , ω 2 )
kω 1 − ω 2 kp-var,[−n,n]

≤ kω1 − ω 2 kp-var,[−n,n] + 2−n ,
2n d(ω 1 ,ω 2 )
1−2n d(ω 1 ,ω 2 ) ,

≤

(2.10)

where the second inequality holds for any fixed n and ω 1 , ω 2 close enough such that 2n d(ω 1 , ω 2 ) < 1. Hence
b p ([−n, n], Rm ),
every Cauchy sequence (ω k )k w.r.t. metric d is also a Cauchy sequence when restricted to C
∗
p
m
b
ep (R, Rm ).
thus converges to a limit ω ∈ C ([−n, n], R ) which is uniquely defined pointwise, so ω ∗ ∈ C
p
m
e (R, R ), d) is a complete metric space.
Therefore, (C

ep (R, Rm )
Remark 2.5 (i) Truncation: Another consequence of (2.10) is that the truncated version of ω ∈ C
p
m
b
in any C ([−n, n], R ) differs very small w.r.t. metric d from the original ω if we choose n large enough.
bp ([−n, n], Rm ) for any n > 0 then it is
Moreover, if a function is continuous w.r.t. ω on any restriction in C
p
m
e (R, R ) with respect to metric d.
also continuous w.r.t. ω in C
b p ([a, b], Rm ), ω 2 ∈ C
bp ([b, c], Rm ) and ω 1 = ω 2 .
(ii) Concatenation: Let a < b < c. Suppose that ω 1 ∈ C
b
b
1
2
p
m
b
Then ω .1[a,b] + ω .1[b,c] belongs to C ([a, c], R ).
For any given λ, µ > 0 we construct a strict increasing sequence of greedy times {τn },

such that τ0 ≡ 0 and

ep (R, Rm ) −→ R+ ,
τn : C

|τi+1 (ω) − τi (ω)|λ + |||ω|||p-var,[τi (ω),τi+1 (ω)] = µ.

(2.11)

ep (R, Rm ) −→ R+ such that
To do so, first define τ : C

τ (ω) := sup{t ≥ 0 : tλ + |||ω|||p-var,[0,t] ≤ µ}.

Observe that the function κ(t) := tλ + |||ω|||p-var,[0,t] is continuous and stricly increasing w.r.t. t with κ(0) = 0
and κ(∞) = ∞, therefore due to the continuity there exists a unique τ = τ (ω) > 0 such that
τ λ + |||ω|||p-var,[0,τ ] = µ.

(2.12)

Thus τ is well defined. Next, we construct the so-called greedy times inductively as follows. Set τ0 := 0,
τ1 (ω) := τ (ω). Suppose that we have defined τn (ω) for n ≥ 1, looking at the following equality as an equation
of δn (ω) ∈ R+ , like above we find an unique δn (ω) such that
µ = δnλ (ω) + |||ω(· + τn (ω))|||p−var,[0,δn (ω)] ,
hence we can set
τn+1 (ω) := τn−1 (ω) + δn (ω),

(2.13)

where δn (ω) is determined above. Thus we have defined a sequence of greedy times {τn } for all n = 0, 1, 2, . . ..
Such a sequence of greedy times then satisfies (2.11).
e p (R, Rm ) and consider the number of greedy times inside an arbitrary finite interval of
Now, we fix ω ∈ C
R . We write τn for τn (ω) to simplify the notation. For given T > 0, we introduce the notation
+

N (T, ω) := sup{n : τn ≤ T } < ∞.

(2.14)

or more general, for any 0 ≤ a < b < ∞,
N (a, b, ω) :=

sup{n : τn ≤ b} − inf{n : τn ≥ a}.

5

(2.15)

Lemma 2.6 Let p′ ≥ max{p, λ1 } be arbitrary, the following estimate holds

2p −1  p′ λ
p′
T
+ |||ω|||p-var,[0,T ] .
′
p
µ
′

N (T, ω) ≤

(2.16)

More general,
i
2p −1 h
p′
p′ λ
(b
−
a)
+
|||ω|||
p-var,[a,b] .
µp′
′

N (a, b, ω) ≤
Proof: We have for all n ∈ N∗
′

nµp

=

n−1
X
i=0

≤
≤
≤

2

′

µp =

p′ −1

2

p′ −1

2

p′ −1

Consequently, we obtain

n−1
Xh

|τi+1 − τi |λ + |||ω|||p-var,[τi ,τi+1 ]

i=0

"n−1
X

"

|τi+1 − τi |

p′ λ

+

 n−1
X

ip′

p
|||ω|||p-var,[τi ,τi+1 ]

i=0

i=0

p′ λ

(τn − τ0 )

 n−1
X

+

p
|||ω|||p-var,[τi ,τi+1 ]

i=0

i
h ′
p′
τnp λ + |||ω|||p-var,[0,τn ] .

p′ /p

(2.17)

p′ /p
#

#

(2.18)

i
2p −1 h p′ λ
p′
T
+ |||ω|||p-var,[0,T ] .
′
p
µ
′

N (T, ω) ≤
Similarly, (2.17) holds.

Remark 2.7
1. Since the left-hand side of (2.18) tends to infinite its right hand side cannot be bounded.
This implies that τn → ∞ as n → ∞.
2. We can construct the sequence of greedy times starts at τ0 = t0 , an arbitrary point in R, and on
(−∞, t0 ]) in a similar manner.
3. The original idea of greedy times was introduced in [4] for autonomous systems. A version of stopping
times was developped before by [9] and then by [6]. Here we propose another version of greedy times
which fits with the nonautonomous setting.

3

Existence and uniqueness theorem

In this section, we are working with the restriction of any trajectory ω in a given time interval [0, T ] by
bp ([0, T ], Rm ), for a certain p ∈ (1, 2) (see Remark 2.5 for the relation between
consider it as an element in C
p
m
e (R, R ) and its restrictions). Consider the Young differential equation in the integral form as:
ω∈C
xt = x0 +

Z

0

t

f (s, xs )ds +

Z

t

g(s, xs )dωs , t ∈ [0, T ].

(3.1)

0

We recall here a result in [14] on existence and uniqueness of solution of (3.1), which was proved using
contraction mapping arguments with ω in a Besov-type space. In this paper we however would like to derive
bp applying Shauder fixed point theorem and greedy time tool. First we need to formulate some
a proof in C
assumptions on the coefficient functions f and g of (3.1).

6

(H1 ) g(t, x) is differentiable in x and there exist some constants 0 < β, δ ≤ 1, a control function h(s, t)
defined on ∆[0, T ] and for every N ≥ 0 there exists MN > 0 such that the following properties hold:


(i) Lipschitz continuity




|g(t, x) − g(t, y)| ≤ Lg |x − y|, ∀x, y ∈ Rd , ∀t ∈ [0, T ],




(ii) Local Hölder continuity



|∂ g(t, x) − ∂ g(t, y)| ≤ M |x − y|δ ,
N
yi
xi
(Hg ) :

∀x,
y
∈
Rd , |x|, |y| ≤ N, ∀t ∈ [0, T ],





(iii) Generalized Hölder continuity in time




|g(t, x) − g(s, x)| + |∂xi g(t, x) − ∂xi g(s, x)| ≤ h(s, t)β



∀x ∈ Rd , ∀s, t ∈ [0, T ], s < t.

1
d
1 ([0, T ], R ), where
(H2 ) There exists a > 0 and b ∈ L 1−α
2 ≤ α < 1, and for every N ≥ 0 there exists
LN > 0 such that the following properties hold:

(i) Local Lipschitz continuity



|f (t, x) − f (t, y)| ≤ L |x − y|, ∀x, y ∈ Rd , |x|, |y| ≤ N, ∀t ∈ [0, T ],
N
(Hf ) :

(ii)
Boundedness



|f (t, x)| ≤ a|x| + b(t), ∀x ∈ Rd , ∀t ∈ [0, T ].

1
1
(H3 ) The parameters in H1 and H2 statisfy the inequalities δ > p − 1, β > 1 − , δα > 1 − .
p
p

We would like to study the existence and uniqueness of the solution of (3.1) under the given conditions
bq ([0, T ], Rd ) with appropriate constant q > 0.
that x ∈ C


δ 1
1
, thus we can choose
By the assumption p ∈ (1, 2) and the condition H3 , 1 − < min β, δα, ,
p
p 2
consecutively constants q0 , q such that


1
δ 1
1
1− <
,
(3.2)
< min β, δα, ,
p
q0
p 2
1
1
1
≤
< min{α, }.
(3.3)
q0 δ
q
p
Then, we have

1
1
> 1, q0 β > 1, q0 ≥ q0 δ ≥ q > p, qα > 1.
+
p q0

(3.4)

b q ([t0 , t1 ], Rd ) with some [t0 , t1 ] ⊂ [0, T ]. Define the mapping given by
We now consider x ∈ C
F (x)t

=

:=

xt0 + I(x)t + J(x)t
Z t
Z t
g(s, xs )dωs ,
f (s, xs )ds +
xt0 +

∀t ∈ [t0 , t1 ].

(3.5)

t0

t0

Note that a fixed point of F is a solution of (3.1) on [t0 , t1 ] with the boundary condition x(t0 ) = xt0 (the
initial condition x0 of (3.1) is then not given).
Introduce the notations
M
′
MN

:= max{Lg , aT 1−α , |g(0, 0)| + h(0, T )β , kbkL
:= max{LN , MN , M },

∀N > 0.

1
1−α

},

(3.6)
(3.7)

It can be seen from the above assumptions that |g(t, x)| ≤ |g(t, 0)| + Lg |x| and |g(t, 0)| ≤ |g(0, 0)| + h(0, T )β ,
hence
|g(t, x)| ≤ |g(0, 0)| + h(0, T )β + Lg |x| ≤ M (1 + |x|).
(3.8)
For the next propositions we need the following auxiliary lemma.
7

Lemma 3.1 Assume that H1 − H3 are satisfied.
b q ([t0 , t1 ], Rd ) then g(·, x. ) ∈ C
bq0 ([t0 , t1 ], Rd×m ) and
(i) If x ∈ C

|||g(·, x. )|||q0 -var,[t0 ,t1 ] ≤ M (1 + |||x|||q-var,[t0 ,t1 ] ).

(3.9)

(ii) For all s < t and for all xi ∈ Rd such that |xi | ≤ N , i = 1, 2, 3, 4, then
Lg |x1 − x2 − x3 + x4 | + |x2 − x4 |h(s, t)β
+MN |x2 − x4 |(|x1 − x2 |δ + |x3 − x4 |δ ).

|g(s, x1 ) − g(s, x3 ) − g(t, x2 ) + g(t, x4 )| ≤

bq ([t0 , t1 ], Rd ) such that xt0 = yt0 and kxk∞,[t ,t ] ≤ N , kyk∞,[t ,t ] ≤ N we have
(iii) For any x, y ∈ C
0 1
0 1


δ
δ
′
|||g(·, x. ) − g(·, y. )|||q0 -var,[t0 ,t1 ] ≤ MN
|||x − y|||q-var,[t0 ,t1 ] 2 + |||x|||q-var,[t0 ,t1 ] + |||y|||q-var,[t0 ,t1 ] .

(3.10)

Proof: (i) For s < t in [t0 , t1 ], we have
|g(t, xt ) − g(s, xs )| ≤
≤

|g(t, xt ) − g(t, xs )| + |g(t, xs ) − g(s, xs )|
Lg |xt − xs | + h(s, t)β .

Let Π = (si )n+1
be an arbitrary finite partition of [t0 , t1 ], s1 = t0 , sn+1 = t1 . Since q0 ≥ q and q0 β > 1 we
1
have
!1/q0
!1/q0
!1/q0
n
n
n
X
X
X
q0 β
q0
q0
h(si , si+1 )
+
|xsi+1 − xsi |
≤ Lg
|g(si+1 , xsi+1 ) − g(si , xsi )|
i=1

i=1

i=1

β

≤ Lg |||x|||q0 -var,[t0 ,t1 ] + h(t0 , t1 )

≤ Lg |||x|||q-var,[t0 ,t1 ] + h(t0 , t1 )β
≤ Lg |||x|||q-var,[t0 ,t1 ] + h(0, T )β
≤ M (1 + |||x|||q-var,[t0 ,t1 ] ) < ∞.
b q0 ([t0 , t1 ], Rd×m ) and
Take the superemum over the set of all finite partition Π we get g(·, x. ) ∈ C
|||g(·, x. )|||q0 -var,[t0 ,t1 ] ≤ M (1 + |||x|||q-var,[t0 ,t1 ] ).

(ii) This part is similar to [14, Lemma 7.1] with our function h(s, t)β playing the role of |t − s|β in [14,
Lemma 7.1].
(iii) Note that q0 β > 1 and q0 δ ≥ q hence
|||g(·, x. ) − g(·, y. )|||q0 -var,[t0 ,t1 ]

:=

sup
Π([t0 ,t1 ])

≤

X

sup

Lg

Π([t0 ,t1 ])

+kx − yk∞,[t0 ,t1 ]

≤

X

sup
Π([t0 ,t1 ])

+MN kx − yk∞,[t0 ,t1 ]
≤

|g(si+1 , xsi+1 ) − g(si+1 , ysi+1 ) − g(si , xsi ) + g(si , ysi )|

i

|xsi+1 − ysi+1 − xsi + ysi |q0

i

X
i

sup
Π([t0 ,t1 ])




q0 β

h(si , si+1 )
X
i

!1/q0

|xsi+1 − xsi |q0 δ

!1/q0

!1/q0

+

q0

+

X
i

|ysi+1 − ysi |q0 δ

!1/q0 

Lg |||x − y|||q-var,[t0 ,t1 ]

i
h
+kx − yk∞,[t0 ,t1 ] h(t0 , t1 )β + MN |||x|||δq-var,[t0 ,t1 ] + |||y|||δq-var,[t0 ,t1 ]


δ
δ
′
MN
|||x − y|||q-var,[t0 ,t1 ] 2 + |||x|||q-var,[t0 ,t1 ] + |||y|||q-var,[t0 ,t1 ] .
8

!1/q0



The lemma is proved.
For a proof of our main theorem on existence and uniqueness of solutions of an Young differential equation,
we need the following proposition.
Proposition 3.2 Assume that H1 − H3 are satisfied. Let 0 ≤ t0 < t1 ≤ T be arbitrary, q be chosen as above
b q ([t0 , t1 ], Rd ) we have F (x) ∈ C
bq ([t0 , t1 ], Rd ),
satisfying (3.3) and F be defined by (3.5). Then for any x ∈ C
thus
bq ([t0 , t1 ], Rd ) −→ C
bq ([t0 , t1 ], Rd ).
F :C
Moreover, the following statements hold
(i) The q-variation of F (x) satisfies
|||F (x)|||q-var,[t0 ,t1 ]

≤

M (K + 2) 1 + kxkq-var,[t0 ,t1 ]




(t1 − t0 )α + |||ω|||p-var,[t0 ,t1 ] .

(3.11)

bq ([t0 , t1 ], Rd ) be such that kxk∞,[t ,t ] ≤ N ,
(ii) Let N ≥ 0 be arbitrary but fixed. Suppose that x, y ∈ C
0 1
kyk∞,[t0,t1 ] ≤ N and xt0 = yt0 , then we have


kF (x) − F (y)kq-var,[t0 ,t1 ] ≤ kx − ykq-var,[t0 ,t1 ] (t1 − t0 ) + |||ω|||p-var,[t0 ,t1 ]


δ
δ
′
×MN
(K + 1) 2 + |||x|||q-var,[t0 ,t1 ] + |||y|||q-var,[t0 ,t1 ] .
(3.12)
Proof: (i) Since 1p + q10 > 1, by virtue of (3.9), the Young integral
Using (2.8), (3.5) and (3.8) we get
|||J(x)|||q-var,[t0 ,t1 ]

≤
≤
≤
≤

Rt
0

g(s, xs )dωs exists for all t ∈ [t0 , t1 ].

|||J(x)|||p-var,[t0 ,t1 ]
(because p ≤ q)
i
h
|||ω|||p-var,[t0 ,t1 ] |g(t0 , xt0 )| + (K + 1) |||g(., x. )|||q0 -var,[t0 ,t1 ]
i
h
|||ω|||p-var,[t0 ,t1 ] M (1 + |xt0 |) + M (K + 1)(1 + |||x|||q-var,[t0 ,t1 ] )
i
h
|||ω|||p-var,[t0 ,t1 ] M (K + 2) + |xt0 | + (K + 1) |||x|||q-var,[t0 ,t1 ] .

Now, by Hölder inequality and the assumption H2 we have
Z

t

|b(u)|du ≤

s

Z

t

|b(u)|

1
1−α

du

s

1−α Z

t

1du

s

α

≤ kbkL

1
1−α

(t − s)α ≤ M (t − s)α .

Therefore, for s < t in [t0 , t1 ] using the assumption H2 we have
Z t

Z t




(a|xu | + |b(u)|)du
f (u, xu )du ≤

s

s

akxk∞,[s,t] (t − s) + kbkL 1 (t − s)α
1−α


(t − s)α aT 1−α kxk∞,[t0 ,t1 ] + kbkL 1
1−α


α
(t − s) M 1 + |xt0 | + |||x|||q-var,[t0 ,t1 ] .

≤

≤
≤
This implies
|||I(x)|||q-var,[t0 ,t1 ]

Z .






=  f (u, xu )du
t0

q-var,[t0 ,t1 ]



≤ M (t1 − t0 )α 1 + |xt0 | + |||x|||q-var,[t0 ,t1 ]

by [7, Proposition 5.10(i), p. 83] and the fact that the function (s, t) → (t − s)qα defined on ∆[t0 , t1 ] is a
control function for qα > 1. Since
|||F (x)|||q-var,[t0 ,t1 ] ≤ |||I(x)|||q-var,[t0 ,t1 ] + |||J(x)|||q-var,[t0 ,t1 ]
9

(3.11) holds.
(ii) By virtue of (2.8), (3.10) and the condition xt0 = yt0 of the Proposition, we have
i
h
|||J(x) − J(y)|||p-var,[t0 ,t1 ] ≤ |||ω|||p-var,[t0 ,t1 ] |g(t0 , xt0 ) − g(t0 , yt0 )| + (K + 1) |||g(., x. ) − g(., y. )|||q0 -var,[t0 ,t1 ]
≤

≤
Furthermore,

|||ω|||p-var,[s,t] (K + 1) |||g(., x. ) − g(., y. )|||q0 -var,[t0 ,t1 ]


′
(K + 1)MN
|||ω|||p-var,[t0 ,t1 ] kx − ykq-var,[t0 ,t1 ] 2 + |||x|||δq-var,[t0 ,t1 ] + |||y|||δq-var,[t0 ,t1 ] .

|[I(x)(t) − I(y)(t)] − [I(x)(s) − I(y)(s)]|

≤

Z

t

|f (u, xu ) − f (u, yu )|du
Z t
LN
|xu − yu |du
s

≤

s

≤
≤

LN kx − yk∞,[t0 ,t1 ] (t − s)

LN kx − ykq-var,[t0 ,t1 ] (t − s),

hence
′
|||I(x) − I(y)|||q-var,[t0 ,t1 ] ≤ MN
kx − ykq-var,[t0 ,t1 ] (t1 − t0 ).

Inequality (3.12) is a direct consequence of these estimates for I(x) and J(x).
Before proving the existence and uniqueness theorem, we need the following lemma of Gronwall type.
Lemma 3.3 (Gronwall-type Lemma) Let 1 ≤ p ≤ q be arbitrary and satisfy
b p ([0, T ], R) and y ∈ C
bq ([0, T ], Rd ) satisfy
ω∈C
|yt − ys | ≤

1/q
As,t

Z t

Z t








+ a1 
yu du + a2 
yu dωu  ,
s

∀s, t ∈ [0, T ],

1
p

+

1
q

> 1. Assume that

s < t,

(3.13)

s

for some fixed control function A on ∆[0, T ] and some constants a1 , a2 ≥ 0. Then there exists a constant C
independent of T such that for every s, t ∈ [0, T ], s < t,
|||y|||q-var,[s,t] ≤ (|ys | + A0 )e

)
C(|t−s|p +|||ω|||p
p-var,[s,t]

,

(3.14)

1/q

where A0 = A0,T .
Proof: Put
c := max{a1 , a2 (K + 1)},
in which K is defined in (2.7). We have
|yt − ys |

1/q

≤ As,t + a1 kyk∞,[s,t](t − s) + a2 |||ω|||p-var,[s,t] (kyk∞,[s,t] + K |||y|||q-var,[s,t] )
n
o
1/q
≤ As,t + max a1 kyk∞,[s,t] , a2 (kyk∞,[s,t] + K |||y|||q-var,[s,t] ) (t − s + |||ω|||p-var,[s,t] ).

Fix the interval [s, t] ⊂ [0, T ] and apply the above inequality for arbitrary subinterval [u, v] ⊂ [s, t] we obtain
|yv − yu | ≤ A1/q
u,v + max{a1 kyk∞,[s,t] , a2 (kyk∞,[s,t] + K |||y|||q-var,[s,t] )}(v − u + |||ω|||p-var,[u,v] )
≤ A1/q
u,v + max{a1 , a2 (K + 1)}(|ys | + |||y|||q-var,[s,t] )(v − u + |||ω|||p-var,[u,v] )
≤ A1/q
u,v + c(|ys | + |||y|||q-var,[s,t] )(v − u + |||ω|||p-var,[u,v] ).
Therefore, by virtue of Lemma 2.3, we get
|||y|||q-var,[s,t]

1/q

≤ As,t + c(|ys | + |||y|||q-var,[s,t] )(t − s + |||ω|||p-var,[s,t] )
≤ A0 + c(|ys | + |||y|||q-var,[s,t] )(t − s + |||ω|||p-var,[s,t] ).
10

(3.15)

1
Now we construct the sequence of greedy times ti with parameter {1, 2c
} according to Subsection 2.2, that is

(ti+1 − ti + |||ω|||p-var,[ti ,ti+1 ] ) =

1
.
2c

Then, by (3.15) for all s, t ∈ [ti , ti+1 ], s < t, we have
1
|||y|||q-var,[s,t] ≤ A0 + (|ys | + |||y|||q-var,[s,t] ),
2
which implies
|||y|||q-var,[ti ,ti+1 ]

≤

2A0 + |yti |,

|||y|||q-var,[u,v]

≤

2A0 + |yu |,

∀ u, v ∈ [ti , ti+1 ], u < v.

Therefore,
|yti+1 | ≤ kyk∞,[ti,ti+1 ] ≤ 2(A0 + |yti |),
or more generally
|yti+1 | ≤ kyk∞,[s,ti+1 ] ≤ 2(A0 + |ys |),

∀s ∈ [ti , ti+1 ].

(3.16)

By induction we obtain for any s ∈ [tk , tk+1 ], 0 ≤ k ≤ i, i ∈ {0, . . . , N (T, ω)}, where N (T, ω) is defined by
(2.14), the sequence of inequalities
2A0 + |yti+1 | ≤ 2(2A0 + |yti |) ≤ · · · ≤ 2i−k (2A0 + |ytk+1 |) ≤ 2i−k+1 (2A0 + |ys |).

(3.17)

Hence,
|||y|||q-var,[ti ,ti+1 ] ≤ 2A0 + |yti | ≤ 2i−k (2A0 + |ys |),

∀s ∈ [tk , tk+1 ], 0 ≤ k ≤ i.

(3.18)

Now, we estimate the q-var norm of y in an arbitrary but fixed interval [s, t] ⊂ [0, T ]. Recall the sequence of
greedy time defined in (2.11). If there exists i such that s < ti < t, put
N

:=

sup{n : tn ≤ t},

N
N

:=
:=

inf{n : tn ≥ s},
N − N = N (s, t, ω).

(3.19)

We have s ≤ tN < tN +1 < · · · < tN ≤ t and
|||y|||q-var,[s,tN ]
|||y|||q-var,[tN +i ,tN +i+1 ]
|||y|||q-var,[t

N ,t]

≤ 2A0 + |ys |,
≤ 2i+1 (2A0 + |ys |), i = 0, . . . , N − 1,
≤ 2A0 + |ytN | ≤ 2N (2A0 + |ys |).

By Lemma 2.1 we have
|||y|||q-var,[s,t]

≤ (N + 1)

q−1
q

q
|||y|||q-var,[s,tN ]

+

N
−1
X

q
|||y|||q-var,[ti ,ti+1 ]

+

i=1

≤ (N + 1)

q−1
q

N
X
2jq )1/q
(2A0 + |ys |)(
j=0

N

≤ (N + 1)(2A0 + |ys |)2 .

In the case [s, t] ⊂ [ti , ti+1 ] with some i ∈ {0, 1, . . . , N (T, ω)}, we already have
|||y|||q-var,[s,t] ≤ 2A0 + |ys |.

11

q
|||y|||q-var,[t ,t]
N

!1/q

To sum up, for any [s, t] ⊂ [0, T ] we have the estimate
|||y|||q-var,[s,t] ≤ (2A0 + |ys |)22N .
Combining with (2.17), we conclude that
|||y|||q-var,[s,t]

)
4p cp (|t−s|p +|||ω|||p
p-var,[s,t]

≤

(2A0 + |ys |)2

≤

(2A0 + |ys |)eC(|t−s|

p

+|||ω|||p
)
p-var,[s,t]

,

where C = 4p cp ln 2. The proof is complete.
Remark 3.4
1. Gronwall Lemma is an important tool in the theory of ordinary differential equations,
and the theory of Young differential equations as well. Some versions of Gronwall-type lemma can be
seen in [14] and [20].
1/q

2. The conclusion of Lemma 3.3 is still true if one replaces A0 by As,t .
3. It can be seen from the proof that in the conditions of Lemma 3.3 we have
kyk∞,[0,T ] ≤ (2A0 + |y0 |)2N (T,ω)+1 ≤ (2A0 + |y0 |)2(4cT )

p

+1+(4c|||ω|||p-var,[s,t] )p

.

Corollary 3.5 If in Lemma 3.3 we replace the condition (3.13) by the condition
1/q

|||y|||q-var,[s,t] ≤ As,t + a1 (|ys | + |||y|||q-var,[s,t] )(t − s + |||ω|||p-var,[s,t] )

(3.20)

bp ([0, T ], Rm). Then there exists a constant C
for all s < t in [0, T ], a positive constant a1 > 0 and ω ∈ C
independent of T such that for every s < t in [0, T ]
1/q

|||y|||q-var,[s,t] ≤ (|ys | + As,t )e

C(|t−s|p +|||ω|||p
)
p-var,[s,t]

(3.21)

.

We are now at the position to state and prove the main theorem of this section.
Theorem 3.6 (Existence and uniqueness of global solution) Consider the Young differential equation
(3.1), starting from an arbitrary initial time t0 ∈ [0, T ),
xt = xt0 +

Z

t

f (s, xs )ds +

Z

t

g(s, xs )dωs ,

t ∈ [t0 , T ],

xt0 ∈ Rd .

t0

t0

with T being an arbitrary fixed positive number and x0 ∈ Rd being an arbitrary initial condition. Assume that
bq ([t0 , T ], Rd), where
the conditions H1 − H3 hold. Then, this equation has a unique solution x in the space C
p′
d
b
q is chosen as above satisfying (3.3). Moreover, the solution is in C ([t0 , T ], R ), where p′ = max{p, α1 }.
Proof: The proof proceeds in several steps.
Step 1: In this step we will show the local existence and uniqueness of solution. Set
µ :=

1
,
2M (K + 2)

(3.22)

where M is defined in (3.6) and K is defined in (2.7). Let s0 ∈ [t0 , T ) be arbitrary but fixed. We recall here
the sequence of greedy times τn with the parameters α, µ, i.e
τ0 = 0, |τi+1 − τi |α + |||ω|||p-var,[τi ,τi+1 ] = µ.
Put r0 = min{n : τn > s0 } and define s1 = min{τr0 , T }. Then,
|s1 − s0 |α + |||ω|||p-var,[s0 ,s1 ] ≤ µ.
12

(3.23)

We will show that the equation (3.1) restricted to [s0 , s1 ],
Z t
Z t
g(s, xs )dωs ,
f (s, xs )ds +
xt = xs0 +
s0

t ∈ [s0 , s1 ],

xs0 ∈ Rd ,

s0

has a a unique solution.
Existence of local solutions.
Recall the mapping F defined by the formula (3.5) with t0 , t1 replaced by s0 , s1 , respectively. By Propobq ([s0 , s1 ], Rd ) −→ C
bq ([s0 , s1 ], Rd )
sition 3.2 and (3.22)–(3.23), for s0 , s1 determined above we have F : C
and
kF (x)kq-var,[s0 ,s1 ] = |F (x)s0 | + |||F (x)|||q-var,[s0 ,s1 ]

≤ |xs0 | +


1
1 + kxkq-var,[s0 ,s1 ] .
2

bq ([s0 , s1 ], Rd ) then F (x) ∈ C (q−ǫ)-var ([s0 , s1 ], Rd ) with small enough ǫ.
We show, furthermore, that if x ∈ C
Indeed, since q > p, qα > 1, we can choose ǫ > 0 such that q − ǫ ≥ p and (q − ǫ)α ≥ 1. For all s < t in
[s0 , s1 ], using (3.11) we have
|F (x)t − F (x)s | ≤ |||F (x)|||q-var,[s,t]


(t − s)α + |||ω|||p-var,[s,t]

1
1 
 q−ǫ
 q−ǫ

 
(q−ǫ)
,
(t − s)(q−ǫ)α
+ |||ω|||p-var,[s,t]
≤ M (K + 2) 1 + kxkq-var,[s0 ,s1 ]
≤ M (K + 2) 1 + kxkq-var,[s0 ,s1 ]

then



|||F (x)|||(q−ǫ)−var,[s0 ,s1 ] ≤ M (K + 2) 1 + kxkq-var,[s0 ,s1 ]



(s1 − s0 )α + |||ω|||p-var,[s0 ,s1 ]



and the assertion follows by an application of Lemma 2.3. Now, looking at the mapping F again, we introduce
the set
o
n
bq ([s0 , s1 ], Rd )| x(s0 ) = xs0 , kxkq-var,[s ,s ] ≤ 2|xs0 | + 1 .
B1 := x ∈ C
0 1
Taking into account (3.12), the map F is continuous and

F : B1 → B1 .
bq ([s0 , s1 ], Rd ), and F is a compact operator on
We show that B1 is a closed convex set in the Banach space C
B1 . Indeed, for the former observation, note that if z = λx + (1 − λ)y for some x, y ∈ B1 , λ ∈ [0, 1] then
zs0 = λxs0 + (1 − λ)ys0 = λxs0 + (1 − λ)xs0 = xs0

and
kzkq-var,[s0 ,s1 ] = kλx + (1 − λ)ykq-var,[s0 ,s1 ] ≤ λkxkq-var,[s0 ,s1 ] + (1 − λ)kykq-var,[s0 ,s1 ] ≤ 2|xs0 | + 1.
Now, we prove that for any sequence y n ∈ F (B1 ), there exists an subsequence converges in p-var norm to an
element y ∈ B1 , i.e. F (B1 ) is relatively compact in B1 . To do that, we will show that (y n ) are equicontinuous,
bounded in (q − ǫ)-var norm. Namely, take the sequence y n = F (xn ) ∈ F (S), xn ∈ B1 . Then, by virtue of
Lemma 2.3 we have
sup ky n k(q−ǫ)-var,[s0 ,s1 ] ≤ |xs0 | + 2M (K + 2)(1 + |xs0 |)((s1 − s0 )α + |||ω|||p-var,[s0 ,s1 ] ).
n

It means that y n are bounded in C([s0 , s1 ], Rd ) with sup norm, as well as bounded in C (q−ǫ)-var ([s0 , s1 ], Rd ).
Moreover, for all n, s0 ≤ s ≤ t ≤ s1 ,


|ytn − ysn | ≤ 2M (K + 2)(1 + |xs0 |) (t − s)α + |||ω|||p-var,[s,t] ,
13

which implies that (y n ) is equicontinuous. Applying Proposition 5.28 of [7], we conclude that y n converges
bq ([s0 , s1 ], Rd ). This proves the compactness of F (B1 ). Hence, F (B1 )
to some y along a subsequence in C
q
b ([s0 , s1 ], Rd ). We conclude that F is a compact operator from B1 into itself.
is a relative compact set in C
Therefore, by the Schauder-Tychonoff fixed point theorem (see e.g [19, Theorem 2.A, p. 56]), there exists a
function x̂ ∈ B1 such that F (x̂) = x̂, thus there exists a solution x̂ ∈ B1 of (3.1) on the interval [s0 , s1 ].
Uniqueness of local solutions.
b q ([s0 , s1 ], Rd ) of the equation (3.1) such that xs0 = ys0 . It
Now, we assume that x, y are two solutions in C
follows that F (x) = x and F (y) = y. Put
N0 = max{kxkq-var,[s0 ,s1 ] , kykq-var,[s0 ,s1 ] },

and z = x − y, we have zs0 = 0 and
kxk∞,[s0 ,s1 ] , kyk∞,[s0 ,s1 ] ≤ N0 .
By virtue of Proposition 3.2(ii), we obtain
|||z|||q-var,[s,t]

=
≤

|||x − y|||q-var,[s,t] = |||F x − F y|||q-var,[s,t]


δ
′
(K
+
1)(1
+
2N
)
|z
|
+
|||z|||
(t − s + |||ω|||p-var,[s,t] ).
MN
s
0
q-var,[s,t]
0

(3.24)

Applying Corollary 3.5 to the function z, since zs0 = 0 we conclude that |||z|||q-var,[s0 ,s1 ] = 0. That implies
z ≡ 0 on [s0 , s1 ]. The uniqueness of the local solution is proved.
Step 2: Next, by virtue of the additivity of the Riemann and Young integrals, the solution can be
concatenated. Namely, let 0 < t1 < t2 < t3 ≤ T . Let xt be a solution of the equation
Z t
Z t
g(s, xs )dωs , t ∈ [t1 , t2 ],
f (s, xs )ds +
xt = xt1 +
t1

t1

and yt be a solution of the equation
yt = yt2 +

Z

t

f (s, ys )ds +

Z

t

g(s, ys )dωs ,

t ∈ [t2 , t3 ],

t1

t2

and y(t2 ) = x(t2 ). Define a continuous function z(·) : [t1 , t3 ] → Rd by setting z(t) = x(t) on [t1 , t2 ] and
z(t) = y(t) on [t2 , t3 ]. Then z(·) is the solution of the Young differential equation
zt = x1 +

Z

t

t1

f (s, zs )ds +

Z

t

g(s, zs )dωs ,

t ∈ [t1 , t3 ].

t1

Conversely, If zt is a solution on [t1 , t3 ] then its restrictions on [t1 , t2 ] and on [t2 , t3 ] are solutions of the
corresponding equation with the corresponding initial values.
Step 3: Finally, apply the estimates (2.17) to the case of µ being defined by (3.22), we can easily get the
unique global solutions to the equation (3.1) on [t0 , T ].
Put n0 = min{n : τn > t0 }. The interval [t0 , T ] can be covered by N (T, ω) − n0 + 1 intervals [ti , ti+1 ],
i = 0, N (T, ω) − n0 + 1, determined by greedy times ti = τn0 +i−1 , i = 1, . . . , N (T, ω) − n0 , with parameter
µ being defined by (3.22) and tN (T,ω)+1 := T . The arguments in Step 1 are applicable to each of intervals
[ti , ti+1 ], i = 0, N (T, ω), implying the existence and uniqueness of solutions on those intervals. Then, starting
at x(t0 ) = xt0 the unique solution of (3.1) on [t0 , t1 ] is extended uniquely to [t1 , t2 ], then further by induction
up to [tN (T,ω)−1 , tN (T,ω) ] and lastly to [tN (T,ω) , T ]. The solution x of (3.1) on [t0 , T ] then exists uniquely.
bq−ǫ ([ti , ti+1 ], Rd ), for all i =
Furthermore, for all ǫ such that q − ǫ ≥ p′ the solution x belongs to C
′
p
d
b ([t0 , T ], R ).
0, N (T, ω). Hence, x ∈ C

14

Proposition 3.7 Assume that the conditions H1 − H3 are satisfied. Let 0 ≤ t0 < T . Denote by x(·) =
x(t0 , ·, ω, x0 ) the solution of the equation (3.1) on [t0 , T ]. Then there exist positive constants C1 = C1 (T ),
C2 = C2 (T ) such that
kxkq-var,[t0 ,T] ≤ C1 [1 + (T − t0 )α ](1 + |x0 |)(1 + |||ω|||p-var,[t0 ,T] )e

′

C2 |||ω|||p
p-var,[t

0 ,T]

(3.25)

,

where p′ = max{p, α1 }.
Proof: Since x is a solution, x = F x, hence by (3.11) we have


|||x|||q-var,[s,t] ≤ M (K + 2) 1 + kxkq-var,[s,t] (t − s)α + |||ω|||p-var,[s,t]


≤ M (K + 2) (t − s)α + |||ω|||p-var,[s,t]


+M (K + 2)(|xs | + |||x|||q-var,[s,t] ) (t − s)α + |||ω|||p-var,[s,t]

Use the arguments similar to that of the proof of Lemma 3.3 we conclude that there exist C1 = C1 (T ) and
C2 = C2 (T ) such that
p′

|||x|||q-var,[s,t] ≤ C1 (|xs | + |t − s|α + |||ω|||p-var,[s,t] )eC2 |||ω|||p-var,[s,t] ,

∀s < t ∈ [t0 , T ].

Thus, we get (3.25).
In order to study the flow generated by the solution of system (3.1) in the next section, we need also to
consider the backward version of (3.1) in the following form
xt = xT +

Z

T

f (s, xs )ds +

t

Z

T

g(s, xs )dωs ,

t ∈ [0, T ],

(3.26)

t

where xT ∈ Rd is the initial value of the backward equation (3.26), the coefficient functions f : [0, T ] × Rd →
Rd , g : [0, T ] × Rd → Rd × Rm are continuous functions, and the driven force ω : [0, T ] → Rm belongs to
b p ([0, T ], Rm ).
C

Theorem 3.8 (Existence and uniqueness of solutions of backward equation) Consider the backward
equation (3.26) on [0, T ]. Assume that the conditions H1 − H3 hold. Then the backward equation (3.26) has
b q ([0, T ], Rd), where q is chosen as above satisfying (3.3).
a unique solution x ∈ C
Proof: We make a change of variables
fˆ(u, x) := f (T − u, x),

ĝ(u, x) := g(T − u, x),

ω̂(u) := ω(T − u),

yu := xT −u ,

u ∈ [0, T ].

Then xT = y0 , and by putting v = T − t and u = T − s we have
Z

T

f (s, xs )ds =

t

Z

T

f (T − u, xT −u )ds = −

t

Z

0

fˆ(u, yu )du =

T −t

Z

v

fˆ(u, yu )du.

0

Furthermore, by virtue of the property (2.9) of the Young integral we have
Z

T

g(s, xs )dωs =

t

Z

T

g(T − u, xT −u )dωT −u =

t

Z

v

ĝ(u, yu )dω̂u .
0

Therefore, the backward equation (3.26) is equivalent to the forward equation
Z v
Z v
yv = y0 +
fˆ(u, yu )du +
ĝ(u, yu )dω̂u , v ∈ [0, T ],
0

0

15

(3.27)

where y0 = xT ∈ Rd . Now, we verify the conditions of Theorem 3.6 for the forward equation (3.27). First
bp ([0, T ], Rm ) then ω̂ ∈ C
b p ([0, T ], Rm ). Furthermore, the condition (H1 ) obviously holds for
note that if ω ∈ C
ĝ and the condition (i) of (H2 ) holds for fˆ. For the condition (ii) of (H2 ) we note that if it holds for f then
|fˆ(v, x)| = |f (T − v, x)| ≤ a|x| + b(T − v) = a|x| + b̂(v),

v ∈ [0, T ],

d
1 ([0, T ], R ) because (H2 )(ii) is satisfied for f . Thus, (H2 )(ii) is satisfied for
where b̂(v) = b(T − v) ∈ L 1−α
fˆ. Consequently, Theorem 3.6 is applicable to the forward equation (3.27) implying that (3.27) has unique
b q ([0, T ], Rd). Since (3.27) is equivalent to the backward equation (3.26) we have the theorem
solution y ∈ C
proved.

Theorem 3.9 Suppose that the assumptions of Theorem 3.6 are satisfied. Denote by X(t0 , ·, ω, x0 ) the
solution of (3.1) starting from x0 at time t0 , i.e. X(t0 , t0 , ω, x0 ) = x0 . Then the solution mapping
b p ([0, T ], Rm ) × Rd
X : [0, T ] × [0, T ] × C

→

(s, t, ω, z) 7→

Rd ,
X(s, t, ω, z),

is continuous.
b p ([0, T ], Rm ) × Rd and looking at forward and backward
Proof: First observe that, fixing (ω, x0 ) ∈ C
equations (3.1) and (3.26), we can extend the solution X(t0 , ·, ω, x0 ) of (3.1), with the initial value x0 at t0
to the whole [0, T ]. The proof is divided into several steps.
Step 1 (Continuity w.r.t x0 ):
By Proposition 3.7, we can choose N0 (depending on x0 , ω) such that
kX(t0 , ·, ω ′ , x′0 )kq-var,[0,T ] ≤ N0
for all t0 ∈ [0, T ], |x0 − x′0 | ≤ 1, kω − ω ′ kp-var,[0,T ] ≤ 1. We use here, for short, notation y. = X(t0 , ·, ω ′ , x0 ),
y.′ = X(t0 , ·, ω ′ , x′0 ). Using arguments similar to that of the proof of Proposition 3.2(ii), we have
Z t

Z t


|f (u, yu ) − f (u, yu′ )|du + 
|(y − y ′ )t − (y − y ′ )s | ≤
g(u, yu ) − g(u, yu′ )dωu′ 
s

≤

′
(t
MN
0

s

′

− s)ky − y k∞,[s,t]



+ 1) ||ω ′ |||p-var,[s,t] |ys − ys′ | + |||y − y ′ |||q-var,[s,t] (2 + 2N0δ )


δ
′
′
′
′
(K
+
1)(2
+
2N
)(|y
−
y
|
+
|||y
−
y
|||
)
t
−
s
+
|||ω
|||
.
MN
s
0
s
q-var,[s,t]
p-var,[s,t]
0

′
(K
+MN
0

≤

Due to Corollary 3.5, there exist constants C3 , C4 depending on parameters of the equation (3.1) and N0 ,
such that
p
p
C4 |||ω ′ |||
p-var,[0,T ] ≤ |y − y ′ |C eC4 (1+kωkp-var,[0,T ] ) .
|||y − y ′ |||q-var,[0,T ] ≤ |y0 − y0′ |C3 e
0
0 3
Therefore,
|xt − yt | ≤
≤

|xt0 − yt0 | + |||x − y|||q-var,[t0 ,t]


p
|x0 − x′0 | C3 eC4 (1+kωkp-var,[0,T ] ) + 1 .

Consequently, we find a positive constants C1 (T, ω, x0 ) such that for all t0 , t ∈ [0, T ], all ω ′ such that
kω ′ − ωkp-var,[0,T ] < 1, we have
|X(t0 , t, ω ′ , x′0 ) − X(t0 , t, ω ′ , x0 )| ≤ C1 (T, ω, x0 )|x0 − x′0 |.
Step 2 (Continuity w.r.t. ω):

16

(3.28)

bp ([0, T ], Rm ) be such that kω ′ − ωkp-var,[0,T ] ≤ 1. We use here, for short, notation x. =
Let ω ′ ∈ C
X(t0 , ·, ω, x0 ), x′. = X(t0 , ·, ω ′ , x0 ). For all s < t in [0, T ], we have
Z t
Z t
xt − xs =
f (u, xu )du +
g(u, xu )dωu ,
s
s
Z t
Z t
f (u, x′u )du +
g(u, x′u )dωu′ .
x′t − x′s =
s

s

This implies
′

′

|(x − x)t − (x − x)s | =

Z t
Z t

 [f (u, x′ ) − f (u, xu )]du +
[g(u, x′u ) − g(u, xu )]dωu
u

s
s

Z t

′
′
+
g(u, xu )d(ω − ω)u 
s

≤

≤

≤

LN0 (t − s)kx′ − xk∞,[s,t] + M (K + 1)(1 + kx′ kq-var,[s,t] ) |||ω ′ − ω|||p-var,[s,t]


′
(K + 1) |(x′ − x)s | + |||x′ − x|||q-var,[s,t]
+ |||ω ′ |||p-var,[s,t] MN
0


δ
δ
× 2 + |||x′ |||q-var,[0,T ] + |||x|||q-var,[0,T ]
C5 |||ω ′ − ω|||p-var,[s,t]



+C6 t − s + |||ω ′ |||p-var,[s,t] |(x′ − x)s | + |||x′ − x|||q-var,[s,t]

C5 |||ω ′ − ω|||p-var,[s,t]



+C6 t − s + |||ω ′ |||p-var,[s,t] |(x′ − x)s | + |||x′ − x|||q-var,[s,t] ,

where C5 , C6 depend on N0 . Consequently, by virtue of Lemma 2.3 we get
|||x′ − x|||q-var,[s,t]

≤

C3 |||ω ′ − ω|||p-var,[s,t]



+C4 t − s + |||ω|||p-var,[s,t] |(x′ − x)s | + |||x′ − x|||q-var,[s,t] .

Now, since x′t0 − xt0 = 0, using Collorary 3.5 on [t0 , t] (or [t, t0 ] and use backward equation if t < t0 ) we find
positive constant C2 (T, ω, x0 ) such that
|||x′ − x|||q-var,[t0 ,t] ≤ C2 (T, ω, x0 ) |||ω ′ − ω|||p-var,[t0 ,t] ≤ C2 (T, ω, x0 )kω ′ − ωkp-var,[0,T ] .
Therefore, for all t0 , t ∈ [0, T ],
|X(t0 , t, ω ′ , x0 ) − X(t0 , t, ω, x0 )| ≤ C2 (T, ω, x0 )kω ′ − ωkp-var,[0,T ] .

(3.29)

Step 3 (Continuity in all variables):
Now we fix (t1 , t2 , ω, x0 ) and let (t′1 , t′2 , ω ′ , x′0 ) be in a neighborhood of (t1 , t2 , ω, x0 ) such that
|t1 − t′1 |, |t2 − t′2 |, kω − ω ′ kp-var,[0,T ] , |x0 − x′0 | ≤ 1.
By triangle inequality and (3.28), (3.29), we have
|X(t′1 , t′2 , ω ′ , x′0 ) − X(t1 , t2 , ω, x0 )| ≤

|X(t′1 , t′2 , ω ′ , x′0 ) − X(t′1 , t′2 , ω ′ , x0 )| + |X(t′1 , t′2 , ω ′ , x0 ) − X(t′1 , t′2 , ω, x0 )|

≤

+|X(t′1 , t′2 , ω, x0 ) − X(t1 , t′2 , ω, x0 )| + |X(t1 , t′2 , ω, x0 ) − X(t1 , t2 , ω, x0 )|
(C1 (T, ω, x0 ) + C2 (T, ω, x0 ))(|x′0 − x0 | + kω ′ − ωkp-var,[0,T ] )

+|X(t′1 , t′2 , ω, x0 )

− X(t′1 , t′2 , ω, X(t1 , t′1 , ω, x0 ))| + |||X(t1 , ·, ω, x0 )|||q-var,[t2 ,t′ ]
2

It is obvious that when the triple (|x′0 − x0 |, kω ′ − ωkp-var,[0,T ] , |t′2 − t2 |) tends to 0 we have (C1 (T, ω, x0 ) +
C2 (T, ω, x0 ))(|x − x0 | + kω ′ − ωkp-var,[0,T ] ) → 0 and |||X(t1 , ., ω, x0 )|||q-var,[t2 ,t′ ] → 0. As for the remaining term,
2
let |t′1 − t1 | be small enough so that |X(t1 , t′1 , ω, x0 ) − x0 | ≤ 1, using (3.28) again we obtain
|X(t′1 , t′2 , ω, X(t1 , t′1 , ω, x0 )) − X(t′1 , t′2 , ω, x0 )| ≤
≤
17

C1 (T, ω, x0 )|X(t1 , t′1 , ω, x0 )) − x0 |
C1 (T, ω, x0 ) |||X(t1 , ·, ω, x0 )|||q-var,[t1 ,t′ ] ,
1

hence |X(t′1 , t′2 , ω, X(t1 , t′1 , ω, x0 )) − X(t′1 , t′2 , ω, x0 )| → 0 as |t′1 − t1 | → 0. Summing up the above arguments,
we conclude that X is continuous.
Remark 3.10 The time interval in Theorem 3.6 to Theorem 3.9 needs not be [0, T ]. It can be [t0 , t0 + T ]
for any t0 ∈ R, T > 0.

4

Topological flow generated by Young differential equations

In this section we show that Young differential equations have many properties of ordinary differential equations. Especially, their solutions generate a two-parameter flow on the phase space Rd , thus we can study
the long term behavior of the solution flow using the tools of the theory of dynamical systems. Moreover, by
ep (R, Rm ), we can study the long term behavior
defining appropriate dynamics in the space of functions ω in C
of the flow also in term of dynamics of ω. For simplity of the presentation, we will assume from now on that
all hypotheses H1 − H3 hold for all T > 0 where all the parameters are independent of T .

4.1

Topological two-parameter flows for nonautonomous systems

Theorem 4.1 (Different trajectories do not intersect) Assume that the conditions H1 − H3 hold. Let
xt and x̂t be two solutions of the Young differential equation (3.1) on [0, T ]. If xa = x̂a for some a ∈ [0, T ]
then xt = x̂t for all t ∈ [0, T ]. In other words, two solutions of the differential equation (3.1) either coincide
or do not intersect.
Proof: Suppose that xa = x̂a for some a ∈ [0, T ]. If a = 0 then by the uniqueness of the solution
provided by Theorem 3.6, xt = x̂t for all t ∈ [0, T ]. Let a ∈ (0, T ]. Since the restrictions of the functions xt
and x̂t on [a, T ] are solutions of the equation
xt = xa +

Z

t

f (s, xs )ds +

Z

t

g(s, xs )dωs ,

t ∈ [a, T ],

0

0

with the initial value xa = x̂a , Theorem 3.6 implies that xt = x̂t for all t ∈ [a, T ].
Now, consider the restrictions of the functions xt and x̂t on [0, a]. They are solutions of the equations
xt = x0 +

Z

t

f (s, xs )ds +

Z

t

g(s, xs )dωs ,

t ∈ [0, a],

0

0

with the initial values x0 and x̂0 respectively. Since xa = x̂a we have
Z a
Z a
f (s, xs )ds +
g(s, xs )dωs = xa = x̂a
x0 +
0
0
Z
Z a
f (s, x̂s )ds +
= x̂0 +

a

g(s, x̂s )dωs .

0

0

Hence,
x0
x̂0

= xa −
= xa −

Z

a

Z0 a

f (s, xs )ds −
f (s, x̂s )ds −

0

Z

a

Z0 a

g(s, xs )dωs ,
g(s, x̂s )dωs .

0

Therefore, on [0, a] the two functions xt and x̂t are solutions of the same backward equation
Z a
Z a
g(s, xs )dωs , t ∈ [0, a],
f (s, xs )ds −
xt = xa −

(4.1)

t

t

with the same initial value xa . Clearly, Theorem 3.8 is applicable and provides uniqueness of solution of the
backward equation (4.1) on [0, a], hence xt must coincide with x̂t on [0, a] and the theorem is proved.
18

Remark 4.2 (Locality of Young differential equations) By virtue of Theorems 3.6, 3.8 and 4.1, under
the assumptions of Theorem 3.6, the equation (3.1) has locality properties like ODE: we can solve it locally
and extend the solution both forward and backward, and any two solutions meeting each other at some time
should coincide in the common interval of definitions.
Now, in analog with the theory of ordinary differential equation we give a definition of the Cauchy operator
of the equation (3.1), which is an operator in Rd acting along trajectoties of (3.1).
Definition 4.3 (Cauchy operator) Suppose that the conditions H1 − H3 hold. For any −∞ < t1 ≤ t2 <
e p (R, Rm ) the Cauchy operator X(t1 , t2 , ω, ·) of the equation (3.1) is defined as follows:
+∞, any ω ∈ C
X(t1 , t2 , ω, ·) : Rd → Rd

is the mapping along trajectories of (3.1) from time moment t1 to time moment t2 , i.e., for any vector
xt1 ∈ Rd we define X(t1 , t2 , ω, xt1 ) to be the vector xt2 ∈ Rd which is the value of the solution x of the
equation
Z
Z
t

t

g(s, xs )dωs ,

f (s, xs )ds +

xt = xt1 +

t ∈ [t1 , t2 ],

t1

t1

evaluated at time t2 .
Theorem 4.4 Assume that the conditions H1 − H3 hold. For any −∞ < t1 ≤ t2 < +∞ the Cauchy operator
X(t1 , t2 , ω, ·) of (3.1) is a homeomorphism. Moreover, X(t1 , t2 , ω, ·) = id.
Proof: By Theorem 4.1 the Cauchy operator X(t1 , t2 , ω, ·) is an injection. Using arguments of the proof
of Theorem 4.1 we get that the equation
Z t
Z t
g(s, xs )dωs , t ∈ [t1 , t2 ],
(4.2)
f (s, xs )ds +
xt = xt1 +
t1

t1

with the terminal value xt2 ∈ Rd and unknown initial value xt1 , is equivalent to the following initial value
problem for the backward equation on [t1 , t2 ]
xt = xt2 −

Z

t2

f (s, xs )ds −

t

Z

t2

g(s, xs )dωs ,

t ∈ [t1 , t2 ],

(4.3)

t

with initial value xt2 ∈ Rd , hence Theorem 3.8 is applicable and provides existence of solution for any terminal
value xt2 of the forward equation on [t1 , t2 ]. Consequently, the Cauchy operator X(t1 , t2 , ω, ·) is a surjection,
thus a bijection.
It is clear from the proof of Theorem 3.6 and Theorem 3.9 that the solutions of (3.1) depend continuously
on the initial values. Therefore, the Cauchy operator X(t1 , t2 , ω, ·) acts continuously on Rd . Similar conclusion
holds for the inverse X −1 (t1 , t2 , ω, ·) by using backward equation. Hence X(t1 , t2 , ω, ·) is a homeomorphism
and trivially X(t1 , t1 , ω, ·) = id.
Following [3, page 114], below we introduce the concept of two parameter flows.
Definition 4.5 (Two-parameter flow) A family of mappings Xs,t : Rd → Rd depending on two real
variables s, t ∈ [a, b] ⊂ R is call a two-parameter flow of homeomorphisms of Rd on [a, b] if it satisfies the
following conditions:
(i) For any s, t ∈ [a, b] the mapping Xs,t is a homeomorphism of Rd ;
(ii) Xs,s = id for any s ∈ [a, b];
−1
(iii) Xs,t
= Xt,s for any s, t ∈ [a, b];

(iv) Xs,t = Xu,t ◦ Xs,u for any s, t, u ∈ [a, b].

19

Theorem 4.6 (Two-parameter flow generated by Young differential equations) Assume that the conditions H1 − H3 hold. The family of Cauchy operators of (3.1) generates a two parameter flow of homeoe p (R, Rm ) we define X(t1 , t2 , ω, ·) according
morphisms of Rd . Namely, for −∞ < t1 ≤ t2 < +∞ and ω ∈ C
−1
to Definition 4.3 and setting X(t2 , t1 , ω, ·) := X (t1 , t2 , ω, ·), then the family X(t1 , t2 , ω, ·), t1 , t2 ∈ [0, T ], is
a two parameter flow of homeomorphisms of Rd on [0, T ]. Furthermore, the flow is continuous.
Proof: Conditions (i)-(ii) of Definition 4.5 follow from Theorem 4.4.
Condition (iii) of Definition 4.5 follows from the definition X(t2 , t1 , ω, ·) := X −1 (t1 , t2 , ω, ·) for t1 ≤ t2 .
Actually, it is seen from the proof of Theorem 4.4 that the inverse X(t2 , t1 , ω, ·) satisfies the backward equation
(4.3).
Condition (iv) of Definition 4.5 follows from the definition of the Cauchy operators and Theorem 4.1.
The continuity of the flow follows directly from Theorem 3.9.

Acknowledgments
This research is funded by Vietnam National Foundation for Science and Technology Development (NAFOSTED) under grant number 101.03-2014.42.

References
[1] L. Arnold. Random Dynamical Systems. Springer, Berlin Heidelberg New York, 1998.
[2] H. Bauer. Probability theory. de Gruyter Studies in Mathematics, 23. Walter de Gruyter & Co., Berlin,
1996.
[3] H. Kunita. Stochastic flows and stochastic differential equations. Cambridge University Press, 1990.
[4] T. Cass, C. Litterer, T. Lyon. Integrability and tail estimates for Gaussian rough differential equations.
Annal of Probability, 41(4), (2013), 3026–3050.
[5] Y. Chen, H. Gao, M. J. Garrido-Atienza, B. Schmalfuß. Pathwise solutions of SPDEs and random
dynamical systems. Discrete Contin. Dyn. Syst., 34(1), (2014), 79–98.
[6] L. H. Duc, M. J. Garrido-Atienza, A. Neuenkirch, B. Schmalfuß. Exponential stability of stochastic evolution equations driven by small fractional Brownian motion with Hurst parameter in ( 21 , 1).
https://arxiv.org/abs/1705.01573
[7] P. Friz, N. Victoir. Multidimensional stochastic processes as rough paths: theory and applications. Cambridge Studies in Advanced Mathematics, 120. Cambridge Unversity Press, Cambridge, 2010.
[8] M. Garrido-Atienza, B. Schmalfuss. Ergodicity of the infinite dimensional fractional Brownian motion.
J. Dyn. Diff. Equat., 23, (2011), 671–681. DOI 10.1007/s10884-011-9222-5.
[9] M. Garrido-Atienza, B. Maslowski, B. Schmalfuß. Random attractors for stochastic equations driven by
a fractional Brownian motion. Internat. J. Bifur. Chaos Appl. Sci. Engrg. 20, (2010), 27612782.
[10] T. Lyons. Differential equations driven by rough signals, I, An extension of an inequality of L.C. Young.
Math. Res. Lett. 1, (1994), 45–464.
[11] T. Lyons, Zh. Qian. System control and rough paths. Oxford Mathematical Monographs, 2002.
[12] T. Lyons, M. Caruana, T. Lévy. Differential equations driven by rough paths. Lecture Notes in Math.
1908. Springer-Verlag, 2007.
[13] B. Mandelbrot, J. van Ness. Fractional Brownian motion, fractional noises and applications. SIAM
Review, 4, No. 10, (1968), 422–437.

20

[14] D. Nualart, A. Răşcanu. Differential equations driven by fractional Brownian motion. Collect. Math.
53, No. 1, (2002), 55–81.
[15] I. Bailleul, S. Riedel, M. Scheutzow. Random dynamical systems, rough paths and rough flows. J.
Differential Equations, Vol. 262, Iss. 12, (2017), 5792–5823.
[16] A. Ruzmaikina. Stieltjes integrals of Hölder continuous functions with applications to fractional Brownian
motion. J. Statist. Phys. 100, (2000), 1049–1069.
[17] L. C. Young. An inequality of the Hölder type, connected with Stieltjes integration.
(1936), 251–282.

Acta Math., 67,

[18] M. Zähle. Integration with respect to fractal functions and stochastic calculus. I. Probab. Theory Related
Fields, 111 (1998), 333–374.
[19] E. Zeidler. Nonlinear Functional Analysis and its Applications I. Springer - Verlag, 1986.
[20] A. Deya, M. Gubinelli, M. Hofmanova, S. Tindel. A priori estimates for rough PDEs with application
to rough conservation laws. https://arxiv.org/abs/1604.00437, 2016.

21

