arXiv:1604.06135v4 [math.CO] 2 Mar 2018

Stability for the Complete Intersection Theorem, and the
Forbidden Intersection Problem of ErdoÌ‹s and SoÌs
David Ellisâˆ—, Nathan Kellerâ€  and Noam Lifshitzâ€¡
March 5, 2018

Abstract
A family F of sets is said to be t-intersecting if |Aâˆ©B| â‰¥ t for any A, B âˆˆ F . The seminal
Complete Intersection Theorem of Ahlswede and Khachatrian (1997) gives the maximal size
f (n, k, t) of a t-intersecting family of k-element subsets of [n] = {1, 2, . . . , n}, together with
a characterisation of the extremal families.
The forbidden intersection problem, posed by ErdoÌ‹s and SoÌs in 1971, asks for a determination of the maximal size g(n, k, t) of a family F of k-element subsets of [n] such that
|A âˆ© B| 6= t âˆ’ 1 for any A, B âˆˆ F .
In this paper, we show that for any fixed t âˆˆ N, if o(n) â‰¤ k â‰¤ n/2 âˆ’ o(n), then
g(n, k, t) = f (n, k, t). In combination with prior results, this solves the problem of ErdoÌ‹s
and SoÌs for any constant t, except for in the ranges n/2 âˆ’ o(n) < k < n/2 + t/2 and k < 2t.
One key ingredient of the proof is the following sharp â€˜stabilityâ€™ result for the Complete
Intersection Theorem: if k/n is bounded away from 0 and 1/2, and F
 is a t-intersecting
family of k-element subsets of [n] such that |F | â‰¥ f (n, k, t) âˆ’ O( nâˆ’d
k ), then there exists
a family G such that G is extremal for the Complete Intersection Theorem, and |F \ G| =
O( nâˆ’d
kâˆ’d ). This proves a conjecture of Friedgut (2008). We prove the result by combining
classical â€˜shiftingâ€™ arguments with a â€˜bootstrappingâ€™ method based upon an isoperimetric
inequality.
Another key ingredient is a weak regularity lemma for families of k-element subsets
of [n], where k/n is bounded away from 0 and 1. This states that any such family F is
approximately contained within a junta, such that the restriction of F to each subcube
determined by the junta is pseudorandom in a certain sense.

1

Introduction


We write [n] := {1, 2, . . . , n}, and [n]
k := {A âŠ‚ [n] : |A| = k}. If X is a set, we write P(X) for
the power-set of X. A family F âŠ‚ P([n]) (i.e., a family of subsets of [n]) is said to be increasing
if A âŠƒ B âˆˆ F implies A âˆˆ F, and intersecting if for any A, B âˆˆ F, we have A âˆ© B 6= âˆ…. For
t âˆˆ N, F is said to be t-intersecting if for any A, B âˆˆ F, we have |A âˆ© B| â‰¥ t. A dictatorship is
a family of the form {S|i âˆˆ S} := Di for some i âˆˆ [n], and a t-umvirate is a family of the form
{S|B âŠ‚ S} =: SB , for some B âˆˆ [n]
t . If X is a set, we write Sym(X) for the symmetric group
âˆ—

School of Mathematical Sciences, Queen Mary, University of London, Mile End Road, London, E1 4NS,
United Kingdom. E-mail: d.ellis@qmul.ac.uk.
â€ 
Department of Mathematics, Bar Ilan University, Ramat Gan, Israel. E-mail: nathan.keller27@gmail.com.
Research supported by the Israel Science Foundation (grant no. 402/13), the Binational US-Israel Science
Foundation (grant no. 2014290), and by the Alon Fellowship.
â€¡
Department of Mathematics, Bar Ilan University, Ramat Gan, Israel. E-mail: noamlifshitz@gmail.com.

1

on X. We say that two families F, G âŠ‚ P([n]) are isomorphic if there exists a permutation
Ïƒ âˆˆ Sym([n]) such that G = {Ïƒ(S) : S âˆˆ F}; in this case, we write F âˆ¼
= G.
The classical ErdoÌ‹s-Ko-Rado theorem [14] determines the maximal size of an intersecting

family F âŠ‚ [n]
k .

Theorem 1.1 (ErdoÌ‹s-Ko-Rado, 1961). Let k < n/2, and let F âŠ‚ [n]
be an intersecting family.
k
nâˆ’1
Then |F| â‰¤ kâˆ’1 . Equality holds if and only if F is a dictatorship.

This theorem is the starting-point of an entire subfield of extremal combinatorics, concerned
with bounding the sizes of families of sets, under various intersection requirements on sets in
the family. Such results are often called ErdoÌ‹s-Ko-Rado type results. For more background and
history on ErdoÌ‹s-Ko-Rado type results, we refer the reader to the surveys [9, 21, 44] and the
references therein.
Also in [14], ErdoÌ‹s, Ko and Rado showed that for n sufficiently large depending on k and t,

nâˆ’t
3
the maximal size of a t-intersecting family F âŠ‚ [n]
k is kâˆ’t . For general (n, k, t) âˆˆ N , we write
f (n, k, t) for this maximum. The determination of f (n, k, t) for a general triple (n, k, t) âˆˆ N3
remained a major open problem for more than three decades. Frankl [18] conjectured that for
any (n, k, t) âˆˆ N3 , there exists r âˆˆ N âˆª {0} such that the family
 
[n]
Fn,k,t,r := {S âˆˆ
: |S âˆ© [t + 2r]| â‰¥ t + r}
k

is a t-intersecting subfamily of [n]
of maximal size. Following partial results by Frankl [18]
k
and Wilson [50], Franklâ€™s conjecture was eventually proved by Ahlswede and Khachatrian [2]:
Theorem 1.2 (Ahlswede-Khachatrian â€˜Complete Intersection Theoremâ€™, 1997). Let n, k, t âˆˆ N,

and let F âŠ‚ [n]
k be a t-intersecting family. Then |F| â‰¤ maxr |Fn,k,t,r |, and equality holds only
if F is isomorphic to Fn,k,t,r for some r â‰¥ 0. In particular, if n â‰¥ (t + 1)(k âˆ’ t + 1), then
|F| â‰¤ |Fn,k,t,0 | = nâˆ’t
kâˆ’t .

In 1971, ErdoÌ‹s and SoÌs (see [13]) raised the question of what happens if the t-intersecting
condition is replaced by the weaker condition that no two sets in F have intersection of size
exactly t âˆ’ 1.
Problem 1.3 (ErdoÌ‹s-SoÌs, 1971). For n, k, t âˆˆ N, what is the maximal size g (n, k, t) of a family

F âŠ‚ [n]
6 t âˆ’ 1 for any A, B âˆˆ F?
k such that |A âˆ© B| =

The first significant progress on this problem was made by Frankl and FuÌˆredi [20] in 1985;
they showed that g (n, k, t) = nâˆ’t
kâˆ’t provided k â‰¥ 2t and n is sufficiently large depending on k
and t.

Theorem 1.4 (Frankl-FuÌˆredi, 1985). For any k, t âˆˆ N such that k â‰¥ 2t, there exists n0 (k, t) âˆˆ N

such that the following holds. Let n â‰¥ n0 (k, t), and let F âŠ‚ [n]
6 t âˆ’ 1 for
k such that |A âˆ© B| =

nâˆ’t
any A, B âˆˆ F. Then |F| â‰¤ kâˆ’t . Equality holds if and only if F is a t-umvirate.

As pointed out
in [20], the hypothesis k â‰¥ 2t in Theorem 1.4 is necessary, in the sense that
nâˆ’t
g (n, k, t) > kâˆ’t if k < 2t, for all sufficiently large n.
In 2007, Keevash, Mubayi and Wilson [38] presented a complete solution of the case (k =
4, t = 2), for all n âˆˆ N. Recently, the second and third
authors [39] proved that for any t âˆˆ N,
nâˆ’t
there exists c = c(t) > 0 such that g(n, k, t) = kâˆ’t whenever 1/c â‰¤ k â‰¤ cn; the extremal
2

families in this range are precisely the t-umvirates. However, no general result was known for
k = Î˜(n), and in particular, in any case where the the extremal families are not t-umvirates.
In this paper, we prove the following Ahlswede-Khachatrian type result for the ErdoÌ‹s-SoÌs
problem, resolving the latter in the case where t is fixed, k/n is bounded away from 0 and 1/2
and n is large.
Theorem 1.5. For any t âˆˆ N and any Î¶ > 0, there exists n0 (t, Î¶) âˆˆ N such that the following

holds. Let n â‰¥ n0 (t, Î¶, ), let n, k âˆˆ N with Î¶n < k < ( 12 âˆ’ Î¶)n, and let F âŠ‚ [n]
such that no
k
two sets in F have intersection of size t âˆ’ 1. Then |F| â‰¤ f (n, k, t), and equality holds only if
F is isomorphic to Fn,k,t,r , for some r â‰¥ 0.
Combined with the aforementioned previous results, this resolves the ErdoÌ‹s-SoÌs problem for
all triples (n, k, t) âˆˆ N3 such that 2t â‰¤ k â‰¤ (1/2 âˆ’ Î¶)n and n is sufficiently large depending on
t and Î¶, for any Î¶ > 0, giving also a characterisation of the extremal families in these cases.
Since Problem 1.3 is trivial for k â‰¥ (n + t)/2 (as in this case, any two distinct sets in [n]
k have
intersection of size at least t), the only remaining cases are k < 2t and n âˆ’ o(n) < k < (n + t)/2.
Our first main tools in proving Theorem 1.5 is the following sharp â€˜stabilityâ€™ result for the
Ahlswede-Khachatrian theorem, which in itself proves a conjecture of Friedgut [23] from 2008.
Theorem 1.6. For any t âˆˆ N and any Î¶ > 0, there exists C = C(t, Î¶) > 0 such that the

be a tfollowing holds. Let n, k, d âˆˆ N such that Î¶n < k < ( 21 âˆ’ Î¶)n, and let F âŠ‚ [n]
k

[n]
1 nâˆ’d
intersecting family such that |F| > f (n, k, t) âˆ’ C k . Then there exists G âŠ‚ k isomorphic

to some Fn,k,t,r , such that |F\G| < C nâˆ’d
kâˆ’d , where r â‰¤ C.
Theorem 1.6 is tight, up to a factor depending only on t and Î¶, as evidenced by the families

 

[n]
Hn,k,t,r,d := A âˆˆ
: |A âˆ© [t + 2r]| â‰¥ t + r, A âˆ© {t + 2r + 1, . . . , t + 2r + d} =
6 âˆ…
k

 

[n]
âˆª Aâˆˆ
: |A âˆ© [t + 2r]| = t + r âˆ’ 1, {t + 2r + 1, . . . , t + 2r + d} âŠ‚ A ,
k

for sufficiently large n and d.
Our second
main tool in proving Theorem 1.5 is a â€˜weak regularity lemmaâ€™ for families

F âŠ‚ [n]
,
where
k/n is bounded away from 0 and 1. This states that such a family F is
k
approximately contained within a â€˜juntaâ€™ (i.e. a family depending upon few coordinates), such
that the restriction of F to each subcube determined by the junta is â€˜pseudorandomâ€™ in a certain
sense. To state it formally, we need some more definitions. 
For 0 â‰¤ k â‰¤ n, we write Âµ for the uniform measure on [n]
k , i.e.
 
 
n
[n]
Âµ(F) := |F|/
, FâŠ‚
.
k
k

[n]\J 
B
For F âŠ‚ [n]
k and B âŠ‚ J âŠ‚ [n], we write FJ = {S \ B : S âˆˆ F, S âˆ© J = B} âŠ‚ kâˆ’|B| . We call
these families â€˜slicesâ€™ of F.

For J âŠ‚ [n], we say that a family J âŠ‚ [n]
if there exists a family G âŠ‚ P(J)
k is a J-junta
[n]
such that S âˆˆ J if and only if S âˆ© J âˆˆ G, for all S âˆˆ k . In this case, we say that F is the
J-junta generated by G, and we write J = hGi.

The crucial definition is as follows. For Î´ > 0 and h âˆˆ N, we say a family F âŠ‚ [n]
k is (Î´, h)slice-quasirandom if for any J âŠ‚ [n] with |J| â‰¤ h, and any B âŠ‚ J, we have |Âµ(FJB ) âˆ’ Âµ(F)| < Î´.
3

In other words, for every B âŠ‚ J, Âµ(FJB ) is close to Âµ(F), which of course would be the expected

value of Âµ(FJB ) if F were a random subset of [n]
with density Âµ(F). (We emphasise that we
k
nâˆ’|J| 
[n]\J 
B
B
.)
regard FJ as a subset of kâˆ’|B| , and so Âµ(FJ ) = |FJB |/ kâˆ’|B|
Here, then, is our â€˜weak regularity lemmaâ€™.
Theorem 1.7. For any Î¶, Î´, Ç« âˆˆ (0, 1) and h âˆˆ N, there exists j = j(Î¶, Î´, h, Ç«) âˆˆ N and
n0 = n0 (Î¶, Î´, h, Ç«) âˆˆ N such that the following holds. Let n â‰¥ n0 , let Î¶n < k < (1 âˆ’ Î¶) n, and let

F âŠ‚ [n]
k . Then there exist a set J âŠ‚ [n] with |J| â‰¤ j, and a subset G âŠ‚ P(J), such that:
(1) Âµ (F\ hGi) < Ç«.

(2) For each B âˆˆ G, the family FJB is a (Î´, h)-slice-quasirandom family satisfying Âµ(FJB ) > 2Ç« .

Informally, Theorem 1.7 says that for any family F âŠ‚ [n]
k , there exists a set J âŠ‚ [n] such
that the 2|J| slices {FJB : B âŠ‚ J} can be divided into two â€˜typesâ€™: â€˜goodâ€™ slices for which FJB is
â€˜random-likeâ€™ and not too small, and â€˜badâ€™ slices, with small total size. Alternatively, condition
(1) says that F is almost contained within the J-junta hGi, and condition (2) says that for each
subcube of the form {S âŠ‚ [n] : S âˆ© J = B} with B âˆˆ G, the restriction of F to that subcube
is â€˜random-likeâ€™ and not too small.
The remainder of this paper is structured as follows. In subsection 1.1, we discuss some
related prior work on stability for ErdoÌ‹s-Ko-Rado type theorems. In subsection 1.2, we discuss
regularity lemmas in general, and compare some previously-known ones with ours. In subsection
1.3, we sketch the methods we will use to prove our main theorems. In Section 2 we present
some of the known results and techniques which we will use in our proofs â€“ concerning juntas,
influences, shifting, cross-intersecting families, and reduction to the â€˜biased measureâ€™ setting.
In Section 3, we prove Theorem 1.6, our stability result for the Ahlswede-Khachatrian theorem.
In Section 4, we prove Theorem 1.7, our weak regularity lemma for hypergraphs of linear
uniformity. In Section 5, we prove Theorem 1.5, our main result on the ErdoÌ‹s-SoÌs problem. We
conclude with some open problems in Section 6.

1.1

Stability for the ErdoÌ‹s-Ko-Rado and Ahlswede-Khachatrian theorems

Over the last fifty years, several authors have obtained stability results for the ErdoÌ‹s-Ko-Rado
(EKR) and the Ahlswede-Khachatrian (AK) theorems. In general, a stability result asserts
that if the size of a family is â€˜closeâ€™ to the maximum possible size, then that family is â€˜closeâ€™ (in
an appropriate sense) to an extremal family.
One of the first such results is due to Hilton and
 Milner [30], who showed in 1967 that if the
size of an intersecting family is very close to nâˆ’1
kâˆ’1 , then the family is contained in a dictatorship.
A similar result for the complete intersection theorem in the domain n â‰¥ (k âˆ’ t + 1)(t + 1) was
obtained in 1996 by Ahlswede and Khachatrian [1]. A simpler proof of the latter result was
presented by Balogh and Mubayi [5], and an alternative result of the same class was obtained
by Anstee and Keevash [3].
For families whose size is not very close to the maximum, Frankl [17] obtained in 1987
a strong stability version of the EKR theorem which implies that if an intersecting family F

log1âˆ’p p n
satisfies |F| â‰¥ (1âˆ’Ç«) nâˆ’1
) k ,
kâˆ’1 , then there exists a dictatorship D such that |F \D| = O(Ç«

but rather
where p â‰ˆ k/n. Franklâ€™s result is tight and holds not only for |F| close to nâˆ’1
kâˆ’1
nâˆ’2
nâˆ’3
whenever |F| â‰¥ 3 kâˆ’2 âˆ’ 2 kâˆ’3 . Proofs of somewhat weaker results using entirely different
techniques were later presented by Dinur and Friedgut [10], Friedgut [23] and Keevash [36].
In [37], Keevash and Mubayi used Franklâ€™s result to prove an EKR-type theorem on set systems
4

that do not contain a simplex or a cluster. Recently, a different notion of stability for the EKR
theorem was suggested by BollobaÌs, Narayanan and Raigorodskii [6]; this has been studied in
several subsequent papers (e.g., [4, 8]).
The case of the AK theorem appeared much harder. The
p first stability result was obtained
by Friedgut [23], who showed in 2008 that for any Ç« â‰¥ (log n)/n, Î¶ > 0 and Î¶n < k <

(1/(t + 1) âˆ’ Î¶)n, if a t-intersecting F âŠ‚ [n]
k  satisfies |F| â‰¥ f (n, k, t)(1 âˆ’ Ç«), then there exists
a t-umvirate G such that |F \ G| = Ot,Î¶ (Ç«) nk . The proof of Friedgut uses Fourier analysis and
spectral methods. In [12], the authors proved a strong version of Friedgutâ€™s
 result, which asserts
that under the conditions of Friedgutâ€™s theorem, |F \ G| = O(Ç«log1âˆ’p p ) nk (where p â‰ˆ k/n) for
some t-umvirate G, and showed that it is tight by an explicit example. The main technique
of [12] is to utilize isoperimetric inequalities on the hypercube.
All the results described above apply only in the so-called â€˜principal domainâ€™ k < n/(t + 1),
in which the extremal example has the simple structure of a t-umvirate. In the general case,
where the extremal examples are the more complex families Fn,k,t,r , no stability result has been
obtained so far (to the best of our knowledge). This situation resembles the history of the
â€˜exactâ€™ results, where Theorem 1.2 was proved for k < n/(t + 1) by Wilson [50] in 1984, but it
was 13 more years until the general case was resolved by Ahlswede and Khachatrian.
The main conjecture stated in Friedgutâ€™s 2008 paper [23] is that his stability result holds
for all Î¶n < k < (1/2 âˆ’ Î¶)n. To state the conjecture, we need some additional explanation.
A direct computation shows that for any Î² âˆˆ (0, 1/2) and any t âˆˆ N, there is either a unique
value of r or two consecutive values of r that asymptotically maximize |Fn,âŒŠÎ²nâŒ‹,t,r | (as n â†’ âˆ).
We say that Î² is non-singular for t if there is a unique such value of r, which we then denote
by r âˆ— = r âˆ— (Î², t). Otherwise we say that Î² is singular for t, and we let r âˆ— and r âˆ— + 1 be the two
extremal values of r.
Conjecture 1.8. [23, Conjecture 4.1] Let t âˆˆ N, let Î¶ > 0, let Î² âˆˆ [Î¶, 1/2 âˆ’ Î¶] be non
singular for t, let Ç« > 0, and let k = âŒŠÎ²nâŒ‹. If F âŠ‚ [n]
is a t-intersecting family such
k
that |F| â‰¥ (1 âˆ’ Ç«)|F(n, k, t, r âˆ— )|, then there exists a set B âŠ‚ [n] of size t + 2r âˆ— such that
|{A âˆˆ F : |A âˆ© B| â‰¥ t + r âˆ— }| â‰¥ (1 âˆ’ Ot,Î¶ (Ç«))|F|. If Î² is singular for t, then either the above
holds or the corresponding statement for r âˆ— + 1 holds.
It is easy to see that our Theorem 1.6 implies Conjecture 1.8. In fact, Theorem 1.6 implies
that the conclusion of Conjecture 1.8 can be strengthened to |{A âˆˆ F : |A âˆ© B| â‰¥ t + r âˆ— }| â‰¥
(1 âˆ’ Ot,Î¶ (Ç«log1âˆ’Î² Î² ))|F| (or |{A âˆˆ F : |A âˆ© B| â‰¥ t + r âˆ— + 1}| â‰¥ (1 âˆ’ Ot,Î¶ (Ç«log1âˆ’Î² Î² ))|F|), if Î²
is singular for t). Combining Theorem 1.6 with Theorem 1.5 in [12], one obtains a stability
version of the Complete Intersection Theorem for all k < (1/2 âˆ’ Î¶)n, sharp up to a constant
factor depending only upon t and Î¶.

1.2

Regularity lemmas

Over the last forty years, â€˜regularity lemmasâ€™ have been crucial ingredients in a wide variety
of important results in Combinatorics. The earliest such lemma is the classical SzemereÌdi
Regularity Lemma for graphs [48]. Roughly speaking, this states that the vertex-set of any
large, dense graph G can be partitioned into a bounded number of parts
V0 , V1 , . . . , VN , where
[N ]
V0 is small, |V1 | = |V2 | = . . . = |VN |, and for most pairs {i, j} âˆˆ 2 , the induced bipartite
subgraph G[Vi , Vj ] of G with parts Vi and Vj is â€˜pseudorandomâ€™, in the sense that for any large
subsets A âŠ‚ Vi and B âŠ‚ Vj , e(G[A, B]) is close to what one would expect if G[Vi , Vj ] were a
random bipartite graph with the same edge-density.
5

Since SzemereÌdi proved his celebrated lemma, â€˜regularity lemmasâ€™ for a wide variety of
combinatorial structures have been obtained. Broadly speaking, such lemmas state that a
sufficiently large combinatorial structure can be partitioned into a bounded number of pieces
which are â€˜random-likeâ€™ in the sense that they behave roughly as if they were â€˜randomâ€™ structures
of the same density, together with a small amount of â€˜wasteâ€™ or â€˜noiseâ€™.
Gowers [26], and independently RoÌˆdl and Skokan [47], proved analogues of SzemereÌdiâ€™s
regularity lemma for hypergraphs of fixed uniformity. Green [28] proved a regularity lemma
for Boolean functions on Abelian groups; the Zn2 case of this states that for any f : Zn2 â†’
{0, 1}, there exists a subgroup H â‰¤ Zn2 of bounded index, such that on most cosets C of H,
the restriction of f to C is â€˜pseuodorandomâ€™ in the sense of having small non-trivial Fourier
coefficients. Jones [31, Theorem 2] (following unpublished work of Oâ€™Donnell, Servedio, Tan
and Wan) and independently Mossel [43, Lemma 5.3], proved variants of the Zn2 -case of Greenâ€™s
regularity lemma, where the subgroup H is of the form {x âˆˆ Zn2 : xi = 0 âˆ€i âˆˆ S} for some
S âŠ‚ [n], and the notions of pseudorandomness are somewhat weaker than Greenâ€™s. Mosselâ€™s
notion of pseudorandomness is termed â€˜resilienceâ€™: a function f : Zn2 â†’ R is said to be (r, Î±)resilient if |E[f |{S = z}] âˆ’ E[f ]| â‰¤ Î± for all S âŠ‚ [n] with |S| â‰¤ r and all z âˆˆ ZS2 . Our notion of
1
pseudorandomness is precisely the analogue of resilience, for Boolean functions on [n]
k .
Our â€˜weak regularity lemmaâ€™ (Theorem 1.7) is a natural variant of the above results of

Jones [31] and of Mossel [43], for Boolean functions on [n]
k , where k/n is bounded away from 0
and 1. In fact, the regularity lemma of Jones et al can be generalised straightforwardly to the
p-biased measure case, and it is not too hard to
lemma from this
p
 deduce our weak regularity
(log
n)/n
and applies
generalisation. Indeed, given a family F âŠ‚ [n]
,
one
takes
p
=
k/n
+
k
the aforementioned generalisation to the function
(
PrT âˆˆ(S(x)) [T âˆˆ F] if |S(x)| â‰¥ k;
n
k
f : {0, 1} â†’ [0, 1]; x 7â†’
0
if |S(x)| < k,
where S(x) = {i âˆˆ [n] : xi = 1}, and the above probability refers to T being chosen uniformly

at random from S(x)
k . We give a different, more self-contained proof of Theorem 1.7, one which
we believe to be more natural. (We remark that it does not seem possible to deduce Theorem 1.7
from the lemma of Mossel, even though his regularity lemma applies to the p-biased measure;
this is because we require a junta hGi such that all the slices of F corresponding to G are highly
pseudorandom.)
We call Theorem 1.7 a â€˜weak regularity lemmaâ€™ because, as with the so-called â€˜weak regularity lemmaâ€™ of Frieze and Kannan [25], our notion of (Î·, h)-slice-quasirandomness does not
imply a general â€˜counting lemmaâ€™ for hypergraphs with a fixed number of edges, in the sense
of [26, 45] (see Remark 4.1). It should be noted, however, that our proof of Theorem 1.7 gives
j, n0 = 2 â†‘â†‘ 1/(Î¶ O(h) Î´2 Ç«), where for m > 0, 2 â†‘â†‘ m denotes a tower of twos of height âŒˆmâŒ‰. Most
known regularity lemmas come with tower-type bounds or worse, and such bounds have been
shown to be necessary in many cases by Gowers [27], and by Conlon and Fox [7]. One exception
is the aforementioned â€˜weak regularity lemmaâ€™ of Frieze and Kannan, where the bound on the
number of parts is only exponential.
Theorem 1.7 can be seen as a â€˜regularity lemmaâ€™ for hypergraphs of linear uniformity (i.e.,
uniformity linear in the number of vertices). We remark that the hypergraph regularity lemmas
of Gowers [26] and of RoÌˆdl and Skokan [47] do not apply to hypergraphs of linear uniformity. The
1

The notion of pseudorandomness used by Jones [31] is stated in terms of the noise operator, and is somewhat
stronger than resilience.

6

notions of â€˜pseudorandomnessâ€™ in these lemmas are very different from ours; unlike ours, both
notions admit general â€˜counting lemmasâ€™ [26, 45] giving asymptotic estimates on the number of
copies of a hypergraph with a fixed number of edges in a â€˜pseudorandomâ€™ hypergraph.

1.3

A sketch of our methods

Stability for t-intersecting families
We first outline our proof of Theorem 1.6. As in several previous works on stability for ErdoÌ‹sKo-Rado type theorems (e.g., [10, 12, 23]), it is more convenient for us to work first with

the biased measure on P([n]), rather than with the uniform measure on [n]
k . Hence, we first
consider t-intersectingPfamilies F âŠ‚ P([n]), and seek to maximize their p-biased measure Âµp (F),
defined by Âµp (F) := SâˆˆF p|S| (1 âˆ’ p)nâˆ’|S| . The biased version of the AK theorem (presented
clearly in [15]) is as follows.
Theorem 1.9 (Biased AK Theorem). Let t âˆˆ N, let 0 < p < 1/2, and let F âŠ‚ P([n]) be a
t-intersecting family. Then Âµp (F) â‰¤ f (n, p, t) := maxr Âµp (Fn,t,r ), where Fn,t,r := {S âŠ‚ [n] :
|S âˆ© [t + 2r]| â‰¥ t + r}, and equality holds iff F is isomorphic to one of the Fn,t,r families. In
particular, if p < 1/(t + 1), then Âµp (F) â‰¤ Âµp (FÌƒn,t,0 ) = pt , with equality iff F âˆ¼
= Fn,t,0 .
We prove the following stability version of Theorem 1.9.
Theorem 1.10. For any
 t âˆˆ N and any Î¶ > 0, there exists C = C(t, Î¶) > 0 such that the
following holds. Let p âˆˆ Î¶, 12 âˆ’ Î¶ , and let Ç« > 0. If F âŠ‚ P([n]) is a t-intersecting family such
that Âµp (F) â‰¥ f (n, p, t) (1 âˆ’ Ç«), then there exists a family G isomorphic to some Fn,t,r , such that
Âµp (F\G) â‰¤ CÇ«log1âˆ’p p .
In particular, if
Gâˆ¼
= Fn,t,râˆ— .

râˆ—
t+2r âˆ— âˆ’1

+Î¶ < p <

r âˆ— +1
t+2r âˆ— +1

âˆ’ Î¶ for some r âˆ— âˆˆ N, then the above holds with

Theorem 1.10 is tight up to a factor depending only upon t and Î¶, as evidenced by the families
HÌƒn,t,r,s = {A âŠ‚ P ([n]) : |A âˆ© [t + 2r]| â‰¥ t + r, A âˆ© {t + 2r + 1, . . . , t + 2r + s} =
6 âˆ…}

âˆª {A âŠ‚ P ([n]) : |A âˆ© [t + 2r]| = t + r âˆ’ 1, {t + 2r + 1, . . . , t + 2r + s} âŠ‚ A} ,

for sufficiently large n and s. The computation showing this is presented in section 3.3.
Theorem 1.10 follows from combination of three ingredients:
â€¢ A bootstrapping lemma showing that if a t-intersecting F is somewhat close to some
Fn,t,r then it must be very close to that Fn,t,r . More precisely, there exists c > 0 such that
if Âµp (F \ Fn,t,r ) > c, and if G is another t-intersecting family which is a small modification
of F, in the sense that Âµp (F \ G) < c/2, then Âµp (G \ Fn,t,r ) > c. Hence, there is a â€˜barrierâ€™
which one cannot cross while making only small modifications.
â€¢ A shifting argument showing that given a t-intersecting family F, one can transform
it into a junta (i.e., a function that depends on only O(1) coordinates) FÌƒ with Âµp (FÌƒ) â‰¥
Âµp (F) by a series of small modifications.
â€¢ An observation that if a t-intersecting junta FÌƒ satisfies Âµp (FÌƒ ) > f (n, p, t)(1 âˆ’ Ç«) for a
sufficiently small Ç«, then it must be isomorphic to one of the Fn,t,r â€™s.

7

While the shifting part is based on â€˜classicalâ€™ shifting arguments summarized in [15], the bootstrapping relies on a recently introduced isoperimetric argument [12]. It seems that the combination of the classical shifting tools with isoperimetry is the main novelty of the proof.
Next, we deduce Theorem 1.6 from Theorem 1.10. For this, we first use a standard reduction
from the k-uniform setting to the biased-measure setting to obtain a â€˜weakâ€™ stability theorem
for t-intersecting families of k-element sets. Then, we â€˜bootstrapâ€™ this weak stability result to
obtain Theorem 1.6, using an argument recently introduced in [12], relying on the KruskalKatona theorem and some extremal results on cross-intersecting families.

Our weak regularity lemma
In common with many other regularity-type results, the proof of our â€˜weak regularity lemmaâ€™
(Theorem 1.7) uses a potential argument. We define a non-positive potential function Ï† :

P( [n]
k ) Ã— P([n]) â†’ [âˆ’1/e, 0] such that:
â€¢ Ï†(F, S) â‰¤ Ï†(F, S â€² ) if S âŠ‚ S â€² ;


â€¢ If k/n is bounded away from 0 and 1, then for any F âŠ‚ [n]
k and any S âŠ‚ [n], either there
exists an S-junta G âŠ‚ P(S) such that G satisfies the conclusion of Theorem 1.7 (with
J = S), or there exists a set S â€² âŠƒ S that is not much larger than S, such that Ï† (F, S â€² )
is significantly larger than Ï† (F, S).
Using our potential function Ï†, we prove the existence of a junta satisfying the conclusion
of Theorem 1.7, as follows. We start by setting S = âˆ…. By the second property of Ï†, either
there exists an S-junta GS âŠ‚ P(S) such that G satisfies the conclusion of Theorem 1.7 (with
J = S), or else there exists a set S â€² âŠƒ S that is not much larger than S, such that Ï† (F, S â€² ) is
significantly larger than Ï† (F, S). In the former case, we are done; in the latter case, we replace
S by S â€² and repeat. Since Ï† is bounded from above by 0, the former case must occur after a
bounded number of steps.
Roughly speaking, our proof yields a sequence of juntas (depending on successively larger,
nested sets of coordinates) approximately containing F. At each stage, we have a set of coordinates S and an S-junta JS approximately containing F. If a significant part of the mass of F
lies in subcubes (determined by S) on which F is not sufficiently random-like, then Ï† may be
increased by a significant amount. When Ï† stops increasing by a significant amount, we have
our required junta.
The function Ï† is entropy-related, so loosely speaking, our method can be viewed as an
â€˜entropy-incrementâ€™ strategy, as opposed to the more common â€˜energy-incrementâ€™ strategy. The
former turns out to be slightly cleaner in our case, but the exact choice of Ï† is not particularly
important, as we do not seek to optimise j = j(Î¶, Î´, h, Ç«) in the conclusion of Theorem 1.7.

Families with a forbidden intersection: a stability result and an exact result

Given a family F âŠ‚ [n]
k that contains no two sets with intersection of size t âˆ’ 1 (where k/n
is bounded away from 0 and 1), we first apply Theorem 1.7 to find a junta J = hGi such
that F is approximately contained within J , and for each B âˆˆ G, the family FJB is highly
slice-quasirandom and not too small. Next, we prove a lemma about pairs of slice-quasirandom
families (Lemma 4.5): if k/n and l/n are bounded away from 0 and 1/2, then for any pair

[n]
A âŠ‚ [n]
of highly slice-quasirandom families which are not too small, and for
k and B âŠ‚
l
any fixed t âˆˆ N, there exist A âˆˆ A and B âˆˆ B such that |A âˆ© B| = t âˆ’ 1. In other words,
8

slice-quasirandomness allows one to achieve any fixed intersection-size. (We prove this by using
the slice-quasirandomness property to reduce to the case t = 1, i.e. to a statement about crossintersecting families; this can be tackled using known techniques, again translating from the
uniform setting to the biased-measure setting.)
We use Lemma 4.5 to show that the junta J must in fact be t-intersecting, so F is approximately contained within a t-intersecting family (namely, J ). It follows that if F has size close
to f (n, k, t), then the t-intersecting family J also has size close to f (n, k, t). We then apply
Theorem 1.6 to deduce that J (and therefore F) is close in symmetric difference to one of the
families Fn,k,t,r , where r is bounded.
To summarize, the above argument yields a stability result for families with a forbidden
intersection: if k/n is bounded away from 0 and 1/2, and F âŠ‚ [n]
is a family such that no
k
two sets in F have intersection of size t âˆ’ 1 and |F| is close to f (n, k, t), then F has small
symmetric difference with some Fn,k,t,r , where r is bounded. Finally, we can show that if F is
a small perturbation of one of the families Fn,k,t,r (where r is bounded), then F is smaller than
Fn,k,t,r , hence deducing Theorem 1.5 from our stability result.

2

Prior results and techniques

Our proofs use several previous results and techniques from extremal and probabilistic combinatorics. In this section we present the notation, definitions, and previous results and techniques
that will be used in the sequel. As some of the results were not proved in the form we use them,
we present their proofs here for sake of completeness. The reader may find it helpful to look
through this section briefly at first, and then go back to specific results when they are used in
the sequel.

2.1

Notation

If F âŠ‚ P([n]), then we write FÌ„ := {[n] \ A : A âˆˆ F}, and we write F âˆ— := P([n]) \ FÌ„ for the

(k) . If F âŠ‚ P([n]), we
dual of F. For each k âˆˆ [n] âˆª {0}, the kth layer of F is F âˆ© [n]
k =: F
define the increasing family generated by F to be
F â†‘ = {A âŠ‚ [n] : âˆƒB âˆˆ F with B âŠ‚ A},
i.e. it is the minimal increasing family that contains F.
In sections 2-3.2, we will often regard p âˆˆ (0, 1) as fixed, and we will sometimes suppress it
from our notation.
For fixed (n, p, t) with n, t âˆˆ N and 0 < p < 1/2, E will denote the collection of extremal families
for the biased AK theorem corresponding to (n, p, t) (i.e., the collection of all t-intersecting
F with Âµp (F) = f (n, p, t)). Note that for any A âˆˆ E and any p âˆˆ [Î¶, 1/2 âˆ’ Î¶], we have
Âµp (A) = Î˜t,Î¶ (1).
For any F, we denote by Âµp (F \ E) the â€˜minimal distanceâ€™ minGâˆˆE Âµp (F \ G).

For k âˆˆ [n], (E)(k) denotes the kth layers of elements of E, i.e., {A âˆ© [n]
: A âˆˆ E}. For
k

[n]
(k)
F âŠ‚ k , we denote by |F \ (E) | the â€˜minimal distanceâ€™ minGâˆˆ(E)(k) |F \ G|.
For B âŠ‚ J âŠ‚ [n], we define FJB := {A âŠ‚ [n] \J : A âˆª B âˆˆ F}.

For a fixed c > 0, we say that G is a c-small modification of F if Âµp (F \ G) â‰¤ c.
9


A uniform family is a subset of [n]
for some k âˆˆ [n] âˆª {0}. When k is understood, we will
k

sometimes write Âµ for the uniform measure on [n]
k , defined by
 
[n]
|A|
.
Âµ(A) = n âˆ€A âŠ‚
k
k
The lower shadow of a uniform family A âŠ‚
A with B âŠ‚ A}.

[n]
k

is defined as âˆ‚(A) := {B âˆˆ

[n] 
kâˆ’1

: âˆƒA âˆˆ

All logs in this paper are to the base e, unless otherwise indicated by a subscript, e.g. logb .
We use the (now standard) â€˜asymptotic notationâ€™, as follows. If f = f (x) and g = g(x) are
non-negative functions, we write f = O(g) if there exists C > 0 such that f (x) â‰¤ Cg(x) for
all x. We write f = â„¦(g) if there exists c > 0 such that f (x) â‰¥ cg(x) for all x, and we write
f = Î˜(g) if f = O(g) and f = â„¦(g). If f = f (x; Î±) and g = g(x; Î±) are non-negative functions,
then we write f = OÎ± (g) if for all Î±, there exists C = C(Î±) > 0 such that f (x; Î±) â‰¤ Cg(x; Î±)
for all x. Similarly, we use the notation f = â„¦Î± (g) and f = Î˜Î± (g). (Here, we view Î± as a
parameter; note that Î± may be vector-valued.)

2.2

The p-biased measure, influences and juntas

Let 0 < p < 1 and let n âˆˆ N. The p-biased measure on P([n]) is defined by
X
Âµp (F) =
p|A| (1 âˆ’ p)nâˆ’|A| âˆ€F âŠ‚ P ([n]) .
AâˆˆF

Definition. Let F âŠ‚ P([n]) and i âˆˆ [n]. The set of i-influential elements with respect to F is
Ii (F) := {S : |{S, Sâ–³{i}} âˆ© F| = 1}.
The influence of the ith coordinate on F withPrespect to Âµp is Iip (F) := Âµp (Ii (F)). The total
influence of F with respect to Âµp is I p (F) := ni=1 Ii (F). When there is no risk of confusion,
we will often suppress p from this notation, writing Ii (F) = Iip (F) and I(F) = I p (F).
Influences play an important role in a variety of applications in combinatorics, theoretical
computer science, mathematical physics and social choice theory (see e.g. the survey [34]).
We need the following well-known isoperimetric inequality for total influence w.r.t. Âµp ; this
appears for example in [33].
Theorem 2.1. Let F âŠ‚ P([n]) be an increasing family, and let 0 < p < 1. Then
pI p (F) â‰¥ Âµp (F) log p (Âµp (F)).

(1)

We also need the well-known Margulis-Russo lemma (due independently to Margulis [42]
and Russo [49]), which relates the total influence of an increasing family F to the derivative of
the function p 7â†’ Âµp (F).
Lemma 2.2 (Margulis-Russo Lemma). Let F âŠ‚ P ([n]) be an increasing family and let 0 <
p0 < 1. Then
dÂµp (F) 
= I p0 (F) .

dp
p=p0
10

We will use the following consequence of the Margulis-Russo Lemma and Theorem 2.1 (this
appears e.g. in [29], Theorem 2.38).
Lemma 2.3. Let F âŠ‚ P([n]) be increasing. Then the function p 7â†’ logp (Âµp (F)) is monotone
non-increasing on (0, 1).
Proof. Let f (p) := logp (Âµp (F)) = log Âµp (F)/ log p. We have
df
=
dp

1 dÂµp (F )
Âµp (F ) dp

log p âˆ’

1
p

log(Âµp (F))

(log p)2

=

1
p
(log p)2

1
p
Âµp (F ) I (F) log p

âˆ’

log(Âµp (F))

â‰¤ 0,

(2)

using the Margulis-Russo Lemma and (1).
Definition. If J âŠ‚ [n] and F âŠ‚ P([n]), F is said to be a J-junta if it depends only upon the
coordinates in J â€” formally, if there exists G âŠ‚ P(J) such that S âˆˆ F if and only if S âˆ© J âˆˆ G,

for all S âŠ‚ [n]. A family F âŠ‚ P([n]) is said to be a j-junta if it is a J-junta for some J âˆˆ [n]
j .
Note that F âŠ‚ P([n]) is a j-junta if and only if Ii (F) = 0 for at least n âˆ’ j coordinates i âˆˆ [n]
(provided 0 < p < 1).
Friedgutâ€™s junta theorem [22] states that a family F âŠ‚ P([n]) with bounded total influence
w.r.t. the Âµp measure can be approximated by a junta depending upon a bounded number of
coordinates.
Theorem 2.4 (Friedgutâ€™s Junta Theorem). For any Î¶ > 0, there exists C = C(Î¶) > 0 such
that the following holds. Let Î¶ â‰¤ p â‰¤ 1 âˆ’ Î¶, let Ç« > 0, and let F âŠ‚ P ([n]). Then there exists a
j-junta J âŠ‚ P ([n]) such that Âµp (Fâˆ†J ) < Ç«, where j â‰¤ exp(CI p (F)/Ç«).
Friedgutâ€™s proof of Theorem 2.4 is based upon the Fourier-analytic proof of the Kahn-KalaiLinial theorem [32].
We will also need another, simpler relation between influences and juntas: if all influences
of an increasing family are large, then the family must be a junta.
Proposition 2.5. Let F âŠ‚ P([n]) be increasing, let 0 < p < 1 and let c > 0. If mini (Iip (F)) â‰¥ c,
1
.
then n â‰¤ c2 p(1âˆ’p)
P
Proof. Let f = SâŠ‚[n] fË†(S)Ï‡S be the Fourier expansion of the characteristic function f = 1F ,
with respect to the measure Âµp . An easy calculation presented in [46, Proposition 8.45] shows
that
n
X
fË† ({i})
p
.
I p (F) =
p (1 âˆ’ p)
i=1
By the Cauchy-Schwarz inequality and Parsevalâ€™s identity,
qP
âˆš
n
2
r
r
n
Ë†
X
Ë†
n
n
n
f ({i})
i=1 f ({i})
p
p
p
I (F) =
â‰¤
â‰¤
kf k2 â‰¤
.
p (1 âˆ’ p)
p (1 âˆ’ p)
p (1 âˆ’ p)
p (1 âˆ’ p)
i=1
If mini (Iip (F)) â‰¥ c, we have cn â‰¤ I p (F) â‰¤

q

n
p(1âˆ’p) .

Rearranging yields the assertion.

Another observation we use is that the measure of a t-intersecting junta F cannot be â€˜too closeâ€™
to f (n, p, t), unless F is isomorphic to one of the Fn,t,r families (which are, of course, juntas).
11

Proposition 2.6. Let t âˆˆ N, let Î¶ > 0, and let m âˆˆ N. There exists Ç« = Ç« (t, Î¶, m) > 0
such that if 0 < p â‰¤ 1/2 âˆ’ Î¶, and F âŠ‚ P ([m]) is a t-intersecting family satisfying Âµp (F) â‰¥
f (m, p, t) (1 âˆ’ Ç«), then F âˆˆ AKm
p,t .
r
â‰¤pâ‰¤
Proof. By Theorem 1.9, for any r âˆˆ N âˆª {0} and any t+2râˆ’1

m
m
F âˆˆ P([m]) \ AKt,Î¶ satisfies Âµp (F) < Âµp Ft,r . Consider the set

r+1
t+2r+1 ,

any t-intersecting

Crm = {Âµq (Fm,t,r ) âˆ’ Âµq (G) : G âˆˆ P([m]) \ AKm
q,t , G is t-intersecting,
r
r+1
â‰¤qâ‰¤
}.
t + 2r âˆ’ 1
t + 2r + 1

m
As m is fixed, Crm is compact and all its elements are positive. Hence, cm
r = min(Cr ) > 0. We
have

â„“ 
[
r+1
r
,
,
[0, 1/2 âˆ’ Î¶] âŠ‚
t + 2r âˆ’ 1 t + 2r + 1
r=0

for some â„“ = â„“ (t, Î¶) âˆˆ N. Let Ç« = min0â‰¤râ‰¤â„“ cm
r . It is clear by the choice of Ç« that for all
p âˆˆ (0, 1/2 âˆ’ Î¶], if F âŠ‚ P ([m]) is a t-intersecting family with Âµp (F) â‰¥ f (m, p, t) (1 âˆ’ Ç«) >
f (m, p, t) âˆ’ Ç« then we must have F âˆˆ AKm
p,t . This completes the proof.

2.3

Shifting

Shifting (a.k.a. â€˜compressionâ€™) is one of the most classical techniques in extremal combinatorics
(see, e.g., [19]).
Definition. For F âŠ‚ P([n]), a set A âˆˆ F, and 1 â‰¤ j < i â‰¤ n, the shifting operator Sij is
defined as follows: Sij (A) = A\ {i} âˆª {j} if i âˆˆ A, j âˆˆ
/ A, and A\ {i} âˆª {j} 6âˆˆ F; and Sij (A) = A
otherwise. We define Sij (F) = {Sij (A) : A âˆˆ F}.
F is called n-compressed if A\ {n} âˆª {j} âˆˆ F for all A âˆˆ F such that A âˆ© {j, n} = n, i.e., if
Snj (F) = F for all j < n. F is called shifted if Sij (F) = F for all j < i.
The following properties of the shifting operator are easy to check.
Claim 2.7. Let F âŠ‚ P ([n]) be increasing and t-intersecting, and let 0 < p < 1. Then Sij (F)
satisfies the following properties:
(a) Âµp (Sij (F)) = Âµp (F),
(b) Âµp (F\Sij (F)) â‰¤ Ii (F),
(c) Ii (Sij (F)) â‰¤ Ii (F), with equality if and only if Sij (F) = F,
(d) Sij (F) is increasing and t-intersecting.
2.3.1

n-compression by small modifications

The following proposition shows that any increasing t-intersecting F can be transformed into
an n-compressed increasing t-intersecting G with Âµp (G) = Âµp (F) by a sequence of c-small
modifications, where c = In (F).

12

Proposition 2.8. Let 0 < p < 1, and let F âŠ‚ P([n]) be an increasing t-intersecting family that
is not n-compressed. Denote Î´ = In (F). Then there exist families F = F0 , F1 , F2 , . . . , Fm âŠ‚
P([n]), such that Fm is n-compressed and for each i âˆˆ [m] we have:
(a) Âµp (Fi ) = Âµp (F),
(b) Fi is increasing and t-intersecting,
(c) Âµp (Fiâˆ’1 \Fi ) â‰¤ Î´,
(d) In (Fi ) < Î´.
Proof. We define Fi inductively. Suppose that Fiâˆ’1 is not n-compressed. Then for some j âˆˆ [n],
we have Snj (Fiâˆ’1 ) 6= Fiâˆ’1 . We choose such a j arbitrarily and define Fi = Snj (Fiâˆ’1 ). By
Claim 2.7, Fi satisfies the desired properties. Thus, we only need to show that for some m âˆˆ N,
Fm is n-compressed. Indeed, by Claim 2.7, In (Fi ) is strictly decreasing (as a function of i).
Since all of {In (Fi ) : i âˆˆ N} belong to a finite set of values, this process cannot last forever.
2.3.2

Increasing the measure by a small modification

Our next goal is to show that if F is an n-compressed, increasing, t-intersecting family, then it
can be transformed to a t-intersecting G with Âµp (G) > Âµp (F) by a c-small modification, where
c = In (F). That is, if F is already n-compressed, then its measure can be increased by a small
modification, without sacrificing the t-intersection property.
To show this, we need several claims. These claims were proved in [15] under the assumption
that F is shifted, but it turns out that the proof of [15] applies also under the weaker assumption
that F is n-compressed. For sake of completeness, we present the claims below.
Lemma 2.9. Let F âŠ‚ P([n]) be a t-intersecting n-compressed family and let a, b âˆˆ [n]. Let
A âˆˆ F (a) and B âˆˆ F (b) be such that |A âˆ© B| = t and n âˆˆ A âˆ© B. Then a + b = n + t, and
A âˆª B = [n].
Proof. It is clearly sufficient to show that A âˆª B = [n]. Suppose for a contradiction that
iâˆˆ
/ A âˆª B. As F is n-compressed, we have Aâ€² = A\ {n} âˆª {i} âˆˆ F. However, |Aâ€² âˆ© B| = t âˆ’ 1,
contradicting the fact that F is t-intersecting.
The next proposition shows that if an n-compressed t-intersecting family F satisfies F âˆ©In (F) *
[n] 
, then the measure of F can be increased by a small modification.
(n+t)/2

Proposition 2.10. Let 0 < p < 1/2. Let F âŠ‚ P([n]) be an increasing t-intersecting ncompressed family. Denote In = In (F). Let a 6= b âˆˆ [n] be such that a + b = n + t. Then the
families
G1 := (F\(In âˆ© F)(a) ) âˆª (In \ F)(bâˆ’1)

and

G2 := (F\(In âˆ© F)(b) ) âˆª (In \ F)(aâˆ’1)

are t-intersecting, and
Âµp (F) â‰¤ max {Âµp (G1 ) , Âµp (G2 )} ,

(3)

with equality only if G1 = G2 = F.
Proof. W.l.o.g. we show that G1 is t-intersecting. Let A, B âˆˆ G1 , and suppose for a contradiction
that |A âˆ© B| â‰¤ t âˆ’ 1. Hence, we have either A âˆˆ (In \ F)(bâˆ’1) or B âˆˆ (In \ F)(bâˆ’1) or both.
Assume, w.l.o.g., B âˆˆ (In \ F)(bâˆ’1) . Then B â€² := B âˆª {n} âˆˆ (In âˆ© F)(b) . Note that we
13

have Aâ€² := A âˆª {n} âˆˆ F. Indeed, either A âˆˆ F and then Aâ€² âˆˆ F since F is increasing, or
A âˆˆ (In \ F)(bâˆ’1) and then Aâ€² âˆˆ (In âˆ© F)(b) . Since F is t-intersecting, this implies


t â‰¤ Aâ€² âˆ© B â€²  â‰¤ |A âˆ© B| + 1 â‰¤ t.
(4)

This allows applying Lemma 2.9 to Aâ€² , B â€² , to get |Aâ€² | = a.
Now, as |(Aâ€² \ {n}) âˆ© B â€² | = t âˆ’ 1 and F is t-intersecting, we have Aâ€² \ {n} âˆˆ
/ F. Hence,
(a)
â€²
â€²
â€²
A âˆˆ (In âˆ© F) , which yields A âˆˆ
/ G1 . As A âˆˆ G1 , we must have A = A \ {n} âˆˆ
/ F. By
(bâˆ’1)
â€²
the construction of G1 , this means that A âˆˆ (In \F)
, and therefore, |A | = a = b, a
contradiction.
The proof of (3) is a straightforward calculation. Write A1 = (In âˆ© F)(a) and A2 =
(In âˆ© F)(b) . Suppose w.l.o.g. that Âµp (A1 ) â‰¥ Âµp (A2 ). Then
Âµp (G2 ) = Âµp (F) âˆ’ Âµp (A2 ) +

1âˆ’p
Âµp (A1 ) > Âµp (F) ,
p

as asserted. It is also clear that equality can hold only if A1 = A2 = âˆ…, that is, if G1 = G2 = F.
This completes the proof.
The following proposition complements the previous one by showing that the measure of an
n-compressed t-intersecting F can be increased by a small modification even if F âˆ© In (F) âŠ‚
[n] 
. Recall that Di denotes a dictatorship Di := {A âˆˆ P([n]) : i âˆˆ A}.
(n+t)/2

Proposition 2.11. Let n, t âˆˆ N such that n + t is even, and let 0 < p < 1. Let F âŠ‚ P([n])
be an increasing n-compressed t-intersecting family such that In (F) > 0. Denote a = n+t
2 . For
1 â‰¤ i â‰¤ n âˆ’ 1, let
Gi = (F\ (F âˆ© In âˆ© Di )(a) ) âˆª (In \ (F âˆª Di ))(aâˆ’1) .

Then the families Gi are t-intersecting. Moreover, if 0 < p â‰¤ 1/2 âˆ’ Î¶, n > t/(2Î¶) and (In âˆ©
F)(a) 6= âˆ…, then
max {Âµp (Gi )} > Âµp (F) .
(5)
iâˆˆ[nâˆ’1]

Proof. First we prove that for all i, Gi is t-intersecting. Let A, B âˆˆ Gi , and suppose for a
contradiction that |A âˆ© B| â‰¤ t âˆ’ 1. Denote Aâ€² := A âˆª {n} and B â€² := B âˆª {n}, and assume
w.l.o.g. B âˆˆ
/ F, and hence, |B â€² | = a and i âˆˆ
/ B â€².
By the same argument as in the proof of Proposition 2.10, we have Aâ€² âˆˆ F âˆ© In . On the
other hand, by Lemma 2.9 (applied for Aâ€² , B â€² ) we have Aâ€² âˆª B â€² = [n], and hence, i âˆˆ Aâ€² and
|Aâ€² | = a. Thus, Aâ€² âˆˆ (F âˆ© In âˆ© Di )(a) , which implies Aâ€² 6âˆˆ Gi . This is a contradiction, as A âˆˆ Gi
and Gi is increasing.
Now we prove Equation (5). Note that for any i â‰¤ nâˆ’1, there is a one-to-one correspondence
between the families (In \ (F âˆª Di ))(aâˆ’1) and (F âˆ© In âˆ© Dic )(a) . Hence,

 1 âˆ’ p 

(a)
Âµp (F âˆ© In âˆ© Dic )(a)
+
Âµp (Gi ) = Âµp (F) âˆ’ Âµp (F âˆ© In âˆ© Di )
p
 1 âˆ’ p 




(a)
c (a)
+
+ Âµp (F âˆ© In âˆ© Di )
= Âµp (F) âˆ’ Âµp (F âˆ© In )
Âµp (F âˆ© In âˆ© Dic )(a)
p

 1 

= Âµp (F) âˆ’ Âµp (F âˆ© In )(a) + Âµp (F âˆ© In âˆ© Dic )(a) .
p

14

Let Ki := F âˆ© In âˆ© Dic . We have
nâˆ’1
1
1 X X
Âµp (A) =
Ei [Âµp (Ki )] =
nâˆ’1
nâˆ’1
i=1 AâˆˆKi

X

Aâˆˆ(F âˆ©In )(a) {i:i6âˆˆA}

Thus, there exists i âˆˆ [n âˆ’ 1] such that Âµp (Ki ) â‰¥
max {Âµp (Gi )} â‰¥ Âµp (F) +

X

nâˆ’a
nâˆ’1 Âµp ((F

Âµp (A) =

nâˆ’a
Âµp ((F âˆ© In )(a) ).
nâˆ’1

âˆ© In )(a) ). This implies


n âˆ’ a âˆ’ (n âˆ’ 1) p 
Âµp (F âˆ© In )(a) > Âµp (F),
(n âˆ’ 1) p

where the last inequality holds since n âˆ’ a âˆ’ (n âˆ’ 1) p > 0 for all n > t/(2Î¶). This completes
the proof.
Combining Propositions 2.10 and 2.11 we obtain:
Corollary 2.12. Let Î¶ > 0, let 0 < p â‰¤ 1/2 âˆ’ Î¶ and let n âˆˆ N with n > t/(2Î¶). Let F âŠ‚ P([n])
be an increasing n-compressed t-intersecting family that depends on the nth coordinate (i.e.,
In (F) > 0). Then there exists a t-intersecting family G âŠ‚ P([n]), such that Âµp (G) > Âµp (F)
and Âµp (F\G) â‰¤ In (F).
While G obtained in Corollary 2.12 is t-intersecting, it is not necessarily n-compressed. However,
by Proposition 2.8 it can be transformed into an n-compressed family GÌƒ by a sequence of small
modifications, without decreasing the measure. Then Corollary 2.12 can be applied to GÌƒ to
increase the measure again. As we show in section 3.2 below, the process can be continued until
the nth coordinate becomes non-influential, i.e., the effective number of coordinates decreases.
Then one may repeat the whole process with the (n âˆ’ 1)th coordinate etc., so that ultimately,
F can be transformed into a junta by a sequence of small modifications.

2.4

Reduction from k-element sets to the biased measure setting

As shown in several previous works (e.g., [10, 23]), EKR-type results for (t)-intersecting subsets

of [n]
k , for a sufficiently large n, can be proved by reduction to similar results on the Âµp
measure of (t)-intersecting subsets of P([n]), for an appropriately chosen p. In this subsection
we present the lemmas required for performing such a reduction for the stability version of the
Ahlswede-Khachatrian theorem.

The reduction (in our case) works as follows. Let F âŠ‚ [n]
k be a t-intersecting family with
|F| > f (n, k, t) âˆ’ Ç« nk . Recall that F â†‘ denotes the increasing family generated by F (i.e., the
minimal increasing family that contains F). We take p slightly larger than nk , and show that:

âˆ’ Ç«,
(a) Âµp F â†‘ & |Fn | > f (n,k,t)
(k)
(nk)

(b) f (n, p, t) âˆ¼

f (n,k,t)

(nk)

,

 |F \(E)(k) |
(c) Âµp F â†‘ \E âˆ¼
.
(nk)


This essentially reduces stability for subsets of [n]
k to stability in the Âµp setting. We present
now three propositions that justify the â€˜âˆ¼â€™ in (a)-(c). These propositions, or close variants
thereof, were proved in previous works; as they do not appear in the exact form we use them,
we present the simple proofs here.
The first proposition, which was essentially proved by Friedgut [23], shows that (a) holds.
15

Proposition 2.13 (Friedgut). Let Î´ > 0, let n, k âˆˆ N with k â‰¤ n, let
let F âŠ‚ P ([n]) be increasing. Then
 (k) 
F 
Âµp (F) â‰¥ n (1 âˆ’ Î´) .

k+

q
2n log( 1Î´ )
n

â‰¤ p â‰¤ 1 and

k

Proposition 2.13 can be proved using the following simple corollary of the local LYM inequality.
Proposition
Let F âŠ‚ P([n]) be an increasing family. For any 1 â‰¤ k â‰¤ m â‰¤ n, we have
 2.14.
n
(m)
(k)
|F |/ m â‰¥ |F |/ nk .
Proof of Proposition 2.13. By Proposition 2.14, we have
   (k)  X
   (k) 
n  (m) 
n
X
F
F
F
[n]
[n]
Âµp (F) â‰¥
Âµp
â‰¥ n
= n Âµp ({S âŠ‚ [n] : |S| â‰¥ k})
n  Âµp
m
m
m
k
k
m=k
m=k
 (k) 
F 
â‰¥ n (1 âˆ’ Î´) ,
k

where the last inequality follows from the choice of p by a standard Chernoff bound.
The second proposition, proved by Dinur and Safra [11], shows that (b) holds.

Proposition 2.15 (Dinur and Safra). Let j âˆˆ N, Î¶, Ç« âˆˆ (0, 1), and p âˆˆ [Î¶, 1 âˆ’ Î¶]. There exist
Î´â€² = Î´â€² (Ç«, j) and n0 = n0 (j, Î¶, Ç«) âˆˆ N such that the following holds for all n > n0 . For any
k âˆˆ [Î¶n, (1 âˆ’ Î¶)n] âˆ© N such that p âˆ’ nk  < Î´â€² and for any j-junta J âŠ‚ P([n]), we have




[n] 

J
âˆ©


k 
Âµp (J ) âˆ’
 < Ç«.

(6)
n




k

Proof. Assume w.l.o.g. that J depends only on the coordinates in [j]. Since j is fixed, it is
sufficient to prove that (6) holds when J = JC := {A âŠ‚ [n] : A âˆ© [j] = C} for any C âŠ‚ [j].
And indeed,


nâˆ’j  

|{A âˆˆ [n]
kâˆ’|C| 
 |C|
jâˆ’|C|
k : A âˆ© [j] = C}|
âˆ’
| = p (1 âˆ’ p)
|Âµp (J ) âˆ’
n
n 

k
k


 |C|
k Â· . . . Â· (k âˆ’ |C| + 1) Â· (n âˆ’ k) Â· . . . Â· (n âˆ’ k + 1 âˆ’ j + |C|) 
jâˆ’|C|

= p (1 âˆ’ p)
âˆ’

n Â· . . . Â· (n âˆ’ j + 1)







k |C| n âˆ’ k jâˆ’|C| 

< p|C| (1 âˆ’ p)jâˆ’|C| âˆ’
 + onâ†’âˆ (1) < Ç«,


n
n
where n0 , Î´â€² clearly can be chosen such that the last inequality holds.

The third proposition, a variant of which was proved by Dinur and Friedgut [10], shows that (c)
holds.
Proposition 2.16 (Dinur and Friedgut). Let j âˆˆ N, Î¶, Î´â€²â€² âˆˆ (0, 1) , and p âˆˆ [Î¶, 1 âˆ’ Î¶]. There
exist C = C (Î¶, j) > 0 and n0 (t, Î¶, Î´â€²â€² ) âˆš
âˆˆ N such that the following holds for all n > n0 and all
log 2
k âˆˆ [Î¶n, (1 âˆ’ Î¶)n] âˆ© N such that p > k+ 2n
. Let F âŠ‚ P([n]) be an increasing family, and let
n
â€²â€²
J be a j-junta such that Âµp (F\J ) < Î´ . Then
 



(k) 
â€²â€² n
(F\J
)
<
CÎ´
.


k
16

Proof. Suppose w.l.o.g. that J depends on the coordinates in [j]. Since j is fixed, it is sufficient
to prove that for any E âˆˆ
/ J , we have
 
(k)
â€² â€²â€² n
|{A âˆˆ F
: A âˆ© [j] = E}| â‰¤ C Î´
,
k
for some C â€² = C â€² (Î¶, j) > 0. We show that
|{A âˆˆ F

(k)

: A âˆ© [j] = E}| <

2Î´â€²â€²




nâˆ’j
,
k âˆ’ |E|

(7)
p|E| (1 âˆ’ p)jâˆ’|E|

which is sufficient, as the right hand side of (7) is â‰¤ C â€² Î´â€²â€² nk by the proof of Proposition 2.15.
Suppose for a contradiction that (7) fails. By Proposition 2.13 (with Î´â€² = 1/2), we have


Î´â€²â€²
2Î´â€²â€²
E
Â·
(1
âˆ’
1/2)
=
.
Âµp F[j] >
p|E| (1 âˆ’ p)jâˆ’|E|
p|E| (1 âˆ’ p)jâˆ’|E|


E > Î´ â€²â€² , a contradiction. This completes the proof.
Hence, Âµp (F\J ) â‰¥ p|E| (1 âˆ’ p)jâˆ’|E| Âµp F[j]

2.5

Cross-Intersecting Families

Definition. Families F, G âŠ‚ P([n]) are said to be cross-intersecting if Aâˆ© B 6= âˆ… for any A âˆˆ F
and B âˆˆ G.
The first generalization of the ErdoÌ‹s-Ko-Rado theorem to cross-intersecting families was
obtained in 1968 by Kleitman [40], and since then, many extremal results on cross-intersecting
families have been proved. Such results assert that if F, G are cross-intersecting then they
cannot be â€˜simultaneously largeâ€™, where the latter can be expressed in various ways. We need
several such results. The first is a consequence of the Kruskal-Katona theorem [41, 35].

[n]
Lemma 2.17. Let n, k, l âˆˆ N with n â‰¥ k + l, letr âˆˆ N âˆª {0}, and let A âŠ‚ [n]
be
k , B âŠ‚
l
n
nâˆ’r
nâˆ’r
cross-intersecting families. Suppose that |A| â‰¥ k âˆ’ k . Then |B| â‰¤ lâˆ’r .
 
n 
nâˆ’r 
Proof. Let AÌ„ := {[n] \ A : A âˆˆ A}; then AÌ„ â‰¥ nâˆ’k
âˆ’ nâˆ’kâˆ’r
. By the Kruskal-Katona
 nâˆ’kâˆ’l 
n
nâˆ’r 


theorem, we have âˆ‚
AÌ„ â‰¥ l âˆ’ lâˆ’r . Since A and B are cross-intersecting, we have

 


nâˆ’kâˆ’l
Bâˆ©âˆ‚
AÌ„ = âˆ…. Hence, |B| â‰¤ nl âˆ’ âˆ‚ nâˆ’kâˆ’l AÌ„  â‰¤ nâˆ’r
lâˆ’r , as required.
Straightforward estimates for the binomial coefficients yield the following consequence.

Lemma 2.18. For each Î¶ > 0, there exists c = c(Î¶) > 1 such that the following holds. Let

[n]
Î¶n â‰¤ k1 , k2 â‰¤ ( 21 âˆ’ Î¶)n, and let A âŠ‚ [n]
k1 , B âŠ‚ k2 be cross-intersecting families. If Âµ (A) >
1 âˆ’ Ç«, then Âµ (B) = OÎ¶ (Ç«c ).
The second extremal result we need is a consequence of Lemma 2.3. It was first proved
in [12]; we reproduce the proof here, for completeness.
Proposition 2.19 ([12], Lemma 2.7). Let 0 < p â‰¤ 1/2, and let F, G âŠ‚ P([n]) be crossintersecting families. Then Âµp (F) â‰¤ (1 âˆ’ Âµp (G))log1âˆ’p p .
Proof. Since F and G are cross-intersecting, we have F âŠ‚ G âˆ— . Hence, Âµ1âˆ’p (F) â‰¤ Âµ1âˆ’p (G âˆ— ) = 1âˆ’
Âµ1âˆ’p (GÌ„) = 1 âˆ’ Âµp (G). Hence, by Lemma 2.3, Âµp (F) â‰¤ (Âµ1âˆ’p (F))log 1âˆ’p (p) â‰¤ (1 âˆ’ Âµp (G))log 1âˆ’p (p) ,
as required.
17

Note that equality holds in Proposition 2.19 when F = {S âŠ‚ [n] : B âŠ‚ S} =: ANDB , and
G = {S âŠ‚ [n] : B âˆ© S 6= âˆ…} =: ORB , where B âŠ‚ [n].
A special case of Proposition 2.19, with a much simpler proof, is as follows.
Lemma 2.20. If F, G âŠ‚ P ([n]) are cross-intersecting, then
Âµ1/2 (F) + Âµ1/2 (G) â‰¤ 1.
Proof. Let A âˆ¼ Âµ1/2 . Then Âµ1/2 (F) = Pr[A âˆˆ F]. On the other hand, [n] \ A is also distributed
according to Âµ1/2 . Therefore, Âµ1/2 (G) = Pr[[n]\A âˆˆ G]. Since the families F, G are crossintersecting, the events {A âˆˆ F} and {[n]\A âˆˆ G} are disjoint. Therefore, we have
Âµ1/2 (F) + Âµ1/2 (G) = Pr[A âˆˆ F] + Pr[[n]\A âˆˆ G] = Pr[{A âˆˆ F} âˆª {[n]\A âˆˆ G}] â‰¤ 1,
as required.
Before we state the third extremal result, we need a few preliminaries.

Notation 2.21. For X âŠ‚ N, i âˆˆ N and F âŠ‚ Xi , we write L(F) for the initial segment of the


lexicographic order on Xi with size |F|. We say a family C âŠ‚ Xi is lexicographically ordered

if it is an initial segment of the lexicographic order on Xi , i.e., L(C) = C.

The following result was proved by Hilton (see [17], Theorem 1.2).

[n]
Proposition 2.22 (Hilton). If F âŠ‚ [n]
are cross-intersecting, then L(F), L(G) are
k , G âŠ‚ l
also cross-intersecting.

The third extremal result we need on cross-intersecting families is the following, which was first
proved in [12]; we reproduce the proof for completeness.
Lemma 2.23 ([12], Lemma 4.7). For any Î· > 0 and any C â‰¥ 0, there exists c0 = c0 (Î·, C) âˆˆ N
such that the following holds. Let n, l, k, d âˆˆ N âˆª {0} with n â‰¥ (1 + Î·)l + k + c0 and l â‰¥ k + c0 âˆ’ 1.

[n]
Suppose that A âŠ‚ [n]
l , B âŠ‚ k are cross-intersecting, and that

    


n
[n] 
nâˆ’d

|A| â‰¤ OR[d] âˆ©
=
âˆ’
.
l
l 
l

Then

  



n
nâˆ’d
nâˆ’d
|A| + C |B| â‰¤
âˆ’
+C
.
l
l
kâˆ’d

Proof. We prove the lemma by induction on k. For k = 0 the lemma holds trivially. Assume
now that k â‰¥ 1, and that the statement of the lemma holds for k âˆ’ 1. For d = 0, the statement
of the lemma holds trivially, so we may assume throughout that d â‰¥ 1. By Proposition 2.22,
we may assume that A and B are lexicographically
ordered. Since
n
o d â‰¥ 1, we have |A| â‰¤




(l)
(i)
n
nâˆ’1
nâˆ’1
[n]
= lâˆ’1 , so A âŠ‚ F1 , where F1 := A âˆˆ i : 1 âˆˆ A for each i âˆˆ [n].
l âˆ’
l
(l)

(l)

We split into two cases: A = F1 and A ( F1 .
(l)

(k)

Case 1: A = F1 . First note that B âŠ‚ F1 . Indeed, suppose on the contrary that B âˆˆ B

and 1 âˆˆ
/ B. Since n â‰¥ k + l, there exists A âˆˆ [n]
such that 1 âˆˆ A and A âˆ© B = âˆ…. Hence,
l
18

(l)

(k)

A âˆˆ F1 = A, and A âˆ© B = âˆ…, a contradiction. Hence, we may assume that B = F1 . We must
prove that



   



nâˆ’1
nâˆ’1
n
nâˆ’d
nâˆ’d
+C
â‰¤
âˆ’
+C
âˆ€d â‰¥ 1.
(8)
lâˆ’1
kâˆ’1
l
l
kâˆ’d

This clearly holds (with equality) if d = 1. To verify it for all d â‰¥ 2 it suffices to show that



   

nâˆ’1
nâˆ’1
n
nâˆ’2
+C
â‰¤
âˆ’
,
lâˆ’1
kâˆ’1
l
l
or equivalently,

 

nâˆ’1
nâˆ’2
C
â‰¤
.
kâˆ’1
lâˆ’1

We have
nâˆ’1
kâˆ’1
nâˆ’2
lâˆ’1

nâˆ’2
n âˆ’ 1 kâˆ’1
(l âˆ’ 1)(l âˆ’ 2) . . . k
=
 â‰¤2
nâˆ’2
n âˆ’ k lâˆ’1
(n âˆ’ k âˆ’ 1)(n âˆ’ k âˆ’ 2) . . . (n âˆ’ l)


lâˆ’k
câˆ’1
lâˆ’1
lâˆ’2
1
â‰¤2
â‰¤2
â‰¤ ,
nâˆ’kâˆ’1
l + Î·l + c âˆ’ 1
C

provided c0 is sufficiently large depending on Î· and C, as required.

(l)
Case 2: A ( F1 . If |A| â‰¤ nâˆ’2
lâˆ’2 , then


  
   



nâˆ’2
n
nâˆ’1
n
nâˆ’d
nâˆ’d
|A| + C |B| â‰¤
+C
â‰¤
â‰¤
âˆ’
+C
,
lâˆ’2
k
lâˆ’1
l
l
kâˆ’d
where the second inequality holds since
nâˆ’1
n
n
n
(l âˆ’ 2)(l âˆ’ 3) . . . (k + 1)
k
k
k
nâˆ’1
nâˆ’2 = nâˆ’1 = n âˆ’ k nâˆ’1 â‰¤ 2 (n âˆ’ k âˆ’ 1)(n âˆ’ k âˆ’ 2) . . . (n âˆ’ l + 2)
lâˆ’1 âˆ’ lâˆ’2
lâˆ’2
lâˆ’2


lâˆ’kâˆ’2
câˆ’3
lâˆ’2
lâˆ’2
1
â‰¤2
â‰¤2
â‰¤ ,
nâˆ’kâˆ’1
l + Î·l + c âˆ’ 1
C
provided c0 is sufficiently large depending on Î· and C. Hence, we may assume that




nâˆ’2
nâˆ’1
â‰¤ |A| â‰¤
.
lâˆ’2
lâˆ’1

Therefore, since A is lexicographically ordered, we have A âŠƒ {S âˆˆ [n]
: 1, 2 âˆˆ S}. Hence,
l
B âˆ©{1, 2} =
6 âˆ… for all B âˆˆ B. (If there exists B âˆˆ B with B âˆ©{1, 2} = âˆ…, then since n â‰¥ k+l, there

exists A âˆˆ [n]
with A âˆ© B = âˆ… and 1, 2 âˆˆ A, but the latter implies A âˆˆ A, a contradiction.)
l
(k)

Therefore, since B is lexicographically ordered, we have B âŠƒ F1 .
Observe that
{2}
{1}
A{1,2} âŠ† ([n] \ [2])(lâˆ’1) , B{1,2} âŠ‚ ([n] \ [2])(kâˆ’1)

{1}
are cross-intersecting, and trivially |A{1,2} | â‰¤ nâˆ’2
lâˆ’1 . Hence, by the induction hypothesis (which
we may apply since (n âˆ’ 2) â‰¥ (1 + Î·)(l âˆ’ 1) + (k âˆ’ 1) + c0 and l âˆ’ 1 â‰¥ k âˆ’ 1 + c0 âˆ’ 1, choosing
d = n âˆ’ 2), we have
 n âˆ’ 2



 {2} 
 {1} 
,
B
+
C
A
 {1,2}  â‰¤
 {1,2} 
lâˆ’1
19

and therefore,



 




nâˆ’2
nâˆ’1
 {1} 
 {2} 
|A| + C|B| =
+ A{1,2}  + C
+ C B{1,2} 
lâˆ’2
kâˆ’1

 



nâˆ’2
nâˆ’2
nâˆ’1
â‰¤
+
+C
lâˆ’2
lâˆ’1
kâˆ’1




nâˆ’1
nâˆ’1
=
+C
lâˆ’1
kâˆ’1
  



n
nâˆ’d
nâˆ’d
â‰¤
âˆ’
+C
,
l
l
kâˆ’d
using (8) for the last inequality. This completes the proof.
We need the following consequence of Lemma 2.23.
Proposition 2.24. Let n, j, M âˆˆ N, Î¶ âˆˆ (0, 1/2), and let Î¶n â‰¤ k1 , k2 â‰¤ ( 21 âˆ’ Î¶)n be such that

|k2 âˆ’ k1 | â‰¤ j. There exists c = c (M, Î¶, j) âˆˆ N such that the following holds. Let F âŠ‚ [n]
k1 and

G âŠ‚ [n]
k2 be cross-intersecting families such that for some d âˆˆ {c, c + 1, . . . , k2 }, we have


Then |F| + M |G| â‰¤

n
k1

âˆ’

nâˆ’d
k1




nâˆ’d
nâˆ’c
â‰¤ |G| â‰¤
.
k2 âˆ’ d
k2 âˆ’ c

+M

(9)

nâˆ’d 
k2 âˆ’d .

Proof. By Lemma 2.22, we may assume that F and G are lexicographically ordered. In addition,
by an appropriate choice of c, we may assume throughout that n â‰¥ n0 for any n0 = n0 (M, Î¶, j) âˆˆ
N.
[c]
âˆ…
Consider the families F[c]
and G[c] (for c to be specified below), which are clearly crossintersecting. As G is lexicographically ordered, the assumption (9) implies G âŠ‚ S[c]. Moreover,
[c]

[c]

âˆ…
G[c] is also lexicographically ordered, and hence, by (9) we have S{c+1,...,d} âŠ‚ G[c] . Since F[c]
[c]

âˆ…
âŠ‚ OR{c+1,...,d} , and thus,
cross-intersects G[c] , this implies F[c]
âˆ…
|F[c]
|

â‰¤



 

nâˆ’c
nâˆ’d
âˆ’
.
k1
k1

This allows us to apply Lemma 2.23 to the cross-intersecting families
âˆ…
F[c]
âŠ‚ ([n] \ [c]) (k1 ) ,

[c]

G[c] âŠ‚ ([n] \ [c])(k2 âˆ’c) ,

with the parameters nâ€² = n âˆ’ c, lâ€² = k1 , kâ€² = k2 âˆ’ c, dâ€² = d âˆ’ c, C â€² = M and Î· â€² = Î¶, provided
that c := c0 (Î¶, M ) + j, to obtain


  n âˆ’ c n âˆ’ d


nâˆ’d
 [c] 
 âˆ…
G
F
+
M
â‰¤
âˆ’
+
M
.
(10)
 [c] 
 [c] 
k1
k1
k2 âˆ’ d

(Note that we have nâ€² â‰¥ (1 + Î· â€² )lâ€² + kâ€² + c0 , provided n0 (M, Î¶, j) is sufficiently large.) Finally,
we clearly have

  
nâˆ’c
n
âˆ…
+ |F[c]
|,
âˆ’
|F| â‰¤
k1
k1
20

[c]

and the assumption (9) implies |G[c] | = |G|. Therefore, (10) yields
  
 

 
n
nâˆ’c
 âˆ…
 [c] 
|F| + M |G| â‰¤
âˆ’
+ F[c]
 + M G[c] 
k1
k1
  
 
 



n
nâˆ’c
nâˆ’c
nâˆ’d
nâˆ’d
â‰¤
âˆ’
+
âˆ’
+M
k1
k1
k1
k1
k2 âˆ’ d
  



n
nâˆ’d
nâˆ’d
=
âˆ’
+M
,
k1
k1
k2 âˆ’ d
as asserted.
We also need a â€˜stability resultâ€™ for cross-intersecting families, giving structural information
about one of the families, when the other family is somewhat large. A similar result (with a
similar proof) appears in Dinur and Friedgut [10, Lemma 3.2]. One of the main tools is the
biased version of Friedgutâ€™s Junta Theorem (Theorem 2.4).
Lemma 2.25. For any Î¶, Ç« âˆˆ (0, 1), there exist s = s(Î¶, Ç«), n0 = n0 (Î¶, Ç«) âˆˆ N such that the

[n]
following holds. Let n â‰¥ n0 , let 0 â‰¤ k1 , k2 â‰¤ ( 21 âˆ’ Î¶)n, let F âŠ‚ [n]
k1 , G âŠ‚ k2 be crossintersecting,
 Ç« and suppose that Âµ (G) â‰¥ Ç«. Then there exists S âŠ‚ [n] such that |S| â‰¤ s and
âˆ…
Âµ FS < 2 .

Informally, this lemma says that if we have a pair of cross-intersecting families of uniformity
bounded away from n/2, and one of the families occupies a positive fraction of its layer, then
all but a small number of the sets in the other family have nontrivial intersection with some
set of bounded size.
Proof of lemma 2.25. Clearly, the families F â†‘ and G â†‘ are cross-intersecting. Hence, by Lemma
2.20, we have
Âµ1/2 (F â†‘ ) + Âµ1/2 (G â†‘ ) â‰¤ 1.
Therefore, using Proposition 2.13, we have
Âµ1/2 (F â†‘ ) â‰¤ 1 âˆ’ Âµ1/2 (G â†‘ ) â‰¤ 1 âˆ’ Âµ(G) + exp(âˆ’Î¶ 2 n/2) â‰¤ 1 âˆ’ Ç« + exp(âˆ’Î¶ 2 n/2) â‰¤ 1 âˆ’ Ç«/2,
provided n is sufficiently large depending on Î¶ and Ç«. Let p = 21 ( kn1 + 21 ). The Margulis-Russo
Lemma and the Mean Value Inequality imply that there exists q âˆˆ (p, 1/2) such that

Âµ1/2 (F â†‘ ) âˆ’ Âµp (F â†‘ )
dÂµq F â†‘
2
q
â†‘


I (F ) =
â‰¤ .
â‰¤
k1
1 1
dq
Î¶
2 2 âˆ’ n

By Theorem 2.4, there exists J âŠ‚ [n] with |J| = OÎ¶,Ç« (1) and a J-junta hHi (i.e. H âŠ‚ P(J)),
Ç«2
. Note also that since q â‰¤ 1/2, F â†‘ is monotone, and the function
such that Âµq (F â†‘ âˆ† hHi) < 16
x 7â†’ Âµx (A) is monotone non-decreasing for any increasing family A âŠ‚ P ([n]), we have
Âµq (F â†‘ ) â‰¤ Âµ1/2 (F â†‘ ) â‰¤ 1 âˆ’ Ç«/2.
 Ç«
Claim 2.26. Âµq (F â†‘ )âˆ…
J < 4.

21

 Ç«
Proof. Suppose for a contradiction that Âµq (F â†‘ )âˆ…
J â‰¥ 4 . Then




X
q |B| (1 âˆ’ q)|J|âˆ’|B| Âµq (F â†‘ )B
Âµq F â†‘ \hHi =
J
B âˆˆH
/

â‰¥

X

B âˆˆH
/

q |B| (1 âˆ’ q)|J|âˆ’|B|

Ç«
4

Ç«
(1 âˆ’ Âµq (hHi))
4


 
Ç«
1 âˆ’ Âµq F â†‘ âˆ’ Âµq hHi\(F â†‘ )
â‰¥
4

Ç«2
Ç« Ç«
âˆ’
â‰¥
4 2 16
Ç«2
>
,
16
â‰¥

a contradiction.
âˆ…
â†‘
Since FJâˆ… = F â†‘ J , we have
Âµ

FJâˆ…



â‰¤ Âµq



(F â†‘ )âˆ…
J



1
+ exp âˆ’
2



Î¶
j
âˆ’
2 n

2 !
Ç«
n < ,
2

provided n is sufficiently large depending on Î¶, Ç« and j, using Proposition 2.13 again. This
completes the proof.

3

Proof of our stability result for the Ahlswede-Khachatrian
theorem

In this section, we prove Theorem 1.6, our stability result for the Ahlswede-Khachatrian theorem.

3.1

A Bootstrapping Lemma

In this subsection, we present a bootstrapping argument showing that if a t-intersecting F is
already â€˜somewhatâ€™ close to E, then it must be â€˜veryâ€™ close to E. We use this argument to show
that there exists a â€˜barrierâ€™ in the distance of F from E that cannot be crossed by performing
only small modifications.
Lemma 3.1 (Bootstrapping Lemma). Let t âˆˆ N and let Î¶ > 0. Then there exists C = C(t, Î¶) >
0 such that the following holds. Let Î¶ â‰¤ p â‰¤ 1/2 âˆ’ Î¶, let Ç« > 0, let F âŠ‚ P([n]) be a t-intersecting
family, and let G âˆˆ E. If
Âµp (F âˆ© G) â‰¥ Âµp (G) (1 âˆ’ Ç«) ,
then
Âµp (F\G) â‰¤ CÇ«log1âˆ’p p .
Proof. Without loss of generality, we may assume that G = Fn,t,r for some r âˆˆ N. Note
that, since p â‰¤ 1/2 âˆ’ Î¶, we have r â‰¤ r0 (t, Î¶) (this argument was already used in the proof

22

of Proposition 2.6). Hence, the assumption Âµp (F âˆ© Fn,t,r ) â‰¥ Âµp (Fn,t,r ) (1 âˆ’ Ç«) implies that for
any D âˆˆ F2r+t,t,r , we have


D
â‰¥ 1 âˆ’ Ot,Î¶ (Ç«) .
(11)
Âµp F[2r+t]

It is clear that for each E âˆˆ
/ F2r+t,t,r , there exists D âˆˆ F2r+t,t,r such that |D âˆ© E| â‰¤ t âˆ’ 1. Since
D
E
F is t-intersecting, for any such D, E, the families F[2r+t]
and F[2r+t]
are cross-intersecting. By
Proposition 2.19 and (11), this implies


 
log1âˆ’p p


E
D
Âµp F[2t+r]
â‰¤ 1 âˆ’ Âµp F[2r+t]
â‰¤ (Ot,Î¶ (Ç«))log1âˆ’p p = Ot,Î¶ Ç«log1âˆ’p p .

Therefore,

Âµp (F\Fn,t,r ) =

X

E âˆˆF
/ 2r+t,t,r



E
p|E| (1 âˆ’ p)2r+tâˆ’|E| Âµp F[2r+t]



â‰¤ Ot,Î¶ Ç«log1âˆ’p p

X

EâˆˆP[2r+t]



p|E| (1 âˆ’ p)2r+tâˆ’|E| = Ot,Î¶ Ç«log1âˆ’p p .

This completes the proof.
The following corollary shows that in order to prove Theorem 1.10, it is sufficient to show that
as Âµp (F) â†’ f (n, p, t), the distance Âµp (F \ E) is smaller than a sufficiently small constant c.
Corollary 3.2. Let t âˆˆ N and Î¶ > 0. There exist positive constants CÌƒ, c, Ç«0 depending only on
Î¶ and t, such that for any t-intersecting family F âŠ‚ P([n]) and any p âˆˆ [Î¶, 1/2 âˆ’ Î¶], if
Âµp (F\E) â‰¤ c
for some Ç« â‰¤ Ç«0 , then

Âµp (F) â‰¥ f (n, p, t) (1 âˆ’ Ç«)

and

Âµp (F\E) â‰¤ CÌƒÇ«log1âˆ’p p .

Proof. By the assumption on F, there exists G âˆˆ E such that
Âµp (F âˆ© G) â‰¥ f (n, p, t)(1 âˆ’ Ç«) âˆ’ c.
Hence, by Lemma 3.1, we have Âµp (F\E) â‰¤ C(Ç« + c/f (n, p, t))log 1âˆ’p p for some C = C(t, Î¶). Let
c be sufficiently small (as a function of t, Î¶) such that C Â· (2c/f (n, p, t))log 1âˆ’p p â‰¤ c/2 for all
p âˆˆ [Î¶, 1/2 âˆ’ Î¶]. If Ç« > c/f (n, p, t), then
Âµp (F\E) â‰¤ C(Ç« + c/f (n, p, t))log1âˆ’p p â‰¤ C Â· (2Ç«)log1âˆ’p p â‰¤ CÌƒÇ«log1âˆ’p p ,
and we are done. Otherwise, we have
Âµp (F\E) â‰¤ C(Ç« + c/f (n, p, t))log1âˆ’p p â‰¤ C Â· (2c/f (n, p, t))log 1âˆ’p p < c/2.
In such a case, we can repeat the process with the same Ç« and c/2 instead of c. At some stage
c will become sufficiently small so that Ç« > c/f (n, p, t), and then (as in the first case) we have
Âµp (F\E) â‰¤ CÌƒÇ«log1âˆ’p p , as asserted.
Finally, we can use the proof of Corollary 3.2 to show the existence of a barrier that cannot be
crossed by small modifications.
23

Corollary 3.3. Let t âˆˆ N and let Î¶ > 0. Let F âŠ‚ P([n]) be t-intersecting, and let p âˆˆ [Î¶, 1/2âˆ’Î¶].
Let c, Ç«0 be as in Corollary 3.2, and let Ç«1 := min(Ç«0 , c/f (n, p, t)). Suppose that
Âµp (F) â‰¥ f (n, p, t) (1 âˆ’ Ç«1 )

and

Âµp (F\E) > c.

Let G âŠ‚ P([n]) be a t-intersecting family with Âµp (G) > Âµp (F) which is a (c/2)-small modification of F (i.e., Âµp (F\G) < 2c ). Then
Âµp (G\E) > c.
Proof. Suppose for a contradiction that Âµp (G\E) â‰¤ c. By the proof of Corollary 3.2, we have
Âµp (G\E) < 2c . This yields
Âµp (F\E) â‰¤ Âµp (F\G) + Âµp (G\E) < c,
a contradiction.

3.2

Proof of Theorem 1.10

Let us recall the statement of Theorem 1.10.
Theorem. For any t âˆˆ N
 and any Î¶ > 0, there exists C = C(t, Î¶) > 0 such that the following
holds. Let p âˆˆ Î¶, 12 âˆ’ Î¶ , and let Ç« > 0. If F âŠ‚ P([n]) is a t-intersecting family such that
Âµp (F) â‰¥ f (n, p, t) (1 âˆ’ Ç«), then there exists a family G isomorphic to some Fn,t,r , such that
Âµp (F\G) â‰¤ CÇ«log1âˆ’p p .



4
Proof. Let c, Ç«1 be as in Corollary 3.3, and let Ç«2 := Ç« t, Î¶, max t + 2â„“(t, Î¶), t/(2Î¶), c2 p(1âˆ’p)
in the notations of Proposition 2.6. Define Ç«3 := min(Ç«1 , Ç«2 ). Let r := â„“(t, Î¶).
Let F âŠ‚ P([n]) be a t-intersecting family. By replacing F with F â†‘ , we may assume that
F is increasing. We may also assume that Âµp (F) â‰¥ f (n, p, t) (1 âˆ’ Ç«3 ). (There is no loss of
generality in this assumption, as C can be chosen such that the theorem holds trivially for all
Ç« > Ç«3 .) We would like to show that Âµp (F\E) â‰¤ c. This will complete the proof of the theorem
by Corollary 3.2.
We let F0 = F and construct a sequence (Fi ) of increasing t-intersecting families such that
each Fi is obtained from Fiâˆ’1 by a series of c/2-small modifications. Each â€˜stepâ€™ in the sequence
is composed of compression (using the process of section 2.3.1) and measure increase (using the
process of section 2.3.2). The construction of Fi from Fiâˆ’1 is defined as follows:
1. If either Fiâˆ’1 depends on at most max{t + 2r, t/(2Î¶)} coordinates, or else
min

j: Ij (Fiâˆ’1 )>0

Ij (Fiâˆ’1 ) â‰¥ c/2,

then stop.
2. Consider the set of coordinates with non-zero influence on Fiâˆ’1 . Assume w.l.o.g. that this
set is [m], and that minjâˆˆ[m] Ij (Fiâˆ’1 ) = Im (Fiâˆ’1 ). Transform Fiâˆ’1 to an m-compressed
increasing t-intersecting family Giâˆ’1 with Âµp (Giâˆ’1 ) = Âµp (Fiâˆ’1 ) by a sequence of small
modifications (as described in Proposition 2.8).
3. Transform Giâˆ’1 into an increasing t-intersecting family Fi with Âµp (Fi ) > Âµp (Giâˆ’1 ) by a
small modification (as described in Corollary 2.12, which can be applied since m > t/(2Î¶))
and then taking the up-closure to turn the family into an increasing family.
24

We claim that during all the process, all modifications are c/2-small, and that the process
terminates after a finite number of steps.
Indeed, Proposition 2.8 assures that all modifications in the m-compression process are
Im (Fiâˆ’1 )-small, and we have Im (Fiâˆ’1 ) < c/2, as otherwise the process terminates by (1.).
Similarly, Corollary 2.12 (which can be applied to Giâˆ’1 , since Giâˆ’1 is m-compressed) assures that
the transformation to Fi is an Im (Giâˆ’1 )-small modification, and by Proposition 2.8, Im (Giâˆ’1 ) â‰¤
Im (Fiâˆ’1 ) < c/2. By the construction, the sequence of measures (Âµp (Fi )) is strictly monotone
increasing in i. As the measure of a family Fi âŠ‚ P([n]) can assume only a finite number of
values, the sequence eventually terminates.
Let Fâ„“ be the last element of the sequence. As the sequence terminated at the â„“â€™th step,
either Fâ„“ depends on at most max{t + 2r, t/(2Î¶)} coordinates or else minj: Ij (Fâ„“ )6=0 Ij (Fâ„“ ) â‰¥ c/2.
4
coordinates. Thus, in either
In the latter case, by Proposition 2.5 Fâ„“ depends on at most c2 p(1âˆ’p)
o
n
4
coordinates. Since Âµp (Fâ„“ ) > Âµp (F) â‰¥
case Fâ„“ depends on at most max t + 2r, t/(2Î¶), c2 p(1âˆ’p)
f (n, p, t) (1 âˆ’ Ç«3 ), Proposition 2.6 implies that Fâ„“ âˆˆ E. In particular, Âµp (Fâ„“ \ E) = 0 < c.
Now, we unroll the steps of the sequence. As Fâ„“ was obtained from Fâ„“âˆ’1 by a c/2-small
modification, Corollary 3.3 implies Âµp (Fâ„“âˆ’1 \ E) < c. The same holds for any step of the
sequence, and thus, by (reverse) induction, we get Âµp (F \ E) = Âµp (F0 \ E) < c. As mentioned
above, this completes the proof of the theorem by Corollary 3.2.

3.3

Tightness of Theorem 1.10

As mentioned in the introduction, Theorem 1.10 is tight (up to a factor depending upon t and
Î¶ alone) for the families
HÌƒn,t,r,s := {A âŠ‚ P ([n]) : |A âˆ© [t + 2r]| â‰¥ t + r, A âˆ© {t + 2r + 1, . . . , t + 2r + s} =
6 âˆ…}

âˆª {A âŠ‚ P ([n]) : |A âˆ© [t + 2r]| = t + r âˆ’ 1, {t + 2r + 1, . . . , t + 2r + s} âŠ‚ A} ,

for all sufficiently large n and s. Here
is the computation
showing this. Let Î¶ â‰¤ p â‰¤ 1/2 âˆ’ Î¶.
i
h
r+1
r
Choose r âˆˆ N âˆª {0} such that p âˆˆ t+2râˆ’1 , t+2r+1 ; then we have
f (n, p, t) = Âµp (Fn,t,r ) =

t+2r
X

i=t+r




t + 2r i
p (1 âˆ’ p)t+2râˆ’i
i

(12)

for all n â‰¥ t + 2r. For all n â‰¥ t + 2r + s, we have

and





t + 2r
s
Âµp HÌƒn,t,r,s = f (n, p, t) (1 âˆ’ (1 âˆ’ p) ) +
pt+râˆ’1 (1 âˆ’ p)r+1 ps ,
t+râˆ’1

(13)

  t + 2r 

Âµp HÌƒn,t,r,s \Fn,t,r =
pt+râˆ’1 (1 âˆ’ p)r+1 ps .
t+râˆ’1

(14)

Note that all the expressions (12), (13) and (14) are independent of n. Moreover, since Î¶ < p <
t+2r
1/2 âˆ’ Î¶, we have r = Ot,Î¶ (1) and therefore t+râˆ’1
pt+râˆ’1 (1 âˆ’ p)r+1 = Î˜t,Î¶ (1). Hence, for all
s â‰¥ s0 (t, Î¶) and all n â‰¥ t + 2r + s, we have



Âµp HÌƒn,t,r,s = f (n, p, t) (1 âˆ’ (1 âˆ’ p)s ) + Î˜t,Î¶ (1)ps â‰¥ f (n, p, t) 1 âˆ’ 12 (1 âˆ’ p)s ,
25

while Âµp (HÌƒn,t,r,s \Fn,t,r ) = Î˜t,Î¶ (1)ps . Writing Ç« := 12 (1 âˆ’ p)s , we have
Âµp (HÌƒn,t,r,s ) â‰¥ f (n, p, t) (1 âˆ’ Ç«) ,

Âµp (HÌƒn,t,r,s \Fn,t,r ) = Î˜t,Î¶ (Ç«log1âˆ’p p ),

which is tight for Theorem 1.10.
We remark that it is very easy to see that the families Hn,k,t,r,d (defined in the Introduction)
are tight for Theorem 1.6, for n and d sufficiently large.

3.4

Proof of Theorem 1.6

In this section we present the proof of Theorem 1.6. First, we deduce a â€˜weak stabilityâ€™ result
from Theorem 1.10, using the reduction technique presented in section 2.4. Then, we use a
â€˜bootstrappingâ€™ technique similar to in the proof of Lemma 3.1, to leverage the weak stability
result into the assertion of the theorem.
Proposition 3.4 (Weak stability theorem). Let t âˆˆ N and Î¶, Ç« > 0. There exist C = C (t, Î¶) > 0
and n0 (t,
Î¶, Ç«) âˆˆ N such that the following holds for all n > n0 , all k âˆˆ [Î¶n, (1/2 âˆ’ Î¶)n] âˆ© N and
âˆš


k+ 4n log n
. Let F âŠ‚ [n]
be a t-intersecting family that satisfies |F| â‰¥ f (n, k, t) âˆ’ Ç« nk .
p=
n
k

Then there exists G isomorphic to some Fn,k,t,r such that |F\G| â‰¤ CÇ«log1âˆ’p p nk , where r â‰¤ C.
Proof. Let F, k and p satisfy the assumption of the proposition, and let F â†‘ âŠ‚ P([n]) be the
increasing family generated by F. By Proposition 2.13, for a sufficiently large n,
!

 
f
(n,
k,
t)
f (n, k, t)
1
â†‘
Âµp F â‰¥
â‰¥
âˆ’Ç«
âˆ’ 2Ç«.
1âˆ’
n
n
n
k
k

Let Fn,p,t,r âˆˆ E be a family for which the maximal Âµp measure is attained, i.e., Âµp (Fn,p,t,r ) =
f (n, p, t). As p â‰¤ 1/2 âˆ’ Î¶/2 (which holds assuming that n is sufficiently large), Fn,p,t,r depends
on at most j coordinates, for some j = j(t, Î¶) âˆˆ N. Hence, by Proposition 2.15,
(k)

f (n, p, t) = Âµp (Fn,p,t,r ) <

|Fn,p,t,r |
f (n, k, t)
 +Ç«â‰¤

+ Ç«.
n
n
k

Thus, Âµp F
get


â†‘

k

â‰¥ f (n, p, t) âˆ’ 3Ç«. Since F â†‘ is t-intersecting, we can apply to it Theorem 1.10 to
Âµp (F â†‘ \ GÌƒ) â‰¤ C â€² Ç«logp (1âˆ’p) ,

for some GÌƒ âˆˆ E and C â€² = C â€² (t, Î¶). Finally, denoting G := GÌƒ (k) , we obtain by Proposition 2.16
 
â†‘
(k)
log1âˆ’p p n
|F\G| = |(F \ GÌƒ) | < CÇ«
,
k
for a sufficiently large C = C(t, Î¶), as asserted.
Proposition 3.4 shows that the assertion of Theorem 1.6 holds for all n â‰¥ n0 (t, Î¶, Ç«). This is
not sufficient for Theorem 1.6, in proving which we may only assume n to be large in terms of
t, Î¶ (and not in terms of Ç«). However, we can apply Proposition 3.4 with any moderately small
Ç«0 (t, Î¶) > 0 to conclude that for any n â‰¥ n1 (t, Î¶), if F satisfies
the assumption of Theorem 1.6

then there exists G âˆ¼
= Fn,k,t,r such that |F\G| â‰¤ Ç«0 nk . In the proof of Theorem 1.6 below,
we use this weak stability version, with Ç«0 chosen in such a way that we will be able to use
Proposition 2.24 to bootstrap the â€˜weak stabilityâ€™ into â€˜strong stabilityâ€™.
Let us recall the formulation of Theorem 1.6.
26

 
Theorem. Let n, t, d âˆˆ N, Î¶ âˆˆ (0, 1/2), and k âˆˆ Î¶n, 12 âˆ’ Î¶ n . There exists C = C (t, Î¶) > 0


such the following holds. Let F âŠ‚ [n]
f (n, k, t) âˆ’ C1 nâˆ’d
.
k
k be a t-intersecting family with |F| >

nâˆ’d
Then there exists G isomorphic to some Fn,k,t,r such that |F\G| < C kâˆ’d , where r â‰¤ C.

Proof of Theorem 1.6. Recall that for fixed t, Î¶, all elements of E are juntas on at most j =
j(t, Î¶) elements. Denote c = c 2j , t, Î¶ in the notations of Proposition 2.24. Let F be a family
that satisfies the assumption of the theorem (with a sufficiently large C = C(t, Î¶) > 0 to be
specified below). Clearly, we may assume that d â‰¤ k + 1. By increasing C if necessary, we may
assume that d â‰¥ d0 (t, Î¶) for any d0 (t, Î¶) âˆˆ N and that n â‰¥ n0 (t,Î¶) for any n
0 (t, Î¶) âˆˆ N.
n
nâˆ’câˆ’j
Provided n0 = n0 (t, Î¶) is sufficiently large, we have kâˆ’câˆ’j = Î˜t,Î¶ k . Hence, we can
apply Proposition 3.4 to conclude that there exists G âˆˆ (E)(k) such that


nâˆ’câˆ’j
|F\G| <
.
(15)
kâˆ’câˆ’j
â€²
Suppose w.l.o.g. that G depends only on the coordinates in [j], and denote
 by G the restriction
 O
of G to P ([j]) (i.e., G â€² = {A âˆ© [j] : A âˆˆ G}). Let O âˆˆ
/ G â€² be such that F[j]
 is maximal. We



 O
would like to show that F[j]
 â‰¤ nâˆ’d
kâˆ’d . This will complete the proof, as

|F \ G| =

X

SâˆˆP([j])\G â€²

Suppose for a contradiction that





 S
 O
F[j]  â‰¤ 2j F[j]
.


 n âˆ’ d
 O
.
F[j]  >
kâˆ’d

It is clear that there exists I âˆˆ G â€² such that |I âˆ© O| â‰¤ t âˆ’ 1. We have





 
X
nâˆ’j
 I 
S
j  O
|F| =
|F[j] | â‰¤ F[j]  + 2 F[j]  + |G| âˆ’
k âˆ’ |I|

(16)

(17)

SâˆˆP([j])

P
P
S
S
(where the two last summands are upper bounds on
SâˆˆG â€² \{I} |F[j] |,
SâˆˆP([j])\G â€² |F[j] | and
I , F O are crossrespectively). Now, we note that since F is t-intersecting, the families F[j]
[j]
intersecting. We have






nâˆ’câˆ’j
nâˆ’jâˆ’c
 O
â‰¤
F[j]  â‰¤
kâˆ’câˆ’j
k âˆ’ |O| âˆ’ c

(where the first inequality follows from (15) and the second holds provided n0 = n0 (t, Î¶) is
sufficiently large), and on the other hand,

 n âˆ’ d  n âˆ’ j âˆ’ d 
 O
â‰¥
F[j]  â‰¥
kâˆ’d
k âˆ’ |O| âˆ’ d

(where the first inequality follows from (16) and the second holds trivially). Thus, we can apply
Proposition 2.24 to get





  n âˆ’ j  n âˆ’ j âˆ’ d 
nâˆ’jâˆ’d
 I 
j  O
j
âˆ’
+2
.
F[j]  + 2 F[j]  â‰¤
k âˆ’ |I|
k âˆ’ |I|
k âˆ’ |O| âˆ’ d
27

By (17), this implies

 


 


nâˆ’j
nâˆ’j âˆ’d
nâˆ’j âˆ’d
nâˆ’j
j
|F| â‰¤
âˆ’
+2
+ |G| âˆ’
k âˆ’ |I|
k âˆ’ |I|
k âˆ’ |O| âˆ’ d
k âˆ’ |I|




nâˆ’jâˆ’d
nâˆ’jâˆ’d
= |G| âˆ’
+ 2j
k âˆ’ |I|
k âˆ’ |O| âˆ’ d


1 nâˆ’d
,
â‰¤ f (n, k, t) âˆ’
C
k
where the last inequality holds for all d0 â‰¤ d â‰¤ k + 1 and all n â‰¥ n0 , provided C = C(t, Î¶),
n0 = n0 (t, Î¶) and d0 = d0 (t, Î¶) are all sufficiently large. This contradicts our assumption on F,
completing the proof.

4

Proof of our weak regularity lemma

In this section we prove Theorem 1.7, our â€˜weak regularity lemmaâ€™ for hypergraphs of uniformity
linear in the number of vertices. First, we need some preliminaries.
Jensenâ€™s inequality states that for any convex function f : R â†’ R, and for any real-valued,
integrable random variable X, we have
E[f (X)] â‰¥ f (E[X]).

(18)

It turns out that under certain conditions, if the inequality (18) is approximately an equality,
then X is â€˜highly concentratedâ€™ around its mean. The following is a restatement of Lemma 7 of
Fox [16]; it may be seen as a stability version of Jensenâ€™s inequality for the function x 7â†’ x log x.
Lemma 4.1. Let â„¦ be a finite probability space, let X : â„¦ â†’ Râ‰¥0 be a nonnegative random
variable, and let f : Râ‰¥0 â†’ R be the convex function defined by
(
x log x x > 0
f (x) :=
0
x = 0,
and let Î² âˆˆ (0, 1). Then
E (f (X)) â‰¥ f (E (X)) + (1 âˆ’ Î² + f (Î²)) Pr [X â‰¤ Î²E (X)] E (X) .
The following is an easy corollary of Lemma 4.1.
Corollary 4.2. Let f be the function in Lemma 4.1. For each Î», Î´ âˆˆ (0, 1) and C > 0, there
exists Î· = Î· (Î», Î´, C) > 0 such that the following holds. Let â„¦ be finite probability space, and
suppose that Pr(Ï‰) â‰¥ Î» for all Ï‰ âˆˆ â„¦. Let X : â„¦ â†’ Râ‰¥0 be a nonnegative random variable such
that E[X] â‰¤ C and
E [f (X)] < f (E[X]) + Î·.
Then
kX âˆ’ E[X]kâˆ < Î´.
Corollary 4.2 says that if Jensenâ€™s inequality (18) is close to being an equality for the function
f and a â€˜well-behavedâ€™ random variable X, then the random variable X is highly concentrated
around its mean.
28

Proof of Corollary 4.2. Let Î· = Î· (Î», Î´, C) > 0 to be chosen later. Suppose that
E [f (X)] < f (E[X]) + Î·,
and suppose for a contradiction that kX âˆ’ E[X]kâˆ â‰¥ Î´. First suppose that minÏ‰âˆˆâ„¦ X(Ï‰) â‰¤
E[X] âˆ’ Î´. Then




Î´
E[X] â‰¥ Î»,
Pr X â‰¤ 1 âˆ’
E[X]

so by applying Lemma 4.1 with Î² = 1 âˆ’ Î´/E[X], we have



Î´
Î´
E[f (X)] â‰¥ f (E[X]) +
+f 1âˆ’
Î»E[X].
E[X]
E[X]
Let Î³ := Î´/E[X]; then Î³ âˆˆ [0, 1]. It is easily checked that
Î³ + f (1 âˆ’ Î³) â‰¥ Î³ 2 /2 âˆ€Î³ âˆˆ [0, 1].
It follows that
E[f (X)] â‰¥ f (E[X]) +

Î»Î´2
Î»Î´2
â‰¥
.
2E[X]
2C

Second, suppose that minÏ‰âˆˆâ„¦ X(Ï‰) > E[X] âˆ’ Î´; then maxÏ‰âˆˆâ„¦ X(Ï‰) â‰¥ E[X] + Î´. Let
M = minÏ‰âˆˆâ„¦ X(Ï‰); then
(1 âˆ’ Î»)M + Î»(E[X] + Î´) â‰¤ E[X],
so

Î»Î´
.
1âˆ’Î»
Hence, by the argument above, replacing Î´ with Î»Î´/(1 âˆ’ Î»), it follows that
M â‰¤ E[X] âˆ’

E[f (X)] â‰¥ f (E[X]) +
Choosing
Î· = min
yields a contradiction.



Î»3 Î´2
.
2(1 âˆ’ Î»)2 C

Î»Î´2
Î»3 Î´2
,
2C 2(1 âˆ’ Î»)2 C



A â€˜potentialâ€™ argument
The idea of the proof of Theorem 1.7 is to define a non-positive potential function Ï† : P
P([n]) â†’ [âˆ’1/e, 0] with the following properties.





[n]
k

Ã—

1. Ï† (F, S) = 0 if and only if F is an S-junta.
2. If S âŠ‚ S â€² âŠ‚ [n], then Ï† (F, S) â‰¤ Ï† (F, S â€² ).

3. If k/n is bounded away from 0 and 1, then for any F âŠ‚ [n]
and any S âŠ‚ [n], either
k
there exist sets B1 , . . . Bl âŠ‚ S such that the junta h{B1 , . . . , Bl }i satisfies the conclusion
of Theorem 1.7, or there exists a set S â€² âŠƒ S that is not much larger than S, and such that
Ï† (F, S â€² ) is significantly larger than Ï† (F, S). In the latter case, we replace S by S â€² and
repeat; since Ï† is bounded from above by 0, the former case must occur after a bounded
number of steps.
29

We now proceed to define our potential function Ï†.
Definition (The (n, k, J)-biased distribution). For each J âŠ‚ [n], we define the (n, k, J)-biased
distribution on P (J) by
Âµ(n,k,J) (B) =

Pr

Aâˆ¼([n]
k )

[A âˆ© J = B]

âˆ€B âŠ‚ J,


[n]
where A âˆ¼ [n]
k denotes a uniform random element of k . We write B âˆ¼ Âµ(n,k,J) if B is chosen
according this distribution.


B
B for each B âŠ‚ J. We define our potential
For F âŠ‚ [n]
k  andJ âŠ‚ [n], we define Î±J := Âµ FJ

Ã— P([n]) by
function Ï† : P [n]
k
Ï† (F, J) =

E

Bâˆ¼Âµ(n,k,J )

Î±B
J

log Î±B
J

âˆ€F âŠ‚




[n]
, J âŠ‚ [n].
k


Since âˆ’1/e â‰¤ f (x) â‰¤ 0 for all x âˆˆ [0, 1], we have âˆ’1/e â‰¤ Ï†(F, J) â‰¤ 0 for all F âŠ‚ [n]
k
and all J âŠ‚ [n]; we have Ï† (F, J) = 0 if and only if F is a J-junta. Moreover, it follows from
Jensenâ€™s inequality that Ï† (F, S) â‰¤ Ï† (F, S â€² ) for any S âŠ‚ S â€² . We note the similarity between
the definition of Ï† and the definition of the entropy of a random variable. We note also that
the product space analogue of the function Ï† (in the slightly simpler setting where Âµ(n,k,J) is
replaced by a product distribution on P(J)) was considered by Friedgut and Regev in [24], and
used in a similar way to in the sequel.

Definition. We say that a family F âŠ‚ [n]
k is (Î·, h)-potentially stable if Ï† (F, J) < Ï† (F, âˆ…) + Î·
for all sets J âŠ‚ [n] with |J| â‰¤ h.
We recall from the Introduction the definition of slice-quasirandomness.

Definition. If Î· > 0 and h âˆˆ N, we say that a family F âŠ‚ [n]
k is (Î´, h)-slice-quasirandom if
for any J âŠ‚ [n] with |J| â‰¤ h, and any B âŠ‚ J, we have |Âµ(FJB ) âˆ’ Âµ(F)| < Î´.
By virtue of Corollary 4.2, there is a close connection between potential stability and slicequasirandomness. Indeed, the following lemma says that if k/n is bounded away from 0 and
1, then (Î·, h)-potential stability implies (Î´, h)-slice-quasirandomness, provided Î· is sufficiently
small.
Lemma 4.3. For any Î¶, Î´ > 0, h âˆˆ N there exist Î· = Î· (Î´, h, Î¶) > 0 and n0 = n0 (Î¶, h) âˆˆ N

such that the following holds. Let n â‰¥ n0 , let Î¶n â‰¤ k â‰¤ (1 âˆ’ Î¶) n, and let F âŠ‚ [n]
be
k
(Î·, h)-potentially stable. Then F is (Î´, h)-slice-quasirandom.
Proof. Let F be as in the statement of the lemma, and let Î· = Î·(Î´, h, Î¶) > 0 to be chosen later.
Let J âŠ‚ [n] with |J| â‰¤ h. Let â„¦ = P(J), and equip â„¦ with the probability distribution Âµ(n,k,J).
Since Î¶n â‰¤ k â‰¤ (1 âˆ’ Î¶)n, we have
 

nâˆ’h
Î¶n âˆ’ h + 1 h
âŒˆÎ¶nâŒ‰âˆ’h

â‰¥ (Î¶/2)h âˆ€Ï‰ âˆˆ â„¦,
â‰¥
Pr(Ï‰) â‰¥
n
n
âˆ’
h
+
1
âŒˆÎ¶nâŒ‰

provided n â‰¥ 2h/Î¶.
Let X be the non-negative random variable defined by X(B) = Î±B
J . Then we have E[X] =
Âµ(F), f (E[X]) = Âµ(F) log Âµ(F) = Ï†(F, âˆ…) and E[f (X)] = Ï†(F, J). The fact that F is (Î·, h)potentially stable implies that E[f (X)] < f (E[X]) + Î·. Corollary 4.2 (with Î» = (Î¶/2)h and
30

C = 1) implies that kX âˆ’ E[X]kâˆ < Î´, provided Î· is sufficiently small depending on Î´, h
and Î¶. This in turn implies that |Âµ(FJB ) âˆ’ Âµ(F)| < Î´ for any B âŠ‚ J. It follows that F is
(Î´, h)-slice-quasirandom, as required.
Armed with this lemma, we can now prove Theorem 1.7.
Proof of Theorem 1.7. Let Î· = Î·(Î´, h, Î¶/2) be as in the statement of Lemma 4.3, and let n0 âˆˆ N
to be chosen later, depending on Î´, h, Î¶ and Ç«. Given a set S âŠ‚ [n], we define a partition of
P(S) into three parts:

â€¢ We let GS âŠ‚ P (S) be the family of all sets B âŠ‚ S, such that Âµ FSB > 2Ç« , and such that
the family FSB is (Î·, h)-potentially stable. We call these the â€˜goodâ€™ sets.

â€¢ We let BS âŠ‚ P(S) be the family of all sets B âŠ‚ S, such that Âµ FSB > 2Ç« , and such that
the family FSB is not (Î·, h)-potentially stable. We call these the â€˜badâ€™ sets.

â€¢ We let ES âŠ‚ P(S) be the family of all sets B âŠ‚ S, such that Âµ FSB â‰¤ 2Ç« . We call these
the â€˜exceptionalâ€™ sets.
By Lemma 4.3 (applied with Î¶/2 in place of Î¶), for each B âˆˆ GS , the family FSB is (Î´, h)slice-quasirandom, provided Î· is sufficiently small depending on Î¶, Î´ and h, and provided n is
sufficiently large depending on Î¶, h and |S|. It suffices to show that there exists a set S of size
bounded from above in terms of Î¶, Î´, h and Ç«, such that Âµ (F\ hGS i) < Ç«. The next claim says
that if this does not hold, then S can be replaced by a set S â€² âŠƒ S of size at most h Â· 2|S| , such
that Ï† (F, S â€² ) is significantly larger than Ï† (F, S).
Claim 4.4. For each S âŠ‚ [n], we either have Âµ (F\ hGS i) < Ç«, or else there exists a set S â€² âŠƒ S
with |S â€² | â‰¤ h2|S| + |S|, such that

Ï† F, S â€² â‰¥ Ï† (F, S) + Î·Ç«/2.

Proof. Suppose that Âµ (F\ hGS i) â‰¥ Ç«. We have

Ç« â‰¤ Âµ (F\ hGS i)
X

Âµ(n,k,S) (B) Âµ FSB
=
BâŠ‚S:
B âˆˆG
/ S

=

X

BâˆˆBS

X


Âµ(n,k,S) (B) Âµ FSB +
Âµ(n,k,S) (B) Âµ FSB
BâˆˆES

â‰¤ Âµ(n,k,S) (BS ) + Ç«/2,
and therefore

Âµ(n,k,S) (BS ) â‰¥ Ç«/2.
For each B âˆˆ BS , let SB âŠ‚ [n] \ S such that |SB | â‰¤ h and


Ï† FSB , SB â‰¥ Ï† FSB , âˆ… + Î·.

Writing

ï£«

Sâ€² = ï£­

[

BâˆˆBS

31

ï£¶

SB ï£¸ âˆªË™ S,

we have

Ï† F, S â€² âˆ’ Ï†(F, S) =

E

Bâˆ¼Âµ(n,k,S)

E

â‰¥

Bâˆ¼Âµ(n,k,S)

â‰¥

Bâˆ¼Âµ(n,k,S)

E




Ï† FSB , S â€² \S âˆ’ Ï† FSB , âˆ…




1BâˆˆBS Ï† FSB , SB âˆ’ Ï† FSB , âˆ…

[1BâˆˆBS Â· Î·]

= Î· Â· Âµ(n,k,S)(BS )
â‰¥ Î·Ç«/2.

This proves the claim.
Let J0 = âˆ…. By Claim 4.4, we either have Âµ (F\ hGJ0 i) < Ç«, or else there exists J1 âŠ‚ [n]
such that |J1 | â‰¤ h Â· 20 + 0 and
Ï† (F, J1 ) â‰¥ Ï† (F, J0 ) + Î·Ç«/2.
We now repeat the process with the set J1 , and so on, producing, for each m âˆˆ N with
m â‰¤ 2/(eÎ·Ç«), a set Jm âŠ‚ [n], such that either



Âµ F\ GJmâˆ’1 < Ç«,

or else


Ï† (F, Jm ) â‰¥ Ï† F, GJmâˆ’1 + Î·Ç«/2,

Since

there exists m â‰¤

1
Ï† (F, âˆ…) â‰¥ âˆ’ ,
e

2
eÎ·Ç«

such that



Âµ F\ GJmâˆ’1 < Ç«.

The size of Jmâˆ’1 is bounded above by a constant depending only upon Î·, h and Ç«. By definition, FJBmâˆ’1 is (Î·, h)-potentially-stable, for each B âˆˆ GJmâˆ’1 . Provided n0 is sufficiently large
(depending on Î¶, Î·, h and Ç«), we may apply Lemma 4.3 with Î¶/2 in place of Î¶, n âˆ’ |Jmâˆ’1 | in
place of n and k âˆ’ |B| in place of k, implying that FJBmâˆ’1 is (Î´, h)-slice-quasirandom for each
B âˆˆ GJmâˆ’1 . Hence, we may take J = Jmâˆ’1 , completing the proof.
Remark 4.1. We note that there is no general â€˜counting lemmaâ€™ for (Î·, h)-slice-quasirandom
families, for hypergraphs with a bounded number of edges â€” unsurprisingly perhaps, given
the relative weakness of the constraint. To see this, let n be even, let k = n/2, and consider
a random family F produced by including exactly one of S and [n] \ S (with probability 1/2
[n] 
. Clearly, Âµ(F) = 21 , and F
each), independently at random for each pair {S, [n] \ S} âŠ‚ n/2
contains no copy of the hypergraph consisting of two disjoint edges. Moreover, for any J âŠ‚ [n]
nâˆ’|J| 
, 1/2), and therefore by a Chernoff bound,
and any B âŠ‚ J, |FJB | âˆ¼ Bin( kâˆ’|B|
Pr[|Âµ(FJB )





2 2 n âˆ’ |J|
âˆ’ 1/2| â‰¥ Î·] < 2 exp âˆ’ Î·
.
3
k âˆ’ |B|

32

Hence, using a union bound, the probability that there exists J âŠ‚ [n] with |J| â‰¤ h and B âŠ‚ J
such that |Âµ(FJB ) âˆ’ 1/2| â‰¥ Î· is at most
X X

J âŠ‚[n]:
|J |â‰¤h

BâŠ‚J





2 2 n âˆ’ |J|
2 exp âˆ’ Î·
â‰¤ 2 Â· 2h Â·
3
k âˆ’ |B|

!
h  
X
n
i=1

i



2 nâˆ’h
= o(1),
exp âˆ’
3 n/2 âˆ’ h


as n â†’ âˆ for any fixed Î· and h. Therefore, F is (Î·, h)-slice-quasirandom with high probability.
To obtain results on families with a forbidden intersection-size, we will need the following
property of pairs of slice-quasirandom families.
Lemma 4.5. For any Ç«, Î¶ âˆˆ (0, 1) and any t âˆˆ N, there exist Î· = Î·(Ç«) > 0, h0 = h0(Ç«, Î¶, t) âˆˆ N
and n0 = n0 (Ç«, Î¶, t) âˆˆ N such that the following holds. Let t âˆ’ 1 â‰¤ k1 , k2 â‰¤ 12 âˆ’ Î¶ n, and let

[n]
A âŠ‚ [n]
k1 , B âŠ‚ k2 be (Ç«/5, h0 )-slice-quasirandom families, with Âµ(A) â‰¥ Ç« and Âµ(B) â‰¥ Ç«. Then
there exist A âˆˆ A and B âˆˆ B such that |A âˆ© B| = t âˆ’ 1. (We may take Î· = Ç«/5.)
This lemma says that if A and B are sufficiently slice-quasirandom, and have uniformity
bounded away from n/2, then we can find a pair of sets A âˆˆ A, B âˆˆ B with any bounded
intersection-size. The idea of the proof is to use the slice-quasirandomness property to reduce
to the case of t = 1, where we can apply a result about cross-intersecting families (Lemma
2.25). Note that Lemma 2.25 immediately implies the t = 1 case of Lemma 4.5.

[n]
Proof of Lemma 4.5. Let n â‰¥ n0 and let A âŠ‚ [n]
and
B
âŠ‚
k1
k2 be (Î·, h0 )-slice-quasirandom
families, such that Âµ (A) â‰¥ Ç« and Âµ (B) â‰¥ Ç«, where Î· = Ç«/5, and h0 , n0 are to be chosen later.
[tâˆ’1]
[tâˆ’1]
It is easy to check that the families Aâ€² := A[tâˆ’1] , B â€² := B[tâˆ’1] are (2Î·, h0 âˆ’ t + 1)-slicequasirandom families with


Âµ Aâ€² , Âµ B â€² â‰¥ Ç« âˆ’ Î·.
By Lemma 2.25, if Aâ€² and B â€² were cross-intersecting, then there would exist S âŠ‚ [n] with
|S| â‰¤ s(Î¶, Ç« âˆ’ Î·) and Âµ((Aâ€² )âˆ…
S ) < (Ç« âˆ’ Î·)/2, provided n0 is sufficiently large depending on Ç« and
Î¶. But then
Âµ(Aâ€² ) âˆ’ Âµ((Aâ€² )âˆ…
S ) > Ç« âˆ’ Î· âˆ’ (Ç« âˆ’ Î·)/2 â‰¥ 2Î·,

contradicting the fact that Aâ€² is (2Î·, h0 âˆ’t+1)-slice-quasirandom, provided h0 âˆ’t+1 â‰¥ s(Ç«âˆ’Î·, Î¶).
Hence, there exist C âˆˆ Aâ€² and D âˆˆ B â€² such that C âˆ© D = âˆ…. We have C âˆª [t âˆ’ 1] âˆˆ A,
D âˆª [t âˆ’ 1] âˆˆ B and |(C âˆª [t âˆ’ 1]) âˆ© (D âˆª [t âˆ’ 1])| = t âˆ’ 1, as required.

5
5.1

Proof of our forbidden intersection theorem
Approximations by juntas


We can now prove that if k/n is bounded away from 0 and 1/2, and F âŠ‚ [n]
k is a family such
that no pair of sets in F have intersection of size t âˆ’ 1, then F is approximately contained
within a t-intersecting junta.
Theorem 5.1. For any Ç«, Î¶ > 0 and t âˆˆ N there exists j = j(t, Î¶, Ç«) âˆˆ N and n1 = n1 (t, Î¶, Ç«) âˆˆ N


such that the following holds. Let n â‰¥ n1 , let Î¶n â‰¤ k â‰¤ 21 âˆ’ Î¶ n, and let F âŠ‚ [n]
k such that
no two sets in F haveintersection of size t âˆ’ 1. Then there exists a t-intersecting j-junta J
such that |F\J | < Ç« nk .
33

The proof uses our â€˜weak regularity lemmaâ€™ (Theorem 1.7) to find a J-junta J in which the
family F is approximately contained, and such that for each B âŠ‚ J with B âˆˆ J , the slice FJB
is highly slice-quasirandom and not too small; we then use Lemma 4.5 to show that the junta
J must be t-intersecting.
Proof of Theorem 5.1. Let t âˆˆ N, let Ç«, Î¶ > 0, let Î· = Ç«/10 and let h, n1 âˆˆ N to be chosen later

(depending on t, Î¶ and Ç«). Let n â‰¥ n1 , let Î¶n â‰¤ k â‰¤ ( 12 âˆ’ Î¶)n, and let F âŠ‚ [n]
k be a family
containing no pair of sets whose intersection has size t âˆ’ 1.
By Theorem 1.7, there exists j = j(Î¶, Î·, h, Ç«) âˆˆ N, a set J âŠ‚ [n] with |J| â‰¤ j, and a J-junta
J = hGi (i.e., G âŠ‚ P(J)), such that Âµ (F\J ) < Ç«, and such that for each B âˆˆ G, the family FJB
is an (Î·, h)-slice-quasirandom family with Âµ(FJB ) â‰¥ Ç«/2. It suffices to show that the junta J is
t-intersecting.
Suppose for a contradiction that there exist A1 , A2 âˆˆ J such that |A1 âˆ© A2 | < t. Then there
exist B1 , B2 âˆˆ G and C1 , C2 âŠ‚ [n] \J, such that
FJB1

A1 = B1 âˆª C1 , A2 = B2 âˆª C2 .

Note that the families
and FJB2 are each (Î·, h)-slice quasirandom with measure at least Ç«/2.
Write |B1 âˆ© B2 | =: tâ€² â‰¤ t âˆ’ 1. Provided h â‰¥ maxtâ€²â€² âˆˆ[tâˆ’1]âˆª{0} h0 (Ç«/2, Î¶/2, tâ€²â€² ) and n1 is sufficiently
large depending on t, Î¶ and Ç«, Lemma 4.5 (applied with A = FJB1 , with B = FJB2 , with Ç«/2 in
place of Ç« and with Î¶/2 in place of Î¶) implies that there exist D1 âˆˆ FJB1 and D2 âˆˆ FJB2 such
that
|D1 âˆ© D2 | = t âˆ’ 1 âˆ’ tâ€² .

This is a contradiction, since B1 âˆª D1 âˆˆ F, B2 âˆª D2 âˆˆ F and |(B1 âˆª D1 ) âˆ© (B2 âˆª D2 )| = t âˆ’ 1.

5.2

A stability result for the forbidden intersection problem

We now apply Theorems 1.6 and 5.1 to obtain the following stability version of Theorem
1.5.
[n] 
For brevity, we say that a family F âŠ‚ [n]
is
a
Frankl
family
if
there
exists
a
set
S
âˆˆ
such
t+2r
k

that F = {A âˆˆ [n]
:
|A
âˆ©
S|
â‰¥
t
+
r}.
If
t
âˆˆ
N
and
Î¶
>
0
are
fixed
and
Î¶n
â‰¤
k
â‰¤
(1/2
âˆ’ Î¶)n,
k
we say such a Frankl family is a Frankl junta if r is bounded from above in terms of t and Î¶.
Theorem 5.2. For any Ç«, Î¶ > 0 and any t âˆˆ N, there exists Î´ > 0and n0 âˆˆ N such that the
following holds. Let n â‰¥ n0 , let Î¶n â‰¤ k â‰¤ ( 21 âˆ’ Î¶)n, and let A âŠ‚ [n]
that does not
k be a family

contain two sets whose intersection is of size t âˆ’ 1. If |A| â‰¥ f (n, k, t) âˆ’ Î´ nk , then there exists

a Frankl family F âŠ‚ [n]
such that Âµ (A\F) < Ç«. Moreover, F can be taken to be a j-junta,
k
where j = j(t, Î¶) âˆˆ N.

Proof. Let Î´ = Î´(t, Î¶, Ç«) > 0 and n0 = n0 (t, Î¶, Ç«) âˆˆ N to be chosen later. Let n â‰¥ n0 , let

Î¶n â‰¤ k â‰¤ (1/2 âˆ’ Î¶)n, let A âŠ‚ [n]
be a family that does not contain a pair of sets with
k
intersection of size t âˆ’ 1, and suppose that |A| â‰¥ f (n, k, t) âˆ’ Î´ nk . By Theorem 5.1, provided
n0 is sufficiently large depending
 Ç« 	 on t, Î¶, Ç« and Î´, there exists a t-intersecting family J âŠ‚ P ([n])
such that Âµ (A\J ) < min Î´, 2 . In particular, we have
 
 
n
n
|J | â‰¥ |A| âˆ’ Î´
â‰¥ f (n, k, t) âˆ’ 2Î´
.
k
k

Provided Î´ is sufficiently small depending on t, Î¶ and Ç«, Theorem 1.6 implies that there exists
a Frankl family F, which is an OÎ¶,t (1)-junta, such that Âµ (J \F) < 2Ç« . We have
completing the proof.

Âµ (A\F) â‰¤ Âµ (A\J ) + Âµ (J \F) < Ç«,

34

5.3

The Frankl families are locally extremal


In the previous subsection, we showed that if A âŠ‚ [n]
k is a family that does not contain two sets
whose intersection is of size t âˆ’ 1, and if |A| is close to f (n, k, t), then A has small symmetric
difference with a Frankl junta. In this subsection, we show that such a family A is no larger
than a Frankl junta. This will complete the proof of Theorem 1.5. The following lemma will
be a key tool.
Lemma 5.3. For any Î¶ > 0 and any j, t âˆˆ N, there exist Ç«0 = Ç«0 (t, Î¶, j) > 0 and
 n0 =
n0 (t, Î¶, j) âˆˆ N such that the following holds. Let n â‰¥ n0 , and let Î¶n â‰¤ k â‰¤ 12 âˆ’ Î¶ n. Let

F âŠ‚ [n]
k be a family not containing a pair of sets whose intersection is of size tâˆ’ 1. Let
B >1âˆ’Ç«
J âˆˆ [n]
0
j , and let G âŠ‚ P (J) be a maximal t-intersecting family. Suppose that Âµ FJ
for any B âˆˆ G. Then Âµ (F) â‰¤ Âµ (hGi), with equality only if F = hGi.


	
Proof. Let Î´ = maxB âˆˆG
Âµ FJB , and let Ç« = maxAâˆˆG 1 âˆ’ Âµ FJA . We observe the following.
/

Claim 5.4. There exists c = c (t, Î¶, j) > 1 such that Î´ = Ot,Î¶,j (Ç«c ).

Proof. Let B âˆˆ
/ G such that Âµ FJB = Î´. Since G âŠ‚ P (J) is maximal t-intersecting, there exists
A âˆˆ G such that
 |A âˆ© B| < t. By averaging, there exists C âŠ‚ [n] \J with |C| = t âˆ’ 1 âˆ’ |A âˆ© B|
BâˆªC â‰¥ Âµ F B = Î´. Note that F AâˆªC and F BâˆªC are cross-intersecting, otherwise F
and Âµ FJâˆªC
J
JâˆªC
JâˆªC
would contain two sets whose intersection is of size t âˆ’ 1. Note also that
nâˆ’j 



kâˆ’|A|
AâˆªC
1 âˆ’ Âµ FJâˆªC
â‰¤ nâˆ’jâˆ’|C|  1 âˆ’ Âµ FJA = Ot,Î¶,j 1 âˆ’ Âµ FJA = Ot,Î¶,j (Ç«) .
kâˆ’|A|âˆ’|C|

AâˆªC and F BâˆªC .
The claim now follows by applying Lemma 2.18 to FJâˆªC
JâˆªC
P
Since Âµ(F) = BâŠ‚J Âµ(n,k,J)(B)Âµ(FJB ), and since Âµ(n,k,J)(B) = â„¦Î¶,j (1) for all B âŠ‚ J (provided n is sufficiently large depending on Î¶ and j), we have

Âµ (F) â‰¤ Âµ (hGi) + Î´ âˆ’ â„¦t,Î¶,j (Ç«) .
Therefore, by Claim 5.4, we have
Âµ (F) â‰¤ Âµ (hGi) + Ot,Î¶,j (Ç«c ) âˆ’ â„¦t,Î¶,j (Ç«)
for some c > 1. Provided Ç«0 is sufficiently small (depending on t, Î¶ and j), this implies that
either Âµ (F) < Âµ (hGi) or F = hGi, proving the lemma.
We may now prove Theorem 1.5.
Proof of Theorem 1.5. Given Î¶ > 0 and t âˆˆ N, we choose j = j (t, Î¶) âˆˆ N as in Theorem
5.2, we choose Ç«0 = Ç«0 (t, Î¶, j) > 0 as in Lemma 5.3, and we let Ç«1 = Ç«1 (Ç«0 , Î¶, j) > 0 and
n0 = n0 (t, Î¶) âˆˆ N to be chosen later.

Let n â‰¥ n0 , let Î¶n â‰¤ k â‰¤ (1/2 âˆ’ Î¶)n, let A âŠ‚ [n]
k be a family that does not contain two
sets whose intersection is of size t âˆ’ 1, and suppose that |A| â‰¥ f (n, k, t). We will show that A
is a Frankl family. By Theorem 5.2, provided n0 is sufficiently large depending on t, Î¶ and Ç«1 ,
there exists a Frankl family F such that F is a j-junta, and
Âµ (A\F) < Ç«1 .
35

Let J âˆˆ

[n]
j

and let G âŠ‚ P(J) such that F = hGi. For any B âˆˆ G, we have
Âµ(n,k,J) (B) 1 âˆ’ Âµ AB
J



â‰¤ Âµ(F\A) â‰¤ Âµ (A\F) < Ç«1 .

Provided n is sufficiently large depending on Î¶ and j, we have Âµ(n,k,J)(B) = â„¦Î¶,j (1) for all B âŠ‚ J.

Hence, provided Ç«1 is sufficiently small depending on Ç«0 , Î¶ and j, we have Âµ AB
J > 1 âˆ’ Ç«0 for
all B âˆˆ G. Therefore, by Lemma 5.3, provided n0 is sufficiently large depending on t, Î¶ and j,
we have Âµ(A) â‰¤ Âµ(F), with equality only if A = F, proving the theorem.

6

Conclusion and open problems

For fixed t âˆˆ N, the results in this paper, combined with the previous results mentioned in the
Introduction, resolve the ErdoÌ‹s-SoÌs problem (i.e., Problem 1.3) for 2t â‰¤ k â‰¤ (1/2âˆ’o(1))n. However, the problem remains unsolved for k/n very close to 1/2. We believe that new techniques
will be required to tackle the case where k/n â‰ˆ 1/2.
It would also be interesting to determine the optimal dependence of j = j(Î¶, Î´, h, Ç«) on Î¶, Î´, h
and Ç«, in Theorem 1.7. As stated above, our proof gives j â‰¤ 2 â†‘â†‘ 1/(Î¶ O(h) Î´2 Ç«).
Acknowledgements
We are grateful to Gil Kalai for several helpful discussions, and to Yuval Filmus for suggesting
a more elegant way of presenting the proof of Theorem 1.10, one which we have adopted.

References
[1] R. Ahlswede and L. H. Khachatrian, The complete nontrivial-intersection theorem for
systems of finite sets, J. Combin. Theory, Ser. A 76 (1996), pp. 121â€“138.
[2] R. Ahlswede and L. H. Khachatrian, The complete intersection theorem for systems of
finite sets, European J. Combin. 18 (1997), pp. 125â€“136.
[3] R. P. Anstee and P. Keevash, Pairwise intersections and forbidden configurations, European
J. Combin. 27 (2006), pp. 1235â€“1248.
[4] J. Balogh, B. Bollobas, and B. Narayanan, Transference for the ErdoÌ‹s-Ko-Rado theorem,
Forum of Mathematics, Sigma 3 (2015), e23.
[5] J. Balogh and D. Mubayi, A new short proof of a theorem of Ahlswede and Khachatrian,
J. Combin. Theory, Ser. A 115 (2008), pp. 326â€“330.
[6] B. Bollobas, B. Narayanan, and A. Raigorodskii, On the stability of the ErdoÌ‹s-Ko-Rado
theorem, J. Combin. Theory, Ser. A 137 (2016), pp. 64â€“78.
[7] D. Conlon and J. Fox, Bounds for graph regularity and removal lemmas, Geom. Funct.
Anal. 22 (2012), pp. 1191â€“1256.
[8] P. Devlin and J. Kahn, On â€˜stabilityâ€™ in the ErdoÌ‹s-Ko-Rado theorem, SIAM J. Disc. Math.
30(2) (2016), pp. 1283-1289.
[9] M. Deza and P. Frankl, ErdoÌ‹s-Ko-Rado theorem â€“ 22 years later, SIAM J. Alg. Disc. Meth.
4 (1983), pp. 419â€“431.
36

[10] I. Dinur and E. Friedgut, Intersecting families are essentially contained in juntas, Combin.
Probab. Comput. 18 (2009), pp. 107â€“122.
[11] I. Dinur and S. Safra, On the hardness of approximating minimum vertex-cover, Ann.
Math. 162 (2005), pp. 439â€“485.
[12] D. Ellis, N. Keller, and N. Lifshitz, Stability versions of ErdoÌ‹s-Ko-Rado type theorems,
via isoperimetry, preprint, 2016. arXiv:1604.02160.
[13] P. ErdoÌ‹s, Problems and results in graph theory and combinatorial analysis, Proc. 5th
British Combinatorial Conference (1975), pp. 169â€“192.
[14] P. ErdoÌ‹s, C. Ko, and R. Rado, Intersection theorems for systems of finite sets, Quart. J.
Math. Oxford, Second Series, 12, pp.313â€“320, 1961.
[15] Y. Filmus, The weighted complete intersection theorem, J. Combin. Th. Ser. A 151 (2017),
pp. 84-101.
[16] J. Fox, A new proof of the graph removal lemma, Ann. Math. 174 (2011), pp. 561â€“579.
[17] P. Frankl, ErdoÌ‹s-Ko-Rado theorem with conditions on the maximal degree, J. Combin.
Theory, Ser. A 46 (1987), pp. 252â€“263.
[18] P. Frankl, The ErdoÌ‹s-Ko-Rado Theorem is true for n = ckt, Coll. Soc. Math. J. Bolyai 11
(1978), pp. 365â€“375.
[19] P. Frankl, The shifting technique in extremal set theory, in: Surveys in Combinatorics,
Lond. Math. Soc. Lect. Note Ser. 123 (1987), pp. 81â€“110.
[20] P. Frankl and Z. FuÌˆredi, Forbidding just one intersection, J. Combin. Theory, Ser. A 39
(1985), pp. 160â€“176.
[21] P. Frankl and N. Tokushige, An invitation to intersection problems for finite sets, J. Combin. Theory, Ser. A 144 (2016), pp. 157â€“211.
[22] E. Friedgut, Boolean functions with low average sensitivity depend on few coordinates,
Combinatorica 18 (1998), no. 1, pp. 27â€“35.
[23] E. Friedgut, On the measure of intersecting families, uniqueness and stability, Combinatorica 28 (2008), pp. 503â€“528.
[24] E. Friedgut and O. Regev, Kneser graphs are like Swiss cheese, Disc. Analysis 2018:2,
arXiv:1702.04073.
[25] A. Frieze and R. Kannan, Quick approximation to matrices and applications, Combinatorica 19 (1999), pp. 175â€“220.
[26] W. T. Gowers, Hypergraph regularity and the multidimensional SzemereÌdi theorem, Ann.
Math. 166 (2007), pp. 897â€“946.
[27] W. T. Gowers, Lower bounds of tower type for SzemereÌdis uniformity lemma, Geom. Funct.
Anal. 7 (1997), pp. 322â€“337.
[28] B. Green, A SzemereÌdi-type lemma in Abelian groups, with applications. Geom. Funct.
Anal. 15 (2005), pp. 340â€“376.
37

[29] G. R. G. Grimmett, Percolation (1st edition), Springer-Verlag, 1989.
[30] A. J. W. Hilton and E. C. Milner, Some intersection theorems for systems of finite sets,
Quart. J. Math. Oxford 18 (1967), pp. 369â€“384.
[31] C. Jones, A noisy-influence regularity lemma for Boolean functions, preprint, October
2016. arXiv:1610.06950.
[32] J. Kahn, G. Kalai, and N. Linial, The Influence of Variables on Boolean Functions, Proc.
29th Annual Symposium on the Foundations of Computer Science, pp. 68â€“80, Computer
Society Press, 1988.
[33] J. Kahn and G. Kalai, Thresholds and expectation thresholds, Combin. Probab. Comput.
16 (2007), pp. 495â€“502.
[34] G. Kalai and M. Safra, Threshold phenomena and influence, in: Computational Complexity
and Statistical Physics, (A.G. Percus, G. Istrate and C. Moore, eds.), Oxford University
Press, New York, 2006, pp. 25â€“60.
[35] G. O. H. Katona, A theorem of finite sets, in: Proceedings of Tihany Conference, 1966,
pp. 187â€“207.
[36] P. Keevash, Shadows and intersections: Stability and new proofs, Adv. Math. 218 (2008),
pp. 1685â€“1703.
[37] P. Keevash and D. Mubayi, Set systems without a simplex or a cluster, Combinatorica, 30
(2010), pp. 175â€“200.
[38] P. Keevash, D. Mubayi and R. Wilson, Set systems with no singleton intersection, SIAM
J. Discrete Math. 20 (2006), pp. 1031â€“1041.
[39] N. Keller and N. Lifshitz, The Junta Method for Hypergraphs, and ChvaÌtalâ€™s Simplex
Conjecture, preprint, July 2017. arXiv:1707.02643
[40] D. J. Kleitman, On a conjecture of Milner on K-graphs with non-disjoint edges, J. Combin.
Theory 5 (1968), pp. 153â€“156.
[41] J. B. Kruskal, The number of simplices in a complex, in Mathematical Optimization Techniques, Univ. California Press, Berkeley, 1963, pp. 251â€“278.
[42] G. A. Margulis, Probabilistic characteristics of graphs with large connectivity, Problems
Info. Transmission 10 (1977), pp. 174â€“179.
[43] E. Mossel, Gaussian bounds for noise correlation of resilient functions, preprint, April 2017.
arXiv:1704.04745.
[44] D. Mubayi and J. VerstraeÌˆte, A survey on TuraÌn problems for expansions, Recent Trends
in Combinatorics (IMA volume 159), pp. 117â€“143, 2016.
[45] B. Nagle, V. RoÌˆdl and M. Schacht, The counting lemma for regular k-uniform hypergraphs,
Random Structures and Algorithms 28 (2006), pp. 113â€“179.
[46] R. Oâ€™Donnell, Analysis of Boolean functions, Cambridge University Press, 2014.

38

[47] V. RoÌˆdl and J. Skokan, Regularity lemma for k-uniform hypergraphs, Random Structures
and Algorithms 25 (2004), pp. 1â€“42.
[48] E. SzemereÌdi, Regular partitions of graphs, ProbleÌ€mes combinatoires et theÌorie des graphes,
Colloq. Internat. CNRS, Univ. Orsay, Orsay, 1976.
[49] L. Russo, An approximate zero-one law, Z. Wahrsch. Verw. Gebiete 61 (1982), pp. 129â€“
139.
[50] R.M. Wilson, The exact bound in the ErdoÌ‹s-Ko-Rado theorem, Combinatorica 4 (1984),
pp. 247â€“257.

39

