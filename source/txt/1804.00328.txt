arXiv:1804.00328v2 [math.CO] 21 Sep 2018

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD
THEOREMS
NOAM LIFSHITZ
Abstract. The classical sharp threshold theorem of Friedgut and Kalai (1996) asserts that any
symmetric monotone function f : {0, 1}n â†’ {0, 1} exhibits a sharp threshold phenomenon. This
means that the expectation of f with respect to the biased measure Âµp increases rapidly from 0 to
1 as p increases.
In this paper we present â€˜robustâ€™ versions of the theorem, which assert that it holds also if the
function is â€˜almostâ€™ monotone, and admits a much weaker notion of symmetry. Unlike the original
proof of the theorem which relies on hypercontractivity, our proof relies on a â€˜regularityâ€™ lemma (of
the class of SzemerÃ©diâ€™s regularity lemma and its generalizations) and on the â€˜invariance principleâ€™
of Mossel, Oâ€™Donnell, and Oleszkiewicz which allows (under certain conditions) replacing functions
on the cube {0, 1}n with functions on Gaussian random variables.
The hypergraph removal lemma of Gowers (2007) and independently of Nagle, RÃ¶dl, Schacht,
and Skokan (2006) says that if a k-uniform hypergraph on n vertices contains few copies of a ï¬xed
hypergraph H, then it can be made H-free by removing few of its edges. While this settles the
â€˜hypergraph removal problemâ€™ in the case where k and H are ï¬xed, the result is meaningless when
k is large (e.g. k > log log log n).
Using our robust version of the Friedgutâ€“Kalai Theorem, we obtain a hypergraph removal lemma
that holds for k up to linear in n for a large class of hypergraphs. These contain all the hypergraphs
such that both their number of edges and the sizes of the intersections of pairs of their edges are
upper bounded by some constant.

1. Introduction

1.1. Problems on H-free families. For any set V we use Vk to denote the family of all subsets

of V of size k. Any H âŠ† Vk is called a k-uniform hypergraph or a k-uniform family on the vertex
set V , and the elements of H are its edges. We write [n] for the set {1, . . . , n} .

The celebrated Mantelâ€™s Theorem [47] from 1907 says that the largest triangle free graph G âŠ† [n]
2
is the balanced complete bipartite graph. In 1941, TurÃ¡n [62] generalized Mantelâ€™s Theorem from
triangles to cliques. He raised the following problem known as the TurÃ¡n problem for hypergraphs.

Problem 1.1. Given a hypergraph H âŠ† Vk , determine the value ex (n, H) of the largest H-free

family in [n]
k .

An H-free family of size ex (n, H) is called an extremal H-free family. The TurÃ¡n problem is one
of the most prominent problems in extremal combinatorics, and it includes many of the well studied
problems in this area. (See the excellent survey of Keevash [41], and the more recent survey of Mubayi
and VerstraÃ«te [51].) One example, is the classical ErdÅ‘s-Ko-Rado Theorem (EKR Theorem) [21]

from 1961, which determines the largest size of a family F âŠ† [n]
such that each two of its edges
k

have nonempty intersection. It can be rephrased by saying that ex (n, M2 ) = nâˆ’1
kâˆ’1 for any n â‰¥ 2k,
where M2 is the k-uniform hypergraph that consists of two disjoint edges.
1

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

2

Another well-studied set of TurÃ¡n problems is the Forbidden intersection problem of ErdÅ‘s and
SÃ³s [20] from 1975. It concerns determining ex (n, H) in the case where the forbidden hypergraph H
consists of two edges with a given intersection, (see [18, 25, 28, 30, 42]).
Besides the TurÃ¡n problem for hypergraphs of determining ex (n, H) for various hypergraphs H,
the research of H-free families in recent years concentrated on the following types of problems.

(1) 0.99-type stability results. Suppose that F is a nearly extremal H-free family in the sense
that its size is close to ex (n, H). Can we say that F is close to an H-free family? (See e.g.
[26, 60]).
(2) 0.01-type stability results. What is the structure of an H-free family whose size is within
a constant of ex (n, H)? (See [15, 34]).
(3) The removal problem. Suppose that F is a family that is almost H-free, in the sense
that it contains few copies of H. Is it true that F is close to an H-free family? (See e.g.
[37, 52, 54, 56]).
(4) The counting problem. How many H-free families are there? Particularly, is it true that
almost all of them are contained in an extremal H-free family? (See e.g. [57, 58].

(5) The random problem. Let p âˆˆ (0, 1), and let [n]
k p be the random family that contains

each set in [n]
k independently with probability p. What is the size of the largest H-free
subfamily of [n]
k p ? (See e.g. [12, 59]).

In this paper our main focus will be on solving the 0.01-type stability problem and the removal
problem for a large class of hypergraphs called expanded hypergraphs. These are the hypergraphs in
which both the number of edges and the intersections of pairs of the edges are bounded by a constant.
While we shall not address the counting problem and the random problem in this paper, we would
like to note that the container method of Balogh, Morris, and Samotij [4], and independently of
Saxton and Thomason [58], essentially reduces the solutions of the counting problem and the random
problem to the solutions of the 0.99-type stability problem and the removal problem. Therefore, our
work should be viewed as progress towards all of the above problems.
Our results are based on a novel theorem about the sharp threshold of â€˜almost monotoneâ€™ Boolean
functions in the discrete cube, whose proof uses the invariance principle of Mossel, Oâ€™Donnell, and
Oleszkiewicz [50]. We believe that the connection we establish between sharp threshold phenomena
of Boolean functions and the removal problem is the main contribution of this paper.
1.2. The structure of large families that are free from an expanded hypergraphs.
Definition 1.2. A hypergraph is said to be (h, d)-expanded if it has at most h edges and the
intersection of each two of its edges is of size at most d.
The hypergraph M2 is an example of a (2, 0)-expanded hypergraph, and hypergraphs that are
(h, 1)-expanded for some h are known as linear hypergraphs. Generally speaking, we shall be concerned with k-uniform (h, d)-expanded hypergraphs, where h and d are ï¬xed, and where k is signiï¬cantly larger.
Our terminology stems from the following standard deï¬nition, (see Mubayi and VerstraÃ«te [51]).
Definition 1.3. Let H be a hypergraph. The k-expansion of H is the k-uniform hypergraph H+
obtained from H by enlarging each of its edges with distinct new vertices. We denote by exk (n, H+ )

the problem of determining the largest size of a family F âŠ† [n]
free of the k-expansion of H.
k

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

3

Note that the k-expansion of a d-uniform hypergraph with h edges is (h, d)-expanded. Conversely,
any (h, d)-expanded hypergraph can be easily seen to be the k-expansion of some d (h âˆ’ 1)-uniform
hypergraph.
Many problems in extremal combinatorics can be expressed as determining exk (n, H+ ) for a ï¬xed
hypergraph H (see e.g. [29, 35, 44, 27], and the survey of Mubayi and VerstraÃ«te [51] for the case
where H is a graph). The methods used for attacking such problems are varied. One of the most
successful methods is the delta-system method of ErdÅ‘s, Deza, and Frankl [14]. This method was
applied by Frankl and FÃ¼redi [25, 28, 29] to solve various TurÃ¡n problems for expanded hypergraphs
(including the case where H is a special simplex, a sunï¬‚ower, or the hypergraph that consist of two
edges with some intersection of a ï¬xed size). This allowed them to make signiï¬cant progress on
several longstanding open problems in extremal combinatorics.
Another notable technique is the shifting technique of ErdÅ‘s, Ko, and Rado [21]. This technique
was applied, e.g., in a recent breakthrough of Frankl [27]. He gave the best bound for the ErdÅ‘s

Matching Conjecture [19], which asks to determine exk (n, Ms+ ) , where Ms âŠ† [n]
is a matching of
2
size s. Other methods include the ErdÅ‘s-Simonovits stability method [60], and the random sampling
from the shadow method of Kostochka, Mubayi, and VerstraÃ«te (see [44, 45, 46]).
Recently, a new approach towards the TurÃ¡n problem for expansion was initiated be Keller and
the author [43] and further developed by Ellis, Keller, and the author [18].

Definition 1.4. A family F âŠ† [n]
is said to depend on the set of coordinates J if for each sets
k

A, B âˆˆ [n]
that
satisfy
A
âˆ©
J
=
B
âˆ©
J we have A âˆˆ F â‡â‡’ B âˆˆ F . A family F is said to be a
k
j-junta if it depends on a set J of size at most j. We say that a family F1 is Ç«-essentially contained
in F2 if
 
n
|F1 \F2 | â‰¤ Ç«
.
k
The notion junta was introduced by Friedgut [31] while studying the isoperimetric problem in
discrete cube. Dinur and Friedgut [15] were the ï¬rst to use this notion in the study of k-uniform
set-systems. They showed the following.
Theorem 1.5 (Dinurâ€“Friedgut [15]). For each r âˆˆ N, there exist C > 0, j âˆˆ N, such that any
r

intersecting family F âŠ† [n]
is C nk -essentially contained in an intersecting j-junta.
k

Note that the theorem is trivial for nk = Î˜ (1) , while it is meaningful once nk is suï¬ƒciently small.
Inspired by [15], Keller and the author [43] extended Theorem 1.5 to show that for each h, r there
r

exist C > 0, j âˆˆ N, such that any Mh+ -free family F âŠ† [n]
is C nk -essentially contained in an
k
Mh+ -free j-junta, and obtained the following result for general expanded hypergraphs.

Theorem 1.6 ([43]). For each Ç« > 0, h, d âˆˆ N, there exist C > 0, j âˆˆ N, such that the following
n
holds. Let C < k < C
, and let H be a k-uniform (h, d)-expanded hypergraph. Then any H-free family

[n]
F âŠ† k is Ç«-essentially contained in an H-free j-junta.

Theorem 1.6 serves as the ï¬rst step in the following strategy for determining ex (n, H) .
(1) Show that any H-free family is essentially contained in an H-free junta J .
(2) Find the extremal junta Jex that is free of H.
(3) Show that if an H-free junta has size that is close to |Jex |, then it must be a small perturbation
of Jex .
(4) Show that any H-free small perturbation of Jex must have smaller size than it.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

4

These four steps together suï¬ƒce in order to show that the extremal junta is the family Jex . Indeed,
if F is the extremal H-free family, then Step 1 implies that F is essentially contained in an H-free
junta J . The fact that F is of the extremal size implies that the size of J cannot be much smaller
than the size of Jex . Step 3 implies that F is essentially contained in Jex , and Step 4 implies that F
is actually equal to Jex .
This strategy was successfully carried out in [43] to solve the TurÃ¡n problem for various (h, d)n
for some C = C (h, d) .
expanded hypergraphs, in the regime where C < k < C
Later, [18] showed that
this
strategy
can
be
carried
out
also for some hypergraphs in the regime

where Ç«n < k < 12 âˆ’ Ç« n for an arbitrarily small constant Ç«, and a suï¬ƒciently large n. Speciï¬cally,
they considered the case where the forbidden hypergraph H is I2,d that consists of two edges that
intersect in d elements.
Their basic observation was that any junta that does not contain a copy of I2,d must be free of
I2,dâ€² for any dâ€² < d as well. In other words, any two sets in an I2,d -free junta have intersection
of size at least d + 1. This essentially reduces the problem to the well known problem on the size
of (d + 1)-wise intersecting families, which was solved decades ago using the shifting technique (see
Ahlswedeâ€“Khachatrian [3], Filmus [22], and Frankl [24]).
It is our belief that this strategy may be carried out for various other (h, d)-expanded hypergraphs,
and that the following result we prove in this paper will serve as the ï¬rst step in the
 solution of the
TurÃ¡n problem for various other hypergraphs in the regime where Ç«n < k â‰¤ h1 âˆ’ Ç« n.
Theorem 1.7. For
 each Ç« > 0, d, h âˆˆ N, there exists j > 0, such that the following holds. Let
is
Ç«n â‰¤ k â‰¤ h1 âˆ’ Ç« n, and let H be an (h, d)-expanded hypergraph. Then any H-free F âŠ† [n]
k
Ç«-essentially contained in an H-free j-junta.

The special case of Theorem 1.7 where H = M2+ = M2 was already proved recently by Friedgut
and Regev [34] who built upon the work of Dinur and Friedgut [15]. Other special cases of Theorem
1.7 were proved in [18], which settles the case h = 2 of the theorem.
Theorem 1.7 is actually a special case of our main Theorem 1.13 below, which deals also with
families that contain few copies of H, rather than dealing only with H-free families.
Similarly to the case where H = I2,d , it turns out that it is a general phenomenon that H-free
juntas are automatically free of some other hypergraphs.
Definition 1.8. Let H be a hypergraph and let v be a vertex of H. The resolution of H at v, denoted
by res (H, v), is the hypergraph obtained from H by taking v out of each edge of H that contains v,
and by replacing it with a new vertex that belongs only to this edge. The resolution of H at a set of
vertices S, denoted by res (H, S), is the hypergraph obtained by resolving H at the vertices of S one
after the other. Any hypergraph of the form res (H, S) will be called a resolution of H.
Example 1.9. Any hypergraph H is a resolution of itself since res (H, âˆ…) = H. Deï¬ning the center
of a hypergraph H to be the set of its vertices that belong to at least two of its edges, the k-uniform
h-matching Mh := Mh+ is the resolution of any k-uniform hypergraph with h edges at its center.
Another simple example is the hypergraph I2,d : its resolutions are the hypergraphs of the form I2,dâ€²
for dâ€² â‰¤ d.

that is free of a hypergraph H with h edges is also
It is easy to show that any j-junta G âŠ† [n]
k
free of every resolution of H, provided that C < k â‰¤ h1 âˆ’ Ç« n and n is large enough. Hence, in order
to show that a given junta J is an extremal H-free family, it would essentially be enough to show
that it is the extremal family that is free of a copy of H as well as of all of its resolutions.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

5

1.3. Removal lemma for expanded hypergraphs. While Theorem 1.7 tells us the structure of
H-free families it tells us nothing on families that are â€˜almost H-freeâ€™, a notion that may be deï¬ned
more precisely as follows.

Definition 1.10. Let Î´ > 0 and let H be a k-uniform hypergraph. We say that a family F âŠ† [n]
k

is Î´-almost H-free if a random copy of H in [n]
lies within F with probability at most Î´.
k

The celebrated triangle removal lemma says that for any Ç« > 0, there exists Î´ > 0, such that any
Î´-almost triangle-free graph is Ç«-essentially contained in a triangle-free graph. This was generalized
by Gowers [36, 37], and independently by Nagle, RÃ¶dl, Schacht, and Skokan [52, 54] to show that

for each ï¬xed k-uniform hypergraph H, there exists Ç« > 0, such that if a family F âŠ† [n]
is Î´k
almost H-free, then F is Ç«-essentially contained in an H-free family. This result is known as the
hypergraph removal lemma. (See the survey of Conlon and Fox [11] for a more thorough history, and
for quantitative aspects of removal lemmas.)
While the hypergraph removal lemma settles the case where k, H, and Ç« are ï¬xed, it becomes
quite useless for k that tends to inï¬nity with n. Indeed, the initial dependence of Î´ on Ç« in the graph
case where k = 2 was
2
.
âˆ’1


..
âˆ’OH (1)
2
Î´ = tower Ç«
=
|2 {z } ,
Ç«âˆ’OH (1) times

1
Ç«

âˆ’1

. For k = 3 the best known bound is
and this was improved by Fox [23] to tower OH log
âˆ’1
Î´ = tower (tower Â· Â· Â· (2)) , and the bounds similarly worsen as k increases (see [61, Remark 2.11]).
{z
}
|
Ç«âˆ’OH (1) times

Friedgut and Regev [34] were the ï¬rst to prove a removal lemma in the case where k is linear in n.


They showed that for each Ç« > 0 there exists Î´ > 0, such that if Ç«n â‰¤ k â‰¤ 21 âˆ’ Ç« n, and if F âŠ† [n]
k
is a Î´-almost M2 -free family, then F is Ç«-essentially cxontained in an M2 -free family. Later, Das
+
and Tran [13] proved
 a quantitatively stronger removal result for Î´-almost M2 -free families whose
nâˆ’1
size is close to kâˆ’1 .
At ï¬rst glance it may seem that the Friedgutâ€“Regev Theorem follows from the hypergraph removal
lemma, but it actually does not. While the hypergraph removal lemma deals with the case where k
and the hypergraph H are ï¬xed, the Friedgutâ€“Regev theorem deals with the case where k is linear in
n. Our goal in this paper it to prove removal lemmas for other expanded hypergraphs in the regime
where k is up to linear in n.
In light of Theorem 1.7, it may seem the Friedgutâ€“Regev Theorem can be generalized to all
(h, d)-expanded hypergraphs. However, we show that the following surprising statement holds.
Theorem 1.11.
 For each h, d âˆˆ N, Ç« > 0 there exists C, Î´ > 0 such that the following holds. Let
C â‰¤ k â‰¤ h1 âˆ’ Ç« n, and let H be a k-uniform (h, d)-expanded hypergraph, then we have the following.
(1) If the family F is Î´-almost H-free, then F is Ç«-essentially contained in an Mh -free family.
(2) Conversely, if the family F is Î´-essentially contained in an Mh -free family, then F is Ç«-almost
H-free.
So suppose that F is a family that we want to check whether it is H-free or not. One natural way
to check if F is H-free is to choose uniformly at random copies of H, and to check that none of them
are contained in F . While we could expect that this would tell us that F is close to some H-free
family, we instead obtain from Theorem 1.11 that this implies that F is close to a family that is free
of the hypergraph Mh . Even more surprisingly, also the converse holds. Any family that is close to

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

6

an Mh -free family contains few copies of H. This phenomenon becomes clearer by inspecting the
following example.
n
o
[n] 
Example 1.12. The star A âˆˆ n/3
: 1 âˆˆ A is o (1)-almost free of the hypergraph I2,1 , which

consists of two edges that intersect in a singleton {i}. Indeed, the probability that a random copy
of this hypergraph lies in the star is n1 , as it is the probability that a random injection from the
vertices of I2,1 to [n] sends the vertex i to 1. As Theorem 1.11 guarantees, the star is o (1)-essentially
contained in an M2 -free family as it is in itself M2 -free. However, the star is not o (1)-essentially
contained in any family free of the hypergraph I2,1 .
More generally, suppose that G is a j-junta depending on a set J and that H is an (h, d)-expanded
hypergraph. Then the center of a random copy of H most likely does not intersect J. So from the
â€˜point of viewâ€™ of the junta G, a random copy of H and a random copy of Mh look the same. It is
therefore easy to see that
Pr [a random copy of H lies in G] = Pr [a random copy of Mh lies in G] + o (1) .

Let F âŠ† [n]
k , and let H be a hypergraph. We say that F is (H, s)-free if it is free of any resolution
of H whose center is of size at most s. While Example 1.12 shows that being o (1)-almost free of H
is not suï¬ƒcient for guaranteeing closeness to an H-free family, the following theorem shows that a
stronger assumption is suï¬ƒcient.
Theorem 1.13. For each h, d, s âˆˆ N, Ç« > 0 there exist Î´ > 0,j âˆˆ N, such that the following holds.
Let H be an (h, d)-expanded hypergraph. Let 1Î´ â‰¤ k â‰¤ h1 âˆ’ Ç« n, and let F be a nÎ´s -almost H-free
family. Then F is Ç«-essentially contained in an (H, s)-free j-junta.
Note that Theorem 1.7 is a special case of Theorem 1.13. Indeed, Theorem 1.13 implies that if H
is a hypergraph whose center is of size c, then any nÎ´c -almost H-free family is Ç«-essentially contained
in an (H, c)-free family, i.e. to a family free of H and of any resolution of it. On the other hand,
Theorem 1.7 yields the same conclusion under the stronger hypothesis that F is H-free.
The following
proposition is a converse to Theorem 1.13. It shows that any (H, s)-free j-juntas is

1
O ns+1 -almost H-free. So in particular, j-juntas are nÎ´s -almost H-free, provided that n is suï¬ƒciently
large as a function of Î´.
Proposition 1.14. For each h, c, j, s âˆˆ N, there exists a constant C > 0, such that the
 following
holds. Let H be a hypergraph with h edges whose center is of size c. Let C â‰¤ k â‰¤ h1 âˆ’ Ç« n, and let
C
J be an (H, s)-free j-junta. Then J is ns+1
-almost H-free.
1.4. Sketch of Proof of Theorem 1.13 for matching. We shall now sketch the proof of Theorem
1.13 in the case where the forbidden hypergraph is Mh . The proof relies on the regularity method
and on a novel sharp threshold result for â€˜almost monotoneâ€™ Boolean functions that will be presented
in Section 2.
Let Ç« > 0, h âˆˆ N be ï¬xed constants, and let F be a family which is not Ç«-contained in any family
free of the matching Mh . Our goal is to show that a random matching lies in F with probability
Î˜ (1).
Note that any set J decomposes the sets in F into 2|J| parts according to their intersection with
J. Following Friedgut and Regev [34] and [18] we apply a regularity lemma which says that we may
ï¬nd a set J, such that in the decomposition of F induced by J, almost all of the parts are either
â€˜random-likeâ€™ or suï¬ƒciently small that we can ignore them. We may then take as our approximating

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

7

junta, the family

 

[n]
G= Aâˆˆ
: A âˆ© J corresponds to a random part of F .
k
The fact that F is not Ç«-essentially contained in an Mh -free family will allow us to show that G is
not Mh -free. This in turn will imply that there exist pairwise disjoints sets A1 , . . . , Ah âŠ† J that
correspond to random parts of F . Now note that a random matching {B 1 , . . . , B h } intersects the set
J in the sets A1 , . . . , Ah with probability Î˜ (1). So the remaining task is to show that if F1 , . . . , Fh
are â€˜random-likeâ€™ parts, then a random matching A1 , . . . , Ah satisï¬es Ai âˆˆ Fi with probability Î˜ (1).
We will accomplish this task using an enhancement of the â€˜sharp threshold technologyâ€™ presented by
Dinur and Friedgut [15]. Let us recall ï¬rst the method in [15]. We say that families F1 , . . . , Fh are
cross free of a matching if there exist no pairwise disjoint sets A1 , . . . , Ah such that Ai âˆˆ Fi for each
i, otherwise they cross-contain a matching.
The p-biased distribution on P ([n]) is a probability distribution on sets A âŠ† [n], where each
element is chosen to be in A independently with probability p. For a family G, write Âµp (G) for
PrAâˆ¼Âµp [A âˆˆ G] . A family F âŠ† P ([n]) is monotone if B âˆˆ F whenever B âŠ‡ A for some A âˆˆ F . The
â€˜sharp threshold principleâ€™ essentially says that for a random-like monotone family F the p-biased
measure of F jumps from being near 0 to being near 1 in a short interval.
Roughly speaking, the analogue of the strategy in [18] for the hypergraph Mh goes as follows.
h

(1) Observe that if {Fi }i=1 are cross-free of a matching, then their up-closures
n
oh
Fiâ†‘ := {B : âˆƒA âŠ† B such that A âˆˆ F }
i=1

are also cross-free of a matching (in the sense that there are no pairwise disjoint sets
A1 , . . . , Ah with Ai âˆˆ Fiâ†‘ ).
 
(2) Use a simple coupling argument to show that if Âµ h1 Fiâ†‘ > 1 âˆ’ h1 for each i, then the families

F1â†‘ , . . . , Fhâ†‘ cross-contain a matching. So in particular, the families F1 , . . . , Fh cross contain
a matching.
(3) Show that the families Fiâ†‘ are random-like monotone families whose Âµ k measure is bounded
n
 
away from 0. The sharp threshold principle will allow us to deduce that Âµ h1 Fiâ†‘ is close to
h

1, so by Step 2 the families {Fi }i=1 cannot be cross free of a matching.

This plan fails completely when we try to show the desired statement that random-like families
contain many matchings. The step which stops to work
is the ï¬rst one. While it is true that if {Fi }
n o
â†‘
are cross free of a matching, then their up closures Fi are cross-free of a matching, it is not true
that if {Fi }-are almost cross free of a matching (in the sense that they cross contain few matchings),
then the families Fiâ†‘ are also almost cross free of a matching. We resolve this issue by replacing the
up-closure of F by the family
{A âˆˆ P ([n]) : |A| â‰¥ k and a random k-subset of A lies in F with probability Î˜ (1)} .
However, this new family is not monotone, and instead it satisï¬es a weaker hypothesis that may be
called â€˜almost monotonicityâ€™.
So to make the above plan work, we shall need to generalize the sharp threshold principle from
monotone families to â€˜almost monotoneâ€™ families. This statement is made more precise in Section 2.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

8

It is accomplished with the help of the invariance principle of Mossel, Oâ€™Donnell, and Oleszkiewicz
[50].
In our view, the main contribution of this paper comes from the fact that we relate between
sharp threshold results and hypergraph removal problems. We believe that further exploration of the
relation between these two well studied problems will improve the understanding of each of them.
In the following section we give a more thorough introduction of the sharp threshold principle
of monotone Boolean functions, and state our sharp threshold result for almost monotone Boolean
functions. (Note that Boolean functions f : {0, 1}n â†’ {0, 1}, and families F âŠ† P ([n]) can be
identiï¬ed).
2. Sharp threshold theorems for almost monotone functions
We use bold letters to denote random variables, and we write [n] for the set {1, . . . , n} . We
n
shall use the convention that the ith coordinate of an x âˆˆ {0, 1} is denoted by xi . A function
n
n
f : {0, 1} â†’ R is said to be monotone if f (x) â‰¤ f (y) whenever x, y are elements of {0, 1} that
satisfy âˆ€i âˆˆ [n] : xi â‰¤ yi . The p-biased distribution Âµp is the distribution on the set {0, 1}n ,
where a random element x âˆ¼ Âµp is chosen by letting its coordinates xi to be independent random
n
variables that take the value 1 with probability p. For a function f : {0, 1} â†’ R, we write Âµp (f )
for Exâˆ¼Âµp [f (x)] .
n
It is easy to see that for any monotone function f : {0, 1} â†’ {0, 1}, the function p 7â†’ Âµp (f ) is
n
a monotone increasing function of p. Roughly speaking, a Boolean function f : {0, 1} â†’ {0, 1} is
said to have a sharp threshold if there exists a â€˜shortâ€™ interval [q, p], such that Âµq (f ) is â€˜closeâ€™ to 0,
and Âµp (f ) is â€˜closeâ€™ to 1. Otherwise, it is said to have a coarse threshold.
A central problem in the area of analysis of Boolean functions is the following (see e.g. [10, 32,
33, 39]).
n

Problem 2.1. Which monotone Boolean functions f : {0, 1} â†’ {0, 1} exhibit a coarse threshold?
n

We shall now make the above discussion more formal. For a non-constant monotone f : {0, 1} â†’
{0, 1}, the critical probability of f (denoted by pc (f )) is the unique number in the interval (0, 1),
such that Âµpc (f ) = 12 . BollobÃ¡s and Thomason [7] showed that for any ï¬xed Ç« > 0, and each Boolean
function f there exists an interval [q, p] with q, p = Î˜ (pc (f )) , such that Âµq (f ) < Ç«, and Âµp (f ) > 1âˆ’Ç«.
Therefore, f should be considered to have a sharp threshold if there exists an interval [q, p] of length
signiï¬cantly smaller than pc (f ), such that Âµq (f ) < Ç« and Âµp (f ) > 1 âˆ’ Ç«.
n
Formally, we say that a Boolean function f : {0, 1} â†’ {0, 1} exhibits an Ç«-sharp threshold if there
exists an interval [q, p] of length Ç«pc (fn ), such that Âµq (f ) < Ç« and Âµp (f ) > 1 âˆ’ Ç«. We say that f
exhibits an Ç«-coarse threshold if there exist an Ç« > 0, and an interval [q, p] of length at least Ç«pc (f ) ,
such that Âµq (fn ) > Ç«, and Âµp (fn ) < 1 âˆ’ Ç«.
n
A function f : {0, 1} â†’ {0, 1} is said to be transitive symmetric if the group of all permutations
Ïƒ âˆˆ Sn , such that

n
âˆ€x âˆˆ {0, 1} : f xÏƒ(1) , . . . , xÏƒ(n) â‰¡ f (x1 , . . . , xn )

acts transitively on {1, . . . , n} .
The Friedgutâ€“Kalai Theorem [33] says that if f is transitive symmetric and pc (f ) is bounded away
from 0 and 1, then f exhibits a sharp threshold.
Theorem 2.2 (Friedgutâ€“Kalai). For each Ç« > 0 there exists n0 = n0 (Ç«) such that the following
holds. Let n > n0 and let f : {0, 1}n â†’ {0, 1} be a monotone transitive symmetric function satisfying
Ç« < pc (f ) < 1 âˆ’ Ç«. Then f exhibits an Ç«-sharp threshold.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

9

On the other hand, f need not exhibit a coarse threshold if f is no longer assumed to be transitive
symmetric. Let j be a constant. A function f is said to be a j-junta if it depends on at most j
coordinates. It is easy to see that any non-constant monotone j-junta exhibits an Ç«-coarse threshold
for some constant Ç« = Ç« (j) > 0. A well known corollary of the celebrated Friedgutâ€™s Junta Theorem
[31] is a partial converse to this statement. We shall say that f is (Âµr , Ç«)-close to g if
Pr [f (x) 6= g (x)] < Ç«.

xâˆ¼Âµr

Theorem 2.3 (Corollary of Friedgutâ€™s Junta Theorem). For each Ç« > 0, there exists j âˆˆ N, such
n
that the following holds. Let f : {0, 1} â†’ {0, 1} be a Boolean function, and let q, p be numbers in
the interval (0, 1) that satisfy p > q + Ç«. Then there exists some r in the interval [q, p] , such that f
is (Âµr , Ç«)-close to a j-junta.
Note that Friedgutâ€™s Junta Theorem becomes trivial if Âµq (f ) < Ç« or if Âµp (f ) > 1 âˆ’ Ç« as in which
case we may take the junta to be the corresponding constant function. For that reason, Friedgutâ€™s
Junta Theorem can be interpreted by saying that non-junta like functions exhibit a sharp threshold
behavior.
2.1. Structural results on monotone families. We extend Theorems 2.2 and 2.3 in the following
directions.
â€¢ We replace the condition that f is monotone with the weaker condition that f satisï¬es a
notion we call (q, p, Î´)-almost monotonicity.
â€¢ We strengthen the Friedgutâ€“Kalai theorem by relaxing the condition that f is transitive
symmetric to the weaker condition that f satisï¬es a notion called (r, Î´, Âµq )-regularity.
â€¢ Bearing in mind our applications to the removal problem, we modify Theorem 2.3 by replacing
the condition that f is â€˜closeâ€™ to a junta with respect to the Âµr measure with a condition that
says that f is â€˜closeâ€™ to a junta in a sense that involves only the measures Âµp and Âµq , i.e. the
measures at the ends of the interval.
We shall now deï¬ne the above notions more precisely, starting with (q, p, Î´)-almost monotonicity.
Intuitively, a function f should be called â€˜almost monotoneâ€™ if f (x) â‰¤ f (y) for almost all values of x
and y that satisfy âˆ€i âˆˆ [n] : xi â‰¤ yi . However, there are many ways to interpret the notion â€˜almost
all values of x and yâ€™. For instance, the following deï¬nitions all seem to ï¬t equally well.
n
â€¢ Choose x uniformly out of {0, 1} and then choose y uniformly among the set of all the elen
ments y âˆˆ {0, 1} that satisfy âˆ€i : yi â‰¥ xi . Say that f is â€˜almost monotoneâ€™ if Pr [f (x) > f (y)]
is â€˜smallâ€™.
n
n
â€¢ First choose y uniformly out of {0, 1} , then choose x among the set of all x âˆˆ {0, 1} that
satisfy âˆ€i : xi â‰¤ yi , and say that f is â€˜almost monotoneâ€™ if Pr [f (x) > f (y)] is â€˜smallâ€™.
n
n
â€¢ Choose a uniformly random pair of elements x, y âˆˆ {0, 1} among the x, y âˆˆ {0, 1} that
satisfy âˆ€i : xi â‰¤ yi , and say that f is â€˜almost monotoneâ€™ if Pr [f (x) > f (y)] is â€˜smallâ€™.
Note that these notions are diï¬€erent. In the ï¬rst we have
3
1
Pr [xi = 1] = and Pr [yi = 1] = ,
2
4
in the second we have
1
1
Pr [xi = 1] = and Pr [yi = 1] = ,
4
2
and in the last we have
1
2
Pr [xi = 1] = and Pr [yi = 1] = .
3
3

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

10

All these notions are captured by the following framework.
Definition 2.4. Let q < p. The (q, p)-biased distribution, denoted by D (q, p), is the unique probability distribution on elements (x, y) âˆˆ {0, 1}n Ã— {0, 1}n that satisï¬es the following.
(1) The pairs (xi , yi ) are independent random variables.
(2) We have xi â‰¤ yi with probability 1.
(3) We have Pr [xi = 1] = q and Pr [yi = 1] = p.
We write x, y âˆ¼ D (q, p) to denote that they are chosen according to this distribution. We say that
n
f : {0, 1} â†’ {0, 1} is (q, p, Î´)-almost monotone if
Pr

x,yâˆ¼D(q,p)

[f (x) > f (y)] < Î´.

It will be convenient for us to deï¬ne the following notion of â€˜closenessâ€™ between a function f and
a function g that takes into considerations both the p-biased measure and the q-biased one. We
n
n
say that functions f, g : {0, 1} â†’ {0, 1} are (Âµq , Âµp , Ç«)-close if the set of all x âˆˆ {0, 1} such that
f (x) 6= g (x) can be partitioned into the union of two sets Sp and Sq , such that Âµp (Sp ) < Ç« and
Âµq (Sq ) < Ç«.
We give the following variant of Friedgutâ€™s junta theorem, which implies that if Ç«, q < p are ï¬xed
numbers in the interval (0, 1), if Î´ > 0 is small enough, and if j âˆˆ N is suï¬ƒciently large, then any
(q, p, Î´)-almost monotone function f is (Âµq , Âµp , Ç«)-close to a monotone j-junta.
Theorem 2.5. For each Ç« > 0, there exists j âˆˆ N, Î´ > 0, such that the following holds. Let p, q be
n
numbers in the interval (Ç«, 1 âˆ’ Ç«) that satisfy pâˆ’ q > Ç« and let f : {0, 1} â†’ {0, 1} be a (q, p, Î´)-almost
monotone function. Then there exists a monotone j-junta g, such that
Pr [f (x) > g (x)] < Ç« and Pr [f (x) < g (x)] < Ç«.

xâˆ¼Âµq

xâˆ¼Âµp

Note that Theorem 2.5 is really a theorem about functions that have a coarse threshold. Indeed,
if we have either Âµp (f ) > 1 âˆ’ Ç« or Âµq (f ) < Ç«, then the theorem becomes trivial by taking g to be a
suitable constant function.
The conclusion of Theorem 2.5 says that f can be â€˜approximatedâ€™ by the junta g, where our
approximation notion is the â€˜two-sidedâ€™ notion of (q, p, Ç«)-closeness. It is natural to ask whether f
can also be approximated by a junta according to a â€˜one-sidedâ€™ notion, such as the notions of (Âµp , Ç«)closeness and (Âµq , Ç«)-closeness. The following example demonstrates that the two-sided approximation
is actually necessary.
Example 2.6. Fix some numbers q, p in
{0, 1} be the function deï¬ned by
ï£±
ï£´
ï£²1
f (x) = 1
ï£´
ï£³
0

the interval (0, 1) that satisfy q < p. Let fn : {0, 1}n â†’
Pn
x1 = 1, and
xi > qn
Pni=2
x1 = 0, and
i=2 xi > pn .
Otherwise

The Central Limit Theorem implies that
(1 + p)
q
+ o (1) .
Âµq (f ) = + o (1) and Âµp (f ) =
2
2
Since both Âµq (f ) and Âµp (f ) are bounded away from 0 and 1, we obtain that f has an Ç«-coarse
threshold
for some constant Ç« independent of n. On the other hand, it is easy to see that f is not


-close to an O (1)-junta and is not (Âµq , q (1 âˆ’ q))-close to an O (1)-junta, provided that n
Âµp , (1âˆ’p)
4

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

11

is suï¬ƒciently large. However, if we take g to be the dictator function deï¬ned by g (x) = x1 , then we
have
Pr [f (x) > g (x)] = o (1) and Pr [f (x) < g (x)] = o (1) ,
xâˆ¼Âµp

xâˆ¼Âµq

as Theorem 2.5 guarantees.
The proof of Theorem 2.5 is based on the invariance principle of Mossel, Oâ€™Donnell, and Oleszkiewicz
[50] and on a recent unpublished regularity lemma of Oâ€™Donnell, Servedio, Tan, and Wan. A presentation of their proof was recently given by Jones [40].
For our next extension of the Friedgutâ€“Kalai Theorem, we need the notion of (r, Ç«, Âµp )-regularity,
(see Oâ€™Donnell [53, Chapter 7] for more about this notion). Let R be a subset of [n] , and let
R
[n]\R
y âˆˆ {0, 1} . We write fRâ†’y for the Boolean function on the domain {0, 1}
deï¬ned by fRâ†’y (x) =
R
[n]\R
f (z) , where z is the vector whose projection to {0, 1} is y and whose projection to {0, 1}
is x.
Note that a function f is a j-junta if there exists a set J of size j, such that all the restrictions
fJâ†’x are constant functions. On the other extreme, we have the following notion of regularity which
could be thought of as the complete opposite of being a junta. It says that for each set J of constant
size r, the Âµp measures of f and of fJâ†’y are not far apart.
n

Definition 2.7. A function f : {0, 1} â†’ [0, 1] is said to be (r, Ç«, Âµp )-regular if
|Âµp (fJâ†’y ) âˆ’ Âµp (f )| < Ç«
J

for each set J âŠ† [n] of size at most r and each y âˆˆ {0, 1} .
As we explain below the following is a robust version of the Friedgutâ€“Kalai Theorem.
Theorem 2.8. For each Ç« > 0, there exists Î´ > 0, such that the following holds. Let q, p âˆˆ (Ç«, 1 âˆ’ Ç«)
and suppose that p > q + Ç«. Let f, g : {0, 1}n â†’ [0, 1]. Suppose that
and that the function f is

1
Î´

E(x,y)âˆ¼D(q,p) [(1 âˆ’ g (y)) f (x)] < Î´,

, Î´, Âµq -regular. Then either Âµq (f ) < Ç«, or Âµp (g) > 1 âˆ’ Ç«.

Theorem 2.8 is a robust version of Theorem 2.2. Indeed, note that one can equivalently restate
Theorem 2.2 as follows. Let q and p be numbers in the interval (Ç«, 1 âˆ’ Ç«), and suppose that p > q + Ç«.
n
Let f : {0, 1} â†’ {0, 1} be a monotone transitive symmetric Boolean function. Then we either have
Âµq (f ) < Ç«, or we have Âµp (g) > 1 âˆ’ Ç«, provided that n is suï¬ƒciently large.
Applying Theorem 2.8 (with f = g), we see that it strengthens Theorem 2.2 in the following
ways. It shows that we may replace the hypothesis that f is monotone by the weaker hypothesis
that f is (q, p, Î´)-almost monotone, and that we may replace

the hypothesis that f is transitive
symmetric, with the weaker hypothesis that the f is 1Î´ , Î´, Âµq -regular for some Î´ = Î´ (n) , where
limnâ†’âˆ Î´ (n) = 0. Example 3.8 below shows that the latter hypothesis is indeed weaker.
Remark 2.9. While Theorem 2.8 is more general than the Friedgutâ€“Kalai Theorem, we remark that
the Friedgutâ€“Kalai Theorem is better in the quantitative aspects that we have not addressed. We
would also like to remark that the proof of Theorem 2.5 is very diï¬€erent than the standard proofs
of Theorems 2.2 and 2.3. While the traditional proofs are based on the hypercontractivity theorem
of Bonami, Gross, and Beckner [8, 38, 5] and on Russoâ€™s Lemma [55], our proof of Theorem 2.8 is
based instead on the invariance principle of Oâ€™Donnell, Mossel, and Oleszkiewicz [50].

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

12

2.2. Sketch of the proof of Theorems 2.5 and 2.8. Our proof of Theorem 2.5 is based on the
regularity method. In the setting of the regularity method we are given a space S, and our goal is to
show a â€˜removal lemmaâ€™ asserting that any subset A âŠ† S that contain few copies of a given â€˜forbiddenâ€™
conï¬guration may be approximated by a family that contains no copies of that conï¬guration. The
proof contains two ingredients.
(1) A regularity lemma showing that for any set A, we may decompose B into some parts, such
that the intersections of A with â€˜almost allâ€™ of the parts are either â€˜quasirandomâ€™ or â€˜smallâ€™.
(2) A counting lemma showing that if we take the quasirandom parts, then together they contain
many forbidden conï¬gurations.
These two ingredients are put together by approximating A by the set J deï¬ned to be the union
of all the quasirandom parts of B. The task is then to use the counting lemma to show that any
forbidden conï¬guration that appears in J results in many forbidden conï¬gurations back in A.
The invariance principle of Mossel Oâ€™Donnell and Oleszkiewicz [50] considers a notion of smoothness called small noisy influences. It roughly says that we may replace the variables of a smooth
n
function f : {0, 1} â†’ [0, 1] by Gaussian random variables and obtain a function that behaves similarly. We call this function the Gaussian analogue of f . The proof of Theorem 2.5 goes through the
following steps.
(1) We apply a regularity lemma presented by Jones [40], which shows that we may ï¬nd a set
J of constant size that decomposes f into the parts {fJâ†’y }yâˆˆ{0,1}J , such that almost all of
the parts either have expectation very close to 0, or have small noisy inï¬‚uences.
n
(2) We give a counting lemma that shows that if two functions f1 , f2 : {0, 1} â†’ [0, 1] have small
noisy inï¬‚uences and satisfy Exâˆ¼Âµq [f1 (x)] , Eyâˆ¼Âµp (1 âˆ’ f2 (y)) = Î˜ (1), then
Ex,yâˆ¼D(q,p) [f1 (x) (1 âˆ’ f2 (y))] = Î˜ (1) .
The proof of the second part follows [50]. We express Ex,yâˆ¼D(q,p) [f1 (x) (1 âˆ’ f2 (y))] in terms of the
Fourier expansions of f1 and f2 , and we show that this expression can be approximated by a similar
expression involving the Gaussian analogues of f1 and f2 . We then apply a classical theorem by
Borell [9] to lower bound the value of the corresponding expression.

 
The proof of Theorem 2.8 is similar. Suppose that f is a 1Î´ , Î´, Âµq -regular function with Âµq (f ) >
Ç«.
(1) We apply the regularity lemma of [40] to ï¬nd a set J of constant size that decomposes f into
the parts {fJâ†’y }yâˆˆ{0,1}J , such that most of the parts either have expectations very close to

 
0, or have small noisy inï¬‚uences. The Î´1 , Î´, Âµq -regularity of f implies that there are no
parts with expectations close to 0, so only the latter option is available.
(2) We note that the term
Ez,wâˆ¼({0,1}nâˆ’|J| ,D(q,p)) [fJâ†’x (z) (1 âˆ’ gJâ†’y (w))]
J

is small for each x, y âˆˆ {0, 1} , such that xi â‰¤ yi for each i.
(3) We deduce from the above counting lemma (applied with f1 = fJâ†’x , f2 = gJâ†’y ) that for
such x, y, if fJâ†’x has small noisy inï¬‚uences, then the function gJâ†’y has expectation close
to 1.
J
J
(4) It is easy that for â€˜almost allâ€™ y âˆˆ {0, 1} we may ï¬nd x âˆˆ {0, 1} with xi â‰¤ yi for each i, such
that fJâ†’x has small noisy inï¬‚uences. So Step 3 implies that for almost all y the expectation
of gJâ†’y is close to 1. Therefore, the expectation of g is close to 1.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

13

3. Prior results and notions that we make use of
In this section we review some facts on the Fourier analysis of the p-biased cube. Many of them
are standard results that can be found e.g. in Oâ€™Donnell [53, Chapters 2,8, and 11].
3.1. Fourier analysis on the p-biased cube. Given a distribution D on a space â„¦, we write
x âˆ¼ (â„¦, D) or x âˆ¼ D to denote thatx is chosen out of â„¦ according to the distribution D. We shall
use bold letters to denote random variables.
n
n
We denote by L2 ({0, 1} , Âµp ) the Hilbert space of function f : {0, 1} â†’ R equipped with the
p-biased inner product
hf, gi = Exâˆ¼({0,1}n ,Âµp ) [f (x) g (x)] .
p
The p-biased norm is deï¬ned by setting kf k = hf, f i. In any time that we write that f is an
element of the space L2 ({0, 1}n , Âµp ) , we shall use the shorthand E [f ] for Exâˆ¼({0,1}n ,Âµp ) [f ].
n
The p-biased Fourier characters are an orthonormal basis of L2 ({0, 1} , Âµp ) deï¬ned as follows.
Definition 3.1. Let i âˆˆ [n]. The Fourier character corresponding to the singleton {i} is the function
n
Ï‡pi âˆˆ L2 ({0, 1} , Âµp ) deï¬ned by the formula
ï£± q
ï£²âˆ’ 1âˆ’p xi = 1
p
p
.
Ï‡i (x) := q p
ï£³
xi = 0
1âˆ’p

More generally, let Q
S be a subset of [n]. The Fourier character corresponding to the set S âŠ† [n] is
the function Ï‡pS := iâˆˆS Ï‡pi .
n

The Fourier characters are known to be an orthonormal basis for L2 ({0, 1} , Âµp ). Thus, each
P
p
p
Ë†
Ë†
function has a unique expansion of the form f =
SâŠ†[n] f (S) Ï‡S , where f (S) = hf, Ï‡S i . This
expansion is called the p-biased Fourier expansion of f , or just the Fourier expansion of f , where p
is clear from context. We also have the following identities known as the Parseval identities.
X
 
2
fË† (S)
E f 2 = hf, f i =
SâŠ†[n]

E [f g] = hf, gi =
For any T âŠ† [n], the averaging operator
is deï¬ned by setting

X

fË† (S) gÌ‚ (S) .

SâŠ†[n]



nâˆ’|T |
n
, Âµp
AT : L2 ({0, 1} , Âµp ) â†’ L2 {0, 1}


AT [f ] (x) = E f[n]\T â†’x .

The operator AT [f ] has the following nice Fourier analytical interpretation. It is the operator that
annihilates all the Fourier coeï¬ƒcients that correspond to sets that have nonempty intersection with
T.
n

Fact 3.2. Let f âˆˆ L2 ({0, 1} , Âµp ) be a function that has the Fourier expansion
X
fË† (S) Ï‡pS .
f=
SâŠ†[n]

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

Then

X

AT [f ] =

14

fË† (S) Ï‡pS

SâŠ†[n]\T

Another notion of importance for us is the notion of influence by Ben-Or and Linial [6].
n

Definition 3.3. The p-biased ith influence of a function f : {0, 1} â†’ R whose Fourier expansion
P
is SâŠ†[n] fË† (S) Ï‡pS is deï¬ned by setting
h
2 i X
(3.1)
Inf pi [f ] = E f âˆ’ A{i} [f ]
=
fË† (S)2 .
Sâˆ‹i

We shall also need to introduce the noise operator.

Definition 3.4. Given x âˆˆ {0, 1}n the (Ï, p)-noisy distribution of x denoted by NÏ,p (x) is a proban
bility distribution on elements y âˆˆ {0, 1} , where we set each coordinate yi independently to be xi
with probability Ï, and to a new p-biased element of {0, 1} with probability 1 âˆ’ Ï.
The noise operator TÏ,p on the space L2 ({0, 1}n , Âµp ) is the operator that associates to each
n
f âˆˆ L2 ({0, 1} , Âµp ) the function
TÏ,p [f ] :=

E
yâˆ¼NÏ,p (x)

[f (y)] .

We have the following Fourier formula for TÏ,p [f ] .
Fact 3.5. Let Ï, p âˆˆ (0, 1), and let

X

f=

fË† (S) Ï‡pS

SâŠ†[n]
n

be a function in L2 ({0, 1} , Âµp ). Then
TÏ,p [f ] =

X

Ï|S| fË† (S) Ï‡pS .

SâŠ†[n]

3.2. The directed noise operators. We shall now introduce a directed analogue of the noise
operator. Recall that D (q, p) is the joint distribution on elements (x, y) âˆˆ {0, 1}n Ã— {0, 1}n , such
that
x âˆ¼ Âµq , y âˆ¼ Âµp , âˆ€i : yi â‰¥ xi .
We deï¬ne an operator

and its adjoint

Tpâ†’q : L2 ({0, 1}n , Âµp ) â†’ L2 ({0, 1}n , Âµq ) ,
n

by setting

and

n

Tqâ†’p : L2 ({0, 1} , Âµq ) â†’ L2 ({0, 1} , Âµp ) ,
Tpâ†’q (f ) (x) = Ex,yâˆ¼D(q,p) [f (y) | x = x] ,
Tqâ†’p (f ) (y) = Ex,yâˆ¼D(q,p) [f (x) | y = y] .

These operators were ï¬rst studied by Ahlberg, Broman, Griï¬ƒths, and Morris [2], and then again
by Abdullah and Venkatasubramania [1]. The one sided noise operator has the following Fourier
formulas:

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

15

q

P
n
q
2
Ë†
Lemma 3.6. Let p > q, and set Ï = q(1âˆ’p)
SâŠ†[n] f (S) Ï‡S be a function in L ({0, 1} , Âµq ).
p(1âˆ’q) . Let f =
Then Tqâ†’p (f ) has the p-biased Fourier expansion:
X
Ï|S| fË† (S) Ï‡pS .
Tqâ†’p (f ) =
SâŠ†[n]

P

p
SâŠ†[n] gÌ‚ (S) Ï‡S

Similarly, if g =
q-biased Fourier expansion

n

is a function in L2 ({0, 1} , Âµp ), then the function Tpâ†’q (g) has the
Tpâ†’q (g) =

X

Ï|S| gÌ‚ (S) Ï‡qS .

SâŠ†[n]
qâ†’p

Proof. We shall prove it for the operator T
, as the proof for the other operator Tpâ†’q will be
similar. By linearity, it is enough to prove the lemma in the case where f = Ï‡qS for some S âŠ† [n] .
n
Let y âˆˆ {0, 1} . Note that
"
#
Y q
q
q
Tqâ†’p [Ï‡S ] (y) = Ex,yâˆ¼D(q,p)| y=y [Ï‡S (x)] = Ex,yâˆ¼D(q,p)| y=y
(3.2)
Ï‡i (xi ) .
iâˆˆS

Claim 3.7 below shows that

Ex,yâˆ¼D(q,p)| y=y [Ï‡qi (xi )] = ÏÏ‡pi (yi ) .
By the independence of the random variables Ï‡qi (xi ) for any x, y âˆ¼ D (q, p) | y = y we obtain:
"
#
Y q
Y
Ex,yâˆ¼D(q,p)| y=y
Ï‡{i} (xi ) =
(3.3)
Ex,yâˆ¼D(q,p)| y=y [Ï‡qi (xi )]
iâˆˆS

iâˆˆS

= Ï|S|

Y

Ï‡pi (yi ) = Ï|S| Ï‡S (y) .

iâˆˆS

Combining (3.2) with (3.3), we complete the proof.

Claim 3.7. Let x, y be elements of {0, 1}n , let p > q âˆˆ (0, 1) , and let Ï =
(3.4)

Ex,yâˆ¼D(q,p)| y=y [Ï‡qi (xi )] = ÏÏ‡pi (yi ) ,


q

q(1âˆ’p)
p(1âˆ’q) .

Then

and
(3.5)

Ex,yâˆ¼D(q,p)| x=x [Ï‡pi (yi )] = ÏÏ‡qi (xi ) .

Proof. Since the functions Ï‡qi , Ï‡pi depend only on the ith coordinate we may assume that n = 1, and
we shall write Ï‡p = Ï‡p1 as well as Ï‡q = Ï‡q1 for brevity. We shall start by showing (3.4), and the proof
of (3.5) will be similar. Let h âˆˆ L2 ({0, 1}n , Âµp ) be the map
y 7â†’ Ex,yâˆ¼D(q,p)| y=y [Ï‡q (x)] .

Note the space L2 ({0, 1} , Âµp ) is a linear space of dimension 2. We shall show that h = ÏÏ‡p by
showing that there are two independent linear functionals on the space L2 ({0, 1} , Âµp ) that agree on
the functions h and ÏÏ‡p . Namely, the ï¬rst functional is the functional of evaluating at 0, and the
second functional is the expectation according to the p-biased distribution. Indeed, we may use the
fact that elements x, y âˆ¼ D (q, p) satisfy xi â‰¤ y i with probability 1 to obtain:
r
r
q
p
=Ï
= ÏÏ‡p (0) .
Ex,yâˆ¼({0,1},D(q,p))| y=0 [Ï‡q (x)] = Ï‡q (0) =
1âˆ’q
1âˆ’p

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

16

On the other hand,


Ezâˆ¼Âµp [h (z)] = Ezâˆ¼Âµp Ex,yâˆ¼D(q,p)| y=z [Ï‡q (x)]

= Ex,yâˆ¼D(q,p) [Ï‡q (x)] = Exâˆ¼Âµq [Ï‡q (x)] = 0

= Ezâˆ¼Âµp [ÏÏ‡p (z)] .
Since the expectation functional and the evaluating by 0 functionals are independent, and since the
space L2 ({0, 1} , Âµp ) is of dimension 2, we obtain h = ÏÏ‡p . This completes the proof of (3.4).
We prove (3.5) in a similar fashion. Deï¬ne h âˆˆ L2 ({0, 1} , Âµq ) by
x 7â†’ Ex,yâˆ¼D(q,p)| x=x [Ï‡p (y)] .

Similarly to the proof of (3.4), it is enough to prove the identities
Ezâˆ¼Âµq (h) = 0, h (1) = ÏÏ‡q (1) .
To prove the former, note that


Ezâˆ¼Âµq (h (z)) = Ezâˆ¼Âµq Ex,yâˆ¼D(q,p)| x=z [Ï‡p (y)] = Ex,yâˆ¼D(q,p) [Ï‡p (y)] = 0.

To prove the latter, note that

h (1) = Ex,yâˆ¼D(q,p)| x=1 [Ï‡p (y)] = Ï‡p (1) = ÏÏ‡q (1) .

n

3.3.
Fourier
regularity. We shall say that a function f : {0, 1} â†’ R is (r, Î´, Âµp )-Fourier regular if


Ë† 
f
(S)
<
Î´
for
each 0 < |S| â‰¤ r. It is easy to see (see Oâ€™Donnell [53, Chapter 7]) that any (r, Î´, Âµp )


regular function is (r, Î´, Âµp )-Fourier regular, and on the converse any (r, Î´, Âµp )-Fourier regular function
is (r, 2r Î´, Âµp )-regular. So in a sense these notions are equivalent.

p
n
Example 3.8. Let f : {0, 1} â†’ [0, 1] be a transitive symmetric function. Then f is r, nr , Âµp 
Fourier regular for any r and p. Indeed, let S âˆˆ [n]
r , then the fact that f is transitive symmetric
implies that there exist distinct r-subsets of [n], S1 , . . . , SâŒˆ n âŒ‰ , such that fË† (Si ) = fË† (S) for each i.
r
By Parsevalâ€™s identity, we have
n
âŒˆX
râŒ‰

lnm
2
2
fË† (Si ) =
fË† (S) .
r
i=1

pr
r
, Âµp -Fourier regular, so it is in fact (r, Î´, Âµp )-Fourier
After rearranging, we obtain that f is r, 2
n
r
regular, provided that n > 4Î´2 .
1â‰¥

kf k2Âµp

â‰¥

n

3.4. The noisy influences. Let f âˆˆ L2 ({0, 1} , Âµp ) be a function. The noise stability of f is
deï¬ned by
StabÏ,p (f ) := hTÏ (f ) , f iÂµp =
E
[f (x) f (y)] .
xâˆ¼Âµp ,yâˆ¼NÏ,p (x)

By Fact 3.5, and by Parsevalâ€™s identity, we have
(3.6)

StabÏ,p (f ) =

X

2

Ï|S| fË† (S) ,

SâŠ†[n]

where fË† (S) are the Fourier coeï¬ƒcients of f with respect to the p-biased distribution.
The (Ï, Âµp )-noisy inï¬‚uences of f are deï¬ned by

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

(Ï,p)

Inf i
By Fact 3.2 and by (3.6) we have

[f ] := StabÏ,p
(Ï,p)

(3.7)

Inf i

[f ] =



X

f âˆ’ A{i} [f ]



17

.

Ï|S| fË† (S)2 .

Sâˆ‹i

Definition 3.9. Let Î´ > 0, Ï, p âˆˆ [0, 1] . A function f : {0, 1}n â†’ R is said to have (Ï, Î´, Âµp )-small
(Ï,p)
[f ] < Î´ for every i âˆˆ [n] .
noisy inï¬‚uences if Inf i
3.5. Regularity lemmas we use. We shall make use of the following regularity lemma presented
by Jones [40].
Theorem 3.10. For each Ç« > 0 there exists j âˆˆ N such that the following holds. Let p âˆˆ (Ç«, 1 âˆ’ Ç«)
and let f âˆˆ L2 
({0, 1} , Âµp ) 
be a function. Then there exists a set J of size at most j, such that if
J

we choose x âˆ¼ {0, 1} , Âµp , then the functions fJâ†’x has (1 âˆ’ Ç«, Ç«, Âµp )-small noisy influences with
probability at least 1 âˆ’ Ç«.

Remark 3.11. Jones [40] proved Theorem 3.10 only for the case where p = 21 . However, as in most of
the results in the area, their proof can be extended verbatim to the p-biased distribution, for any p
bounded away from 0 and 1.
We also make use of the following regularity lemma of [17].
Theorem 3.12 ( [17, Theorem 1.7]). For each Î´, Ç« > 0, there exists j âˆˆ N, such that the following

holds. Let Î´ < nk < 1 âˆ’ Î´, and let F âŠ† [n]
be a family. Then there exists a set J of size at most j
k
and a family G âŠ† P (J), such that:
(1) We have Âµ (F \ hGi) < Ç«.

  
(2) For each B âˆˆ G the family FJB is Î´1 , Î´ -regular and Âµ FJB > 2Ç« .

3.6. Functions on Gaussian spaces. Let Î³ be the standard normal probability distribution N (0, 1)
on R. Abusing notation, we will also use Î³ to denote the product normal probability distribun
2
n
n
tion N (0, 1)n on
 R . We shall denote by L (R , Î³) the space of functions f : R â†’ R, such that
2
kf kÎ³ := EÎ³ f < âˆ. This space is equipped with the inner product
Z
f (x) g (x) Î³ (x) dx.
hf, gi = EÎ³ [f g] =
Rn

n

The operator TÏ on the space (R , N (0, 1)), also known as the Ornstein-Uhlenbeck operator, is
deï¬ned as follows.

Definition 3.13. Let Ï âˆˆ (0, 1), and let x âˆˆ Rn , the Ï-noisy distribution of x ispthe distribution
NÏ,Î³ (x), where we choose y by setting each coordinate yi independently to be Ïxi + 1 âˆ’ Ï2 zi , where
z is a new independent Î³-distributed element of R. The noise operator TÏ on the space L2 (Rn , Î³) is
the operator that associates to each f âˆˆ L2 (Rn , Î³) the function
TÏ [f ] (x) :=

E

yâˆ¼NÏ,Î³ (x)

[f (y)] .

Remark 3.14. The analogy between the distribution NÏ,p , and NÏ,Î³ stems from the fact if we choose
x âˆ¼ Î³, and y âˆ¼ NÏ,Î³ (x) , then we have the following properties.
â€¢ x, y âˆ¼ Î³.
â€¢ âˆ€i : E [xi yi ] = Ï.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

18

â€¢ The R2 -valued random variables(xi , yi ) are independent of each other.
These properties are similarly satisï¬ed when we choose x âˆ¼Âµp and then choose y âˆ¼ NÏ,p (x) .

For Âµ âˆˆ (0, 1), we let FÂµ : R â†’ [0, 1] denote the function 1x<t , where t is the only real number
for which Exâˆ¼Î³ [FÂµ (x)] = Âµ. The following theorem was proved by Borell [9]. It says that if f, g âˆˆ
L2 (Rn , Î³) are functions that take their value in the interval [0, 1] that satisfy E [f ] = Âµ, E [g] = Î½,
then the maximal possible value of the quantity hTÏ [f ] , gi is obtained when f = FÂµ and g = FÎ½ .
Theorem 3.15 (Borell 1985). Let f, g âˆˆ L2 (Rn , Î³) be two [0, 1]-valued functions. Then



 
hTÏ [f ] , gi â‰¤ TÏ FE[f ] , FE[g] .
We denote hTÏ [FÂµ ] , FÎ½ i by Î›Ï (Âµ, Î½) . Note that we trivially have

Î›Ï (Âµ, Î½) := hTÏ [FÂµ ] , FÎ½ i â‰¤ hTÏ [FÂµ ] , 1i = Âµ.

We will be interested in the case where Âµ is bounded away from 0 and Î½, Ï are bounded away from
1. For such parameters, Î›Ï (Âµ, Î½) admits a slightly stronger upper bound.
Lemma 3.16. For each Ç« > 0, there exists Î´ > 0, such that the following holds. Let Âµ âˆˆ (Ç«, 1) and
let Ï, Î½ âˆˆ (0, 1 âˆ’ Ç«). Then
Î›Ï (Âµ, Î½) â‰¤ Âµ âˆ’ Î´.

Proof. Let Î´ = hT1âˆ’Ç« [FÇ« ] , 1 âˆ’ F1âˆ’Ç« i > 0. We have

Î›Ï (Âµ, Î½) = hTÏ [FÂµ ] , FÎ½ i = hTÏ [FÂµ ] , 1i + hTÏ [FÂµ ] , FÎ½ âˆ’ 1i

= Âµ âˆ’ hTÏ [FÂµ ] , 1 âˆ’ FÎ½ i â‰¤ Âµ âˆ’ hT1âˆ’Ç« [FÇ« ] , 1 âˆ’ F1âˆ’Ç« i
= Âµ âˆ’ Î´.



We shall also use the following estimate on Î›Ï .
Lemma 3.17 ([49, Lemma 2.5]). Let Ï1 < Ï2 . Then
|Î›Ï1 (Âµ, Î½) âˆ’ Î›Ï2 (Âµ, Î½)| â‰¤

10 (Ï2 âˆ’ Ï1 )
.
1 âˆ’ Ï2

We would also like to remark that we have the following Fourier formula for TÏ [f ], in the case
where f is a multilinear polynomial:
Q
P
Fact 3.18. Let f = SâŠ†[n] ai iâˆˆS zi be a multilinear polynomial. Then
Y
X
ai Ï|S|
zi .
TÏ [f ] =
SâŠ†[n]

iâˆˆS

3.7. The invariance principle. The invariance principle is a powerful theorem due to Mossel,
n
Oâ€™Donnell, and Oleszkiewicz [50] that relates the distribution of a â€˜smoothâ€™ function f : {0, 1} â†’ R
with the distribution of functions on Gaussian spaces. To state a corollary of it that we shall apply,
we need to introduce some terminology.
Let f : Rn â†’ R be a function. Following [16], we deï¬ne the function Chop (f ) by setting
ï£±
ï£´
ï£²f (x) if f (x) âˆˆ [0, 1]
Chop (f ) (x) = 0
.
if f (x) â‰¤ 0
ï£´
ï£³
1
if f (x) â‰¥ 1
We shall also need the following deï¬nition.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

19

n

Definition 3.19. Let f âˆˆ L2 ({0, 1} , Âµp ) be some function with Fourier expansion
X
fË† (S) Ï‡p .
f=
S

SâŠ†[n]

We let the Gaussian analogue of it be the multilinear polynomial fËœ âˆˆ L2 (Rn , Î³) deï¬ned by
Y
X
fË† (S)
zi .
fËœ (z) =
SâŠ†[n]

iâˆˆS

Roughly speaking, the invariance principle says that if the function f is suï¬ƒciently â€˜smoothâ€™, then
n
the distribution of f (x), where x âˆ¼ ({0, 1} , Âµp ) is somewhat similar to the distribution of fËœ (y),
n
where y âˆ¼ (R , Î³) is a Gaussian random variable. The smoothness requirement that we need is the
n
2
following. Let Î´, Ç« > 0, we shall say that
 a function f âˆˆ L ({0, 1} , Âµp ) is (Î´, 1 âˆ’ Ç«, Âµp )-smooth if


|S|
Inf p [f ] < Î´ for each i âˆˆ [n] , and fË† (S) â‰¤ (1 âˆ’ Ç«) for each S âŠ† [n] .
i

As a corollary of the invariance principle, one can show (see [16, Theorem 3.8] or [50, Theorem
3.18]) the following corollary of it. It says that if f is a â€˜suï¬ƒciently smoothâ€™ function that takes
 its
value in the interval [0, 1], then fËœ is concentrated on [0, 1] as well, in the sense that kfËœ âˆ’ Chop fËœ k
is small.

Corollary 3.20 (Corollary of the invariance principle). For each Ç«, Î· > 0, there exists Î´ > 0, such
n
that the following holds. Let p âˆˆ (Ç«, 1 âˆ’ Ç«), let f : {0, 1} â†’ [0, 1] be a function, and suppose that f
is (Î´, 1 âˆ’ Î·, Âµp )-smooth. Then
 
kfËœ âˆ’ Chop fËœ k < Ç«.
4. Counting lemma for the Ï-noisy influence regularity lemma

In this section we prove our version of the majority is stablest theorem that would serve as a
counting lemma in the proof of Theorem 1.7. The proof is a straightforward adaptation of the
proof by Mossel, Oâ€™Donnell, and Oleszkiewicz [50] of the Majority is Stablest Theorem, and its
generalizations by Mossel [48].
Proposition 4.1. For each Ç« > 0, there exists Î´ > 0, such that the following holds. Let Ï âˆˆ (0, 1 âˆ’ Ç«) ,
n
and suppose that p âˆ’ q > Ç«. Let f, g : {0, 1} â†’ [0, 1] be some functions, and suppose that
o
n
(1âˆ’Î´,q)
(1âˆ’Î´,q)
[g] < Î´.
[f ] , Inf i
max min Inf i
iâˆˆ[n]

Then
(4.1)

X

Ï|S| fË† (S) gÌ‚ (S) < Î›Ï (Âµq (f ) , Âµp (g)) + Ç«.

SâŠ†[n]

We divide the proof into three parts. In each of these parts we prove that if f, g satisfy certain
requirement then (4.1) holds. The hypothesis will be the strongest in the ï¬rst part, weaker on the
second part, and the weakest on the third part. The parts are as follows.
(1) We start by showing that (4.1) holds if f is assumed to be (Î´, 1 âˆ’ Ç«, Âµq )-smooth, and g is
assumed to be (Î´, 1 âˆ’ Ç«, Âµp )-smooth.
(2) We then prove (4.1) in the case where f and g are assumed to satisfy
o
n
(1âˆ’Î´,q)
(1âˆ’Î´,q)
[g] < Î´.
[f ] , Inf i
max max Inf i
iâˆˆ[n]

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

20

(3) Finally, we shall complete the proof of the proposition by proving (4.1) in the case where f
and g are assumed to satisfy
o
n
(1âˆ’Î´,q)
(1âˆ’Î´,q)
[g] < Î´.
[f ] , Inf i
max min Inf i
iâˆˆ[n]

4.1. Proof of the proposition in the case where f is (Î´, 1 âˆ’ Ç«, Âµq )-smooth and g is (Î´, 1 âˆ’ Ç«, Âµp )smooth. The idea of the proof is to convert the statement on f and g to a corresponding statement
about their Gaussian analogues fËœ and gÌƒ, and then to prove the corresponding statement by applying
Borrelâ€™s Theorem. A diï¬ƒculty that arises in this approach is the fact that Borrelâ€™s Theorem may
be applied only on functions that take their values in the interval [0, 1] , while the functions fËœ and
gÌƒ may take their values outside of this interval. However,we overcome this diï¬ƒculty by noting that
Borrelâ€™s theorem may be applied on the functions Chop fËœ and Chop (gÌƒ) , and by observing that
 
Corollary 3.20 shows that fËœ and gÌƒ are approximated by the functions Chop fËœ and Chop (gÌƒ) . The
technical details are below.
Lemma 4.2. For each Ç« > 0, there exists Î´ > 0 such that the following holds. Let q, p âˆˆ (Ç«, 1 âˆ’ Ç«),
PË†
P
let Ï âˆˆ (0, 1) , let f =
f (S) Ï‡qS be a (Î´, 1 âˆ’ Ç«, Âµq )-smooth function, and let g =
gÌ‚ (S) Ï‡pS be a
(Î´, 1 âˆ’ Ç«, Âµp )-smooth function. Then
X
Ï|S| fË† (S) gÌ‚ (S) < Î›Ï (Âµq (f ) , Âµp (g)) + Ç«.
SâŠ†[n]

Proof. Let Ç« > 0 and suppose that Î´ = Î´ (Ç«) is suï¬ƒciently small. Let fËœ be the Gaussian analogue of
f and let gÌƒ be the Gaussian analogue of g. By Fact 3.18 we have
E
D
X
Ï|S| fË† (S) gÌ‚ (S) = TÏ fËœ, gÌƒ .
SâŠ†[n]

So our goal is to show that

D

(4.2)

E
TÏ fËœ, gÌƒ âˆ’ Î›Ï (Âµq (f ) , Âµp (g)) < Ç«,

provided that Î´ is suï¬ƒciently small. Let
D
 
E
E D 


Ç«1 :=  TÏ fËœ, gÌƒ âˆ’ TÏ Chop fËœ , Chop (gÌƒ)  ,
and let

  
 h i
 




Ç«2 = Î›Ï E Chop fËœ , E (Chop (gÌƒ)) âˆ’ Î›Ï E fËœ , E [gÌƒ] 
  


 


= Î›Ï E Chop fËœ , E (Chop (gÌƒ)) âˆ’ Î›Ï (Âµq (f ) , Âµp (g)) .
 
Applying Borrelâ€™s Theorem on the functions Chop fËœ , Chop (gÌƒ) , we obtain
 
 

D
 
E
(4.3)
TÏ Chop fËœ , Chop (gÌƒ) â‰¤ Î›Ï E Chop fËœ , E (Chop (gÌƒ)) ,

and hence

D

E
TÏ fËœ, gÌƒ â‰¤ Î›Ï (Âµq (f ) , Âµp (g)) + Ç«1 + Ç«2 .

So to complete the proof we need to show that Ç«1 + Ç«2 < Ç« provided that Î´ is suï¬ƒciently small.
Claim 4.3. Provided that Î´ is suï¬ƒciently small we have Ç«1 < Ç«/2.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

21

Proof. Note that it follows from Jensenâ€™s inequality that the operator TÏ on the space L2 (Rn , Î³) is
a contraction. Indeed, for each function h âˆˆ L2 (Rn , Î³) we have
h
2 i
2
kTÏ (h)k = Exâˆ¼(Rn ,Î³) Eyâˆ¼NÏ (x) [h (y)]

2
â‰¤ Exâˆ¼(Rn ,Î³) Eyâˆ¼NÏ (x) [h (y)]
2
= Eyâˆ¼(Rn ,Î³) [h (y)]
= khk2 .

Moreover, we note that by Parseval kgÌƒk =

P

2

gÌ‚ (S) =

r
i
h
2
Eyâˆ¼Âµp g (y) â‰¤ 1. Therefore,

D
E
E D 
 


Ç«1 =  TÏ fËœ, gÌƒ âˆ’ TÏ Chop fËœ , Chop (gÌƒ) 
D
  E
E D 


â‰¤  TÏ fËœ, gÌƒ âˆ’ TÏ Chop fËœ , gÌƒ 
D 
 
  E D 
E


+  TÏ Chop fËœ , gÌƒ âˆ’ TÏ Chop fËœ , Chop (gÌƒ) 
 
 
 
 




(By Cauchy-Schwarz) â‰¤ TÏ fËœ âˆ’ Chop fËœ  kgÌƒk + TÏ Chop fËœ  kgÌƒ âˆ’ Chop (gÌƒ)k


 
 




(Since TÏ is a contraction) â‰¤ fËœ âˆ’ Chop fËœ  kgÌƒk + Chop fËœ  kgÌƒ âˆ’ Chop (gÌƒ)k

 


â‰¤ fËœ âˆ’ Chop fËœ  + kgÌƒ âˆ’ Chop (gÌƒ)k .

We may now apply Corollary 3.20 with Ç« replacing Î· and 4Ç« replacing Ç«, to obtain that

 
Ç«
Ëœ

(4.4)
f âˆ’ Chop fËœ  + kgÌƒ âˆ’ Chop (gÌƒ)k < ,
2
provided that Î´ is suï¬ƒciently small. This completes the proof of the claim.



To ï¬nish the proof of the lemma it remains to prove the following claim.
Claim 4.4. Provided that Î´ is suï¬ƒciently small, we hhave
i Ç«2 < Ç«/2.
Ëœ
Choose X âˆ¼ (R, Î³) , Y âˆ¼ NÏ (X) . Then Î›Ï E f , E [gÌƒ] is the probability of the event X <
 h
 i

t1 , Y < t2 for the proper values of t1 , t2 . Similarly, Î›Ï E Chop fËœ , E [Chop (gÌƒ)] is the probability
of the event X < t3 , Y < t4 for the proper values of t3 , t4 . These events diï¬€er either if X is in
the interval whose endpoints are t1 ,ht3 or 
if Yi is inhthe
i interval whose endpoints are t2 , t4 . The


Ëœ
Ëœ
Probability of the former event is E Chop f âˆ’ E f , and the probability of the latter event is
|E [Chop (gÌƒ)] âˆ’ E [gÌƒ] |. Therefore, a union bound implies that:
  h i
 h
 i




Ç«2 = Î›Ï E fËœ , E [gÌƒ] âˆ’ Î›Ï E Chop fËœ , E [Chop (gÌƒ)] 
 h
 i
h i


â‰¤ E Chop fËœ âˆ’ E fËœ  + |E [Chop (gÌƒ)] âˆ’ E [gÌƒ] |
 
Ç«
(By Cauchy-Schwarz and (4.4)) â‰¤ kChop fËœ âˆ’ fËœk + kChop (gÌƒ) âˆ’ gÌƒk < .
2



HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

22

4.2. The case where f, g have small noisy influences. We shall now prove a stronger version
of Lemma 4.2, where we impose on f, g the hypothesis
o
n
(1âˆ’Î´,p)
(1âˆ’Î´,q)
[g] < Î´.
[f ] , Inf i
max max Inf i
iâˆˆ[n]

Lemma 4.5. For each Ç« > 0, there exists Î´ > 0 such that the following holds. Let q, p âˆˆ (Ç«, 1 âˆ’ Ç«),
P
let Ï âˆˆ (0, 1), let f = fË† (S) Ï‡qS be a function and suppose that
o
n
(1âˆ’Î´,p)
(1âˆ’Î´,q)
[g] < Î´.
[f ] , Inf i
max max Inf i
iâˆˆ[n]

Then

X

Ï|S| fË† (S) gÌ‚ (S) < Î›Ï (Âµq (f ) , Âµp (g)) + Ç«.

SâŠ†[n]

Proof. Let Ç« > 0, let Î´1 = Î´1 (Ç«) be suï¬ƒciently small, and let Î´ = Î´ (Î´1 ) be suï¬ƒciently small. Let
Ï
f â€² = Tq,1âˆ’Î´1 (f ) , g â€² = Tp,1âˆ’Î´1 (g) , Ïâ€² = (1âˆ’Î´
2.
1)
â€²
We assert that the functions f is (Î´, 1 âˆ’ Î´1 , Âµq )-smooth and the function g â€² is (Î´, 1 âˆ’ Î´1 , Âµp )-smooth,
provided that Î´ is small enough. Indeed, the functions f â€² is (Î´, 1 âˆ’ Î´1 , Âµq )-smooth since:
(1âˆ’Î´1 ,q)

Inf i [f â€² ] = Inf i

provided that Î´ â‰¤ Î´1 , and

(1âˆ’Î´,q)

[f ] â‰¤ Inf i

[f ] < Î´,


 

 Ë†â€²
 

|S|
|S|
f (S) = (1 âˆ’ Î´1 ) fË† (S) â‰¤ (1 âˆ’ Î´1 ) .

The function g is (Î´, 1 âˆ’ Î´1 , Âµp )-smooth for similar reasons. Provided that Î´ is small enough, Lemma
4.2 implies that
hTÏ f, gi = hTÏâ€² f â€² , g â€² i â‰¤ Î›Ïâ€² (Âµq (f â€² ) , Âµp (g â€² )) + Î´1 = Î›Ïâ€² (Âµq (f ) , Âµp (g)) + Î´1 .

By Lemma 3.17 we have

Î›Ïâ€² (Âµq (f ) , Âµp (g)) < Î›Ï (Âµq (f ) , Âµp (g)) + Ç« âˆ’ Î´1 ,

provided that Î´1 is suï¬ƒciently small. Hence

hTÏ f, gi â‰¤ Î›Ï (Âµq (f ) , Âµp (g)) + Ç«.
4.3. Proof of Proposition 4.1. Finally, we shall replace the hypothesis
o
n
(1âˆ’Î´,p)
(1âˆ’Î´,q)
[g] < Î´
[f ] , Inf i
max max Inf i
iâˆˆ[n]

by the weaker hypothesis

o
n
(1âˆ’Î´,p)
(1âˆ’Î´,q)
[g] < Î´.
[f ] , Inf i
max min Inf i
iâˆˆ[n]

Proof. Let Ç« > 0, let Î´1 = Î´1 (Ç«) be suï¬ƒciently small, and let Î´ = Î´ (Î´1 ) be suï¬ƒciently small. Let
o
n
o
n
(1âˆ’Î´ ,q)
(1âˆ’Î´ ,q)
A1 = i âˆˆ [n] : Inf i 1 [f ] > Î´1 , A2 = i âˆˆ [n] : Inf i 1 [g] > Î´1 ,
let A = A1 âˆª A2 , and set B = [n] \A. Write f â€² = AA (f ) , g â€² = AA (g) . We have
X
X
X
Ï|S| fË† (S) gÌ‚ (S) =
Ï|S| fË† (S) gÌ‚ (S) +
Ï|S| fË† (S) gÌ‚ (S) .
SâŠ†[n]

SâŠ†B

Sâˆ©A6=âˆ…



HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

We shall now bound

P

SâŠ†[n]
P

23

Ï|S| fË† (S) gÌ‚ (S) by bounding each of the terms in the right hand side.
Ï|S| fË† (S) gÌ‚ (S)

Upper bounding SâŠ†B
Since f â€² , g â€² satisfy the hypothesis of Lemma 4.5 (with Î´1 replacing Î´), we have
X
X
Ç«
Ç«
Ï|S| fË†â€² (S) gË†â€² (S) â‰¤ Î›Ï (Âµq (f â€² ) , Âµp (g â€² )) + = Î›Ï (Âµq (f ) , Âµp (g)) + ,
Ï|S| fË† (S) gÌ‚ (S) =
2
2

SâŠ†B

SâŠ†[n]

provided that Î´1 is small
P enough.
Upper bounding Sâˆ©A6=âˆ… Ï|S| fË† (S) gÌ‚ (S) .
By Cauchy Schwarz, we have
sX

 X sX
X
XX

2
2
|S| Ë†
|S|  Ë†
|S|
Ë†
Ï f (S)
Ï|S| gÌ‚ (S) .
Ï f (S) gÌ‚ (S) â‰¤
Ï f (S) gÌ‚ (S) â‰¤
iâˆˆA Sâˆ‹i

Sâˆ©A6=âˆ…

Sâˆ‹i

iâˆˆA

Sâˆ‹i

q
X q (Ï,q)
(Ï,p)
=
(f ) Inf i
(g).
Inf i
iâˆˆA

Now note that

o
n
(Ï,p)
(Ï,q)
(g) â‰¤ 1
(f ) , Inf i
max Inf i
(1âˆ’Î´,q)

(Ï,q)

(Ï,p)

(f ) and Inf i
(f ) â‰¤ Inf i
for any i âˆˆ [n] . Moreover, we have Inf i
provided that Î´ < 1 âˆ’ Ï. The hypothesis implies that
o
n
(1âˆ’Î´,p)
(1âˆ’Î´,q)
(f ) â‰¤ Î´.
(f ) , Inf i
max min Inf i

(1âˆ’Î´,p)

(f ) â‰¤ Inf i

(f ) ,

iâˆˆ[n]

Therefore,

q
X q (Ï,q)
âˆš
(Ï,p)
(f ) Inf i
(g) â‰¤ |A| Î´.
Inf i
iâˆˆA

2

Ç«
So this completes the proof provided that Î´ â‰¤ 4|A|
2 . We shall now complete the proof by showing
that |A| = OÎ´1 (1) .
Upper bounding |A|
We show that |A1 | = OÎ´1 (1) , as the proof that |A2 | = OÎ´1 (1) is similar. Note that the quantity
Pn
(1âˆ’Î´1 ,q)
(f ) is on the one hand bounded from below by |A1 | Î´1 , and on the other hand we
i=1 Inf i
have the following upper bound on it.
n
X

(q,1âˆ’Î´1 )

Inf i

(f ) =

i=1

X

SâŠ†[n]

|S|

(1 âˆ’ Î´1 )

2
|S| fË† (S) â‰¤

âˆ
X
s=1

s

s (1 âˆ’ Î´1 ) = OÎ´1 (1) .

Hence |A1 | = OÎ´1 (1) . This completes the proof of the proposition.



5. Proof of the structural result on almost monotone functions
In this section we prove Theorem 2.5. We restate it for the convenience of the reader.
Theorem. For each Ç« > 0, there exists j âˆˆ N, Î´ > 0, such that the following holds. Let p, q be
numbers in the interval (Ç«, 1 âˆ’ Ç«) that satisfy p âˆ’ q > Ç« and let f : {0, 1}n â†’ {0, 1} be a (q, p, Î´)almost monotone function. Then there exists a monotone j-junta g, such that
Pr [f (x) > g (x)] < Ç« and Pr [f (x) < g (x)] < Ç«.

xâˆ¼Âµq

xâˆ¼Âµp

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

24

We recall that the proof relies on the regularity method, with the regularity lemma being Theorem
3.10 of [40], and with the corresponding counting lemma being Proposition 4.1.
The regularity lemma allows us to decompose f into functions {fJâ†’x }xâˆˆ{0,1}J , such that for most
of the parts the function fJâ†’x has small noisy inï¬‚uences and a q-biased measure that is bounded
J
away from 0. We shall then approximate f by the â€˜leastâ€™ monotone junta g : {0, 1} â†’ {0, 1} that
takes the value 1 on all the the x, such that the function fJâ†’x has small noisy inï¬‚uences. Here, by
least we mean smallest with respect to the partial order: g â‰¤ h if and only if g (x) â‰¤ h (x) for each x.
Proof. Let Î´1 = Î´1 (Ç«) be suï¬ƒciently small, let Î´2 = Î´2 (Î´1 ) be suï¬ƒciently small, let j = j (Î´2 ) be
suï¬ƒciently large, and let Î´ = Î´ (j, Î´1 , Ç«) be suï¬ƒciently
 small. ByTheorem 3.10, there exists a set J
of size at most j, such that the for a random x âˆ¼ {0, 1}J , Âµq the function fJâ†’x does not have

(1 âˆ’ Î´2 , Î´2 , Âµq )-small noisy inï¬‚uences with probability at most Î´2 .
Let Q âŠ† {0, 1}J be the set of â€˜quasirandom partsâ€™ consisting of all x âˆˆ {0, 1}J , such that fJâ†’x
has (1 âˆ’ Î´2 , Î´2 , Âµq )-small noisy inï¬‚uences. So Prxâˆ¼{0,1}J [x âˆˆ Q] > 1 âˆ’ Î´2 .
J

J

Let N âŠ† {0, 1} be the set of â€˜negligible partsâ€™ consisting of all x âˆˆ {0, 1} , such that Âµq (fJâ†’x ) <
Ç«/2. Note that
Pr [f (x) = 1 | xJ âˆˆ N ] â‰¤ max Pr [f (x) = 1 | xJ = y] â‰¤
yâˆˆN xâˆ¼Âµq

xâˆ¼Âµq

Ç«
.
2

Let A be the up-closure of Q/N , i.e. the set of all x âˆˆ {0, 1}J , such that there exists some
J
y âˆˆ Q\N that satisï¬es âˆ€i : yi â‰¤ xi . Finally, we let g : {0, 1} â†’ {0, 1} be the indicator function of
A.
Showing that Prxâˆ¼Âµq [f (x) > g (x)] < Ç«.
n
For each x âˆˆ {0, 1} with f (x) > g (x) we have g (x) = 0, and particularly x âˆˆ
/ Q\N. So we either
have x âˆˆ
/ Q or we have the unlikely event that f (x) = 1 although xJ âˆˆ N. The former event occurs
with probability at most Î´2 , and the latter event occurs with probability at most 2Ç« so
Pr [f (x) > g (x)] <

xâˆ¼Âµq

Ç«
+ Î´2 < Ç«,
2

provided that Î´2 is suï¬ƒciently small.
Showing that Prxâˆ¼Âµp [f (x) < g (x)] < Ç«.
Let y âˆˆ A, let x âˆˆ Q\N be with âˆ€i : xi â‰¤ yi , and let Ï =
Proposition 4.1 to obtain that

q

q(1âˆ’p)
p(1âˆ’q) .

Since x is in Q, we may apply

hTqâ†’p fJâ†’x , fJâ†’y i â‰¤ Î›Ï (Âµq (fJâ†’x ) , Âµp (fJâ†’y )) + Î´1 ,

(5.1)

provided that Î´2 is suï¬ƒciently small.
This gives us an upper bound on hTqâ†’p fJâ†’x , fJâ†’y i . On the other hand we may use the fact that
f is almost monotone to obtain a lower bound on hTqâ†’p fJâ†’x , fJâ†’y i as follows. Note that we have
Î´ â‰¥ hTqâ†’p f, 1 âˆ’ f i =
(5.2)

â‰¥
=

Pr

z,wâˆ¼D(q,p)

Pr

[f (z) = 1, f (w) = 0]




[zJ = x, wJ = y]
Pr
fJâ†’x z[n]\J = 1, fJâ†’y w[n]\J = 0

x,yâˆ¼({0,1}J ,D(q,p))

Pr

z,wâˆ¼D(q,p)

z,wâˆ¼D(q,p)
qâ†’p

[x = x, y = y] hT

fJâ†’x , 1 âˆ’ fJâ†’y i .

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

25

Thus,
hTqâ†’p fJâ†’x , fJâ†’y i = hTqâ†’p fJâ†’x , 1i âˆ’ hTqâ†’p fJâ†’x , 1 âˆ’ fJâ†’y i
(5.3)

â‰¥ Âµq (fJâ†’x ) âˆ’

Î´
Prx,yâˆ¼({0,1}J ,D(q,p)) [x = x, y = y]

â‰¥ Âµq (fJâ†’x ) âˆ’ Î´1 ,

provided that Î´ = Î´ (Î´1 , j, Ç«) is small enough. Combining (5.1) and (5.3) we obtain
Î›Ï (Âµq (fJâ†’x ) , Âµp (fJâ†’y )) â‰¥ Âµq (fJâ†’x ) âˆ’ 2Î´1 .

By Lemma 3.16 we have Âµp (fJâ†’y ) > 1âˆ’ 2Ç« provided that Î´1 is small enough (note that Âµq (fJâ†’x ) >
Ç«/2, since x âˆˆ
/ N ).
This shows that any y with g (y) = 1, f (y) = 0 satisï¬es the unlikely event that f (y) = 0 while
Âµp (fJâ†’yJ ) > 1 âˆ’ Ç«/2. Since a random y âˆ¼ Âµp satisï¬es this event with probability at most Ç«, we

obtain Pryâˆ¼Âµp [f (y) < g (y)] < Ç«. This completes the proof of the theorem.
We may repeat the proof of Theorem 2.5 to obtain the following lemma that we use in the proof
of Theorem 2.8.
Lemma 5.1. For each Ç« > 0, j âˆˆ N there exists Î´ > 0, such that the following holds. Let f, g : {0, 1}n â†’
[0, 1] be functions, let J be a set of size at most j, and let p, q âˆˆ (Ç«, 1 âˆ’ Ç«), be with p âˆ’ q > Ç«. Suppose
that hTqâ†’p f, 1 âˆ’ gi < Î´, and let x, y âˆˆ {0, 1}J be with âˆ€i : xi â‰¤ yi . Suppose additionally that fJâ†’x has
(1 âˆ’ Ç«, Ç«, Âµq )-small noisy influences. Then we either have Âµq (fJâ†’x ) < Ç« or we have Âµp (gJâ†’y ) > 1âˆ’Ç«.
Proof. Let Î´1 = Î´1 (Ç«) be suï¬ƒciently small, and let Î´ = Î´ (Î´1 , j) be suï¬ƒciently small. Similarly to
(5.2) we have
Î´ â‰¥ hTqâ†’p f, 1 âˆ’ gi â‰¥ hTqâ†’p fJâ†’x , 1 âˆ’ gJâ†’y i

Pr

x,yâˆ¼({0,1}J ,D(q,p))

[x = x, y = y] .

Similarly to (5.3) we have
hTqâ†’p fJâ†’x , gJâ†’y i â‰¥ Âµq (fJâ†’x ) âˆ’ Î´1 ,
provided that Î´1 is small enough. Similarly to (5.1), we have
Hence,

hTqâ†’p fJâ†’x , gJâ†’y i â‰¤ Î›Ï (Âµq (fJâ†’x ) , Âµp (gJâ†’y )) + Î´1 .

Î›Ï (Âµq (fJâ†’x ) , Âµp (gJâ†’y )) â‰¥ Âµq (fJâ†’x ) âˆ’ 2Î´1 .
As in the proof of Theorem (2.5), we may now apply Lemma 3.16 to complete the proof.



We shall now prove Theorem 2.8. We restate it for the convenience of the reader.
Theorem. For each Ç« > 0, there exists Î´ > 0, such that the following holds. Let q, p âˆˆ (Ç«, 1 âˆ’ Ç«) and
n
suppose that p > q + Ç«. Let f, g : {0, 1} â†’ [0, 1], and suppose that
and that the function f is

1
Î´

Ex,yâˆ¼D(q,p) [(1 âˆ’ g (y)) f (x)] < Î´,

, Î´, Âµq -regular. Then either Âµq (f ) < Ç«, or Âµp (g) > 1 âˆ’ Ç«.

Proof. Let Î´1 = Î´1 (Ç«) be suï¬ƒciently small, let j = j (Î´1 , Ç«) be suï¬ƒciently large, and let Î´ = Î´ (j, Î´1 , Ç«)
be suï¬ƒcientlysmall. ByTheorem 3.10, there exists a set J of size at most j, such that for a
random x âˆ¼ {0, 1}J , Âµq the function fJâ†’x does not have (1 âˆ’ Î´1 , Î´1 , Âµq )-small noisy inï¬‚uences
J

with probability at most Î´1 . Let Q âŠ† {0, 1} be the set of â€˜quasirandom elementsâ€™ consisting of all

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

26

J

x âˆˆ {0, 1} , such that fJâ†’x has (1 âˆ’ Î´1 , Î´1 , Âµq )-small noisy inï¬‚uences. Let A be the up-closure of Q.
Since A is monotone, we have
Âµp (A) â‰¥ Âµq (A) â‰¥ 1 âˆ’ Î´2 .

1
Moreover, the fact that f is Î´ , Î´, Âµq -regular implies that

Âµq (fJâ†’x ) â‰¥ Ç« âˆ’ Î´ > Ç«/2
o
n
for each x âˆˆ {0, 1} , provided that Î´ < min 2Ç« , 1j . By Lemma 5.1 (applied with Ç«/2 rather than
Ç«), we obtain that Âµp (gJâ†’x ) > 1 âˆ’ Ç«/2 for all x âˆˆ A. So this implies that
J

Âµp (g) â‰¥ (1 âˆ’ Ç«/2) Âµp (A) â‰¥ (1 âˆ’ Ç«/2) (1 âˆ’ Î´/2) > 1 âˆ’ Ç«.

This completes the proof of the theorem.



6. Counting matchings
In this section we prove Theorem 7.1 in the case where H is a matching.
Theorem 6.1. For each h âˆˆ N, Ç« > 0, there exists Î´ > 0, such that the following holds. Let
[n]
k1 , . . . , kh â‰¤ 1s âˆ’ Ç« n, and let F1 âŠ† [n]
measure is at least
k1 , . . . , Fh âŠ† kh be families whose
 
1
Ç«. Suppose that for each i âˆˆ [n], such that ki â‰¥ Î´n the family Fi is Î´ , Î´ -regular, and choose
uniformly at random a matching {A1 , . . . , Ah } , such that
 
 
[n]
[n]
A1 âˆˆ
, . . . , Ah âˆˆ
.
k1
kh
Then

Pr [A1 âˆˆ F1 , . . . , Ah âˆˆ Fh ] > Î´.
We start by stating some constructions that we shall use throughout the proof.
6.1. Basic constructions and overview of the proof. We completely identify between an element
n
x âˆˆ {0, 1} with the set of i âˆˆ [n] , such that xi = 1. Thus, we shall use the notations FJB , FJ1B
interchangeably, we write P (x) for the family of all subsets of {i : xi = 1} , we shall write xk for the
family of all subsets in P (x) whose size is k, and we write |x| for # {i : xi = 1} .

n
The ï¬rst construction that we need associates to each family F âŠ† [n]
a function fF : {0, 1} â†’
k
[0, 1] . This construction is originated in the work of Friedgut and Regev [34].

Definition 6.2. Let F âŠ† [n]
k , we associate to F the function fF deï¬ned by
(
0
|x| < k
fF (x) =
.
PrAâˆ¼(x) [A âˆˆ F ] |x| â‰¥ k
k

n

Another construction we need turns a function f : {0, 1} â†’ R into a Boolean function CutÎ´ (f ) .

Definition 6.3. Given a function f : {0, 1}n â†’ R, and a Î´ âˆˆ R, we deï¬ne the function CutÎ´ (f ) by
setting:
(
1 if f (x) â‰¥ Î´
CutÎ´ (f ) (x) =
.
0 if f (x) < Î´
We shall also need to introduce the following distributions.
Definition 6.4. Let p âˆˆ (0, 1) , and let k âˆˆ [n] .

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

27

n

â€¢ We write Âµâ‰¥k
for the conditional probability distribution on x âˆ¼ ({0, 1} , Âµp ) given that
p
<k
â‰¤k
|x| â‰¥ k. (The distributions Âµ>k
p , Âµp , Âµp are deï¬ned accordingly.)

â‰¥k
â€¢ We write Âµp , J â†’ B for the conditional distribution on sets A âˆ¼ Âµâ‰¥k
p given that A âˆ© J =
 

[n]
B. The distributions (Âµp , J â†’ B) , k , J â†’ B are deï¬ned accordingly.

Another construction we need is the construction of a random matchings
B1 , . . . , Bh âˆˆ P ([n]) ,

such that each of the sets Bi is distributed according to the

1
h -biased

distribution.

Definition 6.5. Choose uniformly and independently [0, 1]-valued random variables X1 , . . ., Xn . For
j
each i âˆˆ {1, . . . , h} we let Bi be the set of all j âˆˆ [n] , such that Xj is in the interval jâˆ’1
h , h . We call
1
the sets (B1 , . . . , Bh ) a random h -biased matching. Let k â‰¤ nh we call the conditional
 distribution on
1
1
matching (B1 , . . . , Bh ) given that |Bi | â‰¥ k for each i a h , k -biased matching.
a random h -biased

Given a h1 , k -biased matching (B1 , . . . , Bh ), we obtain that B1 is distributed according to some
matching
distribution that we denote by Âµ 1 ,k
.
h

Note that if (B1 , . . . , Bh ) a random h1 -biased matching, then each Bi is indeed chosen according
to the h1 -biased distribution, and moreover the sets B1 , . . . , Bh are pairwise disjoint with probability
1.
We will be concerned with the case where k â‰¤ nh âˆ’ Î˜ (n). This would yield that |Bi | â‰¥ k
asymptotically almost surely for all i. So intuitively,
the distribution of a h1 -biased matching is not

1
much diï¬€erent than the distribution of a h , k -biased matching.
The proof of Theorem 6.1 consists of three steps:
(In the following Ç«1 is suï¬ƒciently small and Ç«2 = Ç«2 (Ç«1 ) is suï¬ƒciently small)
(1) We set q to be slightly larger than nk . The
l ï¬rst
m step is to show that for each of the families
Fi of Theorem 6.1, the function fFi is

1
Ç«1

, Ç«1 , Âµq -regular.
matching
(2) The second step is to show that the measure Âµ 1 ,k
(CutÇ«2 (fFi )) is very close to 1.
h
This step is based on Theorem 2.8, and the proof roughly goes as follows.
â€¢ We show that the term Ex,yâˆ¼D(q, 1 ) [fFi (x) (1 âˆ’ CutÇ«2 (fFi (y)))] is always smaller than
h
Ç«2 .
â€¢ We shall apply Theorem 2.8 to deduce that Âµ h1 (CutÇ«2 (fFi )) is large.
matching
to deduce that Âµ 1 ,k
(CutÇ«2 (fFi ))
â€¢ We shall use the similarity between Âµ s1 and Âµmatching
1
h ,k
h
is large.

(3) We then ï¬nish the proof by observing that if we choose a h1 , k -biased matching B1 , . . . , Bh ,


Bh
1
and then choose sets M1 âˆ¼ B
k1 , . . . , Ms âˆ¼ kh . Then M1 , . . . , Mh is a uniformly random
matching. By Step 2 and a union bound we would have CutÇ«2 (fFi ) (Bi ) = 1 with high probability. On the other hand for each Bi with CutÇ«2 (fFi ) (Bi ) = 1, we have PrMi âˆ¼(Bi ) [Mi âˆˆ F ] â‰¥
ki

Ç«2 , and for each choice of disjoint B1 , . . . , Bh these events are independent. Therefore, the
probability that Mi is in F for each i cannot be much smaller than Ç«h2 .
We shall start with the proof of the ï¬rst step.

 
6.2. Showing that if F is regular, then the function fF is 1Ç« , Ç«, Âµq -regular. In order to
show that the function fF is regular, we will need to show that Âµq (fF ) is approximately Âµq ((fF )Jâ†’x )

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

28

 
J
for each |J| â‰¤ 1Ç« , and each x âˆˆ {0, 1} . In order to accomplish this we would need to write both
of the quantities Âµq (fF ) , Âµq ((fF )Jâ†’x ) in terms of F . We shall start by showing that Âµq (fF ) is
approximately equal to Âµ (F ) .
Lemma 6.6. For each Ç« > 0, there exists n0 > 0,
 such that the following holds. Let n > n0 , let
be some family. Then
q âˆˆ (0, 1) , k â‰¤ n satisfy q â‰¥ nk + Ç«, and let F âŠ† [n]
k
(6.1)

Âµq (fF ) â‰¤ Âµ (F ) â‰¤ Âµq (fF ) (1 + Ç«) .

Proof. We have
[fF (x)] + Pr [x < k] Exâˆ¼Âµ<k
[fF (x)] .
Âµq (fF ) = Exâˆ¼Âµq [fF (x)] = Pr [x â‰¥ k] Exâˆ¼Âµâ‰¥k
q
q
#
"
= Pr [|x| â‰¥ k] Exâˆ¼Âµâ‰¥k
q
xâˆ¼Âµq

Pr [A âˆˆ F ] .

Aâˆ¼(x
k)

However, whenever we choose x âˆ¼ Âµâ‰¥k
q , and an A âˆ¼

uniformly in [n]
.
Thus,
k
(6.2)

x
k


, we obtain a set A that is distributed

Âµq (fF ) = Pr [|x| â‰¥ k] Âµ (F ) .
xâˆ¼Âµq

The lemma follows by combining (6.2) with the fact that Prxâˆ¼Âµq [|x| â‰¥ k] tends to 1 as n tends to
inï¬nity.

We now turn to the task of approximating Âµq ((fF )Jâ†’x ) in terms of F . We show that for some
Î» > 0 the term Âµq ((fF )Jâ†’x ) can be approximated by
E
Câˆ¼(P(x),ÂµÎ» )

[Âµ (FJâ†’C )] .

Lemma 6.7. For each Ç« > 0 there exists n0 , such that the following holds. Let n > n0 , let k â‰¤ n
k
and let q be a number in the interval nk + Ç«, 1 , and set Î» = qn
. Then
Âµq ((fF )Jâ†’x ) (1 âˆ’ Ç«) â‰¤

E

Câˆ¼(P(x),ÂµÎ» )

[Âµ (FJâ†’C )] â‰¤ Âµq ((fF )Jâ†’x ) (1 + Ç«) .

Proof. As in Lemma 6.6, we have
(6.3)

Âµq ((fF )Jâ†’x ) =

Pr

yâˆ¼(Âµq ,Jâ†’x)

[|y| â‰¥ k]

E
yâˆ¼(Âµâ‰¥k
q ,Jâ†’x)

[fF (y)] .

Note that
Pr

yâˆ¼(Âµq ,Jâ†’x)

[|y| â‰¥ k] = 1 âˆ’ o (1) ,

where the o (1) is with respect to n tending to inï¬nity. So to complete the proof it remains show that
E
yâˆ¼(Âµâ‰¥k
q ,Jâ†’x)

[fF (y)] = (1 + o (1))

E
Câˆ¼(P(x),ÂµÎ» )

[Âµ (FJâ†’C )] .



y
Choose y âˆ¼ Âµâ‰¥k
q , J â†’ x ,A âˆ¼ k , then A âˆ© J is equal to some subset C of x. Note also that the
conditional distribution of A given that C =C is the distribution of a uniformly random element of

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS
[n]
k



29

that intersects J at the set C. Therefore,
E
yâˆ¼(Âµâ‰¥k
q ,Jâ†’x)

[fF (y)] =

Pr

y
yâˆ¼(Âµâ‰¥k
q ,Jâ†’x),Aâˆ¼( k )

X

CâŠ†x

(6.4)

=

[A âˆˆ F ]

Pr [C = C] Pr [A âˆˆ F | C = C]

X

CâŠ†x


Pr [C = C] Âµ FJC .

So to complete the proof it remains to show that
Pr [C = C] = Î»|C| (1 âˆ’ Î»)

(6.5)

|x|\|C|

(1 + o (1)) .

Indeed, with high probability |y| = qn (1 + o (1)) , and the conditional probability that C = C given
that |y| = s is


	
 |C| 
|x|\|C|
sâˆ’|x| 
 S âˆˆ y that satisfy |S âˆ© x| = C 
k
k
kâˆ’|C|
k
 y

=
1âˆ’
=
(1 + o (1)) .
s
 
s
s
k
k

Let s = |y| . Thus,

#
"  
|x|\|C|
|C|
k
k
1âˆ’
(1 + o (1))
Pr [C = C] = Es [Pr [C = C | s]] = Es
s
s
= Î»|C| (1 âˆ’ Î»)

|x|\|C|

(1 + o (1)) ,

where the last equality follows from the fact that
completes the proof of the lemma.

k
s

= Î» (1 + o (1)) with high probability. This



  
We are now ready to show that if F âŠ† [n]
is a 1Ç« , Ç« -regular family, and if we choose q that
k
1

is bounded from below away of nk , then the function fF is 2Ç«
, 2Ç«, Âµq -regular, provided that n is
suï¬ƒciently large.

Lemma 6.8. For each Ç« < 0, there exists n0 , such that the following holds. Let n > n0 , let F âŠ† [n]
k
1




be a 2Ç« , 2Ç« -regular family, and let q â‰¥ nk + Ç«. Then the function fF is 1Ç« , Ç«, Âµq -regular.

[n]
Proof. Fix Ç« > 0, let n0 be suï¬ƒciently large,
 1 and let F âŠ† k , be as in the hypothesis of the lemma.
Let B âŠ† J âŠ† [n] be sets, such that |J| â‰¤ Ç« . By Lemma 6.6
(6.6)

|Âµ (F ) âˆ’ Âµq (fF )| <

provided that n0 is large enough. By Lemma 6.7



(6.7)
Âµq ((fF )Jâ†’B ) âˆ’ E 

Câˆ¼ P(x),Âµ

provided that n0 is large enough.

k
qn

Ç«
,
4

Âµ

FJC



Ç«
< ,
 4

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

By hypothesis



(6.8)
Âµ (F ) âˆ’ E 

Câˆ¼ P(x),Âµ

k
qn

Âµ

FJC

 
 
 = E 
  Câˆ¼ P(x),Âµ
â‰¤E


Câˆ¼ P(x),Âµ

k
qn

k
qn





Âµ

FJC

Ç«
Ç«
= .
2
2



30



âˆ’ Âµ (F ) 


Thus,





C
Âµ F
|Âµq ((fF )Jâ†’B ) âˆ’ Âµq (fF )| â‰¤ Âµq ((fF )Jâ†’B ) âˆ’ E 
J 


Câˆ¼ P(x),Âµ k
qn






 Âµ F C âˆ’ Âµ (F ) + |Âµ (F ) âˆ’ Âµ (f )|
+ E 

q
F
J
 Câˆ¼ P(x),Âµ k

qn

Ç«
Ç«
Ç«
< + + = Ç«.
4 4 2
 

This completes the proof that fF is 1Ç« , Ç«, Âµq -regular.

 
6.3. Showing that if nk is small, then fF is 1Ç« , Ç«, Âµq -regular.



Lemma 6.9. For each Ç« > 0, there exists Î´ > 0 such that the following holds. Let


 
and let F âŠ† [n]
be some family. Then the function fF is 1Ç« , Ç«, Âµq -regular.
k
 
Proof. Let J be of size at most 1Ç« , and let B âŠ† J. We have

 


(6.9)
|Âµq ((fF )
) âˆ’ Âµq (fF )| â‰¤ Âµ F âˆ… âˆ’ Âµq (fF ) + Âµ F âˆ… âˆ’ Âµq ((fF )
J

Jâ†’B

J

k
n

< Î´, let q â‰¥ Ç«,


.

Jâ†’B )

We shall complete the proof by giving an upper bound of 2Ç« for each of the summands in the right
hand side of (6.9). 


Showing that Âµ FJâˆ… âˆ’ Âµq (fF ) â‰¤ 2Ç« .
By decreasing Î´ if necessary we may assume that n is as large as we wish. Therefore Lemma 6.6
implies that
Ç«
|Âµq (fF ) âˆ’ Âµ (F )| < ,
4
provided that Î´ is small enough. Now note that
X

(6.10)
Âµ (F ) =
Pr [A âˆ© J = B] Âµ FJB
[n]
BâŠ†J Aâˆ¼( k )
 |B| !

 
X


k
k
âˆ…
Âµ FJ +
Âµ FJB .
O
= 1âˆ’O
n
n
âˆ…6=BâŠ†J

So provided that Î´ is small enough, we have
 




Âµq (fF ) âˆ’ Âµ F âˆ…  â‰¤ |Âµq (fF ) âˆ’ Âµ (F )| + Âµ (F ) âˆ’ Âµ F âˆ…  â‰¤ Ç« + OÇ« k < Ç«/2.
J
J
4
n



âˆ…
Ç«
Showing that Âµ FJ âˆ’ Âµq ((fF )Jâ†’B ) < 2 .
By Lemma 6.9




|B|\|C|
X  k |C| 

 Ç«

k
C 
Âµq ((fF )
Âµ FJ  â‰¤ ,
1âˆ’
Jâ†’B ) âˆ’

qn
qn

 4
CâŠ†B

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

31

provided that n is large enough. Now note that similarly to (6.10) we have
|B|\|C|
 
X  k |C| 


k
k
âˆ…
C
1âˆ’
.
Âµ FJ = Âµ FJ + OÇ«
qn
qn
n
CâŠ†B

Thus,

 
 Ç«
Ç«
k
âˆ… 
< ,
+
O
)
âˆ’
Âµ
F
â‰¤
Ç«
Jâ†’B
J
4
n
2
provided that Î´ is small enough. This completes the proof of the lemma.

1

1
In the last two
6.4. Showing that if F is
Î´ , Î´, Âµq -regular, then Âµ h (CutÎ´ (fF )) is large.

1
sections we gave two criteria on a family F that imply that the function fF is Î´ , Î´, Âµq -regular
matching
(CutÎ´ (fF )) is large. As
for a small Î´. We shall now show that both criteria imply that Âµ 1 ,k
Eh
D 1
mentioned, we will ï¬rst show that the pair T h â†’q fF , CutÎ´ (fF ) < Ç«. We would then deduce from
Theorem 2.8 that Âµ h1 (CutÎ´ (fF )) is large, and this would allow us to ï¬nish the proof by using the
matching
fact that the distributions Âµ 1 ,k
, Âµ h1 are very close to each other.

Âµq ((fF )

h

Lemma 6.10. Let Î´ > 0, let p > q >

k
n.

For any F âŠ†

[n]
k



we have

Ex,yâˆ¼D(q,p) [fF (x) (1 âˆ’ CutÎ´ (fF ) (y))] â‰¤ Î´.
Proof. We show that the stronger statement that for each value y of y, we obtain that if we choose
conditionally x, y âˆ¼ D (q, p) given that y = y, then
(6.11)

Ex [fF (x) (1 âˆ’ CutÎ´ (fF ) (y))] â‰¤ Î´.

This clearly holds if CutÎ´ (fF ) (y) = 1. So suppose that CutÎ´ (fF ) (y) = 0, we also suppose that
|y| â‰¥ k for otherwise we would have |x| < k, and hence fF (x) = 0. Now note that
#
"
Ex [fF (x)] â‰¤ Ex

Pr [A âˆˆ F ] | |x| â‰¥ k = Pr [A âˆˆ F ] = fF (y) â‰¤ Î´.
Aâˆ¼(y
k)

Aâˆ¼(x
k)

This completes the proof of the lemma.



We shall now complete the second step of showing that Âµ h1 (CutÎ´ (fF )) is large.
Lemma 6.11. For each Ç« > 0, there exists Î´ > 0, such that the following holds. Let p â‰¥ nk + Ç«, and

let F âŠ† [n]
be some
k 
 family whose measure is at least Ç«. Suppose that we either have k â‰¤ Î´n or the
family F is Î´1 , Î´ -regular. Then
Âµp (CutÎ´ (fF )) > 1 âˆ’ Ç«.

Proof. Let q =

k
n

+ 2Ç« , and note that by Lemma 6.10 we have
Ex,yâˆ¼D(q,p) [fF (x) (1 âˆ’ CutÎ´ (fF ) (y))] â‰¤ Î´.

By decreasing Î´ if necessary, we may assume that n is suï¬ƒciently large for Lemma 6.6 to imply that
Âµq (fF ) â‰¥ 2Ç« . By Theorem 2.8 (applied with 2Ç« rather than Ç«) we have Âµp (fF ) â‰¥ 1 âˆ’ 2Ç« > 1 âˆ’ Ç«,
provided that Î´ is small enough. This completes the proof of the lemma.


HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

32

matching
are â€˜closeâ€™, and
We now complete the ï¬nal step of deducing from the fact that Âµ h1 and Âµ 1 ,k
h
matching
from the fact that Âµ h1 (CutÎ´ (fF )) is large, that Âµ 1 ,k
(CutÎ´ (fF )) is in fact also large.
h

Corollary 6.12. For each Ç« > 0, h there exists Î´ > 0, such that the following holds. Let nk â‰¤ h1 âˆ’ Ç«,

and let F âŠ† [n]
k besome
 family whose measure is at least Ç«. Suppose that we either have k â‰¤ Î´n or
the family F is Î´1 , Î´ -regular. Then
Âµmathching
(CutÎ´ (fF )) â‰¥ 1 âˆ’ Ç«.
1
,k
h

Proof. By Lemma 6.11, we have Âµ h1 (CutÎ´ (fF )) > 1 âˆ’ 2Ç« provided that Î´ is small enough. Also note
that we may assume that n is suï¬ƒciently large by decreasing Î´ if necessary.

We shall now deï¬ne a coupling between h1 -biased matching, and h1 , k -biased matchings as follows.
We choose a h1 -biased matching M1 , M2 , . . . , Mh , and we then let Mâ€²1 , . . . , Mâ€²s to be equal to the
original 1s -biased matching if the (likely) event âˆ€i : |Mi | â‰¥ k occurred, and we let it be equal to a
new h1 , k -biased matching otherwise. Note that
Pr [M1 âˆˆ CutÎ´ (fF )] = Âµ h1 (CutÎ´ (fF )) ,

and that
matching
Pr [Mâ€²1 âˆˆ CutÎ´ (fF )] = Âµ 1 ,k
(CutÎ´ (fF )) .
h

Thus,
matching
(CutÎ´ (fF )) â‰¥ Âµ h1 (CutÎ´ (fF )) âˆ’ Pr [M1 6= Mâ€²1 ] â‰¥ 1 âˆ’ Ç«,
Âµ 1 ,k
h

provided that n is suï¬ƒciently large to imply Pr [M1 6= Mâ€²1 ] < 2Ç« .



6.5. Proof of Theorem 6.1.
[n]
k1


, . . . , Fh âŠ†

[n]
kh



be some families that satisfy the hypothesis of
(Î´â€² )h
the theorem, let Î´ â€² = Î´ â€² (Ç«) be suï¬ƒciently small, and let Î´ = 3 . By Corollary 6.12,

Proof of Theorem 6.1. Let F1 âŠ†

1
matching
Âµ 1 ,k
(CutÎ´â€² (fFi )) > 1 âˆ’
h
2h

for each i, provided that Î´ â€² is small enough. A union bound implies that if we choose a h1 , k -biased
matching A1 , . . . , Ah , then the event âˆ€i CutÎ´â€² (fFi )(Ai ) = 1 happens with probability greater than
Ai
1
2 . Now choose independently a matching Mi âˆ¼ ki . For each choice of values A1 , . . . , Ah of the sets
h

A1 , . . . , Ah , we obtain that the events {Mi âˆˆ Fi |Ai = Ai }i=1 are independent. Therefore
Pr [âˆ€i : M i âˆˆ Fi ] â‰¥ Pr [âˆ€i CutÎ´ (fFi ) (Ai ) = 1] Î´ â€²h â‰¥

Î´ â€²h
= Î´.
2

This completes the proof of the theorem, since the hypergraph {M1 , . . . , Mh } is a uniformly random
matching.


HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

33

7. Counting expanded hypergraphs
We shall now generalize Theorem 6.1 to general expanded hypergraphs.
Theorem 7.1. For each c, h âˆˆ N, Ç« > 0 there exists Î´ > 0, such
that the following holds. Let

[n]
1
1
be
sets,
such that the hypergraph
â‰¤
k
,
.
.
.
,
k
â‰¤
âˆ’
Ç«
n
be
some
numbers,
and
let
A
âˆˆ
1
h
i
Î´
h
ki


[n]
families of
H = {A1 , . . . , Ah } has center of size at most c. Let F1 âŠ† k1 , . . . , Fh âŠ† [n]
kh be some
  
measure at least Ç«. Suppose that for each i, we either have kni â‰¤ Î´ or the family Fi is Î´1 , Î´ -regular.


[n]
Choose uniformly at random a copy (A1 , . . . , Ah ) âˆˆ [n]
k1 Ã— Â· Â· Â· Ã— kh of H. Then
Pr [A1 âˆˆ F1 , . . . , Ah âˆˆ Fh ] > Î´.

Note that H âŠ† P (V ) can be written in the form

{E1 âˆª D1 , . . . , Eh âˆª Dh } ,

where C := E1 âˆª Â· Â· Â· âˆª Eh is the center of H, and where the sets C, D1 , . . . , Dh are pairwise disjoint.
If Ï€ : V â†’ [n] is a random injection, then Ï€ (E1 âˆª D1 ) , . . . , Ï€ (Eh âˆª Dh ) is a uniformly random copy
of H. Write Ei = Ï€ (Ei ) , Di = Ï€ (Di ) , and C = Ï€ (C) . Our basic observation is that the following
events are equal.
(1) The families F1 , . . . , Fh cross contain the random copy of H
(Ï€ (E1 âˆª D1 ) , . . . , Ï€ (Eh âˆª Dh )) = (E1 âˆª D1 , . . . , Eh âˆª Dh ) .

i
(2) The families (Fi )E
C cross contain the uniformly random matching D1 , . . . , Dh .

E

Therefore it is natural to try to apply Theorem 6.1 on the families (Fi )Ci . As it turns out, the only
Ei
hypothesis

 of Theorem 6.1 that the families (Fi )C do not obviously satisfy is the hypothesis that
E

Âµ (Fi )Ci

> Ç«. The following Fairness Proposition by Keller and the author [43, Proposition 5.1]
E

allows us to deduce that the families (Fi )Ci are of measure greater than Ç« with high probability. To
state their result we need to introduce the notion of fairness. Roughly speaking, a set J is â€˜fairâ€™ for
F if the measures of each of the families FJB is not signiï¬cantly smaller than the measure of F .
Definition 7.2. A set J is Ç«-fair for F if


Âµ FJB â‰¥ (1 âˆ’ Ç«) Âµ (F )

for any B âŠ† J.


The Fairness Proposition tells us that for any F âŠ† [n]
k and any J âˆ¼
probability, provided that k is not too close to either 0 or n.

[n]
s



is Ç«-fair for F with high

Proposition 7.3. For each Ç«, s > 0, there exists m > 0 such that the following
holds. Let m < k <

[n]
[n]
n âˆ’ m, let F âŠ† k be some family of measure at least Ç«, and let J âˆ¼ s . Then
Pr [J is Ç«-fair for F ] â‰¥ 1 âˆ’ Ç«.

i
Proof of Theorem 7.1 . Let E i , C, D i be as above. Our goal is to show that the families (Fi )E
C cross
contain the uniformly random matching D1 , . . . , Dh with probability â‰¥ Î´. Noting that the size of C
is ï¬xed, the following observations are easy to verify provided that Î´ is suï¬ƒciently small:
â€¢ Proposition 7.3, implies that the set C is 12 -fair with probability at least 12 . For any such C
[n]\C 
i
Ç«
the measure of the family (Fi )E
C âŠ† ki âˆ’|Ei | is at least 2 .

â€¢ For any i such that

ki
n

< Î´, we have

ki âˆ’|Ei |
nâˆ’|C|

< 2Î´.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

34


1
  
E
, 2Î´ -regular.
â€¢ If Fi is 1Î´ , Î´ -regular, then (Fi )Ci is 2Î´
We shall also assume that the Î´ of this lemma is small enough for Theorem 6.1 to hold with 2Î´
replacing Î´, and 2Ç« replacing Ç«. These observations allow us to apply Theorem 6.1, and to deduce that

Câ€²
we have
for each set C â€² that is 21 -fair for F , and for each set Eiâ€² âˆˆ |E
i|
i
h
Pr âˆ€i : Di âˆˆ FCEâ€²i > 2Î´.
Therefore,


 

i
h
1
1
Ei
Ei
Pr âˆ€i : Di âˆˆ FC â€² â‰¥ Pr C is -fair Pr âˆ€i : Di âˆˆ FC | C is -fair > Î´.
2
2

This completes the proof of the theorem.



8. Removal lemma for expanded hypergraphs
In this section we prove Theorem 1.13, Proposition 1.14, and Theorem 1.11.
Let H = {A1 , . . . , Ah } âŠ† P (V ) . Any hypergraphs of the form {A1 âˆ© S, . . . , Ah âˆ© S} is called a
trace of H. We shall need the following lemma.
Lemma 8.1. For each h, c, s, j âˆˆ N, Ç« > 0 there exists Î´ > 0, such that the following holds. Let H be
a hypergraph with h edges whose center is of size c, and let G âŠ† P (J). Let Î´1 â‰¤ k â‰¤ h1 âˆ’ Ç« n. Then
the following are equivalent.
(1) The junta hGi is (H, s)-free.
(2) There exists no copy of a trace of H in G, whose center is of size at most s.
Proof. We start by showing that if (2) does not hold, then (1) does not holds. By hypothesis, there
[n]\J 
exist a trace {C1 , . . . , Ch } of H in G whose center is of size at most s. Let B1 âˆˆ kâˆ’|C
, . . . , Bh âˆˆ
1|
[n]\J 
be some pairwise disjoint sets (such sets exist provided that Î´ is large enough). Then the
kâˆ’|Ch |
hypergraph {C1 âˆª B1 , . . . , Ch âˆª Bh } is contained in hGi, it is the resolution of the hypergraph H and
its center is of size at most s. Therefore, the family hGi is not (H, s)-free and so (1) does not hold.
We now show that if (1) does not hold, then (2) does not holds. Let {A1 , . . . , Ah } âŠ† hGi be a
resolution of H whose center is of size at most s. The hypergraph {A1 âˆ© J, . . . , Ah âˆ© J} is contained
in G, its center is of size at most s, and in order to complete the proof we need to show that it is a
trace of H.
For each i = 1, . . . , h let Di âŠ† [n] \J be a suï¬ƒciently large set that is contained in Ai and does
not intersect any other edge of H. The fact that {A1 , . . . , Ah } is a resolution of H implies that there
exist sets E1 , . . . , Eh âŠ† [n] \J, such that
Hâ€² := {(A1 \D1 ) âˆª E1 , . . . , (Ah \Dh ) âˆª Eh }

is a copy of H. Now note that if we intersect each of the edges of Hâ€² with J, we obtain the original
hypergraph {A1 âˆ© J, . . . , Ah âˆ© J} . Therefore, A1 âˆ©J, . . . , Ah âˆ©J is indeed a trace of H. This completes
the proof of the lemma.

We will also need the following lemma.

Lemma 8.2. Let Ç« > 0, s â‰¤ c, h âˆˆ N be some constants. Let Ç«n â‰¤ k â‰¤ h1 âˆ’ Ç« n, let H be a k-uniform
hypergraph whose center is of size c. Let {A1 , . . . , Ah } be a uniformly random copy of H, let J âŠ† [n]
be some set of size at most 1Ç« , and let {B1 , . . . , Bh } âŠ† P (J) be a trace of H of center of size s. Then
s 
the probability that Ai âˆ© J = Bi for each i is Î˜ n1
.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

35

Proof. Let C be the center of {A1 , . . . , Ah }, let Ci = C âˆ© Ai , and let Di = Ai \C for each i.
Similarly, let C be the center of {B1 , . . . , Bh } , write Ci = Bi âˆ© C, and Di = Bi \C. We deï¬ne the
following three events:
â€¢ We let E0 be the event that C âˆ© J = C
â€¢ We let E1i be the event that Ci âˆ© J = Ci .
â€¢ We let E2i be the event that Di âˆ© J = Di .
Note that the event that Ai âˆ© J = Bi for each i is the intersection of all the above events. The

(nâˆ’j )
= Î˜ n1s , once we show that
lemma will follow from the fact that E0 occurs with probability câˆ’d
(nc)
the other events occur with conditionalTprobability Î˜ (1) given that E0 holds.
Since |C| = c is constant, the event E1i occur hwith conditional probability
i Î˜ (1) given E0 .
Th
i
1
h
We now complete the proof by showing that Pr i=1 E2 |E1 , . . . , E1 , E0 is Î˜ (1) .

[n]\C1
, then taking a set
Note that D1 , . . . , Dh may be chosen by ï¬rst taking a set D1 âˆ¼ kâˆ’|C
1|
S

D
[n]\(Câˆª hâˆ’1
)
[n]\(CâˆªD1 )
i
i=1
. Since for each i the term
D âˆ¼
, and so on until we choose a set D âˆ¼
2

kâˆ’|C2 |
kâˆ’|Ci |
P
nâˆ’|C|âˆ’ h
i=1 |Dh |

h

kâˆ’|Ch |

is bounded away from 0 to 1, we have

This completes the proof.

Pr [âˆ€i : Di âˆ© J=Di ] = Î˜ (1) .


We now prove the following restatement of Theorem 1.13.
Theorem. For each h, c, Ç«, s âˆˆ N, there exists Î´, j > 0, such that the following holds. Let H be a
hypergraph with h edges whose center is of size c. Let


1
1
â‰¤kâ‰¤
âˆ’ Ç« n,
Î´
h
and let F be a

Î´
ns -almost

H-free family. Then F is Ç«-essentially contained in an (H, s)-free j-junta.

Proof of Theorem 1.13. Let Î´1 = Î´1 (h, c, Ç«, s) be suï¬ƒciently small, let j = j (Î´1 ) be suï¬ƒciently large,
and let Î´ = Î´ (j) be suï¬ƒciently small. By Theorem 7.1 we may take J to be âˆ… if nk < Î´1 , provided
that Î´1 is suï¬ƒciently small. So suppose that nk > Î´1 . By Theorem 3.12, there exists a set J and a
family G âŠ† P (J) l
, suchm that
in J := hGi, and such that for each B âˆˆ G
 F is Ç«-essentially contained
 Ç«
1
B
B
â‰¥ 2.
the family FJ is
Î´1 , Î´1 -regular and Âµ FJ
Showing that J is (H, s)-free.
By Lemma 8.1 it is enough to show that G does not contain a trace of H in G whose center is of
size at most s. Suppose on the contrary that {C1 , . . . , Ch } is a trace of H in G whose center is of size
at most s. Then there exist sets B1 , . . . , Bh âŠ† [n] \J, such that Hâ€² = {C1 âˆª B1 , . . . , Ch âˆª Bh } is a
copy of H. Let {H1 , . . . , Hh } be a random copy of H on [n] . By Lemma 8.2 we have
 
1
,
Pr [âˆ€i : Hi âˆ© J = Ci ] = â„¦Î´1 ,j
ns
and we have
i
h
Pr [{H1 , . . . , Hh } âŠ† F | âˆ€i : Hi âˆ© J = Ci ] = Pr âˆ€i : Hi \J âˆˆ FJCi .
l m

1
Now note the families FJCi are
-regular and have measure greater than 2Ç« . Provided that
,
Î´
1
Î´1

Î´1 is small enough, we may apply Theorem 7.1 with Ç«/2 instead of Ç«, the hypergraph (H 1 \J, . . . , H h \J),

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

and Î´1 instead of Î´, to obtain

36

h
i
Pr âˆ€i : Hi \J âˆˆ FJCi â‰¥ Î´1 .

Putting everything together, we obtain

Pr [{H1 , . . . , Hh } âŠ† F ] â‰¥ Pr [{H1 , . . . , Hh } âŠ† F | âˆ€i : Hi âˆ© J = Ci ] Â· Pr [âˆ€i : Hi âˆ© J = Ci ]
 
1
.
= â„¦Î´1 ,Ç«
ns
Provided that Î´ is small enough, this contradicts the hypothesis.



Note that in the proof of Theorem 1.13, the hypothesis k > Î´1 is not needed in the case where H
is a matching as we may apply Theorem 6.1 rather than Theorem 7.1.
We shall now prove Proposition 1.14. We restate it for the convenience of the reader.
Proposition. For each constants h, c, j, s âˆˆ N, there exists a constant C > 0, such that thefollowing
holds. Let H be a hypergraph with h edges whose center is of size c. Let Ç«n â‰¤ k â‰¤ n h1 âˆ’ Ç« , and let
C
-almost H-free.
J be some (H, s)-free j-junta. Then J is ns+1
Proof. Let {A1 , . . . , Ah } be a random copy of H, and let J be a set of size at most j, such that J
depends on J. Let C1 = A1 âˆ©J, . . . , Ch = Ah âˆ©J. Since J is (H, s)-free, we obtain by Lemma 8.1 that
for any copy {A1 , . . . , Ah } of H in J the center of {A1 âˆ© J, . . . , Ah âˆ© J} is of size at least s + 1. Now
1
for any hypergraph C1 , . . . , Ch of center of size at least s + 1 we have Pr [âˆ€i : Ci = Ci ] = O ns+1
by Lemma 8.2. Since there are only a constant number of subsets{C1 , . . . , Ch } âŠ† P (J) , we obtain
1
. This completes the proof of the
that{A1 , . . . , Ah } is a copy of H with probability at most O ns+1
proposition.

Finally we shall prove Theorem 1.11 that we restate for the convenience of the reader.
Theorem.
For each h, d âˆˆ N, Ç« > 0 there exists C, Î´ > 0 such that the following holds. Let C â‰¤ k â‰¤

1
âˆ’
Ç«
n,
and
let H be a k-uniform (h, d)-expanded hypergraph, then we have the following.
h
(1) If the family F is Î´-almost H-free, then F is Ç«-essentially contained in an Mh -free family.
(2) Conversely, if the family F is Î´-essentially contained in an Mh -free family, then F is Ç«-almost
H-free.

Proof of Theorem 1.11. (1) =â‡’ (2) follows by applying Theorem 1.13 with s = 0, noting that a
family is (H, 0)-free if and only if it is free of a matching. We now show the converse implication.
Ç«
Suppose that (2) holds. By Theorem (1.13) F is h+1
-essentially contained in an Mh -free junta,
provided that Î´ is small enough. Let {A1 , . . . , Ah } be a random copy of H. Note that the event
{A1 , . . . , Ah } âŠ† F can occur only if for some i we have Ai âˆˆ J \F , or if {A1 , . . . , Ah } âŠ† J . So
a union bound implies that it is enough to show that each of these events occurs with probability
Ç«
< h+1
.

Ç«
, provided that C
By Proposition 1.14 a random copy of H lies in J with probability O n1 < h+1
is suï¬ƒciently
large
to
imply
the
needed
lower
bound
on
n.
Moreover,
each
A
is
uniformly
distributed
i

[n]
Ç«
in k . Therefore, for each i the probability that Ai is in F but not in J is at most h+1
. This
completes the proof of the theorem.

Acknowledgment. I would like to thank Nathan Keller for providing many helpful comments and
suggestions, which tremendously improved the exposition of the paper.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

37

References
[1] Amirali Abdullah and Suresh Venkatasubramanian. A directed isoperimetric inequality with application to bregman near neighbor lower bounds. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of
Computing, pages 509â€“518. ACM, 2015.
[2] Daniel Ahlberg, Erik Broman, Simon Griï¬ƒths, and Robert Morris. Noise sensitivity in continuum percolation.
Israel Journal of Mathematics, 201(2):847â€“899, 2014.
[3] Rudolf Ahlswede and Levon H. Khachatrian. The complete nontrivial-intersection theorem for systems of ï¬nite
sets. journal of combinatorial theory, Series A, 76(1):121â€“138, 1996.
[4] JÃ³zsef Balogh, Robert Morris, and Wojciech Samotij. Independent sets in hypergraphs. Journal of the American
Mathematical Society, 28(3):669â€“709, 2015.
[5] William Beckner. Inequalities in fourier analysis. Annals of Mathematics, pages 159â€“182, 1975.
[6] Michael Ben-Or and Nathan Linial. Collective coin ï¬‚ipping. randomness and computation, 5:91â€“115, 1990.
[7] BÃ©la BollobÃ¡s and Arthur G Thomason. Threshold functions. Combinatorica, 7(1):35â€“38, 1987.
[8] Aline Bonami. Ã‰tude des coeï¬ƒcients de fourier des fonctions de lp (g). In Annales de lâ€™institut Fourier, volume 20,
pages 335â€“402, 1970.
[9] Christer Borell. Geometric bounds on the ornstein-uhlenbeck velocity process. Probability Theory and Related
Fields, 70(1):1â€“13, 1985.
[10] Jean Bourgain and Gil Kalai. Inï¬‚uences of variables and threshold intervals under group symmetries. Geometric
and Functional Analysis, 7(3):438â€“461, 1997.
[11] David Conlon and Jacob Fox. Graph removal lemmas. Surveys in combinatorics, 1(2):3, 2013.
[12] David Conlon and William Timothy Gowers. Combinatorial theorems in sparse random sets. Annals of Mathematics, 184:367â€“454, 2016.
[13] Das Shagnik and Tuan Tran. Removal and Stability for ErdÅ‘sâ€“Koâ€“Rado. SIAM Journal on Discrete Mathematics,
30(2): 1102-1114, 2016.
[14] Mikhail Deza, Paul ErdÅ‘s, and Peter Frankl. Intersection properties of systems of ï¬nite sets. Proc. London Math.
Soc., 36(2):369â€“384, 1978.
[15] Irit Dinur and Ehud Friedgut. Intersecting families are essentially contained in juntas. Combinatorics, Probability
and Computing, 18(1-2):107â€“122, 2009.
[16] Irit Dinur, Elchanan Mossel, and Oded Regev. Conditional hardness for approximate coloring. SIAM Journal on
Computing, 39(3):843â€“873, 2009.
[17] David Ellis, Nathan Keller, and Noam Lifshitz. Stability versions of ErdÅ‘sâ€“Koâ€“Rado type theorems, via isoperimetry. arXiv preprint arXiv:1604.02160, 2016.
[18] David Ellis, Nathan Keller, and Noam Lifshitz. Stability for the complete intersection theorem, and the forbidden
intersection problem of ErdÅ‘s and SÃ³s. arXiv preprint arXiv:1604.06135, 2017.
[19] Paul ErdÅ‘s. A problem on independent r-tuples. Ann. Univ. Sci. Budapest, 8:93â€“95, 1965.
[20] Paul ErdÅ‘s. Problems and results in graph theory and combinatorial analysis. Proc. British Combinatorial Conj.,
5th, pages 169â€“192, 1975.
[21] Paul ErdÅ‘s, Chao Ko, and Richard Rado. Intersection theorems for systems of ï¬nite sets. The Quarterly Journal
of Mathematics, 12(1):313â€“320, 1961.
[22] Yuval Filmus. Ahlswede-Khachatrian theorems:
Weighted, inï¬nite, and Hamming. arXiv preprint
arXiv:1610.00756, 2016.
[23] Jacob Fox. A new proof of the graph removal lemma. Annals of Mathematics, pages 561â€“579, 2011.
[24] Peter Frankl. The ErdÅ‘sâ€“Koâ€“Rado theorem is true for n = ckt. combinatorics (proc. ï¬fth hungarian colloq.,
keszthey, 1976), vol. i, 365â€“375. In Colloq. math. Soc. JÃ¡nos Bolyai, volume 18.
[25] Peter Frankl. On families of ï¬nite sets no two of which intersect in a singleton. Bulletin of the Australian Mathematical Society, 17(1):125â€“134, 1977.
[26] Peter Frankl. ErdÃ¶s-ko-rado theorem with conditions on the maximal degree. Journal of Combinatorial Theory,
Series A, 46(2):252â€“263, 1987.
[27] Peter Frankl. Improved bounds for erdÅ‘s matching conjecture. Journal of Combinatorial Theory, Series A,
120(5):1068â€“1072, 2013.
[28] Peter Frankl and ZoltÃ¡n FÃ¼redi. Forbidding just one intersection. Journal of Combinatorial Theory, Series A,
39(2):160â€“176, 1985.
[29] Peter Frankl and ZoltÃ¡n FÃ¼redi. Exact solution of some TurÃ¡n-type problems. Journal of Combinatorial Theory,
Series A, 45(2):226â€“262, 1987.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

38

[30] Peter Frankl and VojtÄ›ch RÃ¶dl. Forbidden intersections. Transactions of the American Mathematical Society,
300(1):259â€“286, 1987.
[31] Ehud Friedgut. Boolean functions with low average sensitivity depend on few coordinates. Combinatorica,
18(1):27â€“35, 1998.
[32] Ehud Friedgut. Sharp thresholds of graph properties, and the k-sat problem (with an appendix by Jean Bourgain).
Journal of the American Mathematical Society, 12(4):1017â€“1054, 1999.
[33] Ehud Friedgut and Gil Kalai. Every monotone graph property has a sharp threshold. Proceedings of the American
mathematical Society, 124(10):2993â€“3002, 1996.
[34] Ehud Friedgut and Oded Regev. Kneser graphs are like swiss cheese. Discrete Analysis, 2:0â€“18, 2018.
[35] ZoltÃ¡n FÃ¼redi, Tao Jiang, and Robert Seiver. Exact solution of the hypergraph TurÃ¡n problem for k-uniform
linear paths. Combinatorica, 34(3):299â€“322, 2014.
[36] William Timothy Gowers. Quasirandomness, counting and regularity for 3-uniform hypergraphs. Combinatorics,
Probability and Computing, 15(1-2):143â€“184, 2006.
[37] William Timothy Gowers. Hypergraph regularity and the multidimensional szemerÃ©di theorem. Annals of Mathematics, pages 897â€“946, 2007.
[38] L. Gross. Logarithmic sobolev inequalities. American J. Math., 97:1061â€“1083, 1975.
[39] Hamed Hatami. A structure theorem for boolean functions with small total inï¬‚uences. Annals of Mathematics,
176(1):509â€“533, 2012.
[40] Chris Jones. A noisy-inï¬‚uence regularity lemma for boolean functions. arXiv preprint arXiv:1610.06950, 2016.
[41] Peter Keevash. Hypergraph TurÃ¡n problems. Surveys in combinatorics, 392:83â€“140, 2011.
[42] Peter Keevash, Dhruv Mubayi, and Richard M. Wilson. Set systems with no singleton intersection. SIAM Journal
on Discrete Mathematics, 20(4):1031â€“1041, 2006.
[43] Nathan Keller and Noam Lifshitz. The junta method for hypergraphs and chvÃ¡talâ€™s simplex conjecture. arXiv
preprint arXiv:1707.02643, 2017.
[44] Alexandr Kostochka, Dhruv Mubayi, and Jacques VerstraÃ«te. TurÃ¡n problems and shadows I: paths and cycles.
Journal of Combinatorial Theory, Series A, 129:57â€“79, 2015.
[45] Alexandr Kostochka, Dhruv Mubayi, and Jacques VerstraÃ«te. TurÃ¡n problems and shadows III: expansions of
graphs. SIAM Journal on Discrete Mathematics, 29(2):868â€“876, 2015.
[46] Alexandr Kostochka, Dhruv Mubayi, and Jacques VerstraÃ«te. TurÃ¡n problems and shadows II: trees. Journal of
Combinatorial Theory, Series B, 122:457â€“478, 2017.
[47] Willem Mantel. Problem 28. Wiskundige Opgaven, 10(60-61):320, 1907.
[48] Elchanan Mossel. Gaussian bounds for noise correlation of functions. Geometric and Functional Analysis,
19(6):1713â€“1756, 2010.
[49] Elchanan Mossel. Majority is asymptotically the most stable resilient function. arXiv preprint arXiv:1704.04745,
2017.
[50] Elchanan Mossel, Ryan Oâ€™Donnell, and Krzysztof Oleszkiewicz. Noise stability of functions with low inï¬‚uences:
Invariance and optimality. Annals of Mathematics, pages 295â€“341, 2010.
[51] Dhruv Mubayi and Jacques VerstraÃ«te. A survey of TurÃ¡n problems for expansions. In Recent Trends in Combinatorics, pages 117â€“143. Springer, 2016.
[52] Brendan Nagle, VojtÄ›ch RÃ¶dl, and Mathias Schacht. The counting lemma for regular k-uniform hypergraphs.
Random Structures & Algorithms, 28(2):113â€“179, 2006.
[53] Ryan Oâ€™Donnell. Analysis of boolean functions. Cambridge University Press, 2014.
[54] VojtÄ›ch RÃ¶dl and Jozef Skokan. Regularity lemma for k-uniform hypergraphs. Random Structures & Algorithms,
25(1):1â€“42, 2004.
[55] Lucio Russo. An approximate zero-one law. Probability Theory and Related Fields, 61(1):129â€“139, 1982.
[56] Imre Z. Ruzsa and Endre SzemerÃ©di. Triple systems with no six points carrying three triangles. Colloq. Math.
Soc. JÃ¡nos Bolyai, 18:939â€“945, 1978.
[57] Wojciech Samotij. Stability results for random discrete structures. Random Structures & Algorithms, 44(3):269â€“
289, 2014.
[58] David Saxton and Andrew Thomason. Hypergraph containers. Inventiones mathematicae, 201(3):925â€“992, 2015.
[59] Mathias Schacht. Extremal results for random discrete structures. Annals of Mathematics, 184(2):333â€“365, 2016.
[60] MiklÃ³s Simonovits. A method for solving extremal problems in graph theory, stability problems. In Theory of
Graphs (Proc. Colloq., Tihany, 1966), pages 279â€“319, 1968.
[61] Terence Tao. A variant of the hypergraph removal lemma. Journal of combinatorial theory, Series A, 113(7):1257â€“
1280, 2006.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

[62] PÃ¡l TurÃ¡n. On an extremal problem in graph theory (in Hungarian). Mat. Fiz. Lapok, 48:436â€“452, 1941.

39

