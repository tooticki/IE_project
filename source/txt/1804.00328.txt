arXiv:1804.00328v2 [math.CO] 21 Sep 2018

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD
THEOREMS
NOAM LIFSHITZ
Abstract. The classical sharp threshold theorem of Friedgut and Kalai (1996) asserts that any
symmetric monotone function f : {0, 1}n → {0, 1} exhibits a sharp threshold phenomenon. This
means that the expectation of f with respect to the biased measure µp increases rapidly from 0 to
1 as p increases.
In this paper we present ‘robust’ versions of the theorem, which assert that it holds also if the
function is ‘almost’ monotone, and admits a much weaker notion of symmetry. Unlike the original
proof of the theorem which relies on hypercontractivity, our proof relies on a ‘regularity’ lemma (of
the class of Szemerédi’s regularity lemma and its generalizations) and on the ‘invariance principle’
of Mossel, O’Donnell, and Oleszkiewicz which allows (under certain conditions) replacing functions
on the cube {0, 1}n with functions on Gaussian random variables.
The hypergraph removal lemma of Gowers (2007) and independently of Nagle, Rödl, Schacht,
and Skokan (2006) says that if a k-uniform hypergraph on n vertices contains few copies of a ﬁxed
hypergraph H, then it can be made H-free by removing few of its edges. While this settles the
‘hypergraph removal problem’ in the case where k and H are ﬁxed, the result is meaningless when
k is large (e.g. k > log log log n).
Using our robust version of the Friedgut–Kalai Theorem, we obtain a hypergraph removal lemma
that holds for k up to linear in n for a large class of hypergraphs. These contain all the hypergraphs
such that both their number of edges and the sizes of the intersections of pairs of their edges are
upper bounded by some constant.

1. Introduction

1.1. Problems on H-free families. For any set V we use Vk to denote the family of all subsets

of V of size k. Any H ⊆ Vk is called a k-uniform hypergraph or a k-uniform family on the vertex
set V , and the elements of H are its edges. We write [n] for the set {1, . . . , n} .

The celebrated Mantel’s Theorem [47] from 1907 says that the largest triangle free graph G ⊆ [n]
2
is the balanced complete bipartite graph. In 1941, Turán [62] generalized Mantel’s Theorem from
triangles to cliques. He raised the following problem known as the Turán problem for hypergraphs.

Problem 1.1. Given a hypergraph H ⊆ Vk , determine the value ex (n, H) of the largest H-free

family in [n]
k .

An H-free family of size ex (n, H) is called an extremal H-free family. The Turán problem is one
of the most prominent problems in extremal combinatorics, and it includes many of the well studied
problems in this area. (See the excellent survey of Keevash [41], and the more recent survey of Mubayi
and Verstraëte [51].) One example, is the classical Erdős-Ko-Rado Theorem (EKR Theorem) [21]

from 1961, which determines the largest size of a family F ⊆ [n]
such that each two of its edges
k

have nonempty intersection. It can be rephrased by saying that ex (n, M2 ) = n−1
k−1 for any n ≥ 2k,
where M2 is the k-uniform hypergraph that consists of two disjoint edges.
1

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

2

Another well-studied set of Turán problems is the Forbidden intersection problem of Erdős and
Sós [20] from 1975. It concerns determining ex (n, H) in the case where the forbidden hypergraph H
consists of two edges with a given intersection, (see [18, 25, 28, 30, 42]).
Besides the Turán problem for hypergraphs of determining ex (n, H) for various hypergraphs H,
the research of H-free families in recent years concentrated on the following types of problems.

(1) 0.99-type stability results. Suppose that F is a nearly extremal H-free family in the sense
that its size is close to ex (n, H). Can we say that F is close to an H-free family? (See e.g.
[26, 60]).
(2) 0.01-type stability results. What is the structure of an H-free family whose size is within
a constant of ex (n, H)? (See [15, 34]).
(3) The removal problem. Suppose that F is a family that is almost H-free, in the sense
that it contains few copies of H. Is it true that F is close to an H-free family? (See e.g.
[37, 52, 54, 56]).
(4) The counting problem. How many H-free families are there? Particularly, is it true that
almost all of them are contained in an extremal H-free family? (See e.g. [57, 58].

(5) The random problem. Let p ∈ (0, 1), and let [n]
k p be the random family that contains

each set in [n]
k independently with probability p. What is the size of the largest H-free
subfamily of [n]
k p ? (See e.g. [12, 59]).

In this paper our main focus will be on solving the 0.01-type stability problem and the removal
problem for a large class of hypergraphs called expanded hypergraphs. These are the hypergraphs in
which both the number of edges and the intersections of pairs of the edges are bounded by a constant.
While we shall not address the counting problem and the random problem in this paper, we would
like to note that the container method of Balogh, Morris, and Samotij [4], and independently of
Saxton and Thomason [58], essentially reduces the solutions of the counting problem and the random
problem to the solutions of the 0.99-type stability problem and the removal problem. Therefore, our
work should be viewed as progress towards all of the above problems.
Our results are based on a novel theorem about the sharp threshold of ‘almost monotone’ Boolean
functions in the discrete cube, whose proof uses the invariance principle of Mossel, O’Donnell, and
Oleszkiewicz [50]. We believe that the connection we establish between sharp threshold phenomena
of Boolean functions and the removal problem is the main contribution of this paper.
1.2. The structure of large families that are free from an expanded hypergraphs.
Definition 1.2. A hypergraph is said to be (h, d)-expanded if it has at most h edges and the
intersection of each two of its edges is of size at most d.
The hypergraph M2 is an example of a (2, 0)-expanded hypergraph, and hypergraphs that are
(h, 1)-expanded for some h are known as linear hypergraphs. Generally speaking, we shall be concerned with k-uniform (h, d)-expanded hypergraphs, where h and d are ﬁxed, and where k is signiﬁcantly larger.
Our terminology stems from the following standard deﬁnition, (see Mubayi and Verstraëte [51]).
Definition 1.3. Let H be a hypergraph. The k-expansion of H is the k-uniform hypergraph H+
obtained from H by enlarging each of its edges with distinct new vertices. We denote by exk (n, H+ )

the problem of determining the largest size of a family F ⊆ [n]
free of the k-expansion of H.
k

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

3

Note that the k-expansion of a d-uniform hypergraph with h edges is (h, d)-expanded. Conversely,
any (h, d)-expanded hypergraph can be easily seen to be the k-expansion of some d (h − 1)-uniform
hypergraph.
Many problems in extremal combinatorics can be expressed as determining exk (n, H+ ) for a ﬁxed
hypergraph H (see e.g. [29, 35, 44, 27], and the survey of Mubayi and Verstraëte [51] for the case
where H is a graph). The methods used for attacking such problems are varied. One of the most
successful methods is the delta-system method of Erdős, Deza, and Frankl [14]. This method was
applied by Frankl and Füredi [25, 28, 29] to solve various Turán problems for expanded hypergraphs
(including the case where H is a special simplex, a sunﬂower, or the hypergraph that consist of two
edges with some intersection of a ﬁxed size). This allowed them to make signiﬁcant progress on
several longstanding open problems in extremal combinatorics.
Another notable technique is the shifting technique of Erdős, Ko, and Rado [21]. This technique
was applied, e.g., in a recent breakthrough of Frankl [27]. He gave the best bound for the Erdős

Matching Conjecture [19], which asks to determine exk (n, Ms+ ) , where Ms ⊆ [n]
is a matching of
2
size s. Other methods include the Erdős-Simonovits stability method [60], and the random sampling
from the shadow method of Kostochka, Mubayi, and Verstraëte (see [44, 45, 46]).
Recently, a new approach towards the Turán problem for expansion was initiated be Keller and
the author [43] and further developed by Ellis, Keller, and the author [18].

Definition 1.4. A family F ⊆ [n]
is said to depend on the set of coordinates J if for each sets
k

A, B ∈ [n]
that
satisfy
A
∩
J
=
B
∩
J we have A ∈ F ⇐⇒ B ∈ F . A family F is said to be a
k
j-junta if it depends on a set J of size at most j. We say that a family F1 is ǫ-essentially contained
in F2 if
 
n
|F1 \F2 | ≤ ǫ
.
k
The notion junta was introduced by Friedgut [31] while studying the isoperimetric problem in
discrete cube. Dinur and Friedgut [15] were the ﬁrst to use this notion in the study of k-uniform
set-systems. They showed the following.
Theorem 1.5 (Dinur–Friedgut [15]). For each r ∈ N, there exist C > 0, j ∈ N, such that any
r

intersecting family F ⊆ [n]
is C nk -essentially contained in an intersecting j-junta.
k

Note that the theorem is trivial for nk = Θ (1) , while it is meaningful once nk is suﬃciently small.
Inspired by [15], Keller and the author [43] extended Theorem 1.5 to show that for each h, r there
r

exist C > 0, j ∈ N, such that any Mh+ -free family F ⊆ [n]
is C nk -essentially contained in an
k
Mh+ -free j-junta, and obtained the following result for general expanded hypergraphs.

Theorem 1.6 ([43]). For each ǫ > 0, h, d ∈ N, there exist C > 0, j ∈ N, such that the following
n
holds. Let C < k < C
, and let H be a k-uniform (h, d)-expanded hypergraph. Then any H-free family

[n]
F ⊆ k is ǫ-essentially contained in an H-free j-junta.

Theorem 1.6 serves as the ﬁrst step in the following strategy for determining ex (n, H) .
(1) Show that any H-free family is essentially contained in an H-free junta J .
(2) Find the extremal junta Jex that is free of H.
(3) Show that if an H-free junta has size that is close to |Jex |, then it must be a small perturbation
of Jex .
(4) Show that any H-free small perturbation of Jex must have smaller size than it.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

4

These four steps together suﬃce in order to show that the extremal junta is the family Jex . Indeed,
if F is the extremal H-free family, then Step 1 implies that F is essentially contained in an H-free
junta J . The fact that F is of the extremal size implies that the size of J cannot be much smaller
than the size of Jex . Step 3 implies that F is essentially contained in Jex , and Step 4 implies that F
is actually equal to Jex .
This strategy was successfully carried out in [43] to solve the Turán problem for various (h, d)n
for some C = C (h, d) .
expanded hypergraphs, in the regime where C < k < C
Later, [18] showed that
this
strategy
can
be
carried
out
also for some hypergraphs in the regime

where ǫn < k < 12 − ǫ n for an arbitrarily small constant ǫ, and a suﬃciently large n. Speciﬁcally,
they considered the case where the forbidden hypergraph H is I2,d that consists of two edges that
intersect in d elements.
Their basic observation was that any junta that does not contain a copy of I2,d must be free of
I2,d′ for any d′ < d as well. In other words, any two sets in an I2,d -free junta have intersection
of size at least d + 1. This essentially reduces the problem to the well known problem on the size
of (d + 1)-wise intersecting families, which was solved decades ago using the shifting technique (see
Ahlswede–Khachatrian [3], Filmus [22], and Frankl [24]).
It is our belief that this strategy may be carried out for various other (h, d)-expanded hypergraphs,
and that the following result we prove in this paper will serve as the ﬁrst step in the
 solution of the
Turán problem for various other hypergraphs in the regime where ǫn < k ≤ h1 − ǫ n.
Theorem 1.7. For
 each ǫ > 0, d, h ∈ N, there exists j > 0, such that the following holds. Let
is
ǫn ≤ k ≤ h1 − ǫ n, and let H be an (h, d)-expanded hypergraph. Then any H-free F ⊆ [n]
k
ǫ-essentially contained in an H-free j-junta.

The special case of Theorem 1.7 where H = M2+ = M2 was already proved recently by Friedgut
and Regev [34] who built upon the work of Dinur and Friedgut [15]. Other special cases of Theorem
1.7 were proved in [18], which settles the case h = 2 of the theorem.
Theorem 1.7 is actually a special case of our main Theorem 1.13 below, which deals also with
families that contain few copies of H, rather than dealing only with H-free families.
Similarly to the case where H = I2,d , it turns out that it is a general phenomenon that H-free
juntas are automatically free of some other hypergraphs.
Definition 1.8. Let H be a hypergraph and let v be a vertex of H. The resolution of H at v, denoted
by res (H, v), is the hypergraph obtained from H by taking v out of each edge of H that contains v,
and by replacing it with a new vertex that belongs only to this edge. The resolution of H at a set of
vertices S, denoted by res (H, S), is the hypergraph obtained by resolving H at the vertices of S one
after the other. Any hypergraph of the form res (H, S) will be called a resolution of H.
Example 1.9. Any hypergraph H is a resolution of itself since res (H, ∅) = H. Deﬁning the center
of a hypergraph H to be the set of its vertices that belong to at least two of its edges, the k-uniform
h-matching Mh := Mh+ is the resolution of any k-uniform hypergraph with h edges at its center.
Another simple example is the hypergraph I2,d : its resolutions are the hypergraphs of the form I2,d′
for d′ ≤ d.

that is free of a hypergraph H with h edges is also
It is easy to show that any j-junta G ⊆ [n]
k
free of every resolution of H, provided that C < k ≤ h1 − ǫ n and n is large enough. Hence, in order
to show that a given junta J is an extremal H-free family, it would essentially be enough to show
that it is the extremal family that is free of a copy of H as well as of all of its resolutions.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

5

1.3. Removal lemma for expanded hypergraphs. While Theorem 1.7 tells us the structure of
H-free families it tells us nothing on families that are ‘almost H-free’, a notion that may be deﬁned
more precisely as follows.

Definition 1.10. Let δ > 0 and let H be a k-uniform hypergraph. We say that a family F ⊆ [n]
k

is δ-almost H-free if a random copy of H in [n]
lies within F with probability at most δ.
k

The celebrated triangle removal lemma says that for any ǫ > 0, there exists δ > 0, such that any
δ-almost triangle-free graph is ǫ-essentially contained in a triangle-free graph. This was generalized
by Gowers [36, 37], and independently by Nagle, Rödl, Schacht, and Skokan [52, 54] to show that

for each ﬁxed k-uniform hypergraph H, there exists ǫ > 0, such that if a family F ⊆ [n]
is δk
almost H-free, then F is ǫ-essentially contained in an H-free family. This result is known as the
hypergraph removal lemma. (See the survey of Conlon and Fox [11] for a more thorough history, and
for quantitative aspects of removal lemmas.)
While the hypergraph removal lemma settles the case where k, H, and ǫ are ﬁxed, it becomes
quite useless for k that tends to inﬁnity with n. Indeed, the initial dependence of δ on ǫ in the graph
case where k = 2 was
2
.
−1


..
−OH (1)
2
δ = tower ǫ
=
|2 {z } ,
ǫ−OH (1) times

1
ǫ

−1

. For k = 3 the best known bound is
and this was improved by Fox [23] to tower OH log
−1
δ = tower (tower · · · (2)) , and the bounds similarly worsen as k increases (see [61, Remark 2.11]).
{z
}
|
ǫ−OH (1) times

Friedgut and Regev [34] were the ﬁrst to prove a removal lemma in the case where k is linear in n.


They showed that for each ǫ > 0 there exists δ > 0, such that if ǫn ≤ k ≤ 21 − ǫ n, and if F ⊆ [n]
k
is a δ-almost M2 -free family, then F is ǫ-essentially cxontained in an M2 -free family. Later, Das
+
and Tran [13] proved
 a quantitatively stronger removal result for δ-almost M2 -free families whose
n−1
size is close to k−1 .
At ﬁrst glance it may seem that the Friedgut–Regev Theorem follows from the hypergraph removal
lemma, but it actually does not. While the hypergraph removal lemma deals with the case where k
and the hypergraph H are ﬁxed, the Friedgut–Regev theorem deals with the case where k is linear in
n. Our goal in this paper it to prove removal lemmas for other expanded hypergraphs in the regime
where k is up to linear in n.
In light of Theorem 1.7, it may seem the Friedgut–Regev Theorem can be generalized to all
(h, d)-expanded hypergraphs. However, we show that the following surprising statement holds.
Theorem 1.11.
 For each h, d ∈ N, ǫ > 0 there exists C, δ > 0 such that the following holds. Let
C ≤ k ≤ h1 − ǫ n, and let H be a k-uniform (h, d)-expanded hypergraph, then we have the following.
(1) If the family F is δ-almost H-free, then F is ǫ-essentially contained in an Mh -free family.
(2) Conversely, if the family F is δ-essentially contained in an Mh -free family, then F is ǫ-almost
H-free.
So suppose that F is a family that we want to check whether it is H-free or not. One natural way
to check if F is H-free is to choose uniformly at random copies of H, and to check that none of them
are contained in F . While we could expect that this would tell us that F is close to some H-free
family, we instead obtain from Theorem 1.11 that this implies that F is close to a family that is free
of the hypergraph Mh . Even more surprisingly, also the converse holds. Any family that is close to

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

6

an Mh -free family contains few copies of H. This phenomenon becomes clearer by inspecting the
following example.
n
o
[n] 
Example 1.12. The star A ∈ n/3
: 1 ∈ A is o (1)-almost free of the hypergraph I2,1 , which

consists of two edges that intersect in a singleton {i}. Indeed, the probability that a random copy
of this hypergraph lies in the star is n1 , as it is the probability that a random injection from the
vertices of I2,1 to [n] sends the vertex i to 1. As Theorem 1.11 guarantees, the star is o (1)-essentially
contained in an M2 -free family as it is in itself M2 -free. However, the star is not o (1)-essentially
contained in any family free of the hypergraph I2,1 .
More generally, suppose that G is a j-junta depending on a set J and that H is an (h, d)-expanded
hypergraph. Then the center of a random copy of H most likely does not intersect J. So from the
‘point of view’ of the junta G, a random copy of H and a random copy of Mh look the same. It is
therefore easy to see that
Pr [a random copy of H lies in G] = Pr [a random copy of Mh lies in G] + o (1) .

Let F ⊆ [n]
k , and let H be a hypergraph. We say that F is (H, s)-free if it is free of any resolution
of H whose center is of size at most s. While Example 1.12 shows that being o (1)-almost free of H
is not suﬃcient for guaranteeing closeness to an H-free family, the following theorem shows that a
stronger assumption is suﬃcient.
Theorem 1.13. For each h, d, s ∈ N, ǫ > 0 there exist δ > 0,j ∈ N, such that the following holds.
Let H be an (h, d)-expanded hypergraph. Let 1δ ≤ k ≤ h1 − ǫ n, and let F be a nδs -almost H-free
family. Then F is ǫ-essentially contained in an (H, s)-free j-junta.
Note that Theorem 1.7 is a special case of Theorem 1.13. Indeed, Theorem 1.13 implies that if H
is a hypergraph whose center is of size c, then any nδc -almost H-free family is ǫ-essentially contained
in an (H, c)-free family, i.e. to a family free of H and of any resolution of it. On the other hand,
Theorem 1.7 yields the same conclusion under the stronger hypothesis that F is H-free.
The following
proposition is a converse to Theorem 1.13. It shows that any (H, s)-free j-juntas is

1
O ns+1 -almost H-free. So in particular, j-juntas are nδs -almost H-free, provided that n is suﬃciently
large as a function of δ.
Proposition 1.14. For each h, c, j, s ∈ N, there exists a constant C > 0, such that the
 following
holds. Let H be a hypergraph with h edges whose center is of size c. Let C ≤ k ≤ h1 − ǫ n, and let
C
J be an (H, s)-free j-junta. Then J is ns+1
-almost H-free.
1.4. Sketch of Proof of Theorem 1.13 for matching. We shall now sketch the proof of Theorem
1.13 in the case where the forbidden hypergraph is Mh . The proof relies on the regularity method
and on a novel sharp threshold result for ‘almost monotone’ Boolean functions that will be presented
in Section 2.
Let ǫ > 0, h ∈ N be ﬁxed constants, and let F be a family which is not ǫ-contained in any family
free of the matching Mh . Our goal is to show that a random matching lies in F with probability
Θ (1).
Note that any set J decomposes the sets in F into 2|J| parts according to their intersection with
J. Following Friedgut and Regev [34] and [18] we apply a regularity lemma which says that we may
ﬁnd a set J, such that in the decomposition of F induced by J, almost all of the parts are either
‘random-like’ or suﬃciently small that we can ignore them. We may then take as our approximating

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

7

junta, the family

 

[n]
G= A∈
: A ∩ J corresponds to a random part of F .
k
The fact that F is not ǫ-essentially contained in an Mh -free family will allow us to show that G is
not Mh -free. This in turn will imply that there exist pairwise disjoints sets A1 , . . . , Ah ⊆ J that
correspond to random parts of F . Now note that a random matching {B 1 , . . . , B h } intersects the set
J in the sets A1 , . . . , Ah with probability Θ (1). So the remaining task is to show that if F1 , . . . , Fh
are ‘random-like’ parts, then a random matching A1 , . . . , Ah satisﬁes Ai ∈ Fi with probability Θ (1).
We will accomplish this task using an enhancement of the ‘sharp threshold technology’ presented by
Dinur and Friedgut [15]. Let us recall ﬁrst the method in [15]. We say that families F1 , . . . , Fh are
cross free of a matching if there exist no pairwise disjoint sets A1 , . . . , Ah such that Ai ∈ Fi for each
i, otherwise they cross-contain a matching.
The p-biased distribution on P ([n]) is a probability distribution on sets A ⊆ [n], where each
element is chosen to be in A independently with probability p. For a family G, write µp (G) for
PrA∼µp [A ∈ G] . A family F ⊆ P ([n]) is monotone if B ∈ F whenever B ⊇ A for some A ∈ F . The
‘sharp threshold principle’ essentially says that for a random-like monotone family F the p-biased
measure of F jumps from being near 0 to being near 1 in a short interval.
Roughly speaking, the analogue of the strategy in [18] for the hypergraph Mh goes as follows.
h

(1) Observe that if {Fi }i=1 are cross-free of a matching, then their up-closures
n
oh
Fi↑ := {B : ∃A ⊆ B such that A ∈ F }
i=1

are also cross-free of a matching (in the sense that there are no pairwise disjoint sets
A1 , . . . , Ah with Ai ∈ Fi↑ ).
 
(2) Use a simple coupling argument to show that if µ h1 Fi↑ > 1 − h1 for each i, then the families

F1↑ , . . . , Fh↑ cross-contain a matching. So in particular, the families F1 , . . . , Fh cross contain
a matching.
(3) Show that the families Fi↑ are random-like monotone families whose µ k measure is bounded
n
 
away from 0. The sharp threshold principle will allow us to deduce that µ h1 Fi↑ is close to
h

1, so by Step 2 the families {Fi }i=1 cannot be cross free of a matching.

This plan fails completely when we try to show the desired statement that random-like families
contain many matchings. The step which stops to work
is the ﬁrst one. While it is true that if {Fi }
n o
↑
are cross free of a matching, then their up closures Fi are cross-free of a matching, it is not true
that if {Fi }-are almost cross free of a matching (in the sense that they cross contain few matchings),
then the families Fi↑ are also almost cross free of a matching. We resolve this issue by replacing the
up-closure of F by the family
{A ∈ P ([n]) : |A| ≥ k and a random k-subset of A lies in F with probability Θ (1)} .
However, this new family is not monotone, and instead it satisﬁes a weaker hypothesis that may be
called ‘almost monotonicity’.
So to make the above plan work, we shall need to generalize the sharp threshold principle from
monotone families to ‘almost monotone’ families. This statement is made more precise in Section 2.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

8

It is accomplished with the help of the invariance principle of Mossel, O’Donnell, and Oleszkiewicz
[50].
In our view, the main contribution of this paper comes from the fact that we relate between
sharp threshold results and hypergraph removal problems. We believe that further exploration of the
relation between these two well studied problems will improve the understanding of each of them.
In the following section we give a more thorough introduction of the sharp threshold principle
of monotone Boolean functions, and state our sharp threshold result for almost monotone Boolean
functions. (Note that Boolean functions f : {0, 1}n → {0, 1}, and families F ⊆ P ([n]) can be
identiﬁed).
2. Sharp threshold theorems for almost monotone functions
We use bold letters to denote random variables, and we write [n] for the set {1, . . . , n} . We
n
shall use the convention that the ith coordinate of an x ∈ {0, 1} is denoted by xi . A function
n
n
f : {0, 1} → R is said to be monotone if f (x) ≤ f (y) whenever x, y are elements of {0, 1} that
satisfy ∀i ∈ [n] : xi ≤ yi . The p-biased distribution µp is the distribution on the set {0, 1}n ,
where a random element x ∼ µp is chosen by letting its coordinates xi to be independent random
n
variables that take the value 1 with probability p. For a function f : {0, 1} → R, we write µp (f )
for Ex∼µp [f (x)] .
n
It is easy to see that for any monotone function f : {0, 1} → {0, 1}, the function p 7→ µp (f ) is
n
a monotone increasing function of p. Roughly speaking, a Boolean function f : {0, 1} → {0, 1} is
said to have a sharp threshold if there exists a ‘short’ interval [q, p], such that µq (f ) is ‘close’ to 0,
and µp (f ) is ‘close’ to 1. Otherwise, it is said to have a coarse threshold.
A central problem in the area of analysis of Boolean functions is the following (see e.g. [10, 32,
33, 39]).
n

Problem 2.1. Which monotone Boolean functions f : {0, 1} → {0, 1} exhibit a coarse threshold?
n

We shall now make the above discussion more formal. For a non-constant monotone f : {0, 1} →
{0, 1}, the critical probability of f (denoted by pc (f )) is the unique number in the interval (0, 1),
such that µpc (f ) = 12 . Bollobás and Thomason [7] showed that for any ﬁxed ǫ > 0, and each Boolean
function f there exists an interval [q, p] with q, p = Θ (pc (f )) , such that µq (f ) < ǫ, and µp (f ) > 1−ǫ.
Therefore, f should be considered to have a sharp threshold if there exists an interval [q, p] of length
signiﬁcantly smaller than pc (f ), such that µq (f ) < ǫ and µp (f ) > 1 − ǫ.
n
Formally, we say that a Boolean function f : {0, 1} → {0, 1} exhibits an ǫ-sharp threshold if there
exists an interval [q, p] of length ǫpc (fn ), such that µq (f ) < ǫ and µp (f ) > 1 − ǫ. We say that f
exhibits an ǫ-coarse threshold if there exist an ǫ > 0, and an interval [q, p] of length at least ǫpc (f ) ,
such that µq (fn ) > ǫ, and µp (fn ) < 1 − ǫ.
n
A function f : {0, 1} → {0, 1} is said to be transitive symmetric if the group of all permutations
σ ∈ Sn , such that

n
∀x ∈ {0, 1} : f xσ(1) , . . . , xσ(n) ≡ f (x1 , . . . , xn )

acts transitively on {1, . . . , n} .
The Friedgut–Kalai Theorem [33] says that if f is transitive symmetric and pc (f ) is bounded away
from 0 and 1, then f exhibits a sharp threshold.
Theorem 2.2 (Friedgut–Kalai). For each ǫ > 0 there exists n0 = n0 (ǫ) such that the following
holds. Let n > n0 and let f : {0, 1}n → {0, 1} be a monotone transitive symmetric function satisfying
ǫ < pc (f ) < 1 − ǫ. Then f exhibits an ǫ-sharp threshold.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

9

On the other hand, f need not exhibit a coarse threshold if f is no longer assumed to be transitive
symmetric. Let j be a constant. A function f is said to be a j-junta if it depends on at most j
coordinates. It is easy to see that any non-constant monotone j-junta exhibits an ǫ-coarse threshold
for some constant ǫ = ǫ (j) > 0. A well known corollary of the celebrated Friedgut’s Junta Theorem
[31] is a partial converse to this statement. We shall say that f is (µr , ǫ)-close to g if
Pr [f (x) 6= g (x)] < ǫ.

x∼µr

Theorem 2.3 (Corollary of Friedgut’s Junta Theorem). For each ǫ > 0, there exists j ∈ N, such
n
that the following holds. Let f : {0, 1} → {0, 1} be a Boolean function, and let q, p be numbers in
the interval (0, 1) that satisfy p > q + ǫ. Then there exists some r in the interval [q, p] , such that f
is (µr , ǫ)-close to a j-junta.
Note that Friedgut’s Junta Theorem becomes trivial if µq (f ) < ǫ or if µp (f ) > 1 − ǫ as in which
case we may take the junta to be the corresponding constant function. For that reason, Friedgut’s
Junta Theorem can be interpreted by saying that non-junta like functions exhibit a sharp threshold
behavior.
2.1. Structural results on monotone families. We extend Theorems 2.2 and 2.3 in the following
directions.
• We replace the condition that f is monotone with the weaker condition that f satisﬁes a
notion we call (q, p, δ)-almost monotonicity.
• We strengthen the Friedgut–Kalai theorem by relaxing the condition that f is transitive
symmetric to the weaker condition that f satisﬁes a notion called (r, δ, µq )-regularity.
• Bearing in mind our applications to the removal problem, we modify Theorem 2.3 by replacing
the condition that f is ‘close’ to a junta with respect to the µr measure with a condition that
says that f is ‘close’ to a junta in a sense that involves only the measures µp and µq , i.e. the
measures at the ends of the interval.
We shall now deﬁne the above notions more precisely, starting with (q, p, δ)-almost monotonicity.
Intuitively, a function f should be called ‘almost monotone’ if f (x) ≤ f (y) for almost all values of x
and y that satisfy ∀i ∈ [n] : xi ≤ yi . However, there are many ways to interpret the notion ‘almost
all values of x and y’. For instance, the following deﬁnitions all seem to ﬁt equally well.
n
• Choose x uniformly out of {0, 1} and then choose y uniformly among the set of all the elen
ments y ∈ {0, 1} that satisfy ∀i : yi ≥ xi . Say that f is ‘almost monotone’ if Pr [f (x) > f (y)]
is ‘small’.
n
n
• First choose y uniformly out of {0, 1} , then choose x among the set of all x ∈ {0, 1} that
satisfy ∀i : xi ≤ yi , and say that f is ‘almost monotone’ if Pr [f (x) > f (y)] is ‘small’.
n
n
• Choose a uniformly random pair of elements x, y ∈ {0, 1} among the x, y ∈ {0, 1} that
satisfy ∀i : xi ≤ yi , and say that f is ‘almost monotone’ if Pr [f (x) > f (y)] is ‘small’.
Note that these notions are diﬀerent. In the ﬁrst we have
3
1
Pr [xi = 1] = and Pr [yi = 1] = ,
2
4
in the second we have
1
1
Pr [xi = 1] = and Pr [yi = 1] = ,
4
2
and in the last we have
1
2
Pr [xi = 1] = and Pr [yi = 1] = .
3
3

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

10

All these notions are captured by the following framework.
Definition 2.4. Let q < p. The (q, p)-biased distribution, denoted by D (q, p), is the unique probability distribution on elements (x, y) ∈ {0, 1}n × {0, 1}n that satisﬁes the following.
(1) The pairs (xi , yi ) are independent random variables.
(2) We have xi ≤ yi with probability 1.
(3) We have Pr [xi = 1] = q and Pr [yi = 1] = p.
We write x, y ∼ D (q, p) to denote that they are chosen according to this distribution. We say that
n
f : {0, 1} → {0, 1} is (q, p, δ)-almost monotone if
Pr

x,y∼D(q,p)

[f (x) > f (y)] < δ.

It will be convenient for us to deﬁne the following notion of ‘closeness’ between a function f and
a function g that takes into considerations both the p-biased measure and the q-biased one. We
n
n
say that functions f, g : {0, 1} → {0, 1} are (µq , µp , ǫ)-close if the set of all x ∈ {0, 1} such that
f (x) 6= g (x) can be partitioned into the union of two sets Sp and Sq , such that µp (Sp ) < ǫ and
µq (Sq ) < ǫ.
We give the following variant of Friedgut’s junta theorem, which implies that if ǫ, q < p are ﬁxed
numbers in the interval (0, 1), if δ > 0 is small enough, and if j ∈ N is suﬃciently large, then any
(q, p, δ)-almost monotone function f is (µq , µp , ǫ)-close to a monotone j-junta.
Theorem 2.5. For each ǫ > 0, there exists j ∈ N, δ > 0, such that the following holds. Let p, q be
n
numbers in the interval (ǫ, 1 − ǫ) that satisfy p− q > ǫ and let f : {0, 1} → {0, 1} be a (q, p, δ)-almost
monotone function. Then there exists a monotone j-junta g, such that
Pr [f (x) > g (x)] < ǫ and Pr [f (x) < g (x)] < ǫ.

x∼µq

x∼µp

Note that Theorem 2.5 is really a theorem about functions that have a coarse threshold. Indeed,
if we have either µp (f ) > 1 − ǫ or µq (f ) < ǫ, then the theorem becomes trivial by taking g to be a
suitable constant function.
The conclusion of Theorem 2.5 says that f can be ‘approximated’ by the junta g, where our
approximation notion is the ‘two-sided’ notion of (q, p, ǫ)-closeness. It is natural to ask whether f
can also be approximated by a junta according to a ‘one-sided’ notion, such as the notions of (µp , ǫ)closeness and (µq , ǫ)-closeness. The following example demonstrates that the two-sided approximation
is actually necessary.
Example 2.6. Fix some numbers q, p in
{0, 1} be the function deﬁned by


1
f (x) = 1


0

the interval (0, 1) that satisfy q < p. Let fn : {0, 1}n →
Pn
x1 = 1, and
xi > qn
Pni=2
x1 = 0, and
i=2 xi > pn .
Otherwise

The Central Limit Theorem implies that
(1 + p)
q
+ o (1) .
µq (f ) = + o (1) and µp (f ) =
2
2
Since both µq (f ) and µp (f ) are bounded away from 0 and 1, we obtain that f has an ǫ-coarse
threshold
for some constant ǫ independent of n. On the other hand, it is easy to see that f is not


-close to an O (1)-junta and is not (µq , q (1 − q))-close to an O (1)-junta, provided that n
µp , (1−p)
4

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

11

is suﬃciently large. However, if we take g to be the dictator function deﬁned by g (x) = x1 , then we
have
Pr [f (x) > g (x)] = o (1) and Pr [f (x) < g (x)] = o (1) ,
x∼µp

x∼µq

as Theorem 2.5 guarantees.
The proof of Theorem 2.5 is based on the invariance principle of Mossel, O’Donnell, and Oleszkiewicz
[50] and on a recent unpublished regularity lemma of O’Donnell, Servedio, Tan, and Wan. A presentation of their proof was recently given by Jones [40].
For our next extension of the Friedgut–Kalai Theorem, we need the notion of (r, ǫ, µp )-regularity,
(see O’Donnell [53, Chapter 7] for more about this notion). Let R be a subset of [n] , and let
R
[n]\R
y ∈ {0, 1} . We write fR→y for the Boolean function on the domain {0, 1}
deﬁned by fR→y (x) =
R
[n]\R
f (z) , where z is the vector whose projection to {0, 1} is y and whose projection to {0, 1}
is x.
Note that a function f is a j-junta if there exists a set J of size j, such that all the restrictions
fJ→x are constant functions. On the other extreme, we have the following notion of regularity which
could be thought of as the complete opposite of being a junta. It says that for each set J of constant
size r, the µp measures of f and of fJ→y are not far apart.
n

Definition 2.7. A function f : {0, 1} → [0, 1] is said to be (r, ǫ, µp )-regular if
|µp (fJ→y ) − µp (f )| < ǫ
J

for each set J ⊆ [n] of size at most r and each y ∈ {0, 1} .
As we explain below the following is a robust version of the Friedgut–Kalai Theorem.
Theorem 2.8. For each ǫ > 0, there exists δ > 0, such that the following holds. Let q, p ∈ (ǫ, 1 − ǫ)
and suppose that p > q + ǫ. Let f, g : {0, 1}n → [0, 1]. Suppose that
and that the function f is

1
δ

E(x,y)∼D(q,p) [(1 − g (y)) f (x)] < δ,

, δ, µq -regular. Then either µq (f ) < ǫ, or µp (g) > 1 − ǫ.

Theorem 2.8 is a robust version of Theorem 2.2. Indeed, note that one can equivalently restate
Theorem 2.2 as follows. Let q and p be numbers in the interval (ǫ, 1 − ǫ), and suppose that p > q + ǫ.
n
Let f : {0, 1} → {0, 1} be a monotone transitive symmetric Boolean function. Then we either have
µq (f ) < ǫ, or we have µp (g) > 1 − ǫ, provided that n is suﬃciently large.
Applying Theorem 2.8 (with f = g), we see that it strengthens Theorem 2.2 in the following
ways. It shows that we may replace the hypothesis that f is monotone by the weaker hypothesis
that f is (q, p, δ)-almost monotone, and that we may replace

the hypothesis that f is transitive
symmetric, with the weaker hypothesis that the f is 1δ , δ, µq -regular for some δ = δ (n) , where
limn→∞ δ (n) = 0. Example 3.8 below shows that the latter hypothesis is indeed weaker.
Remark 2.9. While Theorem 2.8 is more general than the Friedgut–Kalai Theorem, we remark that
the Friedgut–Kalai Theorem is better in the quantitative aspects that we have not addressed. We
would also like to remark that the proof of Theorem 2.5 is very diﬀerent than the standard proofs
of Theorems 2.2 and 2.3. While the traditional proofs are based on the hypercontractivity theorem
of Bonami, Gross, and Beckner [8, 38, 5] and on Russo’s Lemma [55], our proof of Theorem 2.8 is
based instead on the invariance principle of O’Donnell, Mossel, and Oleszkiewicz [50].

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

12

2.2. Sketch of the proof of Theorems 2.5 and 2.8. Our proof of Theorem 2.5 is based on the
regularity method. In the setting of the regularity method we are given a space S, and our goal is to
show a ‘removal lemma’ asserting that any subset A ⊆ S that contain few copies of a given ‘forbidden’
conﬁguration may be approximated by a family that contains no copies of that conﬁguration. The
proof contains two ingredients.
(1) A regularity lemma showing that for any set A, we may decompose B into some parts, such
that the intersections of A with ‘almost all’ of the parts are either ‘quasirandom’ or ‘small’.
(2) A counting lemma showing that if we take the quasirandom parts, then together they contain
many forbidden conﬁgurations.
These two ingredients are put together by approximating A by the set J deﬁned to be the union
of all the quasirandom parts of B. The task is then to use the counting lemma to show that any
forbidden conﬁguration that appears in J results in many forbidden conﬁgurations back in A.
The invariance principle of Mossel O’Donnell and Oleszkiewicz [50] considers a notion of smoothness called small noisy influences. It roughly says that we may replace the variables of a smooth
n
function f : {0, 1} → [0, 1] by Gaussian random variables and obtain a function that behaves similarly. We call this function the Gaussian analogue of f . The proof of Theorem 2.5 goes through the
following steps.
(1) We apply a regularity lemma presented by Jones [40], which shows that we may ﬁnd a set
J of constant size that decomposes f into the parts {fJ→y }y∈{0,1}J , such that almost all of
the parts either have expectation very close to 0, or have small noisy inﬂuences.
n
(2) We give a counting lemma that shows that if two functions f1 , f2 : {0, 1} → [0, 1] have small
noisy inﬂuences and satisfy Ex∼µq [f1 (x)] , Ey∼µp (1 − f2 (y)) = Θ (1), then
Ex,y∼D(q,p) [f1 (x) (1 − f2 (y))] = Θ (1) .
The proof of the second part follows [50]. We express Ex,y∼D(q,p) [f1 (x) (1 − f2 (y))] in terms of the
Fourier expansions of f1 and f2 , and we show that this expression can be approximated by a similar
expression involving the Gaussian analogues of f1 and f2 . We then apply a classical theorem by
Borell [9] to lower bound the value of the corresponding expression.

 
The proof of Theorem 2.8 is similar. Suppose that f is a 1δ , δ, µq -regular function with µq (f ) >
ǫ.
(1) We apply the regularity lemma of [40] to ﬁnd a set J of constant size that decomposes f into
the parts {fJ→y }y∈{0,1}J , such that most of the parts either have expectations very close to

 
0, or have small noisy inﬂuences. The δ1 , δ, µq -regularity of f implies that there are no
parts with expectations close to 0, so only the latter option is available.
(2) We note that the term
Ez,w∼({0,1}n−|J| ,D(q,p)) [fJ→x (z) (1 − gJ→y (w))]
J

is small for each x, y ∈ {0, 1} , such that xi ≤ yi for each i.
(3) We deduce from the above counting lemma (applied with f1 = fJ→x , f2 = gJ→y ) that for
such x, y, if fJ→x has small noisy inﬂuences, then the function gJ→y has expectation close
to 1.
J
J
(4) It is easy that for ‘almost all’ y ∈ {0, 1} we may ﬁnd x ∈ {0, 1} with xi ≤ yi for each i, such
that fJ→x has small noisy inﬂuences. So Step 3 implies that for almost all y the expectation
of gJ→y is close to 1. Therefore, the expectation of g is close to 1.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

13

3. Prior results and notions that we make use of
In this section we review some facts on the Fourier analysis of the p-biased cube. Many of them
are standard results that can be found e.g. in O’Donnell [53, Chapters 2,8, and 11].
3.1. Fourier analysis on the p-biased cube. Given a distribution D on a space Ω, we write
x ∼ (Ω, D) or x ∼ D to denote thatx is chosen out of Ω according to the distribution D. We shall
use bold letters to denote random variables.
n
n
We denote by L2 ({0, 1} , µp ) the Hilbert space of function f : {0, 1} → R equipped with the
p-biased inner product
hf, gi = Ex∼({0,1}n ,µp ) [f (x) g (x)] .
p
The p-biased norm is deﬁned by setting kf k = hf, f i. In any time that we write that f is an
element of the space L2 ({0, 1}n , µp ) , we shall use the shorthand E [f ] for Ex∼({0,1}n ,µp ) [f ].
n
The p-biased Fourier characters are an orthonormal basis of L2 ({0, 1} , µp ) deﬁned as follows.
Definition 3.1. Let i ∈ [n]. The Fourier character corresponding to the singleton {i} is the function
n
χpi ∈ L2 ({0, 1} , µp ) deﬁned by the formula
 q
− 1−p xi = 1
p
p
.
χi (x) := q p

xi = 0
1−p

More generally, let Q
S be a subset of [n]. The Fourier character corresponding to the set S ⊆ [n] is
the function χpS := i∈S χpi .
n

The Fourier characters are known to be an orthonormal basis for L2 ({0, 1} , µp ). Thus, each
P
p
p
ˆ
ˆ
function has a unique expansion of the form f =
S⊆[n] f (S) χS , where f (S) = hf, χS i . This
expansion is called the p-biased Fourier expansion of f , or just the Fourier expansion of f , where p
is clear from context. We also have the following identities known as the Parseval identities.
X
 
2
fˆ (S)
E f 2 = hf, f i =
S⊆[n]

E [f g] = hf, gi =
For any T ⊆ [n], the averaging operator
is deﬁned by setting

X

fˆ (S) ĝ (S) .

S⊆[n]



n−|T |
n
, µp
AT : L2 ({0, 1} , µp ) → L2 {0, 1}


AT [f ] (x) = E f[n]\T →x .

The operator AT [f ] has the following nice Fourier analytical interpretation. It is the operator that
annihilates all the Fourier coeﬃcients that correspond to sets that have nonempty intersection with
T.
n

Fact 3.2. Let f ∈ L2 ({0, 1} , µp ) be a function that has the Fourier expansion
X
fˆ (S) χpS .
f=
S⊆[n]

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

Then

X

AT [f ] =

14

fˆ (S) χpS

S⊆[n]\T

Another notion of importance for us is the notion of influence by Ben-Or and Linial [6].
n

Definition 3.3. The p-biased ith influence of a function f : {0, 1} → R whose Fourier expansion
P
is S⊆[n] fˆ (S) χpS is deﬁned by setting
h
2 i X
(3.1)
Inf pi [f ] = E f − A{i} [f ]
=
fˆ (S)2 .
S∋i

We shall also need to introduce the noise operator.

Definition 3.4. Given x ∈ {0, 1}n the (ρ, p)-noisy distribution of x denoted by Nρ,p (x) is a proban
bility distribution on elements y ∈ {0, 1} , where we set each coordinate yi independently to be xi
with probability ρ, and to a new p-biased element of {0, 1} with probability 1 − ρ.
The noise operator Tρ,p on the space L2 ({0, 1}n , µp ) is the operator that associates to each
n
f ∈ L2 ({0, 1} , µp ) the function
Tρ,p [f ] :=

E
y∼Nρ,p (x)

[f (y)] .

We have the following Fourier formula for Tρ,p [f ] .
Fact 3.5. Let ρ, p ∈ (0, 1), and let

X

f=

fˆ (S) χpS

S⊆[n]
n

be a function in L2 ({0, 1} , µp ). Then
Tρ,p [f ] =

X

ρ|S| fˆ (S) χpS .

S⊆[n]

3.2. The directed noise operators. We shall now introduce a directed analogue of the noise
operator. Recall that D (q, p) is the joint distribution on elements (x, y) ∈ {0, 1}n × {0, 1}n , such
that
x ∼ µq , y ∼ µp , ∀i : yi ≥ xi .
We deﬁne an operator

and its adjoint

Tp→q : L2 ({0, 1}n , µp ) → L2 ({0, 1}n , µq ) ,
n

by setting

and

n

Tq→p : L2 ({0, 1} , µq ) → L2 ({0, 1} , µp ) ,
Tp→q (f ) (x) = Ex,y∼D(q,p) [f (y) | x = x] ,
Tq→p (f ) (y) = Ex,y∼D(q,p) [f (x) | y = y] .

These operators were ﬁrst studied by Ahlberg, Broman, Griﬃths, and Morris [2], and then again
by Abdullah and Venkatasubramania [1]. The one sided noise operator has the following Fourier
formulas:

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

15

q

P
n
q
2
ˆ
Lemma 3.6. Let p > q, and set ρ = q(1−p)
S⊆[n] f (S) χS be a function in L ({0, 1} , µq ).
p(1−q) . Let f =
Then Tq→p (f ) has the p-biased Fourier expansion:
X
ρ|S| fˆ (S) χpS .
Tq→p (f ) =
S⊆[n]

P

p
S⊆[n] ĝ (S) χS

Similarly, if g =
q-biased Fourier expansion

n

is a function in L2 ({0, 1} , µp ), then the function Tp→q (g) has the
Tp→q (g) =

X

ρ|S| ĝ (S) χqS .

S⊆[n]
q→p

Proof. We shall prove it for the operator T
, as the proof for the other operator Tp→q will be
similar. By linearity, it is enough to prove the lemma in the case where f = χqS for some S ⊆ [n] .
n
Let y ∈ {0, 1} . Note that
"
#
Y q
q
q
Tq→p [χS ] (y) = Ex,y∼D(q,p)| y=y [χS (x)] = Ex,y∼D(q,p)| y=y
(3.2)
χi (xi ) .
i∈S

Claim 3.7 below shows that

Ex,y∼D(q,p)| y=y [χqi (xi )] = ρχpi (yi ) .
By the independence of the random variables χqi (xi ) for any x, y ∼ D (q, p) | y = y we obtain:
"
#
Y q
Y
Ex,y∼D(q,p)| y=y
χ{i} (xi ) =
(3.3)
Ex,y∼D(q,p)| y=y [χqi (xi )]
i∈S

i∈S

= ρ|S|

Y

χpi (yi ) = ρ|S| χS (y) .

i∈S

Combining (3.2) with (3.3), we complete the proof.

Claim 3.7. Let x, y be elements of {0, 1}n , let p > q ∈ (0, 1) , and let ρ =
(3.4)

Ex,y∼D(q,p)| y=y [χqi (xi )] = ρχpi (yi ) ,


q

q(1−p)
p(1−q) .

Then

and
(3.5)

Ex,y∼D(q,p)| x=x [χpi (yi )] = ρχqi (xi ) .

Proof. Since the functions χqi , χpi depend only on the ith coordinate we may assume that n = 1, and
we shall write χp = χp1 as well as χq = χq1 for brevity. We shall start by showing (3.4), and the proof
of (3.5) will be similar. Let h ∈ L2 ({0, 1}n , µp ) be the map
y 7→ Ex,y∼D(q,p)| y=y [χq (x)] .

Note the space L2 ({0, 1} , µp ) is a linear space of dimension 2. We shall show that h = ρχp by
showing that there are two independent linear functionals on the space L2 ({0, 1} , µp ) that agree on
the functions h and ρχp . Namely, the ﬁrst functional is the functional of evaluating at 0, and the
second functional is the expectation according to the p-biased distribution. Indeed, we may use the
fact that elements x, y ∼ D (q, p) satisfy xi ≤ y i with probability 1 to obtain:
r
r
q
p
=ρ
= ρχp (0) .
Ex,y∼({0,1},D(q,p))| y=0 [χq (x)] = χq (0) =
1−q
1−p

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

16

On the other hand,


Ez∼µp [h (z)] = Ez∼µp Ex,y∼D(q,p)| y=z [χq (x)]

= Ex,y∼D(q,p) [χq (x)] = Ex∼µq [χq (x)] = 0

= Ez∼µp [ρχp (z)] .
Since the expectation functional and the evaluating by 0 functionals are independent, and since the
space L2 ({0, 1} , µp ) is of dimension 2, we obtain h = ρχp . This completes the proof of (3.4).
We prove (3.5) in a similar fashion. Deﬁne h ∈ L2 ({0, 1} , µq ) by
x 7→ Ex,y∼D(q,p)| x=x [χp (y)] .

Similarly to the proof of (3.4), it is enough to prove the identities
Ez∼µq (h) = 0, h (1) = ρχq (1) .
To prove the former, note that


Ez∼µq (h (z)) = Ez∼µq Ex,y∼D(q,p)| x=z [χp (y)] = Ex,y∼D(q,p) [χp (y)] = 0.

To prove the latter, note that

h (1) = Ex,y∼D(q,p)| x=1 [χp (y)] = χp (1) = ρχq (1) .

n

3.3.
Fourier
regularity. We shall say that a function f : {0, 1} → R is (r, δ, µp )-Fourier regular if


ˆ 
f
(S)
<
δ
for
each 0 < |S| ≤ r. It is easy to see (see O’Donnell [53, Chapter 7]) that any (r, δ, µp )


regular function is (r, δ, µp )-Fourier regular, and on the converse any (r, δ, µp )-Fourier regular function
is (r, 2r δ, µp )-regular. So in a sense these notions are equivalent.

p
n
Example 3.8. Let f : {0, 1} → [0, 1] be a transitive symmetric function. Then f is r, nr , µp 
Fourier regular for any r and p. Indeed, let S ∈ [n]
r , then the fact that f is transitive symmetric
implies that there exist distinct r-subsets of [n], S1 , . . . , S⌈ n ⌉ , such that fˆ (Si ) = fˆ (S) for each i.
r
By Parseval’s identity, we have
n
⌈X
r⌉

lnm
2
2
fˆ (Si ) =
fˆ (S) .
r
i=1

pr
r
, µp -Fourier regular, so it is in fact (r, δ, µp )-Fourier
After rearranging, we obtain that f is r, 2
n
r
regular, provided that n > 4δ2 .
1≥

kf k2µp

≥

n

3.4. The noisy influences. Let f ∈ L2 ({0, 1} , µp ) be a function. The noise stability of f is
deﬁned by
Stabρ,p (f ) := hTρ (f ) , f iµp =
E
[f (x) f (y)] .
x∼µp ,y∼Nρ,p (x)

By Fact 3.5, and by Parseval’s identity, we have
(3.6)

Stabρ,p (f ) =

X

2

ρ|S| fˆ (S) ,

S⊆[n]

where fˆ (S) are the Fourier coeﬃcients of f with respect to the p-biased distribution.
The (ρ, µp )-noisy inﬂuences of f are deﬁned by

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

(ρ,p)

Inf i
By Fact 3.2 and by (3.6) we have

[f ] := Stabρ,p
(ρ,p)

(3.7)

Inf i

[f ] =



X

f − A{i} [f ]



17

.

ρ|S| fˆ (S)2 .

S∋i

Definition 3.9. Let δ > 0, ρ, p ∈ [0, 1] . A function f : {0, 1}n → R is said to have (ρ, δ, µp )-small
(ρ,p)
[f ] < δ for every i ∈ [n] .
noisy inﬂuences if Inf i
3.5. Regularity lemmas we use. We shall make use of the following regularity lemma presented
by Jones [40].
Theorem 3.10. For each ǫ > 0 there exists j ∈ N such that the following holds. Let p ∈ (ǫ, 1 − ǫ)
and let f ∈ L2 
({0, 1} , µp ) 
be a function. Then there exists a set J of size at most j, such that if
J

we choose x ∼ {0, 1} , µp , then the functions fJ→x has (1 − ǫ, ǫ, µp )-small noisy influences with
probability at least 1 − ǫ.

Remark 3.11. Jones [40] proved Theorem 3.10 only for the case where p = 21 . However, as in most of
the results in the area, their proof can be extended verbatim to the p-biased distribution, for any p
bounded away from 0 and 1.
We also make use of the following regularity lemma of [17].
Theorem 3.12 ( [17, Theorem 1.7]). For each δ, ǫ > 0, there exists j ∈ N, such that the following

holds. Let δ < nk < 1 − δ, and let F ⊆ [n]
be a family. Then there exists a set J of size at most j
k
and a family G ⊆ P (J), such that:
(1) We have µ (F \ hGi) < ǫ.

  
(2) For each B ∈ G the family FJB is δ1 , δ -regular and µ FJB > 2ǫ .

3.6. Functions on Gaussian spaces. Let γ be the standard normal probability distribution N (0, 1)
on R. Abusing notation, we will also use γ to denote the product normal probability distribun
2
n
n
tion N (0, 1)n on
 R . We shall denote by L (R , γ) the space of functions f : R → R, such that
2
kf kγ := Eγ f < ∞. This space is equipped with the inner product
Z
f (x) g (x) γ (x) dx.
hf, gi = Eγ [f g] =
Rn

n

The operator Tρ on the space (R , N (0, 1)), also known as the Ornstein-Uhlenbeck operator, is
deﬁned as follows.

Definition 3.13. Let ρ ∈ (0, 1), and let x ∈ Rn , the ρ-noisy distribution of x ispthe distribution
Nρ,γ (x), where we choose y by setting each coordinate yi independently to be ρxi + 1 − ρ2 zi , where
z is a new independent γ-distributed element of R. The noise operator Tρ on the space L2 (Rn , γ) is
the operator that associates to each f ∈ L2 (Rn , γ) the function
Tρ [f ] (x) :=

E

y∼Nρ,γ (x)

[f (y)] .

Remark 3.14. The analogy between the distribution Nρ,p , and Nρ,γ stems from the fact if we choose
x ∼ γ, and y ∼ Nρ,γ (x) , then we have the following properties.
• x, y ∼ γ.
• ∀i : E [xi yi ] = ρ.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

18

• The R2 -valued random variables(xi , yi ) are independent of each other.
These properties are similarly satisﬁed when we choose x ∼µp and then choose y ∼ Nρ,p (x) .

For µ ∈ (0, 1), we let Fµ : R → [0, 1] denote the function 1x<t , where t is the only real number
for which Ex∼γ [Fµ (x)] = µ. The following theorem was proved by Borell [9]. It says that if f, g ∈
L2 (Rn , γ) are functions that take their value in the interval [0, 1] that satisfy E [f ] = µ, E [g] = ν,
then the maximal possible value of the quantity hTρ [f ] , gi is obtained when f = Fµ and g = Fν .
Theorem 3.15 (Borell 1985). Let f, g ∈ L2 (Rn , γ) be two [0, 1]-valued functions. Then



 
hTρ [f ] , gi ≤ Tρ FE[f ] , FE[g] .
We denote hTρ [Fµ ] , Fν i by Λρ (µ, ν) . Note that we trivially have

Λρ (µ, ν) := hTρ [Fµ ] , Fν i ≤ hTρ [Fµ ] , 1i = µ.

We will be interested in the case where µ is bounded away from 0 and ν, ρ are bounded away from
1. For such parameters, Λρ (µ, ν) admits a slightly stronger upper bound.
Lemma 3.16. For each ǫ > 0, there exists δ > 0, such that the following holds. Let µ ∈ (ǫ, 1) and
let ρ, ν ∈ (0, 1 − ǫ). Then
Λρ (µ, ν) ≤ µ − δ.

Proof. Let δ = hT1−ǫ [Fǫ ] , 1 − F1−ǫ i > 0. We have

Λρ (µ, ν) = hTρ [Fµ ] , Fν i = hTρ [Fµ ] , 1i + hTρ [Fµ ] , Fν − 1i

= µ − hTρ [Fµ ] , 1 − Fν i ≤ µ − hT1−ǫ [Fǫ ] , 1 − F1−ǫ i
= µ − δ.



We shall also use the following estimate on Λρ .
Lemma 3.17 ([49, Lemma 2.5]). Let ρ1 < ρ2 . Then
|Λρ1 (µ, ν) − Λρ2 (µ, ν)| ≤

10 (ρ2 − ρ1 )
.
1 − ρ2

We would also like to remark that we have the following Fourier formula for Tρ [f ], in the case
where f is a multilinear polynomial:
Q
P
Fact 3.18. Let f = S⊆[n] ai i∈S zi be a multilinear polynomial. Then
Y
X
ai ρ|S|
zi .
Tρ [f ] =
S⊆[n]

i∈S

3.7. The invariance principle. The invariance principle is a powerful theorem due to Mossel,
n
O’Donnell, and Oleszkiewicz [50] that relates the distribution of a ‘smooth’ function f : {0, 1} → R
with the distribution of functions on Gaussian spaces. To state a corollary of it that we shall apply,
we need to introduce some terminology.
Let f : Rn → R be a function. Following [16], we deﬁne the function Chop (f ) by setting


f (x) if f (x) ∈ [0, 1]
Chop (f ) (x) = 0
.
if f (x) ≤ 0


1
if f (x) ≥ 1
We shall also need the following deﬁnition.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

19

n

Definition 3.19. Let f ∈ L2 ({0, 1} , µp ) be some function with Fourier expansion
X
fˆ (S) χp .
f=
S

S⊆[n]

We let the Gaussian analogue of it be the multilinear polynomial f˜ ∈ L2 (Rn , γ) deﬁned by
Y
X
fˆ (S)
zi .
f˜ (z) =
S⊆[n]

i∈S

Roughly speaking, the invariance principle says that if the function f is suﬃciently ‘smooth’, then
n
the distribution of f (x), where x ∼ ({0, 1} , µp ) is somewhat similar to the distribution of f˜ (y),
n
where y ∼ (R , γ) is a Gaussian random variable. The smoothness requirement that we need is the
n
2
following. Let δ, ǫ > 0, we shall say that
 a function f ∈ L ({0, 1} , µp ) is (δ, 1 − ǫ, µp )-smooth if


|S|
Inf p [f ] < δ for each i ∈ [n] , and fˆ (S) ≤ (1 − ǫ) for each S ⊆ [n] .
i

As a corollary of the invariance principle, one can show (see [16, Theorem 3.8] or [50, Theorem
3.18]) the following corollary of it. It says that if f is a ‘suﬃciently smooth’ function that takes
 its
value in the interval [0, 1], then f˜ is concentrated on [0, 1] as well, in the sense that kf˜ − Chop f˜ k
is small.

Corollary 3.20 (Corollary of the invariance principle). For each ǫ, η > 0, there exists δ > 0, such
n
that the following holds. Let p ∈ (ǫ, 1 − ǫ), let f : {0, 1} → [0, 1] be a function, and suppose that f
is (δ, 1 − η, µp )-smooth. Then
 
kf˜ − Chop f˜ k < ǫ.
4. Counting lemma for the ρ-noisy influence regularity lemma

In this section we prove our version of the majority is stablest theorem that would serve as a
counting lemma in the proof of Theorem 1.7. The proof is a straightforward adaptation of the
proof by Mossel, O’Donnell, and Oleszkiewicz [50] of the Majority is Stablest Theorem, and its
generalizations by Mossel [48].
Proposition 4.1. For each ǫ > 0, there exists δ > 0, such that the following holds. Let ρ ∈ (0, 1 − ǫ) ,
n
and suppose that p − q > ǫ. Let f, g : {0, 1} → [0, 1] be some functions, and suppose that
o
n
(1−δ,q)
(1−δ,q)
[g] < δ.
[f ] , Inf i
max min Inf i
i∈[n]

Then
(4.1)

X

ρ|S| fˆ (S) ĝ (S) < Λρ (µq (f ) , µp (g)) + ǫ.

S⊆[n]

We divide the proof into three parts. In each of these parts we prove that if f, g satisfy certain
requirement then (4.1) holds. The hypothesis will be the strongest in the ﬁrst part, weaker on the
second part, and the weakest on the third part. The parts are as follows.
(1) We start by showing that (4.1) holds if f is assumed to be (δ, 1 − ǫ, µq )-smooth, and g is
assumed to be (δ, 1 − ǫ, µp )-smooth.
(2) We then prove (4.1) in the case where f and g are assumed to satisfy
o
n
(1−δ,q)
(1−δ,q)
[g] < δ.
[f ] , Inf i
max max Inf i
i∈[n]

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

20

(3) Finally, we shall complete the proof of the proposition by proving (4.1) in the case where f
and g are assumed to satisfy
o
n
(1−δ,q)
(1−δ,q)
[g] < δ.
[f ] , Inf i
max min Inf i
i∈[n]

4.1. Proof of the proposition in the case where f is (δ, 1 − ǫ, µq )-smooth and g is (δ, 1 − ǫ, µp )smooth. The idea of the proof is to convert the statement on f and g to a corresponding statement
about their Gaussian analogues f˜ and g̃, and then to prove the corresponding statement by applying
Borrel’s Theorem. A diﬃculty that arises in this approach is the fact that Borrel’s Theorem may
be applied only on functions that take their values in the interval [0, 1] , while the functions f˜ and
g̃ may take their values outside of this interval. However,we overcome this diﬃculty by noting that
Borrel’s theorem may be applied on the functions Chop f˜ and Chop (g̃) , and by observing that
 
Corollary 3.20 shows that f˜ and g̃ are approximated by the functions Chop f˜ and Chop (g̃) . The
technical details are below.
Lemma 4.2. For each ǫ > 0, there exists δ > 0 such that the following holds. Let q, p ∈ (ǫ, 1 − ǫ),
Pˆ
P
let ρ ∈ (0, 1) , let f =
f (S) χqS be a (δ, 1 − ǫ, µq )-smooth function, and let g =
ĝ (S) χpS be a
(δ, 1 − ǫ, µp )-smooth function. Then
X
ρ|S| fˆ (S) ĝ (S) < Λρ (µq (f ) , µp (g)) + ǫ.
S⊆[n]

Proof. Let ǫ > 0 and suppose that δ = δ (ǫ) is suﬃciently small. Let f˜ be the Gaussian analogue of
f and let g̃ be the Gaussian analogue of g. By Fact 3.18 we have
E
D
X
ρ|S| fˆ (S) ĝ (S) = Tρ f˜, g̃ .
S⊆[n]

So our goal is to show that

D

(4.2)

E
Tρ f˜, g̃ − Λρ (µq (f ) , µp (g)) < ǫ,

provided that δ is suﬃciently small. Let
D
 
E
E D 


ǫ1 :=  Tρ f˜, g̃ − Tρ Chop f˜ , Chop (g̃)  ,
and let

  
 h i
 




ǫ2 = Λρ E Chop f˜ , E (Chop (g̃)) − Λρ E f˜ , E [g̃] 
  


 


= Λρ E Chop f˜ , E (Chop (g̃)) − Λρ (µq (f ) , µp (g)) .
 
Applying Borrel’s Theorem on the functions Chop f˜ , Chop (g̃) , we obtain
 
 

D
 
E
(4.3)
Tρ Chop f˜ , Chop (g̃) ≤ Λρ E Chop f˜ , E (Chop (g̃)) ,

and hence

D

E
Tρ f˜, g̃ ≤ Λρ (µq (f ) , µp (g)) + ǫ1 + ǫ2 .

So to complete the proof we need to show that ǫ1 + ǫ2 < ǫ provided that δ is suﬃciently small.
Claim 4.3. Provided that δ is suﬃciently small we have ǫ1 < ǫ/2.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

21

Proof. Note that it follows from Jensen’s inequality that the operator Tρ on the space L2 (Rn , γ) is
a contraction. Indeed, for each function h ∈ L2 (Rn , γ) we have
h
2 i
2
kTρ (h)k = Ex∼(Rn ,γ) Ey∼Nρ (x) [h (y)]

2
≤ Ex∼(Rn ,γ) Ey∼Nρ (x) [h (y)]
2
= Ey∼(Rn ,γ) [h (y)]
= khk2 .

Moreover, we note that by Parseval kg̃k =

P

2

ĝ (S) =

r
i
h
2
Ey∼µp g (y) ≤ 1. Therefore,

D
E
E D 
 


ǫ1 =  Tρ f˜, g̃ − Tρ Chop f˜ , Chop (g̃) 
D
  E
E D 


≤  Tρ f˜, g̃ − Tρ Chop f˜ , g̃ 
D 
 
  E D 
E


+  Tρ Chop f˜ , g̃ − Tρ Chop f˜ , Chop (g̃) 
 
 
 
 




(By Cauchy-Schwarz) ≤ Tρ f˜ − Chop f˜  kg̃k + Tρ Chop f˜  kg̃ − Chop (g̃)k


 
 




(Since Tρ is a contraction) ≤ f˜ − Chop f˜  kg̃k + Chop f˜  kg̃ − Chop (g̃)k

 


≤ f˜ − Chop f˜  + kg̃ − Chop (g̃)k .

We may now apply Corollary 3.20 with ǫ replacing η and 4ǫ replacing ǫ, to obtain that

 
ǫ
˜

(4.4)
f − Chop f˜  + kg̃ − Chop (g̃)k < ,
2
provided that δ is suﬃciently small. This completes the proof of the claim.



To ﬁnish the proof of the lemma it remains to prove the following claim.
Claim 4.4. Provided that δ is suﬃciently small, we hhave
i ǫ2 < ǫ/2.
˜
Choose X ∼ (R, γ) , Y ∼ Nρ (X) . Then Λρ E f , E [g̃] is the probability of the event X <
 h
 i

t1 , Y < t2 for the proper values of t1 , t2 . Similarly, Λρ E Chop f˜ , E [Chop (g̃)] is the probability
of the event X < t3 , Y < t4 for the proper values of t3 , t4 . These events diﬀer either if X is in
the interval whose endpoints are t1 ,ht3 or 
if Yi is inhthe
i interval whose endpoints are t2 , t4 . The


˜
˜
Probability of the former event is E Chop f − E f , and the probability of the latter event is
|E [Chop (g̃)] − E [g̃] |. Therefore, a union bound implies that:
  h i
 h
 i




ǫ2 = Λρ E f˜ , E [g̃] − Λρ E Chop f˜ , E [Chop (g̃)] 
 h
 i
h i


≤ E Chop f˜ − E f˜  + |E [Chop (g̃)] − E [g̃] |
 
ǫ
(By Cauchy-Schwarz and (4.4)) ≤ kChop f˜ − f˜k + kChop (g̃) − g̃k < .
2



HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

22

4.2. The case where f, g have small noisy influences. We shall now prove a stronger version
of Lemma 4.2, where we impose on f, g the hypothesis
o
n
(1−δ,p)
(1−δ,q)
[g] < δ.
[f ] , Inf i
max max Inf i
i∈[n]

Lemma 4.5. For each ǫ > 0, there exists δ > 0 such that the following holds. Let q, p ∈ (ǫ, 1 − ǫ),
P
let ρ ∈ (0, 1), let f = fˆ (S) χqS be a function and suppose that
o
n
(1−δ,p)
(1−δ,q)
[g] < δ.
[f ] , Inf i
max max Inf i
i∈[n]

Then

X

ρ|S| fˆ (S) ĝ (S) < Λρ (µq (f ) , µp (g)) + ǫ.

S⊆[n]

Proof. Let ǫ > 0, let δ1 = δ1 (ǫ) be suﬃciently small, and let δ = δ (δ1 ) be suﬃciently small. Let
ρ
f ′ = Tq,1−δ1 (f ) , g ′ = Tp,1−δ1 (g) , ρ′ = (1−δ
2.
1)
′
We assert that the functions f is (δ, 1 − δ1 , µq )-smooth and the function g ′ is (δ, 1 − δ1 , µp )-smooth,
provided that δ is small enough. Indeed, the functions f ′ is (δ, 1 − δ1 , µq )-smooth since:
(1−δ1 ,q)

Inf i [f ′ ] = Inf i

provided that δ ≤ δ1 , and

(1−δ,q)

[f ] ≤ Inf i

[f ] < δ,


 

 ˆ′
 

|S|
|S|
f (S) = (1 − δ1 ) fˆ (S) ≤ (1 − δ1 ) .

The function g is (δ, 1 − δ1 , µp )-smooth for similar reasons. Provided that δ is small enough, Lemma
4.2 implies that
hTρ f, gi = hTρ′ f ′ , g ′ i ≤ Λρ′ (µq (f ′ ) , µp (g ′ )) + δ1 = Λρ′ (µq (f ) , µp (g)) + δ1 .

By Lemma 3.17 we have

Λρ′ (µq (f ) , µp (g)) < Λρ (µq (f ) , µp (g)) + ǫ − δ1 ,

provided that δ1 is suﬃciently small. Hence

hTρ f, gi ≤ Λρ (µq (f ) , µp (g)) + ǫ.
4.3. Proof of Proposition 4.1. Finally, we shall replace the hypothesis
o
n
(1−δ,p)
(1−δ,q)
[g] < δ
[f ] , Inf i
max max Inf i
i∈[n]

by the weaker hypothesis

o
n
(1−δ,p)
(1−δ,q)
[g] < δ.
[f ] , Inf i
max min Inf i
i∈[n]

Proof. Let ǫ > 0, let δ1 = δ1 (ǫ) be suﬃciently small, and let δ = δ (δ1 ) be suﬃciently small. Let
o
n
o
n
(1−δ ,q)
(1−δ ,q)
A1 = i ∈ [n] : Inf i 1 [f ] > δ1 , A2 = i ∈ [n] : Inf i 1 [g] > δ1 ,
let A = A1 ∪ A2 , and set B = [n] \A. Write f ′ = AA (f ) , g ′ = AA (g) . We have
X
X
X
ρ|S| fˆ (S) ĝ (S) =
ρ|S| fˆ (S) ĝ (S) +
ρ|S| fˆ (S) ĝ (S) .
S⊆[n]

S⊆B

S∩A6=∅



HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

We shall now bound

P

S⊆[n]
P

23

ρ|S| fˆ (S) ĝ (S) by bounding each of the terms in the right hand side.
ρ|S| fˆ (S) ĝ (S)

Upper bounding S⊆B
Since f ′ , g ′ satisfy the hypothesis of Lemma 4.5 (with δ1 replacing δ), we have
X
X
ǫ
ǫ
ρ|S| fˆ′ (S) gˆ′ (S) ≤ Λρ (µq (f ′ ) , µp (g ′ )) + = Λρ (µq (f ) , µp (g)) + ,
ρ|S| fˆ (S) ĝ (S) =
2
2

S⊆B

S⊆[n]

provided that δ1 is small
P enough.
Upper bounding S∩A6=∅ ρ|S| fˆ (S) ĝ (S) .
By Cauchy Schwarz, we have
sX

 X sX
X
XX

2
2
|S| ˆ
|S|  ˆ
|S|
ˆ
ρ f (S)
ρ|S| ĝ (S) .
ρ f (S) ĝ (S) ≤
ρ f (S) ĝ (S) ≤
i∈A S∋i

S∩A6=∅

S∋i

i∈A

S∋i

q
X q (ρ,q)
(ρ,p)
=
(f ) Inf i
(g).
Inf i
i∈A

Now note that

o
n
(ρ,p)
(ρ,q)
(g) ≤ 1
(f ) , Inf i
max Inf i
(1−δ,q)

(ρ,q)

(ρ,p)

(f ) and Inf i
(f ) ≤ Inf i
for any i ∈ [n] . Moreover, we have Inf i
provided that δ < 1 − ρ. The hypothesis implies that
o
n
(1−δ,p)
(1−δ,q)
(f ) ≤ δ.
(f ) , Inf i
max min Inf i

(1−δ,p)

(f ) ≤ Inf i

(f ) ,

i∈[n]

Therefore,

q
X q (ρ,q)
√
(ρ,p)
(f ) Inf i
(g) ≤ |A| δ.
Inf i
i∈A

2

ǫ
So this completes the proof provided that δ ≤ 4|A|
2 . We shall now complete the proof by showing
that |A| = Oδ1 (1) .
Upper bounding |A|
We show that |A1 | = Oδ1 (1) , as the proof that |A2 | = Oδ1 (1) is similar. Note that the quantity
Pn
(1−δ1 ,q)
(f ) is on the one hand bounded from below by |A1 | δ1 , and on the other hand we
i=1 Inf i
have the following upper bound on it.
n
X

(q,1−δ1 )

Inf i

(f ) =

i=1

X

S⊆[n]

|S|

(1 − δ1 )

2
|S| fˆ (S) ≤

∞
X
s=1

s

s (1 − δ1 ) = Oδ1 (1) .

Hence |A1 | = Oδ1 (1) . This completes the proof of the proposition.



5. Proof of the structural result on almost monotone functions
In this section we prove Theorem 2.5. We restate it for the convenience of the reader.
Theorem. For each ǫ > 0, there exists j ∈ N, δ > 0, such that the following holds. Let p, q be
numbers in the interval (ǫ, 1 − ǫ) that satisfy p − q > ǫ and let f : {0, 1}n → {0, 1} be a (q, p, δ)almost monotone function. Then there exists a monotone j-junta g, such that
Pr [f (x) > g (x)] < ǫ and Pr [f (x) < g (x)] < ǫ.

x∼µq

x∼µp

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

24

We recall that the proof relies on the regularity method, with the regularity lemma being Theorem
3.10 of [40], and with the corresponding counting lemma being Proposition 4.1.
The regularity lemma allows us to decompose f into functions {fJ→x }x∈{0,1}J , such that for most
of the parts the function fJ→x has small noisy inﬂuences and a q-biased measure that is bounded
J
away from 0. We shall then approximate f by the ‘least’ monotone junta g : {0, 1} → {0, 1} that
takes the value 1 on all the the x, such that the function fJ→x has small noisy inﬂuences. Here, by
least we mean smallest with respect to the partial order: g ≤ h if and only if g (x) ≤ h (x) for each x.
Proof. Let δ1 = δ1 (ǫ) be suﬃciently small, let δ2 = δ2 (δ1 ) be suﬃciently small, let j = j (δ2 ) be
suﬃciently large, and let δ = δ (j, δ1 , ǫ) be suﬃciently
 small. ByTheorem 3.10, there exists a set J
of size at most j, such that the for a random x ∼ {0, 1}J , µq the function fJ→x does not have

(1 − δ2 , δ2 , µq )-small noisy inﬂuences with probability at most δ2 .
Let Q ⊆ {0, 1}J be the set of ‘quasirandom parts’ consisting of all x ∈ {0, 1}J , such that fJ→x
has (1 − δ2 , δ2 , µq )-small noisy inﬂuences. So Prx∼{0,1}J [x ∈ Q] > 1 − δ2 .
J

J

Let N ⊆ {0, 1} be the set of ‘negligible parts’ consisting of all x ∈ {0, 1} , such that µq (fJ→x ) <
ǫ/2. Note that
Pr [f (x) = 1 | xJ ∈ N ] ≤ max Pr [f (x) = 1 | xJ = y] ≤
y∈N x∼µq

x∼µq

ǫ
.
2

Let A be the up-closure of Q/N , i.e. the set of all x ∈ {0, 1}J , such that there exists some
J
y ∈ Q\N that satisﬁes ∀i : yi ≤ xi . Finally, we let g : {0, 1} → {0, 1} be the indicator function of
A.
Showing that Prx∼µq [f (x) > g (x)] < ǫ.
n
For each x ∈ {0, 1} with f (x) > g (x) we have g (x) = 0, and particularly x ∈
/ Q\N. So we either
have x ∈
/ Q or we have the unlikely event that f (x) = 1 although xJ ∈ N. The former event occurs
with probability at most δ2 , and the latter event occurs with probability at most 2ǫ so
Pr [f (x) > g (x)] <

x∼µq

ǫ
+ δ2 < ǫ,
2

provided that δ2 is suﬃciently small.
Showing that Prx∼µp [f (x) < g (x)] < ǫ.
Let y ∈ A, let x ∈ Q\N be with ∀i : xi ≤ yi , and let ρ =
Proposition 4.1 to obtain that

q

q(1−p)
p(1−q) .

Since x is in Q, we may apply

hTq→p fJ→x , fJ→y i ≤ Λρ (µq (fJ→x ) , µp (fJ→y )) + δ1 ,

(5.1)

provided that δ2 is suﬃciently small.
This gives us an upper bound on hTq→p fJ→x , fJ→y i . On the other hand we may use the fact that
f is almost monotone to obtain a lower bound on hTq→p fJ→x , fJ→y i as follows. Note that we have
δ ≥ hTq→p f, 1 − f i =
(5.2)

≥
=

Pr

z,w∼D(q,p)

Pr

[f (z) = 1, f (w) = 0]




[zJ = x, wJ = y]
Pr
fJ→x z[n]\J = 1, fJ→y w[n]\J = 0

x,y∼({0,1}J ,D(q,p))

Pr

z,w∼D(q,p)

z,w∼D(q,p)
q→p

[x = x, y = y] hT

fJ→x , 1 − fJ→y i .

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

25

Thus,
hTq→p fJ→x , fJ→y i = hTq→p fJ→x , 1i − hTq→p fJ→x , 1 − fJ→y i
(5.3)

≥ µq (fJ→x ) −

δ
Prx,y∼({0,1}J ,D(q,p)) [x = x, y = y]

≥ µq (fJ→x ) − δ1 ,

provided that δ = δ (δ1 , j, ǫ) is small enough. Combining (5.1) and (5.3) we obtain
Λρ (µq (fJ→x ) , µp (fJ→y )) ≥ µq (fJ→x ) − 2δ1 .

By Lemma 3.16 we have µp (fJ→y ) > 1− 2ǫ provided that δ1 is small enough (note that µq (fJ→x ) >
ǫ/2, since x ∈
/ N ).
This shows that any y with g (y) = 1, f (y) = 0 satisﬁes the unlikely event that f (y) = 0 while
µp (fJ→yJ ) > 1 − ǫ/2. Since a random y ∼ µp satisﬁes this event with probability at most ǫ, we

obtain Pry∼µp [f (y) < g (y)] < ǫ. This completes the proof of the theorem.
We may repeat the proof of Theorem 2.5 to obtain the following lemma that we use in the proof
of Theorem 2.8.
Lemma 5.1. For each ǫ > 0, j ∈ N there exists δ > 0, such that the following holds. Let f, g : {0, 1}n →
[0, 1] be functions, let J be a set of size at most j, and let p, q ∈ (ǫ, 1 − ǫ), be with p − q > ǫ. Suppose
that hTq→p f, 1 − gi < δ, and let x, y ∈ {0, 1}J be with ∀i : xi ≤ yi . Suppose additionally that fJ→x has
(1 − ǫ, ǫ, µq )-small noisy influences. Then we either have µq (fJ→x ) < ǫ or we have µp (gJ→y ) > 1−ǫ.
Proof. Let δ1 = δ1 (ǫ) be suﬃciently small, and let δ = δ (δ1 , j) be suﬃciently small. Similarly to
(5.2) we have
δ ≥ hTq→p f, 1 − gi ≥ hTq→p fJ→x , 1 − gJ→y i

Pr

x,y∼({0,1}J ,D(q,p))

[x = x, y = y] .

Similarly to (5.3) we have
hTq→p fJ→x , gJ→y i ≥ µq (fJ→x ) − δ1 ,
provided that δ1 is small enough. Similarly to (5.1), we have
Hence,

hTq→p fJ→x , gJ→y i ≤ Λρ (µq (fJ→x ) , µp (gJ→y )) + δ1 .

Λρ (µq (fJ→x ) , µp (gJ→y )) ≥ µq (fJ→x ) − 2δ1 .
As in the proof of Theorem (2.5), we may now apply Lemma 3.16 to complete the proof.



We shall now prove Theorem 2.8. We restate it for the convenience of the reader.
Theorem. For each ǫ > 0, there exists δ > 0, such that the following holds. Let q, p ∈ (ǫ, 1 − ǫ) and
n
suppose that p > q + ǫ. Let f, g : {0, 1} → [0, 1], and suppose that
and that the function f is

1
δ

Ex,y∼D(q,p) [(1 − g (y)) f (x)] < δ,

, δ, µq -regular. Then either µq (f ) < ǫ, or µp (g) > 1 − ǫ.

Proof. Let δ1 = δ1 (ǫ) be suﬃciently small, let j = j (δ1 , ǫ) be suﬃciently large, and let δ = δ (j, δ1 , ǫ)
be suﬃcientlysmall. ByTheorem 3.10, there exists a set J of size at most j, such that for a
random x ∼ {0, 1}J , µq the function fJ→x does not have (1 − δ1 , δ1 , µq )-small noisy inﬂuences
J

with probability at most δ1 . Let Q ⊆ {0, 1} be the set of ‘quasirandom elements’ consisting of all

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

26

J

x ∈ {0, 1} , such that fJ→x has (1 − δ1 , δ1 , µq )-small noisy inﬂuences. Let A be the up-closure of Q.
Since A is monotone, we have
µp (A) ≥ µq (A) ≥ 1 − δ2 .

1
Moreover, the fact that f is δ , δ, µq -regular implies that

µq (fJ→x ) ≥ ǫ − δ > ǫ/2
o
n
for each x ∈ {0, 1} , provided that δ < min 2ǫ , 1j . By Lemma 5.1 (applied with ǫ/2 rather than
ǫ), we obtain that µp (gJ→x ) > 1 − ǫ/2 for all x ∈ A. So this implies that
J

µp (g) ≥ (1 − ǫ/2) µp (A) ≥ (1 − ǫ/2) (1 − δ/2) > 1 − ǫ.

This completes the proof of the theorem.



6. Counting matchings
In this section we prove Theorem 7.1 in the case where H is a matching.
Theorem 6.1. For each h ∈ N, ǫ > 0, there exists δ > 0, such that the following holds. Let
[n]
k1 , . . . , kh ≤ 1s − ǫ n, and let F1 ⊆ [n]
measure is at least
k1 , . . . , Fh ⊆ kh be families whose
 
1
ǫ. Suppose that for each i ∈ [n], such that ki ≥ δn the family Fi is δ , δ -regular, and choose
uniformly at random a matching {A1 , . . . , Ah } , such that
 
 
[n]
[n]
A1 ∈
, . . . , Ah ∈
.
k1
kh
Then

Pr [A1 ∈ F1 , . . . , Ah ∈ Fh ] > δ.
We start by stating some constructions that we shall use throughout the proof.
6.1. Basic constructions and overview of the proof. We completely identify between an element
n
x ∈ {0, 1} with the set of i ∈ [n] , such that xi = 1. Thus, we shall use the notations FJB , FJ1B
interchangeably, we write P (x) for the family of all subsets of {i : xi = 1} , we shall write xk for the
family of all subsets in P (x) whose size is k, and we write |x| for # {i : xi = 1} .

n
The ﬁrst construction that we need associates to each family F ⊆ [n]
a function fF : {0, 1} →
k
[0, 1] . This construction is originated in the work of Friedgut and Regev [34].

Definition 6.2. Let F ⊆ [n]
k , we associate to F the function fF deﬁned by
(
0
|x| < k
fF (x) =
.
PrA∼(x) [A ∈ F ] |x| ≥ k
k

n

Another construction we need turns a function f : {0, 1} → R into a Boolean function Cutδ (f ) .

Definition 6.3. Given a function f : {0, 1}n → R, and a δ ∈ R, we deﬁne the function Cutδ (f ) by
setting:
(
1 if f (x) ≥ δ
Cutδ (f ) (x) =
.
0 if f (x) < δ
We shall also need to introduce the following distributions.
Definition 6.4. Let p ∈ (0, 1) , and let k ∈ [n] .

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

27

n

• We write µ≥k
for the conditional probability distribution on x ∼ ({0, 1} , µp ) given that
p
<k
≤k
|x| ≥ k. (The distributions µ>k
p , µp , µp are deﬁned accordingly.)

≥k
• We write µp , J → B for the conditional distribution on sets A ∼ µ≥k
p given that A ∩ J =
 

[n]
B. The distributions (µp , J → B) , k , J → B are deﬁned accordingly.

Another construction we need is the construction of a random matchings
B1 , . . . , Bh ∈ P ([n]) ,

such that each of the sets Bi is distributed according to the

1
h -biased

distribution.

Definition 6.5. Choose uniformly and independently [0, 1]-valued random variables X1 , . . ., Xn . For
j
each i ∈ {1, . . . , h} we let Bi be the set of all j ∈ [n] , such that Xj is in the interval j−1
h , h . We call
1
the sets (B1 , . . . , Bh ) a random h -biased matching. Let k ≤ nh we call the conditional
 distribution on
1
1
matching (B1 , . . . , Bh ) given that |Bi | ≥ k for each i a h , k -biased matching.
a random h -biased

Given a h1 , k -biased matching (B1 , . . . , Bh ), we obtain that B1 is distributed according to some
matching
distribution that we denote by µ 1 ,k
.
h

Note that if (B1 , . . . , Bh ) a random h1 -biased matching, then each Bi is indeed chosen according
to the h1 -biased distribution, and moreover the sets B1 , . . . , Bh are pairwise disjoint with probability
1.
We will be concerned with the case where k ≤ nh − Θ (n). This would yield that |Bi | ≥ k
asymptotically almost surely for all i. So intuitively,
the distribution of a h1 -biased matching is not

1
much diﬀerent than the distribution of a h , k -biased matching.
The proof of Theorem 6.1 consists of three steps:
(In the following ǫ1 is suﬃciently small and ǫ2 = ǫ2 (ǫ1 ) is suﬃciently small)
(1) We set q to be slightly larger than nk . The
l ﬁrst
m step is to show that for each of the families
Fi of Theorem 6.1, the function fFi is

1
ǫ1

, ǫ1 , µq -regular.
matching
(2) The second step is to show that the measure µ 1 ,k
(Cutǫ2 (fFi )) is very close to 1.
h
This step is based on Theorem 2.8, and the proof roughly goes as follows.
• We show that the term Ex,y∼D(q, 1 ) [fFi (x) (1 − Cutǫ2 (fFi (y)))] is always smaller than
h
ǫ2 .
• We shall apply Theorem 2.8 to deduce that µ h1 (Cutǫ2 (fFi )) is large.
matching
to deduce that µ 1 ,k
(Cutǫ2 (fFi ))
• We shall use the similarity between µ s1 and µmatching
1
h ,k
h
is large.

(3) We then ﬁnish the proof by observing that if we choose a h1 , k -biased matching B1 , . . . , Bh ,


Bh
1
and then choose sets M1 ∼ B
k1 , . . . , Ms ∼ kh . Then M1 , . . . , Mh is a uniformly random
matching. By Step 2 and a union bound we would have Cutǫ2 (fFi ) (Bi ) = 1 with high probability. On the other hand for each Bi with Cutǫ2 (fFi ) (Bi ) = 1, we have PrMi ∼(Bi ) [Mi ∈ F ] ≥
ki

ǫ2 , and for each choice of disjoint B1 , . . . , Bh these events are independent. Therefore, the
probability that Mi is in F for each i cannot be much smaller than ǫh2 .
We shall start with the proof of the ﬁrst step.

 
6.2. Showing that if F is regular, then the function fF is 1ǫ , ǫ, µq -regular. In order to
show that the function fF is regular, we will need to show that µq (fF ) is approximately µq ((fF )J→x )

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

28

 
J
for each |J| ≤ 1ǫ , and each x ∈ {0, 1} . In order to accomplish this we would need to write both
of the quantities µq (fF ) , µq ((fF )J→x ) in terms of F . We shall start by showing that µq (fF ) is
approximately equal to µ (F ) .
Lemma 6.6. For each ǫ > 0, there exists n0 > 0,
 such that the following holds. Let n > n0 , let
be some family. Then
q ∈ (0, 1) , k ≤ n satisfy q ≥ nk + ǫ, and let F ⊆ [n]
k
(6.1)

µq (fF ) ≤ µ (F ) ≤ µq (fF ) (1 + ǫ) .

Proof. We have
[fF (x)] + Pr [x < k] Ex∼µ<k
[fF (x)] .
µq (fF ) = Ex∼µq [fF (x)] = Pr [x ≥ k] Ex∼µ≥k
q
q
#
"
= Pr [|x| ≥ k] Ex∼µ≥k
q
x∼µq

Pr [A ∈ F ] .

A∼(x
k)

However, whenever we choose x ∼ µ≥k
q , and an A ∼

uniformly in [n]
.
Thus,
k
(6.2)

x
k


, we obtain a set A that is distributed

µq (fF ) = Pr [|x| ≥ k] µ (F ) .
x∼µq

The lemma follows by combining (6.2) with the fact that Prx∼µq [|x| ≥ k] tends to 1 as n tends to
inﬁnity.

We now turn to the task of approximating µq ((fF )J→x ) in terms of F . We show that for some
λ > 0 the term µq ((fF )J→x ) can be approximated by
E
C∼(P(x),µλ )

[µ (FJ→C )] .

Lemma 6.7. For each ǫ > 0 there exists n0 , such that the following holds. Let n > n0 , let k ≤ n
k
and let q be a number in the interval nk + ǫ, 1 , and set λ = qn
. Then
µq ((fF )J→x ) (1 − ǫ) ≤

E

C∼(P(x),µλ )

[µ (FJ→C )] ≤ µq ((fF )J→x ) (1 + ǫ) .

Proof. As in Lemma 6.6, we have
(6.3)

µq ((fF )J→x ) =

Pr

y∼(µq ,J→x)

[|y| ≥ k]

E
y∼(µ≥k
q ,J→x)

[fF (y)] .

Note that
Pr

y∼(µq ,J→x)

[|y| ≥ k] = 1 − o (1) ,

where the o (1) is with respect to n tending to inﬁnity. So to complete the proof it remains show that
E
y∼(µ≥k
q ,J→x)

[fF (y)] = (1 + o (1))

E
C∼(P(x),µλ )

[µ (FJ→C )] .



y
Choose y ∼ µ≥k
q , J → x ,A ∼ k , then A ∩ J is equal to some subset C of x. Note also that the
conditional distribution of A given that C =C is the distribution of a uniformly random element of

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS
[n]
k



29

that intersects J at the set C. Therefore,
E
y∼(µ≥k
q ,J→x)

[fF (y)] =

Pr

y
y∼(µ≥k
q ,J→x),A∼( k )

X

C⊆x

(6.4)

=

[A ∈ F ]

Pr [C = C] Pr [A ∈ F | C = C]

X

C⊆x


Pr [C = C] µ FJC .

So to complete the proof it remains to show that
Pr [C = C] = λ|C| (1 − λ)

(6.5)

|x|\|C|

(1 + o (1)) .

Indeed, with high probability |y| = qn (1 + o (1)) , and the conditional probability that C = C given
that |y| = s is


	
 |C| 
|x|\|C|
s−|x| 
 S ∈ y that satisfy |S ∩ x| = C 
k
k
k−|C|
k
 y

=
1−
=
(1 + o (1)) .
s
 
s
s
k
k

Let s = |y| . Thus,

#
"  
|x|\|C|
|C|
k
k
1−
(1 + o (1))
Pr [C = C] = Es [Pr [C = C | s]] = Es
s
s
= λ|C| (1 − λ)

|x|\|C|

(1 + o (1)) ,

where the last equality follows from the fact that
completes the proof of the lemma.

k
s

= λ (1 + o (1)) with high probability. This



  
We are now ready to show that if F ⊆ [n]
is a 1ǫ , ǫ -regular family, and if we choose q that
k
1

is bounded from below away of nk , then the function fF is 2ǫ
, 2ǫ, µq -regular, provided that n is
suﬃciently large.

Lemma 6.8. For each ǫ < 0, there exists n0 , such that the following holds. Let n > n0 , let F ⊆ [n]
k
1




be a 2ǫ , 2ǫ -regular family, and let q ≥ nk + ǫ. Then the function fF is 1ǫ , ǫ, µq -regular.

[n]
Proof. Fix ǫ > 0, let n0 be suﬃciently large,
 1 and let F ⊆ k , be as in the hypothesis of the lemma.
Let B ⊆ J ⊆ [n] be sets, such that |J| ≤ ǫ . By Lemma 6.6
(6.6)

|µ (F ) − µq (fF )| <

provided that n0 is large enough. By Lemma 6.7



(6.7)
µq ((fF )J→B ) − E 

C∼ P(x),µ

provided that n0 is large enough.

k
qn

ǫ
,
4

µ

FJC



ǫ
< ,
 4

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

By hypothesis



(6.8)
µ (F ) − E 

C∼ P(x),µ

k
qn

µ

FJC

 
 
 = E 
  C∼ P(x),µ
≤E


C∼ P(x),µ

k
qn

k
qn





µ

FJC

ǫ
ǫ
= .
2
2



30



− µ (F ) 


Thus,





C
µ F
|µq ((fF )J→B ) − µq (fF )| ≤ µq ((fF )J→B ) − E 
J 


C∼ P(x),µ k
qn






 µ F C − µ (F ) + |µ (F ) − µ (f )|
+ E 

q
F
J
 C∼ P(x),µ k

qn

ǫ
ǫ
ǫ
< + + = ǫ.
4 4 2
 

This completes the proof that fF is 1ǫ , ǫ, µq -regular.

 
6.3. Showing that if nk is small, then fF is 1ǫ , ǫ, µq -regular.



Lemma 6.9. For each ǫ > 0, there exists δ > 0 such that the following holds. Let


 
and let F ⊆ [n]
be some family. Then the function fF is 1ǫ , ǫ, µq -regular.
k
 
Proof. Let J be of size at most 1ǫ , and let B ⊆ J. We have

 


(6.9)
|µq ((fF )
) − µq (fF )| ≤ µ F ∅ − µq (fF ) + µ F ∅ − µq ((fF )
J

J→B

J

k
n

< δ, let q ≥ ǫ,


.

J→B )

We shall complete the proof by giving an upper bound of 2ǫ for each of the summands in the right
hand side of (6.9). 


Showing that µ FJ∅ − µq (fF ) ≤ 2ǫ .
By decreasing δ if necessary we may assume that n is as large as we wish. Therefore Lemma 6.6
implies that
ǫ
|µq (fF ) − µ (F )| < ,
4
provided that δ is small enough. Now note that
X

(6.10)
µ (F ) =
Pr [A ∩ J = B] µ FJB
[n]
B⊆J A∼( k )
 |B| !

 
X


k
k
∅
µ FJ +
µ FJB .
O
= 1−O
n
n
∅6=B⊆J

So provided that δ is small enough, we have
 




µq (fF ) − µ F ∅  ≤ |µq (fF ) − µ (F )| + µ (F ) − µ F ∅  ≤ ǫ + Oǫ k < ǫ/2.
J
J
4
n



∅
ǫ
Showing that µ FJ − µq ((fF )J→B ) < 2 .
By Lemma 6.9




|B|\|C|
X  k |C| 

 ǫ

k
C 
µq ((fF )
µ FJ  ≤ ,
1−
J→B ) −

qn
qn

 4
C⊆B

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

31

provided that n is large enough. Now note that similarly to (6.10) we have
|B|\|C|
 
X  k |C| 


k
k
∅
C
1−
.
µ FJ = µ FJ + Oǫ
qn
qn
n
C⊆B

Thus,

 
 ǫ
ǫ
k
∅ 
< ,
+
O
)
−
µ
F
≤
ǫ
J→B
J
4
n
2
provided that δ is small enough. This completes the proof of the lemma.

1

1
In the last two
6.4. Showing that if F is
δ , δ, µq -regular, then µ h (Cutδ (fF )) is large.

1
sections we gave two criteria on a family F that imply that the function fF is δ , δ, µq -regular
matching
(Cutδ (fF )) is large. As
for a small δ. We shall now show that both criteria imply that µ 1 ,k
Eh
D 1
mentioned, we will ﬁrst show that the pair T h →q fF , Cutδ (fF ) < ǫ. We would then deduce from
Theorem 2.8 that µ h1 (Cutδ (fF )) is large, and this would allow us to ﬁnish the proof by using the
matching
fact that the distributions µ 1 ,k
, µ h1 are very close to each other.

µq ((fF )

h

Lemma 6.10. Let δ > 0, let p > q >

k
n.

For any F ⊆

[n]
k



we have

Ex,y∼D(q,p) [fF (x) (1 − Cutδ (fF ) (y))] ≤ δ.
Proof. We show that the stronger statement that for each value y of y, we obtain that if we choose
conditionally x, y ∼ D (q, p) given that y = y, then
(6.11)

Ex [fF (x) (1 − Cutδ (fF ) (y))] ≤ δ.

This clearly holds if Cutδ (fF ) (y) = 1. So suppose that Cutδ (fF ) (y) = 0, we also suppose that
|y| ≥ k for otherwise we would have |x| < k, and hence fF (x) = 0. Now note that
#
"
Ex [fF (x)] ≤ Ex

Pr [A ∈ F ] | |x| ≥ k = Pr [A ∈ F ] = fF (y) ≤ δ.
A∼(y
k)

A∼(x
k)

This completes the proof of the lemma.



We shall now complete the second step of showing that µ h1 (Cutδ (fF )) is large.
Lemma 6.11. For each ǫ > 0, there exists δ > 0, such that the following holds. Let p ≥ nk + ǫ, and

let F ⊆ [n]
be some
k 
 family whose measure is at least ǫ. Suppose that we either have k ≤ δn or the
family F is δ1 , δ -regular. Then
µp (Cutδ (fF )) > 1 − ǫ.

Proof. Let q =

k
n

+ 2ǫ , and note that by Lemma 6.10 we have
Ex,y∼D(q,p) [fF (x) (1 − Cutδ (fF ) (y))] ≤ δ.

By decreasing δ if necessary, we may assume that n is suﬃciently large for Lemma 6.6 to imply that
µq (fF ) ≥ 2ǫ . By Theorem 2.8 (applied with 2ǫ rather than ǫ) we have µp (fF ) ≥ 1 − 2ǫ > 1 − ǫ,
provided that δ is small enough. This completes the proof of the lemma.


HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

32

matching
are ‘close’, and
We now complete the ﬁnal step of deducing from the fact that µ h1 and µ 1 ,k
h
matching
from the fact that µ h1 (Cutδ (fF )) is large, that µ 1 ,k
(Cutδ (fF )) is in fact also large.
h

Corollary 6.12. For each ǫ > 0, h there exists δ > 0, such that the following holds. Let nk ≤ h1 − ǫ,

and let F ⊆ [n]
k besome
 family whose measure is at least ǫ. Suppose that we either have k ≤ δn or
the family F is δ1 , δ -regular. Then
µmathching
(Cutδ (fF )) ≥ 1 − ǫ.
1
,k
h

Proof. By Lemma 6.11, we have µ h1 (Cutδ (fF )) > 1 − 2ǫ provided that δ is small enough. Also note
that we may assume that n is suﬃciently large by decreasing δ if necessary.

We shall now deﬁne a coupling between h1 -biased matching, and h1 , k -biased matchings as follows.
We choose a h1 -biased matching M1 , M2 , . . . , Mh , and we then let M′1 , . . . , M′s to be equal to the
original 1s -biased matching if the (likely) event ∀i : |Mi | ≥ k occurred, and we let it be equal to a
new h1 , k -biased matching otherwise. Note that
Pr [M1 ∈ Cutδ (fF )] = µ h1 (Cutδ (fF )) ,

and that
matching
Pr [M′1 ∈ Cutδ (fF )] = µ 1 ,k
(Cutδ (fF )) .
h

Thus,
matching
(Cutδ (fF )) ≥ µ h1 (Cutδ (fF )) − Pr [M1 6= M′1 ] ≥ 1 − ǫ,
µ 1 ,k
h

provided that n is suﬃciently large to imply Pr [M1 6= M′1 ] < 2ǫ .



6.5. Proof of Theorem 6.1.
[n]
k1


, . . . , Fh ⊆

[n]
kh



be some families that satisfy the hypothesis of
(δ′ )h
the theorem, let δ ′ = δ ′ (ǫ) be suﬃciently small, and let δ = 3 . By Corollary 6.12,

Proof of Theorem 6.1. Let F1 ⊆

1
matching
µ 1 ,k
(Cutδ′ (fFi )) > 1 −
h
2h

for each i, provided that δ ′ is small enough. A union bound implies that if we choose a h1 , k -biased
matching A1 , . . . , Ah , then the event ∀i Cutδ′ (fFi )(Ai ) = 1 happens with probability greater than
Ai
1
2 . Now choose independently a matching Mi ∼ ki . For each choice of values A1 , . . . , Ah of the sets
h

A1 , . . . , Ah , we obtain that the events {Mi ∈ Fi |Ai = Ai }i=1 are independent. Therefore
Pr [∀i : M i ∈ Fi ] ≥ Pr [∀i Cutδ (fFi ) (Ai ) = 1] δ ′h ≥

δ ′h
= δ.
2

This completes the proof of the theorem, since the hypergraph {M1 , . . . , Mh } is a uniformly random
matching.


HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

33

7. Counting expanded hypergraphs
We shall now generalize Theorem 6.1 to general expanded hypergraphs.
Theorem 7.1. For each c, h ∈ N, ǫ > 0 there exists δ > 0, such
that the following holds. Let

[n]
1
1
be
sets,
such that the hypergraph
≤
k
,
.
.
.
,
k
≤
−
ǫ
n
be
some
numbers,
and
let
A
∈
1
h
i
δ
h
ki


[n]
families of
H = {A1 , . . . , Ah } has center of size at most c. Let F1 ⊆ k1 , . . . , Fh ⊆ [n]
kh be some
  
measure at least ǫ. Suppose that for each i, we either have kni ≤ δ or the family Fi is δ1 , δ -regular.


[n]
Choose uniformly at random a copy (A1 , . . . , Ah ) ∈ [n]
k1 × · · · × kh of H. Then
Pr [A1 ∈ F1 , . . . , Ah ∈ Fh ] > δ.

Note that H ⊆ P (V ) can be written in the form

{E1 ∪ D1 , . . . , Eh ∪ Dh } ,

where C := E1 ∪ · · · ∪ Eh is the center of H, and where the sets C, D1 , . . . , Dh are pairwise disjoint.
If π : V → [n] is a random injection, then π (E1 ∪ D1 ) , . . . , π (Eh ∪ Dh ) is a uniformly random copy
of H. Write Ei = π (Ei ) , Di = π (Di ) , and C = π (C) . Our basic observation is that the following
events are equal.
(1) The families F1 , . . . , Fh cross contain the random copy of H
(π (E1 ∪ D1 ) , . . . , π (Eh ∪ Dh )) = (E1 ∪ D1 , . . . , Eh ∪ Dh ) .

i
(2) The families (Fi )E
C cross contain the uniformly random matching D1 , . . . , Dh .

E

Therefore it is natural to try to apply Theorem 6.1 on the families (Fi )Ci . As it turns out, the only
Ei
hypothesis

 of Theorem 6.1 that the families (Fi )C do not obviously satisfy is the hypothesis that
E

µ (Fi )Ci

> ǫ. The following Fairness Proposition by Keller and the author [43, Proposition 5.1]
E

allows us to deduce that the families (Fi )Ci are of measure greater than ǫ with high probability. To
state their result we need to introduce the notion of fairness. Roughly speaking, a set J is ‘fair’ for
F if the measures of each of the families FJB is not signiﬁcantly smaller than the measure of F .
Definition 7.2. A set J is ǫ-fair for F if


µ FJB ≥ (1 − ǫ) µ (F )

for any B ⊆ J.


The Fairness Proposition tells us that for any F ⊆ [n]
k and any J ∼
probability, provided that k is not too close to either 0 or n.

[n]
s



is ǫ-fair for F with high

Proposition 7.3. For each ǫ, s > 0, there exists m > 0 such that the following
holds. Let m < k <

[n]
[n]
n − m, let F ⊆ k be some family of measure at least ǫ, and let J ∼ s . Then
Pr [J is ǫ-fair for F ] ≥ 1 − ǫ.

i
Proof of Theorem 7.1 . Let E i , C, D i be as above. Our goal is to show that the families (Fi )E
C cross
contain the uniformly random matching D1 , . . . , Dh with probability ≥ δ. Noting that the size of C
is ﬁxed, the following observations are easy to verify provided that δ is suﬃciently small:
• Proposition 7.3, implies that the set C is 12 -fair with probability at least 12 . For any such C
[n]\C 
i
ǫ
the measure of the family (Fi )E
C ⊆ ki −|Ei | is at least 2 .

• For any i such that

ki
n

< δ, we have

ki −|Ei |
n−|C|

< 2δ.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

34


1
  
E
, 2δ -regular.
• If Fi is 1δ , δ -regular, then (Fi )Ci is 2δ
We shall also assume that the δ of this lemma is small enough for Theorem 6.1 to hold with 2δ
replacing δ, and 2ǫ replacing ǫ. These observations allow us to apply Theorem 6.1, and to deduce that

C′
we have
for each set C ′ that is 21 -fair for F , and for each set Ei′ ∈ |E
i|
i
h
Pr ∀i : Di ∈ FCE′i > 2δ.
Therefore,


 

i
h
1
1
Ei
Ei
Pr ∀i : Di ∈ FC ′ ≥ Pr C is -fair Pr ∀i : Di ∈ FC | C is -fair > δ.
2
2

This completes the proof of the theorem.



8. Removal lemma for expanded hypergraphs
In this section we prove Theorem 1.13, Proposition 1.14, and Theorem 1.11.
Let H = {A1 , . . . , Ah } ⊆ P (V ) . Any hypergraphs of the form {A1 ∩ S, . . . , Ah ∩ S} is called a
trace of H. We shall need the following lemma.
Lemma 8.1. For each h, c, s, j ∈ N, ǫ > 0 there exists δ > 0, such that the following holds. Let H be
a hypergraph with h edges whose center is of size c, and let G ⊆ P (J). Let δ1 ≤ k ≤ h1 − ǫ n. Then
the following are equivalent.
(1) The junta hGi is (H, s)-free.
(2) There exists no copy of a trace of H in G, whose center is of size at most s.
Proof. We start by showing that if (2) does not hold, then (1) does not holds. By hypothesis, there
[n]\J 
exist a trace {C1 , . . . , Ch } of H in G whose center is of size at most s. Let B1 ∈ k−|C
, . . . , Bh ∈
1|
[n]\J 
be some pairwise disjoint sets (such sets exist provided that δ is large enough). Then the
k−|Ch |
hypergraph {C1 ∪ B1 , . . . , Ch ∪ Bh } is contained in hGi, it is the resolution of the hypergraph H and
its center is of size at most s. Therefore, the family hGi is not (H, s)-free and so (1) does not hold.
We now show that if (1) does not hold, then (2) does not holds. Let {A1 , . . . , Ah } ⊆ hGi be a
resolution of H whose center is of size at most s. The hypergraph {A1 ∩ J, . . . , Ah ∩ J} is contained
in G, its center is of size at most s, and in order to complete the proof we need to show that it is a
trace of H.
For each i = 1, . . . , h let Di ⊆ [n] \J be a suﬃciently large set that is contained in Ai and does
not intersect any other edge of H. The fact that {A1 , . . . , Ah } is a resolution of H implies that there
exist sets E1 , . . . , Eh ⊆ [n] \J, such that
H′ := {(A1 \D1 ) ∪ E1 , . . . , (Ah \Dh ) ∪ Eh }

is a copy of H. Now note that if we intersect each of the edges of H′ with J, we obtain the original
hypergraph {A1 ∩ J, . . . , Ah ∩ J} . Therefore, A1 ∩J, . . . , Ah ∩J is indeed a trace of H. This completes
the proof of the lemma.

We will also need the following lemma.

Lemma 8.2. Let ǫ > 0, s ≤ c, h ∈ N be some constants. Let ǫn ≤ k ≤ h1 − ǫ n, let H be a k-uniform
hypergraph whose center is of size c. Let {A1 , . . . , Ah } be a uniformly random copy of H, let J ⊆ [n]
be some set of size at most 1ǫ , and let {B1 , . . . , Bh } ⊆ P (J) be a trace of H of center of size s. Then
s 
the probability that Ai ∩ J = Bi for each i is Θ n1
.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

35

Proof. Let C be the center of {A1 , . . . , Ah }, let Ci = C ∩ Ai , and let Di = Ai \C for each i.
Similarly, let C be the center of {B1 , . . . , Bh } , write Ci = Bi ∩ C, and Di = Bi \C. We deﬁne the
following three events:
• We let E0 be the event that C ∩ J = C
• We let E1i be the event that Ci ∩ J = Ci .
• We let E2i be the event that Di ∩ J = Di .
Note that the event that Ai ∩ J = Bi for each i is the intersection of all the above events. The

(n−j )
= Θ n1s , once we show that
lemma will follow from the fact that E0 occurs with probability c−d
(nc)
the other events occur with conditionalTprobability Θ (1) given that E0 holds.
Since |C| = c is constant, the event E1i occur hwith conditional probability
i Θ (1) given E0 .
Th
i
1
h
We now complete the proof by showing that Pr i=1 E2 |E1 , . . . , E1 , E0 is Θ (1) .

[n]\C1
, then taking a set
Note that D1 , . . . , Dh may be chosen by ﬁrst taking a set D1 ∼ k−|C
1|
S

D
[n]\(C∪ h−1
)
[n]\(C∪D1 )
i
i=1
. Since for each i the term
D ∼
, and so on until we choose a set D ∼
2

k−|C2 |
k−|Ci |
P
n−|C|− h
i=1 |Dh |

h

k−|Ch |

is bounded away from 0 to 1, we have

This completes the proof.

Pr [∀i : Di ∩ J=Di ] = Θ (1) .


We now prove the following restatement of Theorem 1.13.
Theorem. For each h, c, ǫ, s ∈ N, there exists δ, j > 0, such that the following holds. Let H be a
hypergraph with h edges whose center is of size c. Let


1
1
≤k≤
− ǫ n,
δ
h
and let F be a

δ
ns -almost

H-free family. Then F is ǫ-essentially contained in an (H, s)-free j-junta.

Proof of Theorem 1.13. Let δ1 = δ1 (h, c, ǫ, s) be suﬃciently small, let j = j (δ1 ) be suﬃciently large,
and let δ = δ (j) be suﬃciently small. By Theorem 7.1 we may take J to be ∅ if nk < δ1 , provided
that δ1 is suﬃciently small. So suppose that nk > δ1 . By Theorem 3.12, there exists a set J and a
family G ⊆ P (J) l
, suchm that
in J := hGi, and such that for each B ∈ G
 F is ǫ-essentially contained
 ǫ
1
B
B
≥ 2.
the family FJ is
δ1 , δ1 -regular and µ FJ
Showing that J is (H, s)-free.
By Lemma 8.1 it is enough to show that G does not contain a trace of H in G whose center is of
size at most s. Suppose on the contrary that {C1 , . . . , Ch } is a trace of H in G whose center is of size
at most s. Then there exist sets B1 , . . . , Bh ⊆ [n] \J, such that H′ = {C1 ∪ B1 , . . . , Ch ∪ Bh } is a
copy of H. Let {H1 , . . . , Hh } be a random copy of H on [n] . By Lemma 8.2 we have
 
1
,
Pr [∀i : Hi ∩ J = Ci ] = Ωδ1 ,j
ns
and we have
i
h
Pr [{H1 , . . . , Hh } ⊆ F | ∀i : Hi ∩ J = Ci ] = Pr ∀i : Hi \J ∈ FJCi .
l m

1
Now note the families FJCi are
-regular and have measure greater than 2ǫ . Provided that
,
δ
1
δ1

δ1 is small enough, we may apply Theorem 7.1 with ǫ/2 instead of ǫ, the hypergraph (H 1 \J, . . . , H h \J),

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

and δ1 instead of δ, to obtain

36

h
i
Pr ∀i : Hi \J ∈ FJCi ≥ δ1 .

Putting everything together, we obtain

Pr [{H1 , . . . , Hh } ⊆ F ] ≥ Pr [{H1 , . . . , Hh } ⊆ F | ∀i : Hi ∩ J = Ci ] · Pr [∀i : Hi ∩ J = Ci ]
 
1
.
= Ωδ1 ,ǫ
ns
Provided that δ is small enough, this contradicts the hypothesis.



Note that in the proof of Theorem 1.13, the hypothesis k > δ1 is not needed in the case where H
is a matching as we may apply Theorem 6.1 rather than Theorem 7.1.
We shall now prove Proposition 1.14. We restate it for the convenience of the reader.
Proposition. For each constants h, c, j, s ∈ N, there exists a constant C > 0, such that thefollowing
holds. Let H be a hypergraph with h edges whose center is of size c. Let ǫn ≤ k ≤ n h1 − ǫ , and let
C
-almost H-free.
J be some (H, s)-free j-junta. Then J is ns+1
Proof. Let {A1 , . . . , Ah } be a random copy of H, and let J be a set of size at most j, such that J
depends on J. Let C1 = A1 ∩J, . . . , Ch = Ah ∩J. Since J is (H, s)-free, we obtain by Lemma 8.1 that
for any copy {A1 , . . . , Ah } of H in J the center of {A1 ∩ J, . . . , Ah ∩ J} is of size at least s + 1. Now
1
for any hypergraph C1 , . . . , Ch of center of size at least s + 1 we have Pr [∀i : Ci = Ci ] = O ns+1
by Lemma 8.2. Since there are only a constant number of subsets{C1 , . . . , Ch } ⊆ P (J) , we obtain
1
. This completes the proof of the
that{A1 , . . . , Ah } is a copy of H with probability at most O ns+1
proposition.

Finally we shall prove Theorem 1.11 that we restate for the convenience of the reader.
Theorem.
For each h, d ∈ N, ǫ > 0 there exists C, δ > 0 such that the following holds. Let C ≤ k ≤

1
−
ǫ
n,
and
let H be a k-uniform (h, d)-expanded hypergraph, then we have the following.
h
(1) If the family F is δ-almost H-free, then F is ǫ-essentially contained in an Mh -free family.
(2) Conversely, if the family F is δ-essentially contained in an Mh -free family, then F is ǫ-almost
H-free.

Proof of Theorem 1.11. (1) =⇒ (2) follows by applying Theorem 1.13 with s = 0, noting that a
family is (H, 0)-free if and only if it is free of a matching. We now show the converse implication.
ǫ
Suppose that (2) holds. By Theorem (1.13) F is h+1
-essentially contained in an Mh -free junta,
provided that δ is small enough. Let {A1 , . . . , Ah } be a random copy of H. Note that the event
{A1 , . . . , Ah } ⊆ F can occur only if for some i we have Ai ∈ J \F , or if {A1 , . . . , Ah } ⊆ J . So
a union bound implies that it is enough to show that each of these events occurs with probability
ǫ
< h+1
.

ǫ
, provided that C
By Proposition 1.14 a random copy of H lies in J with probability O n1 < h+1
is suﬃciently
large
to
imply
the
needed
lower
bound
on
n.
Moreover,
each
A
is
uniformly
distributed
i

[n]
ǫ
in k . Therefore, for each i the probability that Ai is in F but not in J is at most h+1
. This
completes the proof of the theorem.

Acknowledgment. I would like to thank Nathan Keller for providing many helpful comments and
suggestions, which tremendously improved the exposition of the paper.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

37

References
[1] Amirali Abdullah and Suresh Venkatasubramanian. A directed isoperimetric inequality with application to bregman near neighbor lower bounds. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of
Computing, pages 509–518. ACM, 2015.
[2] Daniel Ahlberg, Erik Broman, Simon Griﬃths, and Robert Morris. Noise sensitivity in continuum percolation.
Israel Journal of Mathematics, 201(2):847–899, 2014.
[3] Rudolf Ahlswede and Levon H. Khachatrian. The complete nontrivial-intersection theorem for systems of ﬁnite
sets. journal of combinatorial theory, Series A, 76(1):121–138, 1996.
[4] József Balogh, Robert Morris, and Wojciech Samotij. Independent sets in hypergraphs. Journal of the American
Mathematical Society, 28(3):669–709, 2015.
[5] William Beckner. Inequalities in fourier analysis. Annals of Mathematics, pages 159–182, 1975.
[6] Michael Ben-Or and Nathan Linial. Collective coin ﬂipping. randomness and computation, 5:91–115, 1990.
[7] Béla Bollobás and Arthur G Thomason. Threshold functions. Combinatorica, 7(1):35–38, 1987.
[8] Aline Bonami. Étude des coeﬃcients de fourier des fonctions de lp (g). In Annales de l’institut Fourier, volume 20,
pages 335–402, 1970.
[9] Christer Borell. Geometric bounds on the ornstein-uhlenbeck velocity process. Probability Theory and Related
Fields, 70(1):1–13, 1985.
[10] Jean Bourgain and Gil Kalai. Inﬂuences of variables and threshold intervals under group symmetries. Geometric
and Functional Analysis, 7(3):438–461, 1997.
[11] David Conlon and Jacob Fox. Graph removal lemmas. Surveys in combinatorics, 1(2):3, 2013.
[12] David Conlon and William Timothy Gowers. Combinatorial theorems in sparse random sets. Annals of Mathematics, 184:367–454, 2016.
[13] Das Shagnik and Tuan Tran. Removal and Stability for Erdős–Ko–Rado. SIAM Journal on Discrete Mathematics,
30(2): 1102-1114, 2016.
[14] Mikhail Deza, Paul Erdős, and Peter Frankl. Intersection properties of systems of ﬁnite sets. Proc. London Math.
Soc., 36(2):369–384, 1978.
[15] Irit Dinur and Ehud Friedgut. Intersecting families are essentially contained in juntas. Combinatorics, Probability
and Computing, 18(1-2):107–122, 2009.
[16] Irit Dinur, Elchanan Mossel, and Oded Regev. Conditional hardness for approximate coloring. SIAM Journal on
Computing, 39(3):843–873, 2009.
[17] David Ellis, Nathan Keller, and Noam Lifshitz. Stability versions of Erdős–Ko–Rado type theorems, via isoperimetry. arXiv preprint arXiv:1604.02160, 2016.
[18] David Ellis, Nathan Keller, and Noam Lifshitz. Stability for the complete intersection theorem, and the forbidden
intersection problem of Erdős and Sós. arXiv preprint arXiv:1604.06135, 2017.
[19] Paul Erdős. A problem on independent r-tuples. Ann. Univ. Sci. Budapest, 8:93–95, 1965.
[20] Paul Erdős. Problems and results in graph theory and combinatorial analysis. Proc. British Combinatorial Conj.,
5th, pages 169–192, 1975.
[21] Paul Erdős, Chao Ko, and Richard Rado. Intersection theorems for systems of ﬁnite sets. The Quarterly Journal
of Mathematics, 12(1):313–320, 1961.
[22] Yuval Filmus. Ahlswede-Khachatrian theorems:
Weighted, inﬁnite, and Hamming. arXiv preprint
arXiv:1610.00756, 2016.
[23] Jacob Fox. A new proof of the graph removal lemma. Annals of Mathematics, pages 561–579, 2011.
[24] Peter Frankl. The Erdős–Ko–Rado theorem is true for n = ckt. combinatorics (proc. ﬁfth hungarian colloq.,
keszthey, 1976), vol. i, 365–375. In Colloq. math. Soc. János Bolyai, volume 18.
[25] Peter Frankl. On families of ﬁnite sets no two of which intersect in a singleton. Bulletin of the Australian Mathematical Society, 17(1):125–134, 1977.
[26] Peter Frankl. Erdös-ko-rado theorem with conditions on the maximal degree. Journal of Combinatorial Theory,
Series A, 46(2):252–263, 1987.
[27] Peter Frankl. Improved bounds for erdős matching conjecture. Journal of Combinatorial Theory, Series A,
120(5):1068–1072, 2013.
[28] Peter Frankl and Zoltán Füredi. Forbidding just one intersection. Journal of Combinatorial Theory, Series A,
39(2):160–176, 1985.
[29] Peter Frankl and Zoltán Füredi. Exact solution of some Turán-type problems. Journal of Combinatorial Theory,
Series A, 45(2):226–262, 1987.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

38

[30] Peter Frankl and Vojtěch Rödl. Forbidden intersections. Transactions of the American Mathematical Society,
300(1):259–286, 1987.
[31] Ehud Friedgut. Boolean functions with low average sensitivity depend on few coordinates. Combinatorica,
18(1):27–35, 1998.
[32] Ehud Friedgut. Sharp thresholds of graph properties, and the k-sat problem (with an appendix by Jean Bourgain).
Journal of the American Mathematical Society, 12(4):1017–1054, 1999.
[33] Ehud Friedgut and Gil Kalai. Every monotone graph property has a sharp threshold. Proceedings of the American
mathematical Society, 124(10):2993–3002, 1996.
[34] Ehud Friedgut and Oded Regev. Kneser graphs are like swiss cheese. Discrete Analysis, 2:0–18, 2018.
[35] Zoltán Füredi, Tao Jiang, and Robert Seiver. Exact solution of the hypergraph Turán problem for k-uniform
linear paths. Combinatorica, 34(3):299–322, 2014.
[36] William Timothy Gowers. Quasirandomness, counting and regularity for 3-uniform hypergraphs. Combinatorics,
Probability and Computing, 15(1-2):143–184, 2006.
[37] William Timothy Gowers. Hypergraph regularity and the multidimensional szemerédi theorem. Annals of Mathematics, pages 897–946, 2007.
[38] L. Gross. Logarithmic sobolev inequalities. American J. Math., 97:1061–1083, 1975.
[39] Hamed Hatami. A structure theorem for boolean functions with small total inﬂuences. Annals of Mathematics,
176(1):509–533, 2012.
[40] Chris Jones. A noisy-inﬂuence regularity lemma for boolean functions. arXiv preprint arXiv:1610.06950, 2016.
[41] Peter Keevash. Hypergraph Turán problems. Surveys in combinatorics, 392:83–140, 2011.
[42] Peter Keevash, Dhruv Mubayi, and Richard M. Wilson. Set systems with no singleton intersection. SIAM Journal
on Discrete Mathematics, 20(4):1031–1041, 2006.
[43] Nathan Keller and Noam Lifshitz. The junta method for hypergraphs and chvátal’s simplex conjecture. arXiv
preprint arXiv:1707.02643, 2017.
[44] Alexandr Kostochka, Dhruv Mubayi, and Jacques Verstraëte. Turán problems and shadows I: paths and cycles.
Journal of Combinatorial Theory, Series A, 129:57–79, 2015.
[45] Alexandr Kostochka, Dhruv Mubayi, and Jacques Verstraëte. Turán problems and shadows III: expansions of
graphs. SIAM Journal on Discrete Mathematics, 29(2):868–876, 2015.
[46] Alexandr Kostochka, Dhruv Mubayi, and Jacques Verstraëte. Turán problems and shadows II: trees. Journal of
Combinatorial Theory, Series B, 122:457–478, 2017.
[47] Willem Mantel. Problem 28. Wiskundige Opgaven, 10(60-61):320, 1907.
[48] Elchanan Mossel. Gaussian bounds for noise correlation of functions. Geometric and Functional Analysis,
19(6):1713–1756, 2010.
[49] Elchanan Mossel. Majority is asymptotically the most stable resilient function. arXiv preprint arXiv:1704.04745,
2017.
[50] Elchanan Mossel, Ryan O’Donnell, and Krzysztof Oleszkiewicz. Noise stability of functions with low inﬂuences:
Invariance and optimality. Annals of Mathematics, pages 295–341, 2010.
[51] Dhruv Mubayi and Jacques Verstraëte. A survey of Turán problems for expansions. In Recent Trends in Combinatorics, pages 117–143. Springer, 2016.
[52] Brendan Nagle, Vojtěch Rödl, and Mathias Schacht. The counting lemma for regular k-uniform hypergraphs.
Random Structures & Algorithms, 28(2):113–179, 2006.
[53] Ryan O’Donnell. Analysis of boolean functions. Cambridge University Press, 2014.
[54] Vojtěch Rödl and Jozef Skokan. Regularity lemma for k-uniform hypergraphs. Random Structures & Algorithms,
25(1):1–42, 2004.
[55] Lucio Russo. An approximate zero-one law. Probability Theory and Related Fields, 61(1):129–139, 1982.
[56] Imre Z. Ruzsa and Endre Szemerédi. Triple systems with no six points carrying three triangles. Colloq. Math.
Soc. János Bolyai, 18:939–945, 1978.
[57] Wojciech Samotij. Stability results for random discrete structures. Random Structures & Algorithms, 44(3):269–
289, 2014.
[58] David Saxton and Andrew Thomason. Hypergraph containers. Inventiones mathematicae, 201(3):925–992, 2015.
[59] Mathias Schacht. Extremal results for random discrete structures. Annals of Mathematics, 184(2):333–365, 2016.
[60] Miklós Simonovits. A method for solving extremal problems in graph theory, stability problems. In Theory of
Graphs (Proc. Colloq., Tihany, 1966), pages 279–319, 1968.
[61] Terence Tao. A variant of the hypergraph removal lemma. Journal of combinatorial theory, Series A, 113(7):1257–
1280, 2006.

HYPERGRAPH REMOVAL LEMMAS VIA ROBUST SHARP THRESHOLD THEOREMS

[62] Pál Turán. On an extremal problem in graph theory (in Hungarian). Mat. Fiz. Lapok, 48:436–452, 1941.

39

