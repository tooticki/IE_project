arXiv:1806.00458v1 [math.OC] 1 Jun 2018

Improved Oracle Complexity for Stochastic Compositional Variance
Reduced Gradient
Tianyi Lin

âˆ—

Chenyou Fan

â€ 

Mengdi Wang

â€¡

Michael I. Jordan

Â§

June 4, 2018

Abstract
We propose an accelerated stochastic compositional variance reduced gradient method for optimizing the sum of a composition function and a convex nonsmooth function. We provide an incremental
first-order oracle (IFO) complexity analysis for the proposed algorithm and show that it is provably
faster than all the existing methods. Indeed,
 we show that our method achieves an asymptotic IFO
complexity of O (m + n) log (1/Îµ) + 1/Îµ3 where m and n are the number of inner/outer compo
nent functions, improving the best-known results of O m + n + (m + n)2/3 /Îµ2 and achieving for
the best known linear run time for convex composition problem. Experiment results on sparse meanvariance optimization with 21 real-world financial datasets confirm that our method outperforms
other competing methods.

1

Introduction

We consider a general nonsmooth convex composition problem in which the objective is the sum of a
composition function and a nonsmooth convex function:
min Î¦(x) = F (x) + r(x),

xâˆˆRd

(1)

where r : Rd â†’ R âˆª {+âˆž} is an extended real-valued closed convex function and F : Rd â†’ R is a
continuously differentiable convex function, given by
ï£¶
ï£«
n
m
1X ï£­1 X
fi
gj (x)ï£¸ .
F (x) =
n
m
i=1

j=1

âˆ—

Department of Industrial Engineering and Operations Research, UC Berkeley, Berkeley, CA 94720, USA.
School of Informatics and Computing, Indiana University, Bloomington, IN 47405, USA.
â€¡
Department of Operations Research and Financial Engineering, Princeton University, Princeton, NJ 08544, USA.
Â§
Department of Electrical Engineering and Computer Science and Department of Statistics, UC Berkeley, Berkeley, CA
94720, USA.
â€ 

1

Here fi : Rl â†’ R (i âˆˆ [n]) and gj : Rd â†’ Rl (j âˆˆ [m]) are continuously differentiable. Problem (1) is
highly structured but also quite general; indeed, various special cases have been studied in a host of
applications, including reinforcement learning [25], nonparametric statistics [8], risk management [18],
multi-stage stochastic programming [24], system control [11], model-based stochastic search [7] and deep
neural nets [6, 29]. Here are two typical examples:
Example 1.1 (Risk-Averse Learning). Consider the mean-variance minimization problem
"
#2
n
n
n
Î»X
1X
1X
h(x, ai , bi ) +
h(x, ai , bi ) âˆ’
h(x, ai , bi ) ,
min
x
n
n
n
i=1

i=1

i=1

where h(x, ai , bi ) is the loss on a sample data point (ai , bi ) and Î» > 0 is a regularization parameter.
Example 1.2 (On-Policy Reinforcement Learning [25, 15]). Given a controllable Markov chain with
states {1, 2, . . . , S}, estimate the value-per-state of a fixed control policy Ï€ that satisfies the Bellman
equation:
Î³P Ï€ V Ï€ + rÏ€ = V Ï€ ,
Ï€ is the transition probability from state s to state sÌƒ and r Ï€ is
where Î³ âˆˆ (0, 1) is a discount factor, PssÌƒ
s
the expected state transition reward at state s. The solution V Ï€ is a vector with each entry VsÏ€ being the
total expected reward starting at state s. In a black-box simulation environment, solving the Bellman
equation is a special case of the stochastic composition optimization problem:
ï£¹ï£¶
ï£« ï£®
m
X

1
I âˆ’ Î³PjÏ€ x âˆ’ rÏ€j ï£»ï£¸ ,
min L ï£­ ï£°
xâˆˆX
m
j=1

where L is a general loss function, x is a policy, and PjÏ€ and rÏ€j are sampled from a simulator.

Despite its usefulness, problem (1) is more computationally challenging than its noncompositional counterpart; i.e., problem (1) with gj (x) = x for all j âˆˆ [m]. Indeed, stochastic-gradient-type methods
deteriorate in the former setting since the sampled gradients are biased in general, being unbiased only
if gj (x) = x for all j âˆˆ [m]. The alternative of using the stochastic variance-reduced
gradient method
1 Pm
(SVRG) [10] leads to a very high computational burden as it needs to compute m j=1 gj (x) at each
iteration. In response to such concerns, a number of computationally efficient stochastic compositional
variance reduced gradient methods have been proposed for solving problem (1).
 Notably, Huo et al.
[9] presented a method having an IFO complexity of O m + n + (m + n)2/3 /Îµ2 for convex objectives;
this is the best known complexity to date. See Table 1 for comparisons to various algorithms.
While there has been abundant work on strongly convex objectives and nonconvex objectives, there
has been relatively little investigation of convex (but not strongly convex) objectives. In particular, the
following important case has been neglected: the composition function F is convex while some of the
composition terms are nonconvex. Perhaps counterintuitively, it has been observed in that the average
of loss functions can be convex even if some loss functions are nonconvex [21, 4]. This can occur when
some of the loss functions are strongly convex. Similarly, F can be convex when there are nonconvex
terms, when some of the other composition terms are strongly convex. In the SVRG setting, [4] has
shown that the dependence of the IFO complexity of SVRG on n can be n log(1/Îµ) when the objective
is convex. What remains unknown is whether this conclusion holds true in the compositional setting.
This is the central question of the current paper:
2

Table 1: The IFO complexity of stochastic composition optimization methods. Îµ is the
tolerance. m is the number of inner functions. n is the number of outer functions. In order to provide
a clean comparison, we hide the dependence of the IFO complexity on the Lipschitz constants of f , fi
and gj , the upper bound of the norm of âˆ‡fi and âˆ‚gj , and the distance between the initial point and
the optimal set. We also omit the dependence on the dimension d since it is linear for all methods.
Method
AGD [14]
SCGD [26]
ASC-PG [27]
VRSC-PG [9]
ASCVRG (This paper)

Convex Objective
Criterion: E [Î¦(x)] âˆ’ Î¦(xâˆ— ) â‰¤ Îµ
âˆš
O ((m + n)/ Îµ)
O 1/Îµ4 
O 1/Îµ3.5

O m + n + (m + n)2/3 /Îµ2 
O (m+n) log (1/Îµ) + 1/Îµ3

r 6= 0?

Shrinking Step Size?

Yes
No
Yes
Yes
Yes

No
Yes
Yes
No
No

Can we develop an accelerated stochastic compositional variance reduced gradient method with
the IFO complexity where the dependence of m + n is (m + n) log(1/Îµ) in the convex setting?

1.1

Related Work

Since the seminal work on SVRG [10], stochastic average gradient [19] and stochastic dual coordinate
ascent [22], variance reduction has been successfully applied to solve problem (1), in the special case of
gj (x) = x for all j âˆˆ [m], in a variety of settings [4, 23, 3, 17, 2, 12]. Allen-Zhu [4] provided an improved
IFO complexity of O(n log(1/Îµ) + 1/Îµ)) for convex objectives, and Reddi et al. [17] and Allen-Zhu and
Hazan [3] obtained an IFO complexity of O(n + n2/3 /Îµ)) for nonconvex objectives. However, all of these
methods are computationally
inefficient as putative solutions to problem (1) in general because they
1 Pm
g
(x)
at each iteration.
need to compute m
j=1 j

To solve problem (1) efficiently, Wang et al. [26] proposed and analyzed a class of stochastic compositional gradient/subgradient (SCGD) methods with iterates at two different time scales instead of a
single iterate as in the case of stochastic gradient descent. Wang et al. [27] proposed an accelerated
SCGD method which improved the IFO complexity over SCGD. On the other hand, variance reduction
has been proposed to accelerate stochastic compositional gradient method in [13] for strongly convex
objectives. Yu and Huang [30] proposed another stochastic compositional variance reduced gradient
method, named com-SVRADMM, for strongly convex objectives. Very recently, Huo et al. [9] analyzed
a new class of stochastic compositional variance reduced gradient methods with an IFO
i of
h complexity
2
2/3
O(m + n + (m + n) /Îµ) for nonconvex objectives, yielding a solution x satisfying E kâˆ‡Î¦(x)k â‰¤ Îµ.
However, in real applications with convex objectives, the quality of training or testing depends on the
objective gap rather than the norm of the gradient. So a solution x satisfying E [Î¦(x)] âˆ’ Î¦(xâˆ— ) â‰¤ Îµ
would be preferred. On the other hand, we have
i
h
1
(2)
E kâˆ‡Î¦(x)k2 â‰¤ E [Î¦(x)] âˆ’ Î¦(xâˆ— ) â‰¤ E [kâˆ‡Î¦(x)k kx âˆ’ xâˆ— k] ,
2LÏ†
where LÏ† is defined in Assumption 3.3, implying that the IFO complexity of Huo et al. â€™s method is
O(m + n + (m + n)2/3 /Îµ2 ) in terms of the objective gap.
3

âˆ—
In contrast, our method can provide a solution
 x satisfying E [Î¦(x)] âˆ’ Î¦(x ) â‰¤ Îµ and achieve an
3
IFO complexity of O (m + n) log (1/Îµ) + 1/Îµ . This is important, suggesting the best linear time
complexity for approximately solving convex composition problem.

1.2

Contributions

We summarize our major contributions as follows:
1. We develop an accelerated SCVRG
 method and prove that it achieves an asymptotic IFO complexity of O (m + n) log (1/Îµ) + 1/Îµ3 when the objective is nonsmooth and convex. This improves the
best known IFO complexity in [9] and provides an accelerated stochastic compositional variance
reduced gradient algorithm for nonsmooth convex stochastic composition optimization.
2. We present a new iterative stochastic analysis approach to achieve Îµ-optimal solutions in terms
of the objective gap. As discussed earlier, this is more reasonable in real application problems
involving convex composition optimization.
3. We conduct extensive experiments on sparse mean-variance optimization with 21 real-world financial datasets to show that our methods outperform other competing methods.

1.3

Notation and Organization

Throughout the paper, we denote vectors by bold lower case letters, e.g., x, and matrices by regular
upper case letters, e.g., X. The transpose of a real vector x is denoted as xâŠ¤ . kxk and kXk denote
the vector â„“2 norm and the matrix spectral norm for a vector x and a matrix X. For a scalar x âˆˆ R,
âŒŠxâŒ‹ is the largest integer which is smaller than x. For two non-negative sequences {at } and {bt }, we
write at = O(bt ) if there exists a constant N > 0 such that at â‰¤ N bt for each t â‰¥ 0, and at = o(bt ) if
there exists a non-negative sequence {ct } such that at â‰¤ ct bt for each t â‰¥ 0 and ct â†’ 0 as t â†’ âˆž. We
denote the gradient1 of F : Rd â†’ R at x as âˆ‡F (x) = [âˆ‚g(x)]âŠ¤ âˆ‡f (g(x)) âˆˆ Rd , where âˆ‚g(x) âˆˆ RlÃ—d is
the Jacobian of g : Rd â†’ Rl at x. We use subscript t and superscript s to denote a iterate, e.g., xst , at
the t-th iteration in the s-th epoch. The sets At , Bt and Ct are randomly selected indices at the t-th
iteration with batch sizes A, B and C. E [Â· | Î¶] is a conditional expectation given the variable Î¶ and E
is an expectation over all randomness.
The rest of the paper is organized as follows. Section 2 presents our incremental first-order oracle (IFO)
framework and our proposed SCVRG method. Section 3 states the IFO complexity bound for our
method, with complete proofs and technical details deferred to the appendices. Section 4 demonstrates
an application of our method to sparse mean-variance optimization problem and presents numerical
results. Conclusions and future directions are presented in Section 5.
1

The gradient operator always calculates the gradient with respect to the first-level variable. More specifically, âˆ‡f (g(x))
refers to the gradient of f (y) at y = g(x), not the gradient of F (x) = f (g(x)) at x.

4

Algorithm 1 Accelerated Stochastic Compositional Variance Reduced Gradient Method
Input: xÌƒ0 =x0k0 =x0 âˆˆ Rd , first epoch length k0 , step size Î· > 0 and the number of epochs S.
Initialization: l = 0 and T = k0 Â· 2S âˆ’ k0 .
for s = 0, 1, . . . , S do
xs+1
= xsks , gÌƒs+1 =g(xÌƒs ), GÌƒs+1 =âˆ‚g(xÌƒs ),
0
vÌƒs+1 = [âˆ‚g(xÌƒs )]âŠ¤ âˆ‡f (gÌƒs+1 ) and ks+1 = 2s+1 Â· k0 .
for t = 0, 1, . . . , ks+1 âˆ’ 1 do
) and gjt (xÌƒs ), then update gts+1 according to (3).
Sample from IFO with gjt (xs+1
t
s+1
according to (4).
Sample from IFO with âˆ‚gjt (xt ) and âˆ‚gjt (xÌƒs ), then update Gs+1
t
s+1
s+1
s+1
Sample from IFO with âˆ‡fitâˆš(gt ) and âˆ‡fit (gÌƒ ), then update vt according to (5).
s+1
Set l = l + 1 and Î·t+1
= âˆšÎ·2TTâˆ’l , then update xs+1
t+1 according to (6).
end for
1 Pks+1 âˆ’1 s+1
xÌƒs+1 = ks+1
xt .
t=0
end for
Output: xÌƒS .

2

Algorithm

In this section, we focus on the algorithmic design of stochastic composition optimization methods under
a black-box sampling environment with the access to an incremental first-order oracle (IFO). The IFO
is a typical simulation oracle studied in both online and batch learning [20]; it is also widely used in
complexity theory [1, 28].
Definition 2.1 (Incremental First-order Oracle (IFO)). Given some x âˆˆ Rd and j âˆˆ [m], the IFO
returns a vector gj (x) or a matrix âˆ‚gj (x). Alternatively, given some y âˆˆ Rl and i âˆˆ [n], the IFO
returns a value fi (y) or a vector âˆ‡fi (y).
We propose the Accelerated Stochastic Compositional Variance Reduced Gradient method, denoted as
ASCVRG for short; see Algorithm 1. A variance reduction scheme, it involves the estimation of three
). Given a reference point xÌƒs ,
unknown quantities. First, it computes an estimate of the value of g(xs+1
t
s+1
s+1
s
gÌƒ
= g(xÌƒ ), we approximate g(xt ) by
gts+1 =

1 X
1 X
gjt (xs+1
gjt (xÌƒs ) + gÌƒs+1 ,
)âˆ’
t
A
A
jt âˆˆAt

(3)

jt âˆˆAt

where At âŠ‚ [m] is a subset of cardinality A. Furthermore, it computes an estimate of the Jacobian
), which plays a key role in the acceleration of convergence. Given a reference Jacobian
matrix âˆ‚g(xs+1
t
matrix GÌƒs+1 = âˆ‚g(xÌƒs ), we approximate âˆ‚g(xs+1
) by
t
Gs+1
=
t

1 X
1 X
âˆ‚gjt (xs+1
âˆ‚gjt (xÌƒs ) + GÌƒs+1 ,
)âˆ’
t
B
B
jt âˆˆBt

(4)

jt âˆˆBt


âŠ¤
where Bt âŠ‚ [m] is a subset of cardinality B. Also, the method estimates the gradient vector âˆ‚g(xs+1
) âˆ‡f (g(xs+1
)
t
t
5

âŠ¤

)) by
) âˆ‡f (g(xs+1
Given a reference gradient vector vÌƒs+1 = [âˆ‚g(xÌƒs )]âŠ¤ âˆ‡f (gÌƒs+1 ), we estimate âˆ‚g(xs+1
t
t
!
!
h
iâŠ¤ 1 X

âŠ¤ 1 X
s+1
s+1
)
âˆ’
âˆ‡f
âˆ‡fit (gÌƒs+1 ) + vÌƒs+1 ,
(g
(5)
GÌƒ
vts+1 = Gs+1
it t
t
C
C
it âˆˆCt

it âˆˆCt

s+1
where Ct âŠ‚ [n] is a subset of cardinality C. We then compute Î·t+1
, update xs+1
t+1 by
(
)





1
2
xs+1
vts+1 , x + s+1 x âˆ’ xts+1  + r(x) ,
t+1 = argmin
2Î·t+1
xâˆˆRd

(6)

for 0 â‰¤ t â‰¤ ks+1 âˆ’ 1 as the reference point for the next epoch.
and use the average of all iterates xs+1
t
The final output is the reference point of the last iteration, i.e., xÌƒS .
Discussion: In terms of IFO complexity per epoch, a full gradient vector and a full Jacobian matrix
are computed at the point xÌƒs , requiring m + n IFO queries. Therefore, the IFO complexity of ASCVRG
for the s-th epoch is m + n + ks (A + B + C) since ASCVRG carries out a variance reduction scheme
for both the value and the Jacobian matrix.

3
3.1

Main Result
Assumptions

For clarity of presentation, we defer the proofs for the theorems and technical lemmas to the appendices.
Throughout this paper, we measure the efficiency of different algorithms by comparing the number of
IFO queries to achieve an Îµ-optimal solution defined by Definition 3.1; recall that this is stronger than
the criterion E [kÎ¦(x)k] â‰¤ Îµ defined in [9].
Definition 3.1. Given Îµ âˆˆ (0, 1), we say x âˆˆ Rd is an Îµ-optimal solution to problem (1) if
E [Î¦(x)] âˆ’ Î¦(xâˆ— ) â‰¤ Îµ,
where xâˆ— âˆˆ Rd is an optimal solution to problem (1).
We make the following assumptions on F , fi and gj for i âˆˆ [n] and j âˆˆ [m].
Assumption 3.1. The objective F and r are both convex, i.e.,
F (x) âˆ’ F (y) âˆ’ hâˆ‡F (y), x âˆ’ yi â‰¥ 0,

r(x) âˆ’ r(y) âˆ’ hÎ¾, x âˆ’ yi â‰¥ 0,

x, y âˆˆ Rd ,
x, y âˆˆ Rd ,

where Î¾ âˆˆ âˆ‚r(y) is a subgradient of r.
Assumption 3.2. The proximal mapping of the objective r, given by


1
2
kx âˆ’ yk + r(x) ,
argmin hg, xi +
2Î·
xâˆˆRd
is easily computed for any given g âˆˆ Rd and y âˆˆ Rd and Î· > 0.
6

Assumption 3.3. For i âˆˆ [n] and j âˆˆ [m], there exist constants 0 < Lf , Lg , LÏ† < âˆž such that
kâˆ‡fi (x) âˆ’ âˆ‡fi (y)k â‰¤ Lf kx âˆ’ yk ,
kâˆ‚gj (x) âˆ’ âˆ‚gj (y)k â‰¤ Lg kx âˆ’ yk ,

and

x, y âˆˆ Rl ,

x, y âˆˆ Rd ,





âŠ¤
âŠ¤
[âˆ‚g
(x)]
âˆ‡f
(g(x))
âˆ’
[âˆ‚g
(y)]
âˆ‡f
(g(y))
 â‰¤ LÏ† kx âˆ’ yk ,
 j
i
j
i

x, y âˆˆ Rd .

Intuitively, the constants Lf , Lg and LÏ† jointly characterize the smoothness and complexity of stochastic
composition optimization.
Assumption 3.4. For i âˆˆ [n] and j âˆˆ [m], there exist two constants 0 < Bf , Bg < âˆž such that
kâˆ‚gj (x)k â‰¤ Bg , x âˆˆ Rd ,

kâˆ‡fi (x)k â‰¤ Bf , x âˆˆ Rl .

Assumptions 3.1-3.4 are standard ones in the literature of composition optimization [13, 30, 9].

3.2

Improved IFO Complexity

We present an asymptotic IFO complexity of Algorithm 1 in this subsection, showing that it is an
accelerated algorithm with an IFO complexity where the dependence on m + n is O((m + n) log(1/Îµ))
and Îµ is better than SCGD and ASC-PG.
Theorem 3.5. Given the initial vector x0 âˆˆ Rd satisfies that
 0

x âˆ’ xâˆ— 2 â‰¤ Dx , Î¦(x0 ) âˆ’ Î¦(xâˆ— ) â‰¤ DÏ† ,

and the first epoch length k0 > 0 and the number of epochs S > 0 satisfy that





6DÏ†
Dx
+ 1,
S = log2
+ 1,
k0 =
2Î·DÏ†
Îµ
and the sample sizes A > 0, B > 0 and C > 0 satisfy
A=

12Bg4 L2f
Î· 2Î± L2Ï†

,

B=

12Bf2 L2g

for some Î± > 1 and Î· > 0 satisfies
ï£±

1
ï£² 1
Î±
2DÏ†
Î· = min
,
,
ï£³ 2LÏ†
3LÏ† Dx

Î· 2Î± L2Ï†

,

C=

12
,
Î· 2Î±

Îµ
âˆš
60 2LÏ† (Dx + 2DÏ† )

!1ï£¼
Î±ï£½
ï£¾

,

and Îµ âˆˆ (0, 1) is a tolerance, then the total IFO complexity, i.e., the number of IFO queries to achieve
an Îµ-optimal solution that satisfies


E Î¦(xÌƒs+1 ) âˆ’ Î¦(xâˆ— ) â‰¤ Îµ,
7

is

 

1
1
+
O (m + n) log
,
1
Îµ
Îµ3+ Î±
where we omit the dependence of the IFO complexity on the Lipschitz constants LÏ† , Lf , Lg , the upper
bound of the norm of gradient and Jacobian Bf , Bg , the distances between the initial point and the
optimal set, i.e., Dx (the iterative gap) and DÏ† (the objective gap).


Remark 3.6. We highlight that our goal is to develop an efficient algorithm that targets the case when
m and n are very large. In this case, we observe that A, B and C are independent of m and n and can
assume that A, B â‰ª m and C â‰ª n. This implies that our method will achieve superior performance
compared to AGD, an assertion confirmed by our experimental results.
Remark 3.7. This holds true for any Î± > 1 so the total asymptotic IFO complexity is


 
1
1
+ 3 .
O (m + n) log
Îµ
Îµ
Furthermore,



âˆšÎµ
120 2LÏ† Dx

1

Î±

â†’ 1 and



2DÏ†
3LÏ† Dx

1

Î±

â†’ 1 as Î± â†’ +âˆž, implying that

Î·=

1
.
2LÏ†

On the other hand, since Î· < 1 and Î± â†’ +âˆž, we have A, B, C â†’ +âˆž. This makes sense since the
IFO complexity turns out to be better if we allow a large step size and increase the sample size.

3.3

Comparison with Previous Work

We provide a comprehensive comparison among AGD, ASC-PG, VRSC-PG and ASCVRG based on
the IFO complexity for achieving an Îµ-optimal solution.
1. Dependence on m + n: The number of IFO queries of AGD, VRSC-PG and ASCVRG depend
explicitly on m + n. In contrast, the IFO complexity of ASC-PG is independent of m + n while
this comes at the expense of worse dependence on Îµ. The IFO complexity of AGD is proportional
to m + n and that of VRSC-PG is proportional to (m + n)2/3 while m + n is independent of 1/Îµ3
for ASCVRG. In fact, ASCVRG is the best known linear-time algorithm since log(1/Îµ) is nearly
a constant. This makes ASCVRG clearly superior to AGD and VRSC-PG as m + n is large.
2. Dependence on Îµ: The complexity bound of ASC-PG depends as O(1/Îµ3.5 ) while ASCVRG
âˆš
converges as O(1/Îµ3 ) and AGD converge as O(1/ Îµ). This speedup of ASCVRG in convergence
over ASC-PG is especially significant when medium to high accuracy solutions are required.
3. Dependence on shrinking step size: It is beneficial to compare the step sizes used by different
algorithms. It is undesirable that the step size of ASC-PG shrinks to zero as the number of
iterations t increases, while the step sizes of AGD, VRSC-PG and ASCVRG can remain constant.
The usage of the constant step size is crucial to the effectiveness and robustness of the algorithms
when a huge number of iterations are requiredâ€”which is the case in many real-world learning
problems.
8

4

Experiments

In this section, we present the results of experiments on 21 US Research Returns datasets from the
Center for Research in Security Prices (CRSP) website2 , including three large 100-porfolio datasets and
18 medium datasets for Developed Market Factors and Returns; see Table 2 for details.
Table 2: The Statistics of 21 CRSP Real Datasets
Type
100 Portfolios

N
13781

d
100

Market Factors

7240

25

Problems
Book-to-Market (BM), Operating Profitability (OP), Investment (INV)
BM: Asia Pacific ex Japan, Europe, Global ex US, Global, Japan, North America
OP: Asia Pacific ex Japan, Europe, Global ex US, Global, Japan, North America
INV: Asia Pacific ex Japan, Europe, Global ex US, Global, Japan, North America

d
Given d assets and the reward vectors observed at N time points, i.e., {ri }N
i=1 âŠ‚ R , the goal of
portfolio management optimization is to maximize the return of the investment as well as to control
the investment risk. This can be formulated as sparse mean-variance optimization [16] in the form of
problem (1) with m = n = N , given by

min Î¦(x) =

xâˆˆRd

=

ï£¶2
ï£«
N
N
N
X
X
1 X
1
ï£¸
ï£­hri , xi âˆ’ 1
hrj , xi
âˆ’
hri , xi + Î» kxk1
N
N
N
i=1
j=1
i=1
ï£¶
ï£«
n
m
X
X
1
1
fi ï£­
gj (x)ï£¸ + Î» kxk1 ,
n
m
i=1

(7)

j=1

âŠ¤
with fi (z, y) = (hri , zi + y)2 âˆ’ hri , zi and gj (x) = xâŠ¤ , âˆ’ hrj , xi , for x, z âˆˆ Rd and y âˆˆ R. Problem (7)
satisfies Assumption 3.1-3.4 so that it serves as a good example for our experiment.
We compare our ASCVRG method with AGD, SCGD [26], ASC-PG [27] and VRSC-PG [9]. Except
that we use our own implementation of AGD, we use official implementation of other methods provided
by the authors and run the experiments with default parameters 3 . We exclude the method in [13] since
problem (7) is neither smooth nor strongly convex. On the other hand, although problem (7) can be
formulated as a saddle point problem, [9] has shown that VRSC-PG is superior to prior work based on
the saddle-point formulation, e.g., [30], so we do not consider such approaches.
We set Î» = 5 Ã— 10âˆ’7 in problem (7) and A = B = C = 5 and Î· = 1/2LÏ† in ASCVRG. For the
x-axis, we use the number of gradient oracles divided by the number of samples, denoted as #grad/n,
which is proportional to the query complexity. For the y-axis, we use the log-scale of the objective gap
Î¦(x) âˆ’ Î¦(xâˆ— ) where xâˆ— is obtained by running ASCVRG for enough iterations until convergence and is
used as the optimal solution for all methods.
Figure 1 shows that, on three large datasets, ASCVRG consistently outperforms the other four methods
in terms of the IFO complexity. Moreover, ASCVRG and VRSC-PG are more robust than SCGD and
ASC-PG, showing that the use of variance reduction together with constant step size stabilizes the
behavior of the stochastic algorithms. Although SCGD and ASC-PG perform well on some datasets,
2
3

http://mba.tuck.dartmouth.edu/pages/faculty/ken.french/Data Library/changes crsp.html
We will release our code to facilitate future research once the paper gets accepted.

9

Objective Gap in Log-Scale

Objective Gap in Log-Scale

10

0

10

-2

10

-4

10

-6

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

0

2

4

6

OP, n=13781, d=100

10 2

8

10

10

0

10

-2

10

-4

10

-6

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

0

2

4

6

INV, n=13781, d=100

10 2

Objective Gap in Log-Scale

ME, n=13781, d=100

10 2

8

10

10

0

10

-2

10

-4

10

-6

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

0

2

4

6

#grad/n

#grad/n

#grad/n

(a) Book-to-Market

(b) Operating Profitability

(c) Investment

8

Figure 1: The Performance of All Methods on three Large 100-Portfolio Datasets
pure stochastic gradient-type methods can be sensitive to choices of shrinking step sizes and thus require
effort to tune parameters in practice [5]. In contrast, the step sizes of ASCVRG and VRSC-PG are
not shrinking, yielding improved robustness in practice. As expected, AGD performs worse than other
methods, having the highest IFO complexity on large datasets.
Figures 2-4 further show that, on 18 different medium datasets, ASCVRG consistently outperforms
the other four methods in terms of the IFO complexity even if the margin is smaller than that on
large datasets. Actually ASCVRG and VRSC-PG are comparable on nearly half of the datasets,
significantly outperforming the other three methods by a large margin. This is consistent with the
theoretical IFO complexity ofASCVRG and VRSC-PG. In comparison to ASCVRGâ€™s IFO complexity
of O (m + n) log(1/Îµ) + 1/Îµ3 , VRSC-PGâ€™s IFO complexity of O(m + n + (m + n)2/3 /Îµ2 ) is favorable
when m + n is not very large. On the other hand, we observe from Figures 2-4 that VRSC-PG is less
robust than ASCVRG. One possible reason is that VRSC-PG uses a constant step size while ASCVRG
uses an adaptive but not shrinking step size. In sum, the ASCVRG method has the potential to be a
benchmark algorithm for nonsmooth convex composition optimization.

5

Conclusions

We propose an accelerated stochastic compositional variance reduced gradient method for convex composition optimization. We establish a better IFO complexity than the best-known result prior to this
paper under the same reasonable conditions. Experimental results on sparse mean-variance optimization with 21 real-world financial datasets demonstrate that our method outperforms other competing
methods. An important direction for future work is to study the possibility of a lower oracle complexity
for stochastic composition optimization and the optimal compositional gradient method.

10

10

10 -3

0

2

4

6

8

10 -2

10 -3

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

0

2

#grad/n

4

6

8

10 -1

10 -2

10 -3

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

0

2

#grad/n

(a) Asia Pacific ex Japan

4

6

8

10 -1

10 -2

10 -3

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

0

2

#grad/n

(b) Europe

4

6

8

Europe ME, n=7240, d=25

10 1

10 0

10

10

-1

10 -3

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

-2

0

2

4

#grad/n

(c) Global ex US

6

8

North America ME, n=7240, d=25

10 1

Objective Gap in Log-Scale

10 -1

Global ME, n=7240, d=25

10 0

Objective Gap in Log-Scale

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

Global ex US ME, n=7240, d=25

10 0

Objective Gap in Log-Scale

Objective Gap in Log-Scale

Objective Gap in Log-Scale

10 -1

10 -2

Europe ME, n=7240, d=25

10 0

Objective Gap in Log-Scale

Asia Pacific ex Japan ME, n=7240, d=25

10 0

10 0

10 -1

10

10 -3

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

-2

0

2

#grad/n

(d) Global

4

6

8

10

#grad/n

(e) Japan

(f) North America

Figure 2: The Performance of All Methods on six 25-Portfolio Book-to-Market Datasets

10 -4
10 -5

0

2

4

6

8

10 -2

10

10 -4

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

-3

0

2

#grad/n

4

6

8

10

10 -2
10 -3

10 -5

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -4

0

2

#grad/n

(a) Asia Pacific ex Japan

4

6

8

10

10 -2
10 -3

10 -5

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -4

0

2

#grad/n

(b) Europe

4

6

8

Japan OP, n=7240, d=25

10 1

-1

10

0

10 -1
10 -2

10 -4

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -3

0

2

4

#grad/n

(c) Global ex US

6

8

North America OP, n=7240, d=25

10 1

Objective Gap in Log-Scale

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -1

Global OP, n=7240, d=25

10 0

-1

Objective Gap in Log-Scale

10 -3

Global ex US OP, n=7240, d=25

10 0

Objective Gap in Log-Scale

10 -2

Europe OP, n=7240, d=25

10 0

Objective Gap in Log-Scale

Objective Gap in Log-Scale

10

-1

Objective Gap in Log-Scale

Asia Pacific ex Japan OP, n=7240, d=25

10 0

10

0

10 -1
10 -2

10 -4

10

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -3

0

2

#grad/n

(d) Global

4

6

8

10

#grad/n

(e) Japan

(f) North America

Figure 3: The Performance of All Methods on six 25-Portfolio Operating Profitability Datasets

ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -4
10 -5

0

2

4

6

8

10

10 -2
10 -3
ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -4
10 -5

0

2

#grad/n

4

6

#grad/n

(a) Asia Pacific ex Japan

(b) Europe

8

10

10 -1
10 -2
10 -3
ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -4
10 -5

0

2

4

6

8

10

10 -1
10 -2
10 -3
ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -4
10 -5

0

#grad/n

2

4

6

#grad/n

(c) Global ex US

(d) Global

8

Japan INV, n=7240, d=25

10 2

10

10 0

10 -2
ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -4

10 -6

0

2

4

6

8

North America INV, n=7240, d=25

10 2

Objective Gap in Log-Scale

10 -3

10 -1

Global INV, n=7240, d=25

10 0

Objective Gap in Log-Scale

10 -2

Global ex US INV, n=7240, d=25

10 0

Objective Gap in Log-Scale

Objective Gap in Log-Scale

Objective Gap in Log-Scale

10 -1

Europe INV, n=7240, d=25

10 0

Objective Gap in Log-Scale

Asia Pacific ex Japan INV, n=7240, d=25

10 0

10

10 0

10 -2
ASCVRG
VRSC-PG
ASC-PG
SCGD
AGD

10 -4

10 -6

0

#grad/n

(e) Japan

2

4

6

(f) North America

Figure 4: The Performance of All Methods on six 25-Portfolio Investment Datasets

References
[1] A. Agarwal and L. Bottou. A lower bound for the optimization of finite sums. In ICML, pages
78â€“86, 2015.
[2] Z. Allen-Zhu. Natasha: Faster non-convex stochastic optimization via strongly non-convex parameter. In ICML, pages 89â€“97, 2017.
[3] Z. Allen-Zhu and E. Hazan. Variance reduction for faster non-convex optimization. In ICML, pages
699â€“707, 2016.
[4] Z. Allen-Zhu and Y. Yuan. Improved SVRG for non-strongly-convex or sum-of-non-convex objectives. In ICML, pages 1080â€“1089, 2016.
[5] A. S. Berahas, R. Bollapragada, and J. Nocedal. An investigation of Newton-sketch and subsampled
Newton methods. ArXiv Preprint: 1705.06211, 2017.
11

8

#grad/n

10

[6] I. Goodfellow, Y. Bengio, and A. Courville. Deep Learning. MIT press, 2016.
[7] J. Hu. Model-based stochastic search methods. In Handbook of Simulation Optimization, pages
319â€“340. Springer, 2015.
[8] J. Huang, J. L. Horowitz, and F. Wei. Variable selection in nonparametric additive models. Annals
of Statistics, 38(4):2282, 2010.
[9] Z. Huo, B. Gu, and H. Huang. Accelerated method for stochastic composition optimization with
nonsmooth regularization. ArXiv Preprint: 1711.03937, 2017.
[10] R. Johnson and T. Zhang. Accelerating stochastic gradient descent using predictive variance reduction. In NIPS, pages 315â€“323, 2013.
[11] P. Kundur, N. J. Balu, and M. G. Lauby. Power System Stability and Control, volume 7. McGrawhill New York, 1994.
[12] L. Lei, C. Ju, J. Chen, and M. I. Jordan. Nonconvex finite-sum optimization via SCSG methods.
ArXiv Preprint: 1706.09156, 2017.
[13] X. Lian, M. Wang, and J. Liu. Finite-sum composition optimization via variance reduced gradient
descent. In AISTATS, pages 1159â€“1167, 2017.
[14] Y. Nesterov. Introductory Lectures on Convex Optimization: A Basic Course, volume 87. Springer
Science & Business Media, 2013.
[15] M. L. Puterman. Markov Decision Processes: Discrete Stochastic Dynamic Programming. John
Wiley & Sons, 2014.
[16] P. Ravikumar, J. Lafferty, H. Liu, and L. Wasserman. Sparse additive models. Journal of the Royal
Statistical Society. Series B, Statistical Methodology, pages 1009â€“1030, 2009.
[17] S. J. Reddi, A. Hefny, S. Sra, B. Poczos, and A. Smola. Stochastic variance reduction for nonconvex
optimization. In ICML, pages 314â€“323, 2016.
[18] R. T. Rockafellar and S. Uryasev. Optimization of conditional value-at-risk. Journal of Risk,
2:21â€“42, 2000.
[19] M. Schmidt, N. Le Roux, and F. Bach. Minimizing finite sums with the stochastic average gradient.
Mathematical Programming, 162(1-2):83â€“112, 2017.
R in
[20] S. Shalev-Shwartz. Online learning and online convex optimization. Foundations and Trends
Machine Learning, 4(2):107â€“194, 2012.

[21] S. Shalev-Shwartz. SDCA without duality, regularization, and individual convexity. In ICML,
pages 747â€“754, 2016.
[22] S. Shalev-Shwartz and T. Zhang. Stochastic dual coordinate ascent methods for regularized loss
minimization. Journal of Machine Learning Research, 14(Feb):567â€“599, 2013.
[23] O. Shamir. Fast stochastic algorithms for SVD and PCA: Convergence properties and convexity.
In ICML, pages 248â€“256, 2016.
12

[24] A. Shapiro, D. Dentcheva, and A. RuszczynÌski. Lectures on Stochastic Programming: Modeling
and Theory. SIAM, 2009.
[25] R. S. Sutton and A. G. Barto. Reinforcement Learning: An Introduction, volume 1. MIT press
Cambridge, 1998.
[26] M. Wang, E. X. Fang, and H. Liu. Stochastic compositional gradient descent: algorithms for
minimizing compositions of expected-value functions. Mathematical Programming, 161(1-2):419â€“
449, 2017.
[27] M. Wang, J. Liu, and E. X. Fang. Accelerating stochastic composition optimization. Journal of
Machine Learning Research, 18:1â€“23, 2017.
[28] B. E. Woodworth and N. Srebro. Tight complexity bounds for optimizing composite objectives. In
NIPS, pages 3639â€“3647, 2016.
[29] S. Yang, M. Wang, and E. X. Fang. Multi-level stochastic gradient methods for nested compositon
optimization. ArXiv Preprint: 1801.03600, 2018.
[30] Y. Yu and L. Huang. Fast stochastic variance reduced ADMM for stochastic composition optimization. ArXiv Preprint: 1705.04138, 2017.

A

Proof Outline

We list the assumptions in our paper and some major steps to give a whole picture of the proof.
Proof Outlines:
1. We provide two basic lemmas, which concerns with convex objective and common
variance; see Lemmas B.1 and B.2.
h
2 s+1 s i
 | x , xÌƒ using the term kxÌƒs âˆ’ xâˆ— k2 ,
2. We bound the term of E vts+1 âˆ’ âˆ‡f (xs+1
)
t
t
2
 s+1
âˆ—
x
âˆ’ x  and the size of At , Bt and Ct , i.e., A, B and C; see Lemma B.3.
t
2



3. We bound the term of E Î¦(xÌƒs+1 ) âˆ’ Î¦(xâˆ— ) using the term Î¦(x0 ) âˆ’ Î¦(xâˆ— ), x0 âˆ’ xâˆ— 
and the parameters Î· and k0 ; see Lemmas C.1 and C.2.
4. We provide the explicit IFO complexity in terms of m + n, LÏ† , Lf , Lg , Bf and Bg ;
see Theorem C.3.

Assumption A.1. The objective F and r are both convex, i.e.,
F (x) âˆ’ F (y) âˆ’ hâˆ‡F (y), x âˆ’ yi â‰¥ 0,

r(x) âˆ’ r(y) âˆ’ hÎ¾, x âˆ’ yi â‰¥ 0,

where Î¾ âˆˆ âˆ‚r(y) is a subgradient of r.
13

x, y âˆˆ Rd ,
x, y âˆˆ Rd ,

Assumption A.2. The proximal mapping of the objective r, given by


1
2
kx âˆ’ yk + r(x) ,
argmin hg, xi +
2Î·
xâˆˆRd
is easily computed for any given g âˆˆ Rd and y âˆˆ Rd and Î· > 0.
Assumption A.3. For i âˆˆ [n] and j âˆˆ [m], there exist constants 0 < Lf , Lg , LÏ† < âˆž such that
kâˆ‡fi (x) âˆ’ âˆ‡fi (y)k â‰¤ Lf kx âˆ’ yk ,
kâˆ‚gj (x) âˆ’ âˆ‚gj (y)k â‰¤ Lg kx âˆ’ yk ,

and

x, y âˆˆ Rl ,

x, y âˆˆ Rd ,





âŠ¤
âŠ¤
[âˆ‚gj (x)] âˆ‡fi (g(x)) âˆ’ [âˆ‚gj (y)] âˆ‡fi (g(y)) â‰¤ LÏ† kx âˆ’ yk ,

x, y âˆˆ Rd .

Intuitively, the constants Lf , Lg and LÏ† jointly characterize the smoothness and complexity of stochastic
composition optimization.
Assumption A.4. For i âˆˆ [n] and j âˆˆ [m], there exist two constants 0 < Bf , Bg < âˆž such that
kâˆ‚gj (x)k â‰¤ Bg , x âˆˆ Rd ,

B

kâˆ‡fi (x)k â‰¤ Bf , x âˆˆ Rl .

Proof of Technical Lemmas

Lemma B.1. The following statement holds true,


2


 s+1 âŠ¤
s+1 
s+1
s+1 âŠ¤
s+1
s
E  Gt
âˆ‡fit (gt ) âˆ’ âˆ‚g(xt ) âˆ‡fit (g(xt )) | xt , xÌƒ â‰¤

where xâˆ— is one optimal solution.

4Bf2 L2g
4Bg4 L2f
+
A
B

!

h


 i
2
âˆ— 2
.
kxÌƒs âˆ’ xâˆ— k + xs+1
âˆ’
x
t

Proof. We observe that


2


 s+1 âŠ¤
s+1 s
s+1 
s+1 âŠ¤
s+1
âˆ‡fit (gt ) âˆ’ âˆ‚g(xt ) âˆ‡fit (g(xt )) | xt , xÌƒ
E  Gt


2


 s+1 âŠ¤
s+1
s+1 âŠ¤
s+1
s+1 
s
âˆ‡fit (gt ) âˆ’ âˆ‚g(xt ) âˆ‡fit (gt ) | xt , xÌƒ
â‰¤ 2E  Gt


2




s+1 
s+1 s
s+1 âŠ¤
s+1
s+1 âŠ¤
+2E  âˆ‚g(xt ) âˆ‡fit (gt ) âˆ’ âˆ‚g(xt ) âˆ‡fit (g(xt )) | xt , xÌƒ
h
i
 

s+1 2 
s+1 2
s+1 s
â‰¤ 2E Gs+1
)
âˆ’
âˆ‚g(x
Â·
)
âˆ‡f
(g
,
xÌƒ
|
x
i
t
t
t
t
t
h
i



2
 Â· âˆ‡fit (gs+1 ) âˆ’ âˆ‡fit (g(xs+1 ))2 | xs+1 , xÌƒs
+2E âˆ‚g(xs+1
)
t
t
t
t
h
i
h
i

2
2
â‰¤ 2Bf2 E Gs+1
âˆ’ âˆ‚g(xs+1
) | xs+1
, xÌƒs + 2Bg2 E âˆ‡fit (gts+1 ) âˆ’ âˆ‡fit (g(xs+1
)) | xs+1
, xÌƒs
t
t
t
t
t
h
i
h
i
2
2
â‰¤ 2Bf2 E Gs+1
) | xs+1
, xÌƒs ,
âˆ’ âˆ‚g(xs+1
) | xs+1
, xÌƒs + 2Bg2 L2f E gts+1 âˆ’ g(xs+1
t
t
t
t
t
14

where the first inequality comes from the Cauchy-Schwarz inequality, the third inequality comes from
Assumption A.4 and the last inequality comes from Assumption A.3. So it suffices to bound the terms
h
i
h
i
2
2
E Gs+1
âˆ’ âˆ‚g(xs+1
) | xs+1
, xÌƒs
and E gts+1 âˆ’ g(xs+1
) | xs+1
, xÌƒs .
t
t
t
t
t

Indeed, we have

2
ï£¹
ï£®


i
h
X
X



1
1
2
s+1 s ï£»
)âˆ’
)
gjt (xs+1
gjt (xÌƒs ) + gÌƒs+1 âˆ’ g(xs+1
, xÌƒs = E ï£°
E gts+1 âˆ’ g(xs+1
) | xs+1
t
t
t
t
 | xt , xÌƒ
A
A

 jt âˆˆAt
jt âˆˆAt
2
ï£®
ï£¹


X

1 ï£°
s+1 s ï£»
=
) + gÌƒs+1 
) âˆ’ gjt (xÌƒs ) âˆ’ g(xs+1
gjt (xs+1
E 
t
t
 | xt , xÌƒ

2
A

jt âˆˆAt
i

1 X h
gjt (xs+1 ) âˆ’ gjt (xÌƒs ) âˆ’ g(xs+1 ) + gÌƒs+1 2 | xs+1 , xÌƒs
E
=
t
t
t
A2
jt âˆˆAt
i

1 X h
gjt (xs+1 ) âˆ’ gjt (xÌƒs )2 | xs+1 , xÌƒs
â‰¤
E
t
t
A2
â‰¤

â‰¤

Bg2
A2

jt âˆˆAt

X

xs+1 âˆ’ xÌƒs 2

t
jâˆˆAt
2Bg2 h s+1
x
t

A

i
2
âˆ’ xâˆ—  + kxÌƒs âˆ’ xâˆ— k2 ,

where the third equality holds true since the indices in At are drawn independently without replacement,
the first inequality holds true since E kÎ¾ âˆ’ E [Î¾]k2 â‰¤ E kÎ¾k2 , and the second inequality comes from
Assumption A.4. Furthermore, we have
h
i

s+1 2
s+1 s
E Gs+1
,
xÌƒ
âˆ’
âˆ‚g(x
)
|
x
t
t
t
2
ï£®
ï£¹
 X

X
1

1
sï£»
s+1
= E ï£°
)âˆ’
)
âˆ‚gjt (xs+1
âˆ‚gjt (xÌƒs ) + GÌƒs+1 âˆ’ âˆ‚g(xs+1
t
t
B
 | xt , xÌƒ
B
 jt âˆˆBt

jt âˆˆBt
2
ï£¹
ï£®

X 


1 ï£°
s+1 s ï£»
) + GÌƒs+1 
) âˆ’ âˆ‚gjt (xÌƒs ) âˆ’ âˆ‚g(xs+1
âˆ‚gjt (xs+1
E 
=
t
t
 | xt , xÌƒ

B2

jt âˆˆBt




2
1 X

s+1
s+1
s+1 s
s
s+1 
=
E âˆ‚gjt (xt ) âˆ’ âˆ‚gjt (xÌƒ ) âˆ’ âˆ‚g(xt ) + GÌƒ  | xt , xÌƒ
B2
jt âˆˆBt
i

1 X h
âˆ‚gjt (xs+1 ) âˆ’ âˆ‚gjt (xÌƒs )2 | xs+1 , xÌƒs
â‰¤
E
t
t
B2
â‰¤

â‰¤

L2g
B2

jt âˆˆBt

X 

xs+1 âˆ’ xÌƒs 2
t

jt âˆˆBt
2
2Lg h s+1
x
t

B

i
2
âˆ’ xâˆ—  + kxÌƒs âˆ’ xâˆ— k2 ,

15

where the third equality holds true since the indices in Bt are drawn independently without replacement,
the first inequality holds true since E kÎ¾ âˆ’ E [Î¾]k2 â‰¤ E kÎ¾k2 , and the second inequality comes from
Assumption A.3. This completes the proof.

Lemma B.2. For i âˆˆ [n], we have
"
#
2
iâŠ¤
h



âŠ¤
s+1
s+1
s+1
s+1
s
E 
âˆ‡fit (gÌƒs+1 )
 âˆ‚g(xt ) âˆ‡fit (g(xt )) âˆ’ GÌƒ
 | xt , xÌƒ



2


âˆ’ xâˆ—  + kxÌƒs âˆ’ xâˆ— k2 .
) âˆ’ Î¦(xâˆ— ) + Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— ) + 4L2Ï† xs+1
â‰¤ 4LÏ† Î¦(xs+1
t
t

where xâˆ— is an optimal solution to the objective Î¦.

Proof. Given any z âˆˆ Rd and an optimal solution xâˆ— to the objective Î¦, we define Ï•it (z) as
D
E L
Ï†
kz âˆ’ xâˆ— k2 .
Ï•it (z) = fit (g(z)) âˆ’ [âˆ‚g(xâˆ— )]âŠ¤ âˆ‡fit (g(xâˆ— )), z âˆ’ xâˆ— +
2
It is clear that Ï•it (z) is a convex function with the gradient being Lipschitz continuous with 2LÏ† > 0
and has a minimzer xâˆ— . Therefore, we obtain from Theorem 2.1.5 in the textbook [14] that
Ï•it (z) âˆ’ Ï•it (xâˆ— ) â‰¥

1
kâˆ‡Ï•it (z)k2 .
2LÏ†

Equivalently, we have
E L
D
Ï†
fit (g(z)) âˆ’ fit (g(xâˆ— )) âˆ’ [âˆ‚g(xâˆ— )]âŠ¤ âˆ‡fit (g(xâˆ— )), z âˆ’ xâˆ— +
kz âˆ’ xâˆ— k2
2
2
1 


âŠ¤
âŠ¤
â‰¥
[âˆ‚g(z)] âˆ‡fit (g(z)) âˆ’ [âˆ‚g(xâˆ— )] âˆ‡fit (g(xâˆ— )) + LÏ† (z âˆ’ xâˆ— ) .
2LÏ†

Therefore, we have

2


âŠ¤
âŠ¤
[âˆ‚g(z)] âˆ‡fit (g(z)) âˆ’ [âˆ‚g(xâˆ— )] âˆ‡fit (g(xâˆ— ))
2



â‰¤ 2 [âˆ‚g(z)]âŠ¤ âˆ‡fit (g(z)) âˆ’ [âˆ‚g(xâˆ— )]âŠ¤ âˆ‡fit (g(xâˆ— )) + LÏ† (z âˆ’ xâˆ— ) + 2L2Ï† kz âˆ’ xâˆ— k2
Ei
h
D
â‰¤ 4LÏ† fit (g(z)) âˆ’ fit (g(xâˆ— )) âˆ’ [âˆ‚g(xâˆ— )]âŠ¤ âˆ‡fit (g(xâˆ— )), z âˆ’ xâˆ— + 4L2Ï† kz âˆ’ xâˆ— k2 .

(8)

where the second inequality comes from (8). Letting z = xs+1
and z = xÌƒs and taking the conditional
t
s+1
s
expectation on xt and xÌƒ yields that
"
#
2
h
iâŠ¤


âŠ¤
s+1
s+1
s+1
s+1
s+1
s
E 
âˆ‡fit (gÌƒ )
 âˆ‚g(xt ) âˆ‡fit (g(xt )) âˆ’ GÌƒ
 | xt , xÌƒ


2


âˆ— âŠ¤
âˆ— 
s+1 s
s+1
s+1 âŠ¤
â‰¤ E  âˆ‚g(xt ) âˆ‡fit (g(xt )) âˆ’ [âˆ‚g(x )] âˆ‡fit (g(x )) | xt , xÌƒ
#
"
2

h s+1 iâŠ¤
s+1 s
âˆ‡fit (gÌƒs+1 ) âˆ’ [âˆ‚g(xâˆ— )]âŠ¤ âˆ‡fit (g(xâˆ— ))
+E 
 | xt , xÌƒ
 GÌƒ
2





âˆ’ xâˆ— 
âˆ’ xâˆ— + 4L2Ï† xs+1
) âˆ’ F (xâˆ— ) âˆ’ âˆ‡F (xâˆ— ), xs+1
â‰¤ 4LÏ† F (xs+1
t
t
t
+4LÏ† [F (xÌƒs ) âˆ’ F (xâˆ— ) âˆ’ hâˆ‡F (xâˆ— ), xÌƒs âˆ’ xâˆ— i] + 4L2Ï† kxÌƒs âˆ’ xâˆ— k2 .
16

In addition, we have
âˆ’ hâˆ‡F (xâˆ— ), x âˆ’ xâˆ— i = hÎ¾, x âˆ’ xâˆ— i â‰¤ r(x) âˆ’ r(xâˆ— ),

where the first equality since xâˆ— is an optimal solution to the objective Î¦ and the inequality comes from
Assumption A.1. Therefore, we conclude that
#
"
2
h
iâŠ¤



âŠ¤
s+1
s+1
s+1
s
s+1
âˆ‡fit (gÌƒs+1 )
E 
 | xt , xÌƒ
 âˆ‚g(xt ) âˆ‡fit (g(xt )) âˆ’ GÌƒ





âˆ— 2
s
âˆ— 2
âˆ—
s
âˆ—
2  s+1
.
âˆ’
x
+
kxÌƒ
âˆ’
x
k
x
)
âˆ’
Î¦(x
)
+
Î¦(xÌƒ
)
âˆ’
Î¦(x
)
+
4L
â‰¤ 4LÏ† Î¦(xs+1
Ï†
t
t

This completes the proof.



) and its approximation vts+1 is upper bounded by kxÌƒs âˆ’ xâˆ— k2
Lemma B.3. The gap between âˆ‡F (xs+1
t
 s+1

2
and xt âˆ’ xâˆ—  in terms of conditional expectation, given by
h
2 s+1 s i
 | x , xÌƒ
E vts+1 âˆ’ âˆ‡F (xs+1
)
t
t
!
4 L2
2 L2
2
h
i

8B
8B
8L

8L
8LÏ† 
g
g
f
f
Ï†
Ï†
xs+1 âˆ’ xâˆ— 2 + kxÌƒs âˆ’ xâˆ— k2 .
[Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )] +
+
+
) âˆ’ Î¦(xâˆ— ) +
Î¦(xs+1
â‰¤
t
t
C
C
A
B
C
Proof. Let us+1
be an unbiased estimate of âˆ‡F (xs+1
), i.e.,
t
t
=
us+1
t

âŠ¤
1 X h s+1 iâŠ¤
1 X
s+1
GÌƒ
âˆ‡fit (gÌƒs+1 ) + vÌƒs+1 ,
))
âˆ’
)
âˆ‡f
(g(x
âˆ‚g(xs+1
i
t
t
t
C
C
it âˆˆCt

it âˆˆCt

then we have
h
i
h
h
i
2
2 s+1 s i

 | x , xÌƒ +2E us+1 âˆ’ âˆ‡F (xs+1 )2 | xs+1 , xÌƒs .
E vts+1 âˆ’ âˆ‡F (xs+1
) | xs+1
, xÌƒs â‰¤ 2E vts+1 âˆ’ us+1
t
t
t
t
t
t
t

So it suffices to bound the terms
h
2 s+1 s i
 | x , xÌƒ
E vts+1 âˆ’ us+1
t
t

i
h

s+1 s
s+1 2
.
and E us+1
,
xÌƒ
)
|
x
âˆ’
âˆ‡F
(x
t
t
t

17

Indeed, we have
h
2 s+1 s i
 | x , xÌƒ
E vts+1 âˆ’ us+1
t
t
ï£¹
ï£®
2

1 X 
X
âŠ¤
âŠ¤

1


âˆ‡fit (gts+1 ) âˆ’
)) | xs+1
Gs+1
âˆ‚g(xts+1 ) âˆ‡fit (g(xs+1
, xÌƒs ï£»
= E ï£°
t
t
t

C
C
it âˆˆCt
it âˆˆCt
ï£®
ï£¹
2


X
X




1 ï£°
âŠ¤
âŠ¤

=
E 
Gs+1
, xÌƒs ï£»
âˆ‡fit (gts+1 ) âˆ’
)) | xs+1
) âˆ‡fit (g(xs+1
âˆ‚g(xs+1
t
t
t
t


C2
it âˆˆCt
it âˆˆCt


2
X


1
 s+1 âŠ¤
s+1 s
s+1 
s+1 âŠ¤
s+1
E  Gt
âˆ‡fit (gt ) âˆ’ âˆ‚g(xt ) âˆ‡fit (g(xt )) | xt , xÌƒ
â‰¤
C
iâˆˆCt
!
4 2

 i
4Bf2 L2g h s
1 X 4Bg Lf
âˆ— 2
â‰¤
kxÌƒ âˆ’ xâˆ— k2 + xs+1
âˆ’
x
+
t
C
A
B
iâˆˆCt
!

 i
4Bg4 L2f
4Bf2 L2g h s
âˆ— 2
,
kxÌƒ âˆ’ xâˆ— k2 + xs+1
âˆ’
x
=
+
t
A
B

where the first inequality comes from Cauchy-Schwarz inequality and the second inequality comes from
Lemma B.1. Furthermore, we have
i
h

s
s+1 2
s+1
E us+1
)
,
xÌƒ
âˆ’
âˆ‡F
(x
|
x
t
t
t
ï£®
ï£¹
2
1 X 

i
h
X
âŠ¤

1
âŠ¤


= E ï£°
) | xs+1
GÌƒs+1 âˆ‡fit (gÌƒs+1 ) + vÌƒs+1 âˆ’ âˆ‡F (xs+1
âˆ‚g(xs+1
) âˆ‡fit (g(xs+1
)) âˆ’
, xÌƒs ï£»
t
t
t
t
C

C
it âˆˆCt
it âˆˆCt
ï£®
ï£¹
2




h
i
X
âŠ¤


1 ï£°
âŠ¤

)) âˆ’ GÌƒs+1 âˆ‡fit (gÌƒs+1 ) + vÌƒs+1 âˆ’ âˆ‡F (xs+1
) âˆ‡fit (g(xs+1
âˆ‚g(xs+1
)  | xs+1
E 
, xÌƒs ï£»
=
t
t
t
t


C2
it âˆˆCt
"
#
2
h
iâŠ¤


âŠ¤
1 X
s+1
s+1
s+1
s+1
s+1
s+1
s+1
s
E 
âˆ‡fit (gÌƒ ) + vÌƒ
âˆ’ âˆ‡F (xt )
=
 âˆ‚g(xt ) âˆ‡fit (g(xt )) âˆ’ GÌƒ
 | xt , xÌƒ
C2
it âˆˆCt
"
#
2
h
iâŠ¤



1 X
âŠ¤
s+1
s+1
s+1
s+1
s
E 
âˆ‡fit (gÌƒs+1 )
â‰¤
 âˆ‚g(xt ) âˆ‡fit (g(xt )) âˆ’ GÌƒ
 | xt , xÌƒ
C2
it âˆˆCt

i



1 Xh
s+1
âˆ— 2
s
âˆ— 2
âˆ—
s
âˆ—
2  s+1
â‰¤
+ kxÌƒ âˆ’ x k
4LÏ† Î¦(xt ) âˆ’ Î¦(x ) + Î¦(xÌƒ ) âˆ’ Î¦(x ) + 4LÏ† xt âˆ’ x
C2
it âˆˆCt

=



 4L2Ï†  s+1
4LÏ† 
âˆ— 2
s
âˆ— 2
âˆ—
s
âˆ—
x
âˆ’
x
+
kxÌƒ
âˆ’
x
k
Î¦(xs+1
)
âˆ’
Î¦(x
)
+
Î¦(xÌƒ
)
âˆ’
Î¦(x
)
+
t
t
C
C

where the third equality holds true since the indices in Ct are drawn independently without replacement,
the first inequality holds true since E kÎ¾ âˆ’ E [Î¾]k2 â‰¤ E kÎ¾k2 and the second inequality comes from

18

Lemma B.2. Therefore, we conclude that
h
2 s+1 s i
 | x , xÌƒ
E vts+1 âˆ’ âˆ‡F (xs+1
)
t
t
â‰¤

 8LÏ†
8LÏ† 
[Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )] +
Î¦(xs+1
) âˆ’ Î¦(xâˆ— ) +
t
C
C

8Bg4 L2f
A

+

8Bf2 L2g
B

+

8L2Ï†
C

This completes the proof.

C

!

h
i

xs+1 âˆ’ xâˆ— 2 + kxÌƒs âˆ’ xâˆ— k2 .
t



Proof of Main Theorem

Lemma C.1. For any x âˆˆ Rd , we have
i
h


 Î· Î± LÏ† 

Î·
s+1 s
x âˆ’ xs+1 2 +
vs+1 âˆ’ âˆ‡F (xs+1 )2 | xs+1 , xÌƒs
E
,
xÌƒ
+
0 â‰¤ Î¦(x) âˆ’ E Î¦(xs+1
)
|
x
t
t
t
t
t
t+1
2
2(1 âˆ’ Î·LÏ† )
h
ii
h






1 
E vs+1 âˆ’ us+1 | xs+1 , xÌƒs 2 + 1
x âˆ’ xs+1 2 âˆ’ E x âˆ’ xs+1 2 | xs+1 , xÌƒs .
+ Î±
t
t
t
t
t
t+1
s+1
2Î· LÏ†
2Î·t+1
where Î± > 1 is a constant.

Proof. We have



s+1
s+1
+
0 â‰¤ r(x) âˆ’ r(xs+1
t+1 ) + x âˆ’ xt+1 , vt

1




s+1
s+1
Â· x âˆ’ xs+1
t+1 , xt+1 âˆ’ xt

s+1
Î·t+1



s+1
s+1
, vt
= r(x) âˆ’ r(xs+1
âˆ’ xs+1
+ xs+1
t
t+1 ) + x âˆ’ xt
t+1 , vt


2 
 i
1 h
 âˆ’ x âˆ’ xs+1 2 âˆ’ xs+1 âˆ’ xs+1 2
+ s+1 x âˆ’ xs+1
t
t
t+1
t+1
2Î·t+1

 






s+1
s+1
s+1
)
âˆ’ âˆ‡F (xs+1
âˆ’ xs+1
) + xs+1
âˆ’ xs+1
, vts+1 + xs+1
= r(x) âˆ’ r(xs+1
t
t
t
t+1 , vt
t+1 , âˆ‡F (xt
t+1 ) + x âˆ’ xt


2 
 i
1 h
 âˆ’ x âˆ’ xs+1 2 âˆ’ xs+1 âˆ’ xs+1 2
+ s+1 x âˆ’ xs+1
t
t
t+1
t+1
2Î·t+1




LÏ† 
s+1
s+1
s+1
s+1
xs+1 âˆ’ xs+1 2
+
F
(x
)
âˆ’
F
(x
)
+
â‰¤ r(x) âˆ’ r(xs+1
)
+
x
âˆ’
x
,
v
t
t
t
t
t+1
t+1
t+1
2
h


 i




 s+1
1
s+1
s+1
x âˆ’ xs+1 2 âˆ’ x âˆ’ xs+1 2 âˆ’ xs+1 âˆ’ xs+1 2
)
+
âˆ’
âˆ‡F
(x
,
v
+ xt âˆ’ xs+1
t
t
t
t
t+1
t+1
t+1
s+1
2Î·t+1





s+1




s+1
) âˆ’ F (xs+1
, vts+1 + F (xs+1
â‰¤ r(x) âˆ’ r(xs+1
t
t+1 ) +
t+1 ) + x âˆ’ xt
+

1
s+1
2Î·t+1

h
 i


x âˆ’ xs+1 2 âˆ’ x âˆ’ xs+1 2 ,
t
t+1

s+1
Î·t+1

2(1 âˆ’

s+1
Î·t+1
LÏ† )

2
 s+1
v
)
âˆ’ âˆ‡F (xs+1
t
t

where
the first inequality comes
from the update of xs+1
t+1 , the first equality holds true since hx, yi =
i
h
2
2
2
1
2 kx + yk âˆ’ kxk âˆ’ kyk , the second inequality comes from Assumption A.3, and the third inequality
comes from the Young inequality.
19

Taking the conditional expectation of both side on xts+1 and xÌƒs yields that


 


s+1 s
, xÌƒs
| xs+1
, E vts+1 âˆ’ us+1
, xÌƒ + x âˆ’ xs+1
0 â‰¤ r(x) âˆ’ E r(xs+1
t
t
t
t+1 ) | xt





s+1 s
, xÌƒ
) âˆ’ E F (xs+1
) + F (xs+1
, âˆ‡F (xs+1
+ x âˆ’ xs+1
t
t
t
t+1 ) | xt
s+1
h
ii
h
i
h



Î·t+1
x âˆ’ xs+1 2 âˆ’ E x âˆ’ xs+1 2 | xs+1 , xÌƒs
vs+1 âˆ’ âˆ‡F (xs+1 )2 | xs+1 , xÌƒs + 1
E
+
t
t
t
t
t
t+1
s+1
s+1
2(1 âˆ’ Î·t+1
LÏ† )
2Î·t+1






s+1 s
, xÌƒs
| xs+1
, E vts+1 âˆ’ us+1
, xÌƒ + x âˆ’ xs+1
â‰¤ Î¦(x) âˆ’ E Î¦(xs+1
t
t
t
t+1 ) | xt
s+1
h
h
i
ii
h



Î·t+1
x âˆ’ xs+1 2 âˆ’ E x âˆ’ xs+1 2 | xs+1 , xÌƒs
vs+1 âˆ’ âˆ‡F (xs+1 )2 | xs+1 , xÌƒs + 1
+
E
t
t
t
t
t
t+1
s+1
s+1
2(1 âˆ’ Î·t+1
LÏ† )
2Î·t+1
s+1
i
h



 Î· Î± LÏ† 
Î·t+1
s+1 s
x âˆ’ xs+1 2 +
vs+1 âˆ’ âˆ‡F (xs+1 )2 | xs+1 , xÌƒs
,
xÌƒ
â‰¤ Î¦(x) âˆ’ E Î¦(xs+1
)
|
x
+
E
t
t
t
t
t
t+1
s+1
2
2(1 âˆ’ Î·t+1
LÏ† )
h
ii
h




1 
x âˆ’ xs+1 2 âˆ’ E x âˆ’ xs+1 2 | xs+1 , xÌƒs
E vs+1 âˆ’ us+1 | xs+1 , xÌƒs 2 + 1
+ Î±
t
t
t
t
t
t+1
s+1
2Î· LÏ†
2Î·t+1
), the second
is an unbiased estimator of âˆ‡F (xs+1
where the first inequality holds true since us+1
t
t
inequality comes from Assumption A.1 and the third inequality comes from the Young inequality with
Î· Î± LÏ† > 0 and Î± > 1. Finally, we observe that
s+1
Î·t+1

2(1 âˆ’

s+1
Î·t+1
LÏ† )

=

1
1
Î·
.
â‰¤ 1
=
2(1 âˆ’ Î·LÏ† )
2( Î·s+1 âˆ’ LÏ† )
2( Î· âˆ’ LÏ† )
1

t+1

s+1
where the inequality comes from the fact that Î·t+1
âˆˆ

h

âˆšÎ· , Î·
2

i

. This implies that

h
i



 Î· Î± LÏ† 
Î·
s+1 s
x âˆ’ xs+1 2 +
vs+1 âˆ’ âˆ‡F (xs+1 )2 | xs+1 , xÌƒs
0 â‰¤ Î¦(x) âˆ’ E Î¦(xs+1
)
|
x
,
xÌƒ
+
E
t
t
t
t
t
t+1
2
2(1 âˆ’ Î·LÏ† )
ii
h
h






1 
x âˆ’ xs+1 2 âˆ’ E x âˆ’ xs+1 2 | xs+1 , xÌƒs .
E vs+1 âˆ’ us+1 | xs+1 , xÌƒs 2 + 1
+ Î±
t
t
t
t
t
t+1
s+1
2Î· LÏ†
2Î·t+1
This completes the proof.



Lemma C.2. Assume that k0 â‰¥ 1 and the sample sizes A > 0, B > 0 and C > 0 satisfy
A=

12Bg4 L2f
Î· 2Î± L2Ï†

,

B=

12Bf2 L2g
Î· 2Î± L2Ï†

,

C=

12
,
Î· 2Î±

for some Î± > 1 and Î· > 0 satisfies
Î·â‰¤

1
,
2LÏ†

Î·Î± â‰¤

1
âˆš
,
20 2Î·LÏ† T

we have
 âˆ—





Î± L xâˆ— âˆ’ x0 2
0 ) âˆ’ Î¦(xâˆ— )
x âˆ’ x0 2

3Î·
2
Î¦(x
Ï†
+
+
.
E Î¦(xÌƒs+1 ) âˆ’ Î¦(xâˆ— ) â‰¤
2S
2S
2S Î·k0


where xâˆ— is an optimal solution, i.e.,

xâˆ— = argmin Î¦(x).
xâˆˆRd

20

Proof. Letting x = xâˆ— in Lemma C.1 and combining Lemma B.1 and Lemma B.3 yields that

i
h


 Î· Î± LÏ†  âˆ—

Î·
s+1 s
x âˆ’ xs+1 2 +
vs+1 âˆ’ âˆ‡F (xs+1 )2 | xs+1 , xÌƒs
E
,
xÌƒ
+
0 â‰¤ Î¦(xâˆ— ) âˆ’ E Î¦(xs+1
)
|
x
t
t
t
t
t
t+1
2
2(1 âˆ’ Î·LÏ† )
ii
h
h

 âˆ—




1 
x âˆ’ xs+1 2 âˆ’ E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs
E vs+1 âˆ’ us+1 | xs+1 , xÌƒs 2 + 1
+ Î±
t
t
t
t
t
t+1
s+1
2Î· LÏ†
2Î·t+1

 Î· Î± LÏ†  âˆ—




4Î·LÏ†
s+1 s
x âˆ’ xs+1 2 +
,
xÌƒ
+
â‰¤ Î¦(xâˆ— ) âˆ’ E Î¦(xs+1
)
|
x
) âˆ’ Î¦(xâˆ— ) + [Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )]
Î¦(xs+1
t
t
t
t+1
2
C(1 âˆ’ Î·LÏ† )
!
!#
"
2
2
4
4
2
2
2
h

2 i
Bg L f
Bg L f
Bf L g
LÏ†
Bf2 L2g
2
4Î·
kxÌƒs âˆ’ xâˆ— k2 + xs+1
âˆ’ xâˆ— 
+ Î±
+
+
+
+
t
1 âˆ’ Î·LÏ†
A
B
C
Î· LÏ†
A
B
h
ii
h




1
2 âˆ’ E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs .
+ s+1 xâˆ— âˆ’ xs+1
t
t
t+1
2Î·t+1
Recall that the sample size of At , Bt and Ct are selected as
A=

12Bg4 L2f
Î· 2Î± L2Ï†

,

B=

12Bf2 L2g
Î· 2Î± L2Ï†

,

C=

12
,
Î· 2Î±

(9)

we have
4Î·
1 âˆ’ Î·LÏ†

Bg4 L2f
A
2
Î±
Î· LÏ†

+

Bf2 L2g

+

B

Bg4 L2f
A

L2Ï†
C

Bf2 L2g

+

B

!

=

!

â‰¤

Î· 2Î± L2Ï†
1 âˆ’ Î·LÏ†

,

Î· Î± LÏ†
.
4

Plugging (9) into the above inequality yields that



 Î· Î± LÏ†  âˆ—



4Î·LÏ†
s+1 s
x âˆ’ xs+1 2 +
, xÌƒ +
0 â‰¤ Î¦(xâˆ— ) âˆ’ E Î¦(xs+1
) âˆ’ Î¦(xâˆ— ) + [Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )]
Î¦(xs+1
t
t
t+1 ) | xt
2
C(1 âˆ’ Î·LÏ† )
!
2Î±
2
ii
i
h
h
Î±




Î· LÏ†
Î· LÏ†
1 h
âˆ— 2
xâˆ— âˆ’ xs+1 2 âˆ’ E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs
+
+
kxÌƒs âˆ’ xâˆ— k2 + xs+1
âˆ’
x
+
t
t
t
t+1
s+1
1 âˆ’ Î·LÏ†
2
2Î·t+1
Furthermore, since Î± > 1 and 0 < Î· â‰¤

1
2LÏ†

< 1, we have

4Î·LÏ†
Î· 1+2Î± LÏ†
Î· 3 LÏ†
Î·LÏ†
=
â‰¤
â‰¤
â‰¤
C(1 âˆ’ Î·LÏ† )
3 âˆ’ 3Î·LÏ†
3 âˆ’ 3Î·LÏ†
3 âˆ’ 3Î·LÏ†
and

Î· 2Î± L2Ï†
1 âˆ’ Î·LÏ†

â‰¤

Î· 1+Î± L2Ï†
1 âˆ’ Î·LÏ†

=

21

Î· Î± L2Ï†
1
Î·

âˆ’ LÏ†

â‰¤ Î· Î± LÏ† .

3
Î·

LÏ†
1
â‰¤ ,
3
âˆ’ 3LÏ†

(10)

(11)

Plugging (10) and (11) yields that




 Î· Î± LÏ†  âˆ—

s+1 s
x âˆ’ xs+1 2 + 1 Î¦(xs+1 ) âˆ’ Î¦(xâˆ— ) + [Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )]
,
xÌƒ
+
0 â‰¤ Î¦(xâˆ— ) âˆ’ E Î¦(xs+1
)
|
x
t
t
t
t+1
2
3
h
ii
h
i




3Î· Î± LÏ† h s
1
2
âˆ—
xâˆ— âˆ’ xs+1 2 âˆ’ E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs
+
+
kxÌƒ âˆ’ xâˆ— k2 + xs+1
âˆ’
x
t
t
t
t+1
s+1
2
2Î·t+1



 1 
s+1 s
) âˆ’ Î¦(xâˆ— ) + [Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )]
Î¦(xs+1
, xÌƒ +
= Î¦(xâˆ— ) âˆ’ E Î¦(xs+1
t
t+1 ) | xt
3
ii
h


 i

Î· Î± LÏ† h
1 h
âˆ— 2
xâˆ— âˆ’ xs+1 2 âˆ’ E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs
+
+
3 kxÌƒs âˆ’ xâˆ— k2 + 4 xs+1
âˆ’
x
t
t
t
t+1
s+1
2
2Î·t+1

 1 


s+1 s
, xÌƒ +
= Î¦(xâˆ— ) âˆ’ E Î¦(xs+1
) âˆ’ Î¦(xâˆ— ) + [Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )]
Î¦(xs+1
t
t+1 ) | xt
3
ii
h
 s+1
2 i
2

Î· Î± LÏ† h
1 h
s
âˆ— 2
 âˆ’ E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs
3 kxÌƒ âˆ’ x k âˆ’ 6 xt âˆ’ xâˆ—  + s+1 xâˆ— âˆ’ xs+1
+
t
t
t+1
2
2Î·t+1
2

+5Î· Î± LÏ† xs+1
âˆ’ xâˆ—  ,
t
Furthermore, we observe that

1
Î·ts+1

âˆ’

1
s+1
Î·t+1

â‰¥

1
1
âˆš âˆš
â‰¥ 10Î· Î± LÏ† ,
= âˆš
2 2Î·T
2Î· T 2T

where the last inequality comes from the fact that
0 < Î·Î± â‰¤

1
âˆš
.
20 2Î·LÏ† T

This implies that

â‰¤
â‰¤

ii
h




1 h
xâˆ— âˆ’ xs+1 2 âˆ’ E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs + 5Î· Î± LÏ† xâˆ— âˆ’ xs+1 2
t
t
t
t+1
s+1
2Î·t+1
!
i
h

 âˆ—

1
Î±
x âˆ’ xs+1 2 âˆ’ 1 E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs
+
5Î·
L
Ï†
t
t
t+1
s+1
s+1
2Î·t+1
2Î·t+1
i
h


1 
xâˆ— âˆ’ xs+1 2 âˆ’ 1 E xâˆ— âˆ’ xs+1 2 | xs+1 , xÌƒs .
t
t
t+1
s+1
2Î·ts+1
2Î·t+1

Therefore, we conclude that


s+1 s
, xÌƒ âˆ’ Î¦(xâˆ— )
E Î¦(xs+1
t+1 ) | xt

2 i

 Î· Î± LÏ† h
1 
3 kxÌƒs âˆ’ xâˆ— k2 âˆ’ 6 xs+1
âˆ’ xâˆ— 
â‰¤
Î¦(xs+1
) âˆ’ Î¦(xâˆ— ) + [Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )] +
t
t
3
2
i
h


1 
1
s+1 2
s+1 2
s
âˆ—
âˆ—


.
+ s+1 x âˆ’ xt
,
xÌƒ
âˆ’ s+1 E x âˆ’ xt+1 | xs+1
t
2Î·t
2Î·t+1

We take the expectation of both sides of the above inequality, sum the resulting inequality up over

22

t = 0, 1, 2, . . . , ks+1 âˆ’ 1, and divide both sides of the final inequality by ks+1 . Then we arrive at
ï£¹
ï£®
 âˆ—

ks+1 âˆ’1
s+1 2
Î±

X Î¦(xs+1
t+1 ) + 3Î· LÏ† x âˆ’ xt
âˆ’ Î¦(xâˆ— )ï£»
Eï£°
ks+1
t=0
ï£® ï£«
ï£¶
ks+1 âˆ’1
s+1
X

 âˆ—
3Î· Î± LÏ† âˆ—
1
1
Î¦(xt )
x âˆ’ xs+1 2
â‰¤ Eï£° ï£­
kx âˆ’ xÌƒs k2 + s+1
âˆ’ Î¦(xâˆ— ) + Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— )ï£¸ +
0
3
ks+1
2
2Î·0 ks+1
t=0
#
2

1
 âˆ—
s+1 
âˆ’ s+1
x âˆ’ xks+1  .
2Î·ks+1 ks+1

Multiplying both sides of the above inequality by 3 and rearranging yields that
ï£®
ï£¹

ks+1 âˆ’1
9Î·Î± LÏ† 
s+1 2
âˆ—

X Î¦(xs+1
)+ 2
x âˆ’ xt
t
2 Â· Eï£°
âˆ’ Î¦(xâˆ— )ï£»
ks+1
t=0
h
i
ï£® 

âˆ— ) âˆ’ 3 Î¦(xs+1 ) âˆ’ Î¦(xâˆ— )
3 Î¦(xs+1
)
âˆ’
Î¦(x
0
ks+1
9Î· Î± LÏ† s
â‰¤ Eï£°
+ Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— ) +
kxÌƒ âˆ’ xâˆ— k2
ks+1
2
#

2

 âˆ—
3
3
2


 âˆ’
Â· xâˆ— âˆ’ xs+1
Â· x âˆ’ xs+1
.
+ s+1
0
ks+1 
Â·
k
2Î·0 Â· ks+1
2Î·ks+1
s+1
s+1
According to Assumption A.1 and the definition of xÌƒs+1 , we obtain that

 s+1
2
xÌƒ
âˆ’ xâˆ— 

which implies that


E Î¦(xÌƒs+1 ) âˆ’ Î¦(xâˆ— ) +

9Î· Î± L
2

Ï†

ks+1 âˆ’1

X Î¦(xs+1 )
t
,
k
s+1
t=0
2
ks+1 âˆ’1 
X xs+1
âˆ’ xâˆ— 
t
â‰¤
,
ks+1
t=0

Î¦(xÌƒs+1 ) â‰¤

ï£®

ks+1 âˆ’1
X Î¦(xs+1
 s+1

)+
t
âˆ— 2
xÌƒ
ï£°
âˆ’x
â‰¤E
t=0

9Î·Î± LÏ†
2

 âˆ—

x âˆ’ xs+1 2
t

ks+1

âˆ’ Î¦(xâˆ— )ï£» .

Then we arrive at


2
9Î· Î± LÏ† 
s+1
âˆ—
s+1
âˆ—
xÌƒ
âˆ’x 
2 Â· E Î¦(xÌƒ ) âˆ’ Î¦(x ) +
2
h
i
ï£® 

âˆ— ) âˆ’ 3 Î¦(xs+1 ) âˆ’ Î¦(xâˆ— )
3 Î¦(xs+1
)
âˆ’
Î¦(x
0
ks+1
9Î· Î± LÏ† s
â‰¤ Eï£°
+ Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— ) +
kxÌƒ âˆ’ xâˆ— k2
ks+1
2
#

2

 âˆ—
3
3
2


 âˆ’
Â· x âˆ’ xs+1
Â· xâˆ— âˆ’ xs+1
.
+ s+1
0
ks+1 
2Î·0 Â· ks+1
2Î·ks+1
Â·
k
s+1
s+1
23

ï£¹

s+2
s+1
s+2
Combining the fact that xs+1
and ks+2 = 2ks+1 , we have
ks+1 = x0 , Î·ks+1 = Î·0

2


#
s+2
âˆ—)

2 3 xâˆ— âˆ’ xs+2
3
Î¦(x
)
âˆ’
Î¦(x
9Î· Î± LÏ† 
0
0
âˆ—
s+1
x âˆ’ xÌƒ  +
+
2 Â· E Î¦(xÌƒ ) âˆ’ Î¦(x ) +
2
2ks+1
4Î·0s+2 Â· ks+1
"

 âˆ—

#
Î±L
x âˆ’ xs+1 2 3 Î¦(xs+1 ) âˆ’ Î¦(xâˆ— )
3
9Î·
Ï†
0
0
kxâˆ— âˆ’ xÌƒs k2 +
.
â‰¤ E Î¦(xÌƒs ) âˆ’ Î¦(xâˆ— ) +
+
2
2ks
4Î·0s+1 Â· ks
"

s+1

âˆ—

Finally, we telescope the above inequality for s = 0, 1, 2, . . . , S and obtain that


E Î¦(xÌƒs+1 ) âˆ’ Î¦(xâˆ— )
"
 âˆ—

#

1 2
1 ) âˆ’ Î¦(xâˆ— )
Î±L 


3
x
âˆ’
x
3
Î¦(x
9Î·
1
2
Ï†  âˆ—
0
0
â‰¤
Â· E Î¦(xÌƒ0 ) âˆ’ Î¦(xâˆ— ) +
x âˆ’ xÌƒ0  +
+
2S+1
2
2k0
4Î·01 Â· k0






2
xâˆ— âˆ’ x0 2
2 Î¦(x0 ) âˆ’ Î¦(xâˆ— )
3Î· Î± LÏ† xâˆ— âˆ’ x0 
â‰¤
+
+
.
2S
2S
2S Î· Â· k0

This completes the proof.



Theorem C.3. Given the initial vector x0 âˆˆ Rd satisfies that
 0

x âˆ’ xâˆ— 2 â‰¤ Dx , Î¦(x0 ) âˆ’ Î¦(xâˆ— ) â‰¤ DÏ† ,

and the first epoch length k0 > 0 and the number of epochs S > 0 satisfy that





6DÏ†
Dx
+ 1,
S = log2
+ 1,
k0 =
2Î·DÏ†
Îµ
and the sample sizes A > 0, B > 0 and C > 0 satisfy
A=

12Bg4 L2f
Î· 2Î± L2Ï†

,

B=

12Bf2 L2g

for some Î± > 1 and Î· > 0 satisfies
ï£±

1
ï£² 1
Î±
2DÏ†
,
,
Î· = min
ï£³ 2LÏ†
3LÏ† Dx

Î· 2Î± L2Ï†

,

C=

12
,
Î· 2Î±

Îµ
âˆš
60 2LÏ† (Dx + 2DÏ† )

!1ï£¼
Î±ï£½

,

ï£¾

and Îµ âˆˆ (0, 1) is a tolerance, then the total IFO complexity, i.e., the number of IFO queries to achieve
an Îµ-optimal solution that satisfies


E Î¦(xÌƒs+1 ) âˆ’ Î¦(xâˆ— ) â‰¤ Îµ,

is


 
1
1
+
,
O (m + n) log
1
Îµ
Îµ3+ Î±
where we omit the dependence of the IFO complexity on the Lipschitz constant LÏ† , Lf , Lg , the upper
bound of the norm of gradient and Jacobian Bf , Bg , and the distance between the initial point and the
optimal set, i.e., Dx (the iterative gap) and DÏ† (the objective gap).


24

Proof. Firstly, we check if the choices of parameter satisfy the requirement in Lemma C.2. Indeed, we
observe that k0 â‰¥ 1 and the sample sizes A > 0, B > 0 and C > 0 satisfy
A=

12Bg4 L2f
Î· 2Î± L2Ï†

,

B=

for some Î± > 1 and Î· > 0 satisfies
Î·â‰¤

12Bf2 L2g
Î· 2Î± L2Ï†

,

C=

12
,
Î· 2Î±

1
.
2LÏ†

Then it suffices to check if the following statement holds true,
Î·â‰¤

1
,
2LÏ†

Î·Î± â‰¤

1
âˆš
.
20 2Î·LÏ† T

We observe that
1
âˆš
20 2Î·LÏ† T

â‰¥
â‰¥
â‰¥
=
â‰¥
â‰¥

1
âˆš
20 2Î·LÏ† k0 2S
Îµ
1
âˆš
Â·
20 2Î·LÏ† k0 6DÏ†
1
Îµ

Â·
âˆš
Dx
6DÏ†
20 2Î·LÏ† 2Î·D
+1
Ï†
Îµ
âˆš
60 2LÏ† (Dx + 2Î·DÏ† )
Îµ
âˆš
60 2LÏ† (Dx + 2DÏ† )
Î·Î± ,

S
where the jfirst inequality
k comes from the fact that T = k0 Â· 2 âˆ’ kj0 , thekfirst equality comes from
6DÏ†
Dx
S = S = log2 Îµ
+ 1, the third inequality
+ 1, the second inequality comes from k0 = 2Î·D
Ï†
comes from the fact that 0 < Î· < 1 and the last inequality comes from 0 < Î· Î± < 60âˆš2L ÎµD +2D .
Ï†)
Ï†( x
Therefore, we arrive at


2  âˆ—


x âˆ’ x0 2

 2 Î¦(x0 ) âˆ’ Î¦(xâˆ— )
3Î· Î± LÏ† xâˆ— âˆ’ x0 
s+1
âˆ—
E Î¦(xÌƒ ) âˆ’ Î¦(x ) â‰¤
+
+
.
2S
2S
2S Î·k0

Furthermore, we have



2 Î¦(x0 ) âˆ’ Î¦(xâˆ— )
2S

2
3Î· Î± LÏ† x0 âˆ’ xâˆ— 
2S
 0

x âˆ’ xâˆ— 2
2S Î·k0

â‰¤

Îµ
,
3
ÎµÎ· Î± LÏ† Dx
Îµ
â‰¤ ,
2DÏ†
3

â‰¤

Îµ
,
3

â‰¤

25

2D

Ï†
where the second inequality comes from 0 < Î· Î± â‰¤ 3LÏ† D
and the third inequality comes from k0 =
x
j
k
Dx
2Î·DÏ† + 1. Therefore, the total IFO complexity, i.e., the number of IFO queries to achieve an Îµ-optimal
solution that satisfies


E Î¦(xÌƒs+1 ) âˆ’ Î¦(xâˆ— ) â‰¤ Îµ,

is

S Â· (m + n) + 2S Â· k0 Â· (A + B)



 
 


6DÏ†
12DÏ†
Dx
1
= (m + n) Â·
log2
+1 +
Â·
+ 1 Â· 2Î± Â·
Îµ
Îµ
2Î·DÏ†
Î·

 

1
1
= O (m + n) Â· log
.
+
1
Îµ
Îµ3+ Î±
This completes the proof.

12Bg4 L2f
L2Ï†

+

12Bf2 L2g
L2Ï†

!

+ 12 ,



26

