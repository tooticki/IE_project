1

arXiv:1508.05905v3 [math.PR] 2 Jan 2016

Local Stability of the Free Additive Convolution

Zhigang Bao†

László Erdős∗

Kevin Schnelli†

IST Austria
zhigang.bao@ist.ac.at

IST Austria
lerdos@ist.ac.at

IST Austria
kevin.schnelli@ist.ac.at

We prove that the system of subordination equations, defining the free additive convolution of two probability measures, is stable away from the edges of the support
and blow-up singularities by showing that the recent smoothness condition of Kargin
is always satisfied. As an application, we consider the local spectral statistics of the
random matrix ensemble A + U BU ∗ , where U is a Haar distributed random unitary
or orthogonal matrix, and A and B are deterministic matrices. In the bulk regime,
we prove that the empirical spectral distribution of A + U BU ∗ concentrates around
the free additive convolution of the spectral distributions of A and B on scales down
to N −2/3 .
Keywords: Free convolution, subordination, local eigenvalue density
AMS Subject Classification (2010): 46L54, 60B20

1. Introduction
One of the basic concepts of free probability theory is the free additive convolution of two
probability laws in a non-commutative probability space; it describes the law of the sum of
two free random variables. In the case of a bounded self-adjoint random variable, its law
can be identified with a probability measure of compact support on the real line. Hence
the free additive convolution of two probability measures is a well-defined concept and it is
characteristically different from the classical convolution.
In this paper, we prove a local stability result of the free additive convolution. A direct
consequence is the continuity of the free additive convolution in a much stronger topology
than established earlier by Bercovici and Voiculescu [10]. A second application of our stability result is to establish a local law on a very small scale for the eigenvalue density of a
random matrix ensemble A + U BU ∗ where U is a Haar distributed unitary or orthogonal
matrix and A, B are deterministic N by N hermitian matrices.
The free additive convolution was originally introduced by Voiculescu [36] for the sum
of free bounded noncommutative random variables in an algebraic setup (see Maassen [32]
and by Bercovici and Voiculescu [10] for extensions to the unbounded case). The Stieltjes
transform of the free additive convolution is related to the Cauchy-Stieltjes transforms of the
original measures by an elegant analytic change of variables. This subordination phenomenon
was first observed by Voiculescu [38] in a generic situation and extended to full generality by
Biane [14]. In fact, the subordination equations, see (2.5)-(2.6) below, may directly be used
∗Partially supported by ERC Advanced Grant RANMAT No. 338804.
†

Supported by ERC Advanced Grant RANMAT No. 338804.

2

to define the free additive convolution. This analytic definition was given independently by
Belinschi and Bercovici [4] and by Chistyakov and Götze [18]; for further details we refer to,
e.g., [39, 27, 2].
Kargin [30] pointed out that the analytic approach to the subordination equations, in
contrast to the algebraic one, allows one to effectively study how free additive convolution
is affected by small perturbations; this is especially useful to treat various error terms in the
random matrix problem [31]. The basic tool is a local stability analysis of the subordination
equations. In [30], Kargin assumed a lower bound on the imaginary part of the subordination
functions and a certain non-degeneracy condition on the Jacobian that holds for generic
values of the spectral parameter. While these so-called smoothness conditions hold in many
examples, a general characterization was lacking. Our first result, Theorem 2.5, shows
that the smoothness conditions hold wherever the absolutely continuous part of the free
convolution measure is finite and nonzero. In particular, local stability holds unconditionally
(Corollary 2.6) and, following Kargin’s argument [30], we immediately obtain the continuity
of the free additive convolution in a stronger sense; see Theorem 2.7.
The random matrix application of this stability result, however, goes well beyond Kargin’s
analysis [31] since our proof is valid on a much smaller scale. To explain the new elements,
we recall how free probability connects to random matrices.
The following fundamental observation was made by Voiculescu [37] (later extended by
Dykema [20] and Speicher [35]): if A = A(N ) and B = B (N ) are two sequences of Hermitian
matrices that are asymptotically free with eigenvalue distributions converging to probability
measures µα and µβ , then the eigenvalue density of A + B is asymptotically given by the
free additive convolution µα ⊞ µβ . One of the most natural ways to ensure asymptotic
freeness is to consider conjugation by independent unitary matrices. Indeed, if A and B
are deterministic (may even be chosen diagonal) with limit laws µα and µβ , then A and
U BU ∗ are asymptotically free if U = U (N ) is a Haar distributed matrix; see [37] and many
subsequent works, e.g., [34, 40, 15, 33, 19]. In particular, the limiting spectral density of
the eigenvalues of H = A + U BU ∗ is given by µα ⊞ µβ .
The conventional setup of free probability operates with moment calculations. An alternative approach [33] proves the convergence of the resolvent at any fixed spectral parameter z ∈ C+ . Both approaches give rise to weak convergence of measures, in particular they
identify the limiting spectral density on macroscopic scale.
Armed with these macroscopic results, it is natural to ask for a local law, i.e., for the
smallest possible (N -dependent) scale so that the local eigenvalue density on that scale still
converges as N tends to infinity. Local laws have been somewhat outside of the focus of free
probability before Kargin’s recent works. After having improved a concentration result for
the Haar measure by Chatterjee [17] by using the Gromov-Milman concentration inequality,
Kargin obtained a local law for the ensemble H = A + U BU ∗ on scale η ≫ (log N )−1/2 [29],
i.e., slightly below the macroscopic scale. Recently in [31], he improved this result down
to scale η ≫ N −1/7 under the above mentioned smoothness condition. In Theorem 2.8 we
prove the local law down to scale η = Im z ≫ N −2/3 without any additional assumption.
To achieve this short scale, we effectively use the positivity of the imaginary parts of the
subordination functions by localizing the Gromov–Milman concentration inequality within
the spectrum. Since the subordination functions are obtained as the solution of a system
of self-consistent equations whose derivation itself requires bounds on the subordination
functions, the reasoning seems circular. We break this circularity by a continuity argument
(similarly as in [23]) in which we reduce the imaginary part of the spectral parameter in
very small steps, use the previous step as an a priori bound and show that the bound does
not deteriorate by using the local stability result, Theorem 2.6.

3

Finally, we remark that the local stability result is also a key ingredient in [3], where we
were able to prove a local law down to the smallest possible scale η ≫ N −1 , but with a
weaker error bound than in Theorem 2.8; see Remark 2.4 for details.
1.1. Notation. We use the symbols O( · ) and o( · ) for the standard big-O and little-o
notation. We use c and C to denote positive numerical constants. Their values may change
from line to line. For a, b > 0, we write a . b, a & b if there is C ≥ 1 such that a ≤ Cb,
a ≥ C −1 b respectively. We write a ∼ b, if a . b and a & b both hold. We denote by kvk the
Euclidean norm of v ∈ p
CN . For an N ×N matrix A ∈ MN (C), we denote by kAk its operator
norm and by kAk2 := hA, Ai its Hilbert-Schmidt norm, where hA, Bi := Trace(AB ∗ ), for
A, B ∈ MN (C). Finally, we denote by trA the normalized trace of A, i.e., trA = N1 Trace A.
Acknowledgment. We thank an anonymous referee for many useful comments and remarks, and bringing references [7, 12] to our attention.
2. Main results
2.1. Free additive convolution. In this subsection, we recall the definition of the free
additive convolution. Given a probability measure∗ µ on R, its Stieltjes transform, mµ , on
the complex upper half-plane C+ := {z ∈ C : Im z > 0} is defined by
Z
dµ(x)
,
z ∈ C+ .
(2.1)
mµ (z) :=
R x−z
We denote by Fµ the negative reciprocal Stieltjes transform of µ, i.e.,
Fµ (z) := −

1
,
mµ (z)

z ∈ C+ .

(2.2)

Observe that
lim

ηր∞

Fµ (iη)
= 1,
iη

(2.3)

as follows easily from (2.1). Note, moreover, that Fµ is an analytic function on C+ with
non-negative imaginary part. Conversely, if F : C+ → C+ is an analytic function such that
limηր∞ F (iη)/iη = 1, then F is the negative reciprocal Stieltjes transform of a probability
measure µ, i.e., F (z) = Fµ (z), for all z ∈ C+ ; see, e.g., [1].
The free additive convolution is the binary operation on probability measures on R characterized by the following result.
Proposition 2.1 (Theorem 4.1 in [4], Theorem 2.1 in [18]). Given two probability measures
µ1 and µ2 on R, there exist unique analytic functions, ω1 , ω2 : C+ → C+ , such that,
(i) for all z ∈ C+ , Im ω1 (z), Im ω2 (z) ≥ Im z, and
lim

ηր∞

ω2 (iη)
ω1 (iη)
= lim
= 1;
ηր∞
iη
iη

(2.4)

(ii) for all z ∈ C+ ,
Fµ1 (ω2 (z)) − ω1 (z) − ω2 (z) + z = 0 ,

Fµ2 (ω1 (z)) − ω1 (z) − ω2 (z) + z = 0 .
∗

All probability measures considered will be assumed to be Borel.

(2.5)

4

It follows from (2.4) that the analytic function F : C+ → C+ defined by
F (z) := Fµ1 (ω2 (z)) = Fµ2 (ω1 (z)) ,

(2.6)

satisfies (2.3). Thus F is the negative reciprocal Stieltjes transform of a probability measure µ, called the free additive convolution of µ1 and µ2 , usually denoted by µ ≡ µ1 ⊞ µ2 .
Note that (2.6) shows that the rôles of µ1 and µ2 are symmetric and thus µ1 ⊞ µ2 = µ2 ⊞ µ1 .
The functions ω1 and ω2 of Proposition 2.1 are called subordination functions and F is said
to be subordinated to Fµ1 , respectively to Fµ2 .
We mention that Voiculescu [36] originally introduced the free additive convolution in
a different, algebraic manner. The equivalent analytic definition based on the existence of
subordination functions (taken up in Proposition 2.1 above) was introduced in [4, 18].
We next recall some basic examples. Choosing µ1 arbitrary and µ2 as a single point
mass at b ∈ R, it is easy to check that µ1 ⊞ µ2 simply is µ1 shifted by b. We exclude this
uninteresting case by henceforth assuming that µ1 and µ2 are both supported at more than
one point. Choosing µ1 = µ2 = µ as the Bernoulli distribution
µ = (1 − ξ)δ0 + ξδ1 ,

ξ ∈ (0, 1) ,

the free additive convolution is explicitly given by (see e.g., (5.5) of [33])
p
(ℓ+ − x)+ (x − ℓ− )+
+ (1 − 2ξ)+ δ0 (x) + (2ξ − 1)+ δ2 (x) ,
(2.7)
(µ ⊞ µ)(x) =
πx(2 − x)
p
x ∈ R, where ℓ± := 1 ± 2 ξ(1 − ξ) and where ( · )+ denotes the positive part. Observe that
µ ⊞ µ has a nonzero absolutely continuous part and, depending on the choice of ξ, a point
mass. Another important choice for µ2 is Wigner’s semicircle law µsc . For arbitrary µ1 ,
µ1 ⊞ µsc is then purely absolutely continuous with a bounded density† that is real analytic
wherever positive [13].
Returning to the generic setting, the atoms of µ1 ⊞ µ2 are identified as follows. A point
c ∈ R is an atom of µ1 ⊞ µ2 , if and only if there exist a, b ∈ R such that c = a + b and
µ1 ({a}) + µ2 ({b}) > 1; see [Theorem 7.4, [11]]. For another interesting properties of the
atoms of µ1 ⊞ µ2 we refer the reader to [12]. The boundary behavior of the functions
Fµ1 ⊞µ2 , ω1 and ω2 has been studied by Belinschi [5, 6, 7] who proved the next two results.
For simplicity, we restrict the discussion to compactly supported probability measures.
Proposition 2.2 (Theorem 2.3 in [5], Theorem 3.3 in [6]). Let µ1 and µ2 be compactly
supported probability measures on R, none of them being a single point mass. Then the
functions Fµ1 ⊞µ2 , ω1 , ω2 : C+ → C+ extend continuously to R.
Belinschi further showed in Theorem 4.1 in [6] that the singular continuous part of µ1 ⊞µ2
is always zero and that the absolutely continuous part, (µ1 ⊞ µ2 )ac , of µ1 ⊞ µ2 is always
nonzero. We denote the density function of (µ1 ⊞ µ2 )ac by fµ1 ⊞µ2 .
We are now ready to introduce our notion of regular bulk, Bµ1 ⊞µ2 , of µ1 ⊞ µ2 . Informally,
we let Bµ1 ⊞µ2 be the open set on which µ1 ⊞ µ2 admits a continuous density that is strictly
positive and bounded from above. For a formal definition we first introduce the set



ac
(2.8)
{x ∈ R : lim Fµ1 ⊞µ2 (x + iη) = 0} .
Uµ1 ⊞µ2 := int supp (µ1 ⊞ µ2 )
ηց0

Note that Uµ1 ⊞µ2 does not contain any atoms of µ1 ⊞ µ2 . By Privalov’s theorem the set
{x ∈ R : limηց0 Fµ1 ⊞µ2 (x + iη) = 0} has Lebesgue measure zero. In fact, an even stronger
statement applies for the case at hand. Belinschi [7] showed that if x ∈ R is such that
†

All densities are with respect to Lebesgue measure on R.

5

limηց0 Fµ1 ⊞µ2 (x + iη) = 0, then it must be of the form x = a + b with µ1 ({a}) + µ2({b}) ≥ 1,
a, b ∈ R. There could only be finitely many such x, thus Uµ1 ⊞µ2 must contain an open nonempty interval.
Proposition 2.3 (Theorem 3.3 in [6]). Let µ1 and µ2 be as above and fix any x ∈ Uµ1 ⊞µ2 .
Then Fµ1 ⊞µ2 , ω1 , ω2 : C+ → C+ extend analytically around x. In particular, the density
function fµ1 ⊞µ2 is real analytic in Uµ1 ⊞µ2 wherever positive.
The regular bulk is obtained from Uµ1 ⊞µ2 by removing the zeros of fµ1 ⊞µ2 inside Uµ1 ⊞µ2 .
Definition 2.4. The regular bulk of the measure µ1 ⊞ µ2 is defined as the set
	

Bµ1 ⊞µ2 := Uµ1 ⊞µ2 \ x ∈ Uµ1 ⊞µ2 : fµ1 ⊞µ2 (x) = 0 .

(2.9)

Note that Bµ1 ⊞µ2 is an open non-empty set on which µ1 ⊞ µ2 admits the density fµ1 ⊞µ2 .
The density is strictly positive and thus (by Proposition 2.3) real analytic on Bµ1 ⊞µ2 .

2.2. Stability Result. To present our results it is convenient to recast (2.5) in a compact
form: For generic probability measures µ1 , µ2 as above, let the function Φµ1 ,µ2 : (C+ )3 → C2
be given by


Fµ1 (ω2 ) − ω1 − ω2 + z
.
(2.10)
Φµ1 ,µ2 (ω1 , ω2 , z) :=
Fµ2 (ω1 ) − ω1 − ω2 + z
Considering µ1 , µ2 as fixed, the equation
Φµ1 ,µ2 (ω1 , ω2 , z) = 0 ,

(2.11)

is equivalent to (2.5) and, by Proposition 2.1, there are unique analytic functions ω1 , ω2 :
C+ → C+ , z 7→ ω1 (z), ω2 (z) satisfying (2.4) that solve (2.11) in terms of z. We use the
following conventions: We denote by ω1 and ω2 generic variables on C+ and we denote, with
a slight abuse of notation, by ω1 (z) and ω2 (z) the subordination functions solving (2.11) in
terms of z. When no confusion can arise, we simply write Φ for Φµ1 ,µ2 .
We call the system (2.11) linearly S-stable at (ω1 , ω2 ) if

−1 


−1
Fµ′ 1 (ω2 ) − 1


Γµ1 ,µ2 (ω1 , ω2 ) := 
(2.12)
≤S,
′
−1
 Fµ2 (ω1 ) − 1

for some constant S. Especially, the partial Jacobian matrix, DΦ(ω1 , ω2 ), of (2.10) given by

 

∂Φ
∂Φ
−1
Fµ′ 1 (ω2 ) − 1
,
(ω1 , ω2 , z) ,
(ω1 , ω2 , z) =
DΦ(ω1 , ω2 ) :=
−1
Fµ′ 2 (ω1 ) − 1
∂ω1
∂ω2

admits a bounded inverse at (ω1 , ω2 ). Note that DΦ(ω1 , ω2 ) is independent of z.
Our first main result shows that the system (2.11) is linearly stable and that the imaginary
parts of the subordination functions are bounded below in the regular bulk. We require some
more notation: For a, b ≥ 0, b ≥ a, and an interval I ⊂ R, we introduce the domain
SI (a, b) := {z = E + iη ∈ C+ : E ∈ I , a ≤ η ≤ b} .

(2.13)

Theorem 2.5. Let µ1 and µ2 be compactly supported probability measures on R, and assume
that neither is supported at a single point and that at least one of them is supported at more
than two points. Let I ⊂ Bµ1 ⊞µ2 be a compact non-empty interval and fix some 0 < ηM < ∞.
Then there are two constants k > 0 and S < ∞, both depending on the measures µ1
and µ2 , on the interval I as well as on the constant ηM , such that following statements hold.

6

(i) The imaginary parts Im ω1 and Im ω2 of the subordination functions associated
with µ1 and µ2 satisfy
min

z∈SI (0,ηM )

Im ω1 (z) ≥ 2k ,

min

z∈SI (0,ηM )

Im ω2 (z) ≥ 2k .

(2.14)

(ii) The system Φµ1 ,µ2 (ω1 , ω2 , z) = 0 is linearly S-stable at (ω1 (z), ω2 (z)) uniformly in
SI (0, ηM ), i.e.,
max

z∈SI (0,ηM )

Γµ1 ,µ2 (ω1 (z), ω2 (z)) ≤ S .

(2.15)

Remark 2.1. The assumption that neither of µ1 , µ2 is a point mass guarantees that the
free additive convolution is not a simple translate. The case when both, µ1 and µ2 are
combinations of two point masses is special and its discussion is postponed to Section 7.
Theorem 2.5 has the following local stability result as corollary.
Corollary 2.6. Let µ1 , µ2 and SI (0, ηM ) be as in Theorem 2.5. Fix z0 ∈ C+ . Assume that
the functions ω
e1 , ω
e2 , re1 , re2 : C+ → C satisfy Im ω
e1 (z0 ) > 0, Im ω
e2 (z0 ) > 0 and
ω1 (z0 ), ω
e2 (z0 ), z0 ) = re(z0 ) ,
Φµ1 ,µ2 (e

(2.16)

with re(z) := (e
r1 (z), re2 (z))⊤ . Let ω1 , ω2 be the subordination functions solving the system
Φµ1 ,µ2 (ω1 (z), ω2 (z), z) = 0, z ∈ C+ .
Then there exists a (small) constant δ0 > 0 such that whenever we have
we also have

|e
ω1 (z0 ) − ω1 (z0 )| ≤ δ0 ,

|e
ω1 (z0 ) − ω1 (z0 )| ≤ 2Ske
r(z0 )k ,

|e
ω1 (z0 ) − ω1 (z0 )| ≤ δ0 ,

(2.17)

|e
ω2 (z0 ) − ω2 (z0 )| ≤ 2Ske
r(z0 )k .

(2.18)

The constant δ0 > 0 depends on µ1 and µ2 , on the interval I as well as on ηM .
We omit the proof of Corollary 2.6 from Theorem 2.5, since it follows directly from
Proposition 4.1 in Section 4 below.
2.3. Applications. We next explain two main applications of the stability estimates obtained in Theorem 2.5.
2.3.1. Continuity of the free additive convolution. Our first application shows that the free
additive convolution is a continuous operation when the image is equipped with the topology
of local uniform convergence of the density in the regular bulk; see (2.23). Bercovici and
Voiculescu (Proposition 4.13 of [10]) showed that the free additive convolution is continuous
with respect to weak convergence of measures. More precisely, given two pairs of probability
measures µA , µB and µα , µβ on R, the measures µA ⊞ µB and µα ⊞ µβ satisfy
dL (µA ⊞ µB , µα ⊞ µβ ) ≤ dL (µA , µα ) + dL (µB , µβ ) ,

(2.19)

where dL denotes the Lévy distance. In particular, weak convergence of µA to µα and weak
convergence of µB to µβ imply weak convergence of µA ⊞ µB to µα ⊞ µβ .
Using the Stieltjes transform, we can easily link (2.19) to the systems of equations in (2.5),
respectively in (2.10). Using integration by parts and the definition of the Stieltjes transform,
a direct computation reveals that there is a numerical constant C such that
C
1
|mµA ⊞µB (z) − mµα ⊞µβ (z)| ≤
1+
dL (µA ⊞ µB , µα ⊞ µβ )
η
η
1
C
1+
(dL (µA , µα ) + dL (µB , µβ )) ,
η = Im z , (2.20)
≤
η
η

7

for all z ∈ C+ , where we used (2.19) to get the second line. Note that the estimate in (2.20)
deteriorates as η approaches the real line. Our next result strengthens (2.20) as follows. We
consider the measure µα ⊞ µβ as “reference” measure (in the sense that it locates the regular
bulk) while µA , µB are arbitrary probability measures and show that the Lévy distances
bound |mµA ⊞µB (E + iη) − mµα ⊞µβ (E + iη)| uniformly in η, for all E inside the regular bulk
of µα ⊞ µβ .
Theorem 2.7. Let µα and µβ be compactly supported probability measures on R, and assume
that neither is supported at a single point and that at least one of them is supported at more
than two points. Let I ⊂ Bµα ⊞µβ be a compact non-empty interval and fix some 0 < ηM < ∞.
Let µA and µB be two arbitrary probability measures on R.
Then there are constants b > 0 and Z < ∞, both depending on the measures µα and µβ ,
on the interval I as well as on the constant ηM , such that whenever
dL (µA , µα ) + dL (µB , µβ ) ≤ b
holds, then
max

z∈SI (0,ηM )

holds, too.


 mµ

A ⊞µB


(z) − mµα ⊞µβ (z) ≤ Z (dL (µA , µα ) + dL (µB , µβ )) ,

(2.21)

(2.22)

Note that maxz∈SI (0,ηM ) |mµα ⊞µβ (z)| < ∞ by compactness of I and analyticity of mµα ⊞µβ
in I. Thus the Stieltjes-Perron inversion formula directly implies that (µA ⊞ µB )ac has a
density, fµA ⊞µB , inside I and that
max |fµA ⊞µB (x) − fµα ⊞µβ (x)| ≤ Z (dL (µA , µα ) + dL (µB , µβ )) ,
x∈I

(2.23)

provided that (2.21) holds, where fµα ⊞µβ is the density of (µα ⊞ µβ )ac .
Remark 2.2. The estimate (2.22) was recently given by Kargin [30] under the assumption
that (2.14) and (2.15) hold for all z ∈ SI (0, ηM ), i.e., under the assumption that the conclusions of our Theorem 2.5 hold. It is quite surprising that one can directly set Im z = 0
in (2.22). As first noted by Kargin, this is due to the regularizing effect of ωα , ωβ and to
the global uniqueness of solutions to (2.5) for arbitrary probability measures.
2.3.2. Application to random matrix theory. We now turn to an application of Theorem 2.5
in random matrix theory. Let A ≡ A(N ) and B ≡ B (N ) be two sequences of N × N deterministic real diagonal matrices, whose empirical spectral distributions are denoted by µA
and µB respectively, i.e.,
N
1 X
δa ,
µA :=
N i=1 i

N
1 X
µB :=
δb ,
N i=1 i

(2.24)

where A = diag(ai ), B = diag(bi ). The matrices A and B depend on N , but we omit
this fact from the notation. Let ωA and ωB denote the subordination functions associated
with µA and µB by Proposition 2.1.
We assume that there are deterministic probability measures µα and µβ on R, neither
of them being a single point mass, such that the empirical spectral distributions µA , µB
converge weakly to µα , µβ , as N → ∞. More precisely, we assume that
dL (µA , µα ) + dL (µB , µβ ) → 0 ,

(2.25)

as N → ∞. Let ωα , ωβ denote the subordination functions associated with µα and µβ .

8

Let U be an independent N × N Haar distributed unitary matrix (in short Haar unitary)
and consider the random matrix
H ≡ H (N ) := A + U BU ∗ .

(2.26)

We introduce the Green function, GH , of H and its normalized trace, mH , by setting
1
GH (z) :=
,
mH (z) := tr GH (z) ,
(2.27)
H −z
z ∈ C+ . We refer to z as the spectral parameter and we often write z = E + iη, E ∈ R,
η > 0. Recall the definition of SI (a, b) in (2.13). We have the following local law for mH .
Theorem 2.8. Let µα and µβ be two compactly supported probability measures on R, and
assume that neither is only supported at one point and that at least one of them is supported
at more than two points. Let I ⊂ Bµα ⊞µβ be a compact non-empty interval and fix some
0 < ηM < ∞. Assume that the sequences of matrices A and B in (2.26) are such that their
empirical eigenvalue distributions µA and µB satisfy (2.25). Fix any small γ > 0 and set
ηm := N −2/3+γ .
Then we have the following uniform estimate: For any (small) ǫ > 0 and any (large) D,



ǫ
[


1
mH (z) − mµ ⊞µ (z) > N
(2.28)
P
≤ D,
A
B
3/2
N
Nη
z∈SI (ηm ,ηM )

holds for N ≥ N0 , with some N0 sufficiently large, where we write z = E + iη.

Using standard techniques of random matrix theory, we can translate the estimate (2.28)
on the Green function into an estimate on the empirical spectral distribution of the matrix H.
Let λ1 , . . . , λN denote the ordered eigenvalues of H and denote by
µH :=

N
1 X
δλ
N i=1 i

(2.29)

its empirical spectral distribution. Our result on the rate of convergence of µH is as follows.
Corollary 2.9. Let I ⊂ Bµα ⊞µβ be a compact non-empty interval. Then, for any E1 < E2
in I, we have the following estimate. For any (small) ǫ > 0 and any (large) D we have



Nǫ


P µH ([E1 , E2 )) − µA⊞B ([E1 , E2 )) > 2/3 ≤ N −D ,
(2.30)
N
for N ≥ N0 , with some N0 sufficiently large.
We omit the proof of Corollary 2.9 from Theorem 2.8, but mention that the normalized
trace mH of the Green function and the empirical spectral distribution µH of H are linked by
Z
N
dµH (x)
1 X 1
=
,
z ∈ C+ .
mH (z) = tr GH (z) =
N i=1 λi − z
x
−
z
R

Corollary 2.9 then follows from a standard application of the Helffer-Sjöstrand functional
calculus; see e.g., Section 7.1 of [22] for a similar argument.
Note that assumption (2.25) does not exclude that the matrix H has outliers in the
large N limit. In fact, the model H = A + U BU ∗ shows a rich phenomenology when, say, A
has a finite number of large spikes; we refer to the recent works in [8, 9, 16, 31].
Remark 2.3. Our results in Theorem 2.8 and Corollary 2.9 are stated for U Haar distributed
on the unitary group U (N ). However, they also hold true (with the same proofs) when U
is Haar distributed on the orthogonal group O(N ).

9

Remark 2.4. In [3], we derive, with a different approach, the estimate (with the notation
of (2.28))



ǫ
[


1
mH (z) − mµ ⊞µ (z) > √N
P
≤ D,
(2.31)
A
B
N
Nη
z∈SI (ηm ,ηM )

for N ≥ N0 , with some N0 sufficiently large, and with ηm = N −1+γ . In fact, we obtain
estimates for individual matrix elements of the resolvent GH as well. Comparing with (2.28),
we see √that we can choose η in (2.31) almost as small as N −1 at the price of losing a
factor N . The stability and perturbation analysis in [3] rely on the optimal results in
Theorem 2.5 and Theorem 2.7 as well as in Sections 3-5 of the present paper.

2.4. Organization of the paper. In Section 3, we consider the stability of the system (2.5)
when at least one of the measures µ1 and µ2 is supported at more than two points and we
give the proof of Theorem 2.5. In Section 4, we consider perturbations of the system (2.5)
and derive results that will be used in the proof of Theorem 2.8 and also in [3]. In Section 5, we prove Theorem 2.7. In Section 6 we consider the random matrix setup and prove
Theorem 2.8. In the final Section 7, we separately settle the special case when both µ1
and µ2 are combinations of two point masses and give the results analogous to Theorem 2.5,
Theorem 2.7 and Theorem 2.8 for that case.
3. Stability of the system (2.11) and proof of Theorem 2.5
In this section, we discuss stability properties of the system (2.11), with µ1 , µ2 two
compactly supported probability measures satisfying the assumptions of Theorem 2.5.
Lemma 3.1. Let µ1 , µ2 be two probability measures on R neither of them being supported
at a single point. Then there is, for any compact set K ⊂ C+ , a strictly positive constant
0 < σ(µ1 , K) < 1 such that the reciprocal Stieltjes transform Fµ1 (see (2.2)) satisfies
Im z ≤ (1 − σ(µ1 , K)) Im Fµ1 (z) ,

∀z ∈ K .

(3.1)

Similarly, there is 0 < σ(µ2 , K) < 1 such that (3.1) holds with µ2 and Fµ2 , respectively.
Assume in addition that µ1 is supported at more than two points. Then there is, for any
compact set K ⊂ C+ , a strictly positive constant 0 < σ
e(µ1 , K) < 1 such that
e(µ1 , K))
|Fµ′ 1 (z) − 1| ≤ (1 − σ

Im Fµ1 (z) − Im z
,
Im z

∀z ∈ K ,

(3.2)

where Fµ′ 1 (z) ≡ ∂z Fµ1 (z).

Proof of Lemma 3.1. Assuming by contradiction that inequality (3.1) saturates (with vanishing constant σ(µ1 , K) = 0, for some z ∈ K ⊂ C+ ), we have Im Fµ1 (z) = Im z for some z,
thus Fµ1 (z) = z − a, a ∈ R, i.e., µ1 = δa . This shows (3.1).
To establish (3.2), we first note that the analytic functions Fµj : C+ → C+ , j = 1, 2,
have the Nevanlinna representations
Z
1 + zx
Fµj (z) = aFµj + z +
j = 1, 2 ,
z ∈ C+ ,
(3.3)
dρFµj (x) ,
x
−
z
R
where aFµj ∈ R and ρµFj are finite Borel measures on R. Note that the coefficients of z on
the right-hand side are determined by (2.3). From (3.3) we see that

Z


1 + x2
,
(x)
z ∈ C+ ,
(3.4)
dρ
|Fµ′ 1 (z) − 1| = 
Fµ1

2
(x
−
z)
R

10

as well as
Im Fµ1 (z) − Im z
=
Im z

Z

R

1 + x2
dρFµ1 (x) ,
|x − z|2

z ∈ C+ .

(3.5)

e (µ1 , K) = 0, for
Hence, assuming by contradiction that inequality (3.2) saturates (with σ
some z ∈ K), we must have
Z

Z


1 + x2
1 + x2

,
(x)
=
(x)
dρ
dρ
(3.6)
F
F
µ
µ


1
1
2
2
R |x − z|
R (x − z)
for some z ∈ K, implying that ρFµ1 is either a single point mass or ρFµ1 = 0. In the latter
case, we have Fµ1 (z) = aµ1 + z and we conclude that µ1 must be single point measure, but
this is excluded by assumption. Thus ρFµ1 is a single point mass, i.e., there is a constant
dµ1 ∈ R such that Fµ1 (z) = aFµ1 + z + (1 + zd2µ1 )/(dµ1 − z), z ∈ K. It follows that µ1 is a

convex combination of two point measures yielding a contradiction. This shows (3.2).
3.1. Bounds on the subordination functions. Let µ1 , µ2 be as above and let ω1 (z),
ω2 (z) be the associated subordination functions. Recall that we rewrite the defining equations (2.5) for ω1 and ω2 in the compact form Φµ1 ,µ2 (ω1 , ω2 , z) = 0 introduced in (2.11).
We first provide upper bounds on the subordination functions ω1 (z), ω2 (z). Our proof
relies on the assumption that µ1 , µ2 are compactly supported, i.e., that there is a constant
L < ∞ such that
supp µ1 ⊂ [−L, L] ,

supp µ2 ⊂ [−L, L] .

(3.7)

Recall from Theorem 2.5 that we fixed a compact non-empty interval I ⊂ Bµ1 ⊞µ2 . Since
the density fµ1 ⊞µ2 is real analytic inside the regular bulk by Proposition 2.3 and since I is
compact, there exists a constant κ0 > 0 such that
0 < κ0 ≤ min fµ1 ⊞µ2 (x) .
x∈I

(3.8)

Fixing a constant 0 < ηM < ∞, it further follows that there is a constant M < ∞ such that
max

z∈SI (0,ηM )

|mµ1 ⊞µ2 (z)| ≤ M .

(3.9)

Lemma 3.2. Let µ1 , µ2 be two compactly supported probability measures on R satisfying (3.7), for some L < ∞, and assume that both are supported at more than one point. Let
I ⊂ Bµ1 ⊞µ2 be a compact non-empty interval. Then there is a constant K < ∞ such that

K
K
,
max |ω2 (z)| ≤
.
(3.10)
2
z∈SI (0,ηM )
2
z∈SI (0,ηM )
The constant K depends on the constant ηM and on the interval I as well as on the measures
µ1 , µ2 through the constants κ0 in (3.8) and the constant L in (3.7).
max

|ω1 (z)| ≤

Proof. We start by noticing that there is a constant κ1 > 0 such that
Z
Z
η fµ1 ⊞µ2 (x)dx
η d(µ1 ⊞ µ2 )(x)
≥
≥ κ1 ,
Im mµ1 ⊞µ2 (z) =
2
2
2
2
I (x − E) + η
R (x − E) + η

(3.11)

uniformly in z = E + iη ∈ SI (0, ηM ), where we used (3.8). Thus by subordination we have

Z

dµ1 (a) 
≥ κ1 ,
(3.12)
min 
min |mµ1 ⊞µ2 (z)| =
a − ω2 (z) 
z∈SI (0,ηM )
z∈SI (0,ηM )
R

since mµ1 ⊞µ2 (z) = −1/Fµ1 ⊞µ2 (z) by (2.6).
On the other hand, µ1 is supported on the interval [−L, L]; see (3.7). Hence, using (3.12),
|ω2 (z)| must be bounded from above on SI (0, ηM ). Interchanging the rôles of the indices 1
and 2, we also get that |ω1 (z)| is bounded from above on SI (0, ηM ).


11

Having established upper bounds on the subordination functions, we show that their
imaginary parts are uniformly bounded from below on the domain SI (0, ηM ). The proof
relies on inequality (3.1).
Lemma 3.3. Let µ1 , µ2 be two probability measures on R satisfying (3.7), for some L < ∞,
and assume that neither of them is only supported at a single point. Let I ⊂ Bµ1 ⊞µ2 be a
compact non-empty interval. Then there is a strictly positive constant k > 0 such that
min

z∈SI (0,ηM )

Im ω1 (z) ≥ 2k ,

min

z∈SI (0,ηM )

Im ω2 (z) ≥ 2k .

(3.13)

Remark 3.1. The constant k in (3.13) depends on the interval I through the constants κ0
in (3.8) and M in (3.9). It further depends on ηM , as well as on σ(µ1 , K2 ) and σ(µ2 , K1 )
in (3.1), with
Ki = {u ∈ C+ : u = ωi (z) , z ∈ SI (0, ηM )} ,

i = 1, 2 .

(3.14)

Proof of Lemma 3.3. First note that there is κ1 > 0 such that Im mµ1 ⊞µ2 (z) ≥ κ1 for all
z ∈ SI (0, ηM ); c.f., (3.11). Moreover, there is M < ∞ such that |mµ1 ⊞µ2 (z)| ≤ M for all
z ∈ SI (0, ηM ); c.f., (3.9). Recall from (2.5) and (2.6) that
ω1 (z) + ω2 (z) = z −

1

mµ1 ⊞µ2 (z)

,

z ∈ C+ .

(3.15)

Hence, considering the imaginary part, we notice from (3.9) that there is κ2 > 0 such that
min

z∈SI (0,ηM )

(Im ω1 (z) + Im ω2 (z)) ≥ κ2 .

(3.16)

It remains to show that Im ω1 and Im ω2 are separately bounded from below. To do so we
invoke (3.1) and assume by contradiction that Im ω1 (z) ≤ ǫ, for some small 0 ≤ ǫ < κ2 /2.
We must thus have Im ω2 (z) ≥ κ2 /2. Since µ1 is assumed not to be a single point mass,
Lemma 3.1 assures that
Im ω2 (z)
,
z ∈ SI (0, ηM ) ,
(3.17)
Im Fµ1 (ω2 (z)) ≥
1 − σ(µ1 , K2 )
with 0 < σ(µ1 , K2 ) < 1, where K2 denotes the image of SI (0, ηM ) under the map ω2 (which
is necessarily compact by Lemma 3.2). On the other hand, (2.11) implies
Im Fµ1 (ω2 (z)) = Im ω2 (z) + Im ω1 (z) − Im z ,

z ∈ C+ .

(3.18)

Since Im ω1 (z) ≥ Im z, by Proposition 2.1, we get, by comparing (3.18) and (3.17), a contradiction with the assumption that Im ω1 (z) ≤ ǫ, for sufficiently small ǫ. Repeating the
argument with the rôles of the indices 1 and 2 interchanged, we get (3.13).

3.2. Linear stability of (2.11). Having established lower and upper bounds on the subordination functions ω1 , ω2 , we now turn to the stability of the system Φµ1 ,µ2 (ω1 , ω2 , z) = 0.
Remember that we call the system linearly S-stable at (ω1 , ω2 ) if Γµ1 ,µ2 (ω1 , ω2 ) ≤ S,
where Γµ1 ,µ2 is defined in (2.12).
Lemma 3.4. Let µ1 , µ2 be two probability measures on R satisfying (3.7) for some L < ∞.
Assume that neither of them is a single point mass and that at least one of them is supported
at more than two points. Let I ⊂ Bµ1 ⊞µ2 be a compact non-empty interval.
Then, there is a finite constant S such that
max

z∈SI (0,ηM )

Γµ1 ,µ2 (ω1 (z), ω2 (z)) ≤ S ,

(3.19)

12

and
max

z∈SI (0,ηM )

|ω1′ (z)| ≤ 2S ,

max

z∈SI (0,ηM )

|ω2′ (z)| ≤ 2S ,

(3.20)

where ω1 (z), ω2 (z) are the solutions to Φµ1 ,µ2 (ω1 , ω2 , z) = 0.
Remark 3.2. Lemma 3.4 is the first instance where we use that at least one of µ1 and µ2
is supported at more than two points. For definiteness, we assume that µ1 is supported
at more than two points. The constant S in (3.19) depends on the interval I through the
constant κ0 in (3.8), on the constants ηM , L in (3.7), σ(µ1 , K2 ) and σ(µ2 , K2 ), as well as on
σ
e(µ1 , K2 ) of (3.2) with K2 defined in (3.14).
Proof of Lemma 3.4. Using (2.12) and Cramer’s rule, Γ ≡ Γµ1 ,µ2 (ω1 , ω2 , z) equals


1
−1

Γ = 
′
′
′

1 − (Fµ1 (ω2 ) − 1)(Fµ2 (ω1 ) − 1)  −Fµ2 (ω1 (z)) + 1

−Fµ′ 1 (ω2 (z)) + 1
−1



.


(3.21)

As above, we assume for definiteness that µ1 is supported at more than two points. We first
focus on Fµ′ 1 (ω2 ). Recalling the definition of K2 from Remark 3.1 and invoking (3.2), we
obtain
 Im Fµ1 (ω2 (z)) − Im ω2 (z)
,
(3.22)
e(µ1 , K2 )
|Fµ′ 1 (ω2 (z)) − 1| ≤ 1 − σ
Im ω2 (z)
for all z ∈ SI (0, ηM ), where 0 < σ
e (µ1 , K2 ) < 1. Abbreviating σ
e ≡ σ
e(µ1 , K2 ) and using
Φµ1 ,µ2 (ω1 (z), ω2 (z), z) = 0, we thus have
e)
|Fµ′ 1 (ω2 (z)) − 1| ≤ (1 − σ

Im ω1 (z)
,
Im ω2 (z)

z ∈ SI (0, ηM ) .

(3.23)

z ∈ C+ ,

(3.24)

Reasoning in the similar way (c.f., (4.9)), we also obtain
|Fµ′ 2 (ω1 (z)) − 1| ≤

Im ω2 (z)
,
Im ω1 (z)

where the inequality may saturate here since we do not exclude µ2 being supported at two
points only. Multiplying (3.23) and (3.24), we get
max

z∈SI (0,ηM )

e.
|Fµ′ 1 (ω2 (z)) − 1| |Fµ′ 2 (ω1 (z)) − 1| ≤ 1 − σ

(3.25)

Using Lemma 3.2 and Lemma 3.3, we also have from (3.23) and (3.24) that
max

z∈SI (0,ηM )

|Fµ′ i (ωj (z)) − 1| ≤

K
,
4k

{i, j} = {1, 2} .

(3.26)

Hence, bounding the operator norm by the Hilbert-Schmidt norm in (3.21), we obtain
by (3.26) and (3.25) that
√ 
 K 2 1/2
2
max Γµ1 ,µ2 (ω1 (z), ω2 (z)) ≤
1+
=: S ,
(3.27)
z∈SI (0,ηM )
σ
e
4k

with finite constant S. This proves (3.19).
The estimates in (3.20) follow by differentiating the equation Φµ1 ,µ2 (ω1 (z), ω2 (z), z) = 0
with respect to z. We get
 ′

 

−1
Fµ′ 1 (ω2 (z)) − 1
ω1 (z)
1
=
.
(3.28)
−1
Fµ′ 2 (ω1 (z)) − 1
ω2′ (z)
1
From (3.19) we know that Φ is uniformly S-stable and we get (3.20) by inverting (3.28). 

13

Remark 3.3. The crucial estimate in the proof above is (3.25). An alternative proof of (3.25)
under the assumptions that both µ1 and µ2 are supported at more than two points was
pointed out by an anonymous referee. From (2.5) we observe that the subordination function ω1 (z) appears, for fixed z ∈ C+ , as the fixed point of the map Fz : C+ → C+ ,
u 7→ Fz (u) := Fµ1 (Fµ2 (u) − u + z) − Fµ2 (u) − u + z .

(3.29)

+

Indeed, assuming that ω1 ∈ C and that µ1 , µ2 are supported at least at three points
(so that Fµ1 (z) − z and Fµ2 (z) − z are not Möbius transformations), the fixed point ω1 (z)
is attracting as was shown in [4]. Thus, for any fixed k > 0, the Schwarz–Pick Theorem
b of {z ∈ C+ ∪ R : Im ω1 (z), Im ω2 (z) ≥ 2k}
and (2.5) imply that for any compact subset K
b < 1 such that |F ′ (ω2 (z) − 1||F ′ (ω1 (z) − 1| ≤ σ
b < 1, for any
there is a constant σ
b(K)
b(K)
1
2
b
z ∈ K. Thus, under the assumption that µ1 and µ2 are both supported at least at three
points, (3.25) follows from Lemma 3.2 and Lemma 3.3.
Collecting the results of this section, we obtain the proof of Theorem 2.5.

Proof of Theorem 2.5. Lemma 3.3 proves (2.14). Lemma 3.4 proves (2.15).



4. Perturbations of the system (2.11)
In this section, we study perturbations of the system Φµ1 ,µ2 (ω1 , ω2 , z) = 0, where µ1 ,
µ2 denote general compactly supported probability measures on R. The main results of
this section, Proposition 4.1 below, is used repeatedly in the continuity argument to prove
Theorem 2.8. Yet, as noted in Corollary 2.6, it is of interest itself and it is also used in [3].
Proposition 4.1. Fix z0 ∈ C+ . Assume that the functions ω
e1 , ω
e2 , re1 , re2 : C+ → C satisfy
Im ω
e1 (z0 ) > 0, Im ω
e2 (z0 ) > 0 and
ω1 (z0 ), ω
e2 (z0 ), z0 ) = re(z0 ) ,
Φµ1 ,µ2 (e

(4.1)

where re(z) := (e
r1 (z), re2 (z))⊤ . Assume moreover that there is δ ∈ [0, 1] such that
|e
ω1 (z0 ) − ω1 (z0 )| ≤ δ ,

|e
ω2 (z0 ) − ω2 (z0 )| ≤ δ ,

(4.2)

where ω1 (z), ω2 (z) solve the unperturbed system Φµ1 ,µ2 (ω1 , ω2 , z) = 0. Assume that there
is a constant S such that Φ is linearly S-stable at (ω1 (z0 ), ω2 (z0 )), and assume in addition
that there are strictly positive constants K and k with k > δ and with k 2 > δKS such that
0 < 2k ≤ Im ω1 (z0 ) ≤ K ,

0 < 2k ≤ Im ω2 (z0 ) ≤ K .

Then we have the bounds

|e
ω1 (z0 ) − ω1 (z0 )| ≤ 2Ske
r(z0 )k ,

|e
ω2 (z0 ) − ω2 (z0 )| ≤ 2Ske
r(z0 )k .

(4.3)
(4.4)

Proof. Combining (4.3) and (4.2) with δ < k, we get
Im ω
e1 (z0 ) ≥ k ,

Im ω
e2 (z0 ) ≥ k .

(4.5)

Next, we bound higher derivatives of Fi ≡ Fµi , i = 1, 2. We first note that by the Nevanlinna
representation (3.3) we have
Z
Im Fi (ω)
1 + x2
ω ∈ C+ ,
i = 1, 2 .
(4.6)
dρFi (x) ,
=1+
2
Im ω
R |x − ω|
On the other hand, we also have from (3.3) that
Z
1 + x2
dρFi (x) ,
|Fi′ (ω) − 1| ≤
2
R |x − ω|

ω ∈ C+ ,

i = 1, 2 ,

(4.7)

14

and analogously for higher derivatives, n ≥ 1,
Z
Z
1 + x2
1
1 + x2
(n)
|Fi (ω)| ≤
(x)
≤
dρ
dρFi (x) ,
Fi
n+1
n−1
2
(Im ω)
R |x − ω|
R |x − ω|

(4.8)

ω ∈ C+ , i = 1, 2. Thus, combining (4.7), (4.6) and (2.11) we get
|Fi′ (ωj (z)) − 1| ≤

Im ωi (z) − Im z
Im Fi (ωj (z)) − Im ωj (z)
=
,
Im ωj (z)
Im ωj (z)

{i, j} = {1, 2} , (4.9)

z ∈ C+ , and similarly, starting from (4.8),
(n)

|Fi

(ωj (z))| ≤

Im ωi (z) − Im z
,
(Im ωj (z))n

z ∈ C+ ,

{i, j} = {1, 2} .

(4.10)

Let Ωi (z) := ω
ei (z) − ωi (z), i = 1, 2, and Ω := (Ω1 , Ω2 )⊤ . Fixing z = z0 and Taylor
expanding F1 (e
ω2 (z0 )) around ω2 (z0 ) we get
X 1 (n)
F1′ (ω2 (z0 ))Ω2 (z0 ) − Ω1 (z0 ) − Ω2 (z0 ) = re1 (z) −
F (ω2 (z0 ))Ω2 (z0 )n .
(4.11)
n! 1
n≥2

Recalling that kΩ(z0 )k/2k ≤ δ/k < 1 and using (4.10) together with (4.3), we obtain
from (4.11) the estimate

K
kΩ(z0 )k2 ,
(4.12)
4k 2
and the analogous expansion with the rôles of the indices 1 and 2 interchanged. We therefore
obtain from (2.12) and from solving the linearized equation that
|F1′ (ω2 (z0 ))Ω2 (z0 ) − Ω1 (z0 ) − Ω2 (z0 )| ≤ ke
r(z0 )k +

KS
kΩ(z0 )k2 .
(4.13)
4k 2
Thus, we have the dichotomy that either kΩ(z0 )k ≤ 2S ke
r k or 2(KS)−1 k 2 ≤ kΩ(z0 )k. Since
2
k > δKS by assumption, the second alternative contradicts kΩ(z0 )k ≤ 2δ. This proves the

estimates in (4.4).
kΩ(z0 )k ≤ Ske
r(z0 )k +

ωi − ωi | ≤ δ; see (4.2). The next lemma
In Proposition 4.1 we assumed the apriori bound |e
shows that we may drop this assumption, for spectral parameters z with sufficiently large
imaginary part, at the price of assuming effective lower bounds on Im ω
ei . This statement
will be used as an initial input to start the continuity argument in Section 6.
Lemma 4.2. Assume there is a (large) ηe0 > 0 such that for any z ∈ C+ with Im z ≥ ηe0 the
analytic functions ω
e1 , ω
e2 , re1 , re2 : C+ → C satisfy
and

Im ω
e1 (z) − Im z ≥ 2ke
r(z)k ,

Im ω
e2 (z) − Im z ≥ 2ke
r(z)k .

ω1 (z), ω
e2 (z), z) = re(z) ,
Φµ1 ,µ2 (e

where re(z) := (e
r1 (z), re2 (z))⊤ .
Then there is a constant η0 > 0, with η0 ≥ ηe0 , such that
|e
ω1 (z) − ω1 (z)| ≤ 2ke
r(z)k ,

|e
ω2 (z) − ω2 (z)| ≤ 2ke
r(z)k ,

(4.14)

(4.15)

(4.16)

on the domain {z ∈ C+ : Im z ≥ η0 }, where ω1 and ω2 are the subordination functions
associated with µ1 and µ2 . The constant η0 depends on the measures µ1 and µ2 , and on the
function re through the constant ηe0 > 0.

15

Proof. Recall the Nevanlinna representation (3.3) for Fµ1 and Fµ2 . Since µ1 and µ2 are
compactly supported, we have, as Im ω ր ∞,
Fµ2 (ω) − ω = a2 + O(|ω|−1 ) ,

(4.17)

with a1 ≡ aFµ1 and a2 ≡ aFµ2 . There are thus se1 , se2 : C+ → C such that

 

a1 + se1 (z) − ω
e1 (z) + z
re1 (z)
ω1 (z), ω
e2 (z), z) =
Φµ1 ,µ2 (e
=
,
a2 + se2 (z) − ω
e2 (z) + z
re2 (z)

(4.18)

Fµ1 (ω) − ω = a1 + O(|ω|−1 ) ,

with

se1 (z) = O(|e
ω2 (z)|−1 ) ,

se2 (z) = O(|e
ω1 (z)|−1 ) ,

(4.19)

as Im z ր ∞. It follows immediately that ω
e1 (z) = O(Im z) and ω
e2 (z) = O(Im z), as
Im z ր ∞. Thus, recalling the definition of Γµ1 ,µ2 in (2.12), we get
ω1 (z), ω
e2 (z)) = 1 + O(η −2 ) ,
Γµ1 ,µ2 (e

(4.20)

as η = Im z ր ∞. In particular, we obtain

ω1 (z), ω
e2 (z))kkΦ(e
ω1 (z), ω
e2 (z), z)k
k((DΦ)−1 Φ)(e
ω1 (z), ω
e2 (z), z)k ≤ kΓµ1 ,µ2 (e
≤ 2ke
r(z)k ,

(4.21)

for Im z sufficiently large. From (4.8) and (4.17), we also get
(ω)| ≤
|Fµ(2)
i

Im Fµi (ω) − Im ω
= O((Im ω)−3 ) ,
(Im ω)2

ω ∈ C+ ,

i = 1, 2 ,

(4.22)

as Im ω ր ∞. Thus the matrix of second derivatives of Φ given by
!

 2
(2)
∂2Φ
∂ Φ
0
Fµ1 (ω2 )
2
,
(ω1 , ω2 , z) ,
(ω1 , ω2 , z) =
D Φ(ω1 , ω2 ) :=
(2)
∂ω12
∂ω22
0
Fµ2 (ω1 )
satisfies kD2 Φ(e
ω1 (z), ω
e2 (z))k = O(Im z)−3 , as Im z ր ∞. Hence, choosing η0 > 0 sufficiently
large, we achieve that
r(z)k kD2 Φ(e
ω1 (z), ω
e2 (z))k <
s0 := 2ke

1
,
2

on the domain {z ∈ C+ : Im z ≥ η0 }. Thus, by the Newton-Kantorovich theorem
(see, e.g., Theorem 1 in [25]), there are for every such z unique ω
b1 (z), ω
b2 (z) such that
ω1 (z), ω
b2 (z), z) = 0, with
Φµ1 ,µ2 (b
√
1 − 1 − 2s0
ke
r(z)k ≤ 2ke
r(z)k ,
i = 1, 2 .
(4.23)
|e
ωi (z) − ω
bi (z)| ≤
s0

Finally, we note that Im ω
b1 (z) = Im ω
b1 (z)−Im ω
e1 (z)+Im ω
e1 ≥ Im z, by (4.14), for Im z ≥ η0 .
ω1 (z), ω
b2 (z)) 6= 0,
Similarly, Im ω
b2 (z) ≥ Im z, for Im z ≥ η0 . It further follows that Γµ1 ,µ2 (b
for all z ∈ C+ with Im z ≥ η0 , thus ω
b1 (z) and ω
b2 (z) are analytic on {z ∈ C : Im z > η0 }
since Fµ1 and Fµ2 are. Finally, using (4.17) with ω = ω
b1 , ω = ω
b2 respectively, we see that
Im ω
b1 (iη)
Im ω
b1 (iη)
= lim
= 1.
ηր∞
ηր∞
iη
iη
lim

b1 (z), ω
b2 (z) agree with ω1 (z), ω2 (z) on
Thus, by the uniqueness claim in Proposition 2.1, ω

the domain {z ∈ C+ : Im z ≥ η0 }. This proves (4.16) from (4.23).

16

5. Proof of Theorem 2.7
In the setup of Theorem 2.7 we have two pairs of probability measures on R, µα , µβ and
µA , µB , where we consider µα , µβ as “reference” measures (in the sense that they satisfy
the assumptions of Theorem 2.7), while µA , µB are arbitrary. Under the assumptions of
Theorem 2.7 we can apply Theorem 2.5 with the choices µα = µ1 and µβ = µ2 .
Recall from (2.13) the definition of the domain SI (a, b), a ≤ b.

Lemma 5.1. Let µA , µB and µα , µβ be the probability measures from (2.24) and (2.25)
satisfying the assumptions of Theorem 2.7. Let ωA , ωB and ωα , ωβ denote the associated subordination functions by Proposition 2.1. Let I ⊂ Bµα ⊞µβ be a compact non-empty interval.
Fix 0 < ηM < ∞.
Then there are a (small) constant b0 > 0 and a (large) constant K1 < ∞, both depending
on the measures µα and µβ , on the interval I and on the constant ηM , such that whenever
dL (µA , µα ) + dL (µB , µβ ) ≤ b0 ,

holds, then

(5.1)

dL (µA , µα )
dL (µB , µβ )
+ K1
,
(Im ωβ (z))2
(Im ωα (z))2
dL (µB , µβ )
dL (µA , µα )
+ K1
,
|ωB (z) − ωβ (z)| ≤ K1
(Im ωβ (z))2
(Im ωα (z))2
|ωA (z) − ωα (z)| ≤ K1

(5.2)

hold uniformly on SI (0, ηM ). In particular, choosing b ≤ b0 sufficiently small and assuming
that dL (µA , µα ) + dL (µB , µβ ) ≤ b, we have,
max

|ωA (z)| ≤ K ,

z∈SI (0,ηM )

Im ωA (z) ≥ k ,

z∈SI (0,ηM )

z∈SI (0,ηM )

min

z∈SI (0,ηM )

max

|ωB (z)| ≤ K ,

(5.3)

min

Im ωB (z) ≥ k ,

(5.4)

where K and k are the constant from Lemma 3.2 and Lemma 3.3, respectively.
Remark 5.1. Armed with the conclusions of Theorem 2.5, our proof follows closely the arguments of [30]. We further remark that the main argument in the proof of Lemma 5.1 is different from the ones given in Section 4: it crucially relies on the global uniqueness of solutions
on the upper half plane for both systems, Φµα ,µβ (ωα , ωβ , z) = 0 and ΦµA ,µB (ωA , ωB , z) = 0,
asserted by Proposition 2.1.
Proof of Lemma 5.1. We first write the system Φµα ,µβ (ωα (z), ωβ (z), z) = 0 as
ΦµA ,µB (ωα (z), ωβ (z), z) = r(z) ,
with
r(z) ≡



rA (z)
rB (z)



:=



z ∈ C+ ,

FµA (ωβ (z)) − Fµα (ωβ (z))
FµB (ωα (z)) − Fµβ (ωα (z))



.

(5.5)

From Lemma 3.3, we know that the imaginary parts of the subordination functions ωα , ωβ
are uniformly bounded from below on SI (0, ηM ). Next, integration by parts reveals that for
any probability measures µ1 and µ2 ,


1
dL (µ1 , µ2 )
1+
,
z ∈ C+ ,
(5.6)
|mµ1 (z) − mµ2 (z)| ≤ c
Im z
Im z
with some numerical constant c; see, e.g., [31]. Thus,
|FµA (ωβ (z)) − Fµα (ωβ (z))| =

dL (µA , µα )
|mµA (ωβ (z))) − mµα (ωβ (z))|
,
≤C
|mµA (ωβ (z))mµα (ωβ (z))|
(Im ωβ (z))2

(5.7)

17

with a new constant C that depends on the lower bound of Im mµα (ωβ (z)) = Im mµα ⊞µβ (z)
which is strictly positive on SI (0, ηM ); c.f., (3.12). Here we used
Im mµA (ωβ (z)) ≥ Im mµα (ωβ (z)) − |Im mµA (ωβ (z)) − Im mµα (ωβ (z))| ≥

1
Im mµα (ωβ (z)) ,
2

as follows from (5.6) for small enough dL (µA , µα ) ≤ b0 . Repeating the argument with the
rôles of A and B interchanged, we arrive at
|rA (z)| ≤ C

dL (µA , µα )
,
(Im ωβ (z))2

|rB (z)| ≤ C

dL (µB , µβ )
,
(Im ωα (z))2

z ∈ SI (0, ηM ) ,

(5.8)

for some constant C. Recalling the definition of Γ in (2.12), we get for sufficiently small b0 ,
ΓµA ,µB (ωα , ωβ ) ≤ 2Γµα ,µβ (ωα , ωβ ) ≤ 2S ,

(5.9)

where S is from Lemma 3.4, and where we also use Lemma 3.3 and the assumption dL (µA , µα )+
dL (µB , µβ ) ≤ b0 . The Newton–Kantorovich theorem then implies (c.f., the proof of Lemma 4.2
for a similar application) that there are ω
bA (z), ω
bB (z) satisfying
and

ωA (z), ω
bB (z), z) = 0 ,
ΦµA ,µB (b

|ωα (z) − ω
bA (z)| ≤ 2kr(z)k ,

z ∈ SI (0, ηM ) ,

(5.10)

|ωβ (z) − ω
bB (z)| ≤ 2kr(z)k ,

(5.11)

z ∈ SI (0, ηM ). Invoking (5.8), (5.11) and Lemma 3.3, we see that ω
bA (z) ∈ C+ and ω
bB (z) ∈
+
C , for any z ∈ SI (0, ηM ) if b0 is sufficiently small. Yet, by the global uniqueness of solutions
bA (z) = ωA (z), ω
bB (z) = ωB (z), z ∈ C+ . Together
asserted in Proposition 2.1, we must have ω
with (5.11) and (5.8) this implies (5.2) and concludes the proof. Then, choosing b0 sufficiently
small, (5.3) and (5.4) are direct consequences of (5.2), Lemma 3.2 and Lemma 3.3.

With the aid of Lemma 3.4, we prove the stability of the system ΦµA ,µB (ωA , ωB , z) = 0.
Corollary 5.2. Under the assumptions of Lemma 5.1, there is a (small) constant b1 > 0,
depending on the measures µα and µβ , on the interval I and on the constant ηM , such that
dL (µA , µα ) + dL (µB , µβ ) ≤ b1

(5.12)

implies
max

z∈SI (0,ηM )

ΓµA ,µB (ωA (z), ωB (z)) ≤ 2S

(5.13)

and
max

z∈SI (0,ηM )

′
|ωA
(z)| ≤ 4S ,

max

z∈SI (0,ηM )

′
|ωB
(z)| ≤ 4S ,

(5.14)

where ωA (z), ωB (z) satisfy ΦµA ,µB (ωA (z), ωB (z), z) = 0 and S is the constant in Lemma 3.4.
Proof. Let Γ ≡ ΓµA ,µB (ωA (z), ωB (z)). Analogously to (3.21), we have


1
−1

Γ = 
′
′
′

1 − (FµA (ωB ) − 1)(FµB (ωA ) − 1)  −FµB (ωA (z)) + 1

−Fµ′ A (ωB (z)) + 1
−1



.


(5.15)

Using the bounds (5.3) and (5.4) for sufficiently small b1 , we follow, mutatis mutandis, the
proof of Lemma 3.4 to get (5.13). The estimates in (5.14) then follow as in Lemma 3.4. 
We are now ready to complete the proof of Theorem 2.7.

18

Proof of Theorem 2.7. Recall that mµA ⊞µB (z) = mµA (ωB (z)), z ∈ C+ . We first note that


dL (µA , µα )
1
|mµA (ωB (z)) − mµα (ωB (z))| ≤ C
1+
,
Im ωβ (z)
Im ωβ (z)
for some numerical constant C; c.f., (5.6). Thus using (5.4) we get
|mµA (ωB (z)) − mµα (ωB (z))| ≤ K2 k −2 dL (µA , µα ) ,

z ∈ SI (0, ηM ) ,

for some numerical constant K2 . Choosing b as in Lemma 5.1 and assuming that dL (µA , µα )+
dL (µA , µβ ) ≤ b, we get from (5.2) that
|mµα (ωB (z)) − mµα (ωβ (z))| ≤ K1 k −4 ((dL (µA , µα ) + dL (µA , µβ )) ,

Setting Z := K1 k

−4

+ K2 k

−2

z ∈ SI (0, ηM ) .

we thus obtain (2.22).



Remark 5.2. Note that under the assumptions of Theorem 2.7, we have, for dL (µA , µα ) +
dL (µA , µβ ) ≤ b, the bounds
κ1 /2 ≤ |mµA ⊞µB (z)| ≤ 1/k ,

(5.16)

uniformly on SI (0, ηM ) with κ1 > 0 from (3.12) and k > 0 from (5.4).
6. Proof of Theorem 2.8
Before we immerse into the details of the proof of Theorem 2.8, we outline how Theorem 2.5 and the local stability results of Section 4 in combination with concentration
estimates for the unitary groups lead to the local law in (2.28).
6.1. Outline of proof. We briefly outline of our proof when U is Haar distributed on U (N ).
Since we are interested in the tracial quantity mH of H = A + U BU ∗ , we may replace H
by the matrix
e := V AV ∗ + U BU ∗ ,
H

(6.1)

where V is another Haar unitary independent from U . By cyclicity of the trace we have mH =
mHe and we study mHe below. We emphasize that this replacement is a convenient technicality which is not essential to our proof.
Using the shorthand
e := V AV ∗ ,
A

we introduce the Green functions
e − z)−1 ,
G e(z) := (A
A

e := U BU ∗ ,
B

(6.2)

e − z)−1 ,
GBe (z) := (B

For a given N × N matrix Q, we introduce the function
fQ (z) := tr QGHe (z) ,

z ∈ C+ .

z ∈ C+ ,

(6.3)
(6.4)

e − z)−1 is the Green function of H.
e We define the approximate subordination
where GHe = (H
c
c
functions, ωA and ωB , by setting
c
ωA
(z) := z −

EfAe(z)
,
EmHe (z)

c
ωB
(z) := z −

EfBe (z)
,
EmHe (z)

z ∈ C+ ,

(6.5)

where the expectation E is with respect to both Haar unitaries U and V . From the identity
e − z)G e (z) = 1, z ∈ C+ , we then obtain the relation
(H
H
c
c
ωA
(z) + ωB
(z) − z = −

1

EmHe (z)

,

z ∈ C+ ,

(6.6)

19

reminiscent to (c.f., (2.5)–(2.6))
ωA (z) + ωB (z) − z = −

1
mA⊞B (z)

z ∈ C+ .

,

For the proof of Theorem 2.8, we decompose



mHe (z) − mA⊞B (z) = mHe (z) − EmHe (z) + EmHe (z) − mA⊞B (z) ,

(6.7)

where we abbreviate mA⊞B ≡ mµA ⊞µB . To control the fluctuation part, mHe (z) − EmHe (z),
we rely on the Gromov–Milman concentration inequality [26] for the unitary group; see (6.22)
below. To control the deterministic part, we first note that, by (6.6) and mA⊞B (z) =
c
mA (ωB ((z)), bounding |EmHe (z) − mA⊞B (z)| amounts to bounding |ωA
(z) − ωA (z)| and
c
c
c
|ωB (z) − ωB (z)|. We then show that ωA (z) and ωB (z) are both in the upper-half plane and
satisfy
c
c
(z), ωB
(z), z) = r(z) ,
ΦµA ,µB (ωA

z ∈ SI (ηm , ηM ) ,

(6.8)

for some small error r(z) ∈ C+ , i.e., we consider (6.8) as a perturbation of the system ΦµA ,µB (ωA (z), ωB (z), z) = 0; c.f., (2.10). The formal derivation of (6.8) goes back
to Pastur and Vasilchuk [33]. Using Proposition 4.1 (with rough a priori estimates on
c
c
|ωA
(z) − ωA (z)| and |ωB
(z) − ωB (z)| obtained from the continuity argument below) and
c
stability results of Theorem 2.5 and of Section 5, we then bound |ωA
(z) − ωA (z)| and
c
|ωB (z) − ωB (z)| in terms of r(z).
In sum, for fixed z ∈ C+ , our proof includes two parts: (i) estimation of the error r(z)
in (6.8) and (ii) concentration for mHe (z) around EmHe (z). Both parts rely on the estimates
c
c
EmHe (z) , ωA
(z) , ωB
(z) ∼ 1 ,

c
c
Im ωA
(z) , Im ωB
(z) & 1 ,

z ∈ SI (ηm , ηM ) .

(6.9)

e by averaging
Note that the quantities in (6.9) are obtained from the Green function of H
with respect to the Haar measure. Similar bounds for mA⊞B , ωA and ωB were obtained in
Section 5. These latter quantities are defined directly from µA and µB via Proposition 2.1
To establish (6.9), we use a similar continuity argument as was used for Wigner matrices
in [24]: For Im z = ηM sufficiently large, the estimates in (6.9) directly follow from definitions.
For z = E + iη, with E ∈ I fixed, we decrease η = ηM down to η = ηm in steps of size
O(N −5 ), where, at each step, we invoke parts (i) and (ii). However, a direct application of
the Gromov–Milman concentration inequality for part (i) does not allow to push η below
the mesoscopic scale η = N −1/2 . Indeed, the Gromov–Milman inequality is effective if
L2 /N = o(1), where L is the Lipschitz constant of mHe (z) with respect to the Haar unitary V .
p
p
It is roughly bounded by tr |GHe (z)|4 /N , which in turn is trivially bounded by 1/ N η 4 ,
giving
the η ≥ N −1/2+γ , γ > 0, threshold.
However, in reality, the random quantity
p
p
tr |GHe (z)|4 /N is typically of order 1/ N η 3 as follows by combining the deterministic
estimate tr |GHe (z)|4 ≤ η −3 Im mHe (z) with a probabilistic order one bound for Im mHe (z).
Our key novelty here is to capitalize on this latter information. We introduce a smooth
cutoff that regularizes mHe (z) and then apply the Gromov–Milman inequality for this regup
larized quantity. With the bound 1/ N η 3 for the Lipschitz constant, we get concentration
estimates down to scales η ≥ N −2/3+γ , γ > 0.
6.1.1. Notation. The following notation for high-probability estimates is suited for our purposes. A slightly different form was first used in [21].
Definition 6.1. Let
X = (X (N ) (v) : N ∈ N , v ∈ V (N ) ) ,

Y = (Y (N ) (v) : N ∈ N , v ∈ V (N ) )

(6.10)

20

be two families of nonnegative random variables where V (N ) is a possibly N -dependent parameter set. We say that Y stochastically dominates X, uniformly in v, if for all (small)
ǫ > 0 and (large) D > 0,

 [ 
(N )
ǫ (N )
X (v) > N Y
(v)
≤ N −D ,
(6.11)
P
v∈V (N )

for sufficiently large N ≥ N0 (ǫ, D). If Y stochastically dominates X, uniformly in v, we
write X ≺ Y . If we wish to indicate the set V (N ) explicitly, we write that X(v) ≺ Y (v) for
all v ∈ V (N ) .
6.2. Localized Gromov–Milman concentration estimate. In this subsection, we derive concentration bounds for some key tracial quantities. They are tailored for the continuity
argument of Subsection 6.3 used to complete the proof of Theorem 2.8. The argument works
with U , V independent and both Haar distributed on U (N ) or on O(N ). Below, E denotes
the expectation with respect Haar measure.
In the rest of this section, we let I ⊂ Bµα ⊞µβ denote the compact non-empty subset fixed
in Theorem 2.8. Also recall from Theorem 2.8 that we set ηm = N −2/3+γ , γ > 0. Below we
choose the constant ηM ∼ 1 to be sufficiently large at first, but from the proof it will be clear
that we can eventually choose 0 < ηM < ∞ arbitrary. Recall from (6.4) the notation fQ ,
where Q is an arbitrary N × N matrix.
Proposition 6.2. Let Q be a given N × N deterministic matrix with kQk . 1. Fix E ∈ I
and ηb ∈ [ηm , ηM ]. Then
Im mHe (E + iη) ≺ 1 ,

∀η ∈ [b
η , ηM ] ,

(6.12)

implies the concentration bound
1
.
η )| ≺ p
η ) − EfV QV ∗ (E + ib
|fV QV ∗ (E + ib
N 2 ηb3

(6.13)

The same concentration holds with V QV ∗ replaced by U QU ∗ .

Proof. For fixed E ∈ I, we consider z = E + iη ∈ C+ as a varying spectral parameter and
use zb = E + ib
η for the specific choice in the lemma. By the definition of f(·) and cyclicity of
the trace, we have
−1
−1
= tr Q A + V ∗ U BU ∗ V − z
,
(6.14)
fV QV ∗ (z) = tr V QV ∗ V AV ∗ + U BU ∗ − z
where tr ( · ) stands for the normalized trace. For simplicity, we denote
W := V ∗ U,

H := A + W BW ∗ ,

GH (z) := (H − z)−1 .

(6.15)

Observe that W is Haar distributed on U (N ), respectively O(N ), too. By cyclicity of the
trace we have tr GH (z) = tr GH (z) = mH (z). According to (6.14) and (6.15), we may regard
in the sequel fV QV ∗ as a function of the Haar unitary matrix W by writing
h(z) = hW (z) := fV QV ∗ (z) .
For any fixed (small) ε > 0, let χ
b be a smooth cutoff supported on [0, 2N ε ], with χ
b(x) = 1,
ε
x ∈ [0, N ], and with bounded derivatives. Since mH (z) = tr GH (z), we can regard mH (z)
as a function of W and write
χ(z) = χW (z) := χ
b(Im mH (z)) .

(6.16)

21

We then introduce a regularization, e
hW , of hW by setting
⌈− log2 η⌉

Y

e
h(z) = e
hW (z) := hW (z)

χW (E + i2n η) .

(6.17)

n=0

We will often drop the W subscript from the notations hW (z), e
hW (z) and χW (z) but
remember that these are random variables depending on the Haar unitary W .
We will use assumption (6.12) at dyadic points, i.e., that
Im mH (E + i2l ηb) ≺ 1 ,

0 ≤ l ≤ ⌈− log2 ηb⌉ ,

(6.18)

(recall that mH (z) = mHe (z) so we may drop the tilde in the subscript of m). Hence,
by (6.16) and (6.18) we see that, for arbitrary large D > 0,
⌈− log2 η
b⌉

Y

l=0

χ(E + i2l ηb) = 1 ,

i.e.,

e
h(b
z ) = h(b
z) ,

(6.19)

with probability larger than 1 − N −D , for N sufficiently large (depending on ε and D).
Taking the trivial bound kQk/b
η for h(b
z ) and for e
h(b
z ) into account, we also have

(6.20)
Ee
h(b
z ) − E h(b
z ) = O N −D+1 .

To prove (6.13), it therefore suffices to establish the concentration estimate


1
e

,
z ) − Ee
h(b
z ) ≺ p
h(b
N 2 ηb3

(6.21)

for the regularized quantity e
h(b
z ).
To verify (6.21), we use the Gromov–Milman concentration inequality [26] (see Theorem 4.4.27 in [2] for similar applications) which states the following. Let M(N ) = SO(N )
or SU(N ) endowed with the Riemann metric kdsk2 inherited from MN (C) (equipped with
the Hilbert-Schmidt norm). If g : (M(N ), kdsk2 ) → R is an L-Lipschitz function satisfying
Eg = 0, then
P (|g| > δ) ≤ e−c

N δ2
L2

,

∀δ > 0,

(6.22)

with some numerical constant c > 0 (depending only on the symmetry type and not on N ).
Here P and E are with respect Haar measure on M(N ).
hW (b
z) = e
h(b
z ), we need to control its
In order to apply (6.22) to the function W 7→ e
Lipschitz constant. To that end, we define the event
	

(6.23)
Ω(b
η ) ≡ ΩE (b
η ) := Im mH (E + i2n ηb) ≤ 2N ε : ∀n ∈ N0 .

To bound the Lipschitz constant, we need to bound quantities of the form tr |GH (b
z )|k restricted to the event Ω(b
η ). Let (λi (H)) denote the eigenvalues of H and introduce
In := [E − 2n ηb, E + 2n ηb] ∩ I ,

Nn := |{i : λi (H) ∈ In }| ,

n ∈ N0 .

Since H and H are unitarily equivalent, their empirical eigenvalue distributions are the
same, µH ; c.f., (2.29). Using the definition of the Stieltjes transform we have, for all n ∈ N0 ,
the estimate
Z E+2n ηb
Z
ηb dµH (x)
3
n+1
≤ 3N · 2n ηb Im mH (b
z) .
ηb
dµH ≤ N · 2
Nn = N
2
(x
− E)2 + ηb2
n
E−2 η
b
In
Thus we have on the event Ω(b
η ) that

Nn . 2n N 1+ε ηb ,

∀n ∈ N0 .

(6.24)

22

By the spectral theorem, we can bound
N
1
1 X
.
N i=1 |λi (H) − E| + ηb

tr |GH (b
z )| .

(6.25)

Then we observe (with the convention I−1 = ∅) that

N
N ∞
1 X
1
1 XX
1
=
1(λi ∈ In \ In−1 )
N i=1 |λi (H) − E| + ηb
N i=1 n=0
|λi (H) − E| + ηb

1
=
N

⌈c log N ⌉

X

n=0

X

λi ∈In \In−1

1
,
|λi (H) − E| + ηb

where we used kHk ≤ C to truncate the sum over n at ⌈c log N ⌉. We then bound
1(Ω(b
η ))

1
N

⌈c log N ⌉

X

n=0

X

λi ∈In \In−1

1
1
≤ 1(Ω(b
η ))
|λi (H) − E| + ηb
N

⌈c log N ⌉

X

n=0

where we used (6.24), i.e., with (6.25) we arrive at

Nn
. N ε log N ,
2n ηb

1(Ω(b
η ))tr |GH (b
z )| . N ε log N .

(6.26)

Using the spectral decomposition of H we see that
tr |GH (b
z )|2 =

N
N
1
ηb
1 X
Im mH (b
z)
1 X
=
=
, (6.27)
N i=1 |λi (H) − E|2 + ηb2
N ηb i=1 |λi (H) − E|2 + ηb2
ηb

where we also used that tr GH (b
z ) = tr GH (b
z ) = mH (b
z ). Thus, we bound
1(Ω(b
η ))tr |GH (b
z )|k ≤ 1(Ω(b
η ))b
η −k+1 Im mH (b
z ) . N ε ηb−k+1 ,

∀k ≥ 2 .

(6.28)

Having established (6.26) and (6.28), we proceed to estimate the Lipschitz constant of e
h(b
z)
as a function of W . Let su(N ) and so(N ) denote the (fundamental representations in MN (C)
of the) Lie algebras of SU (N ) and SO(N ) respectively. Let m stand for either su(N ) or
so(N ). Note that X ∈ m satisfies X ∗ = −X. Since SU (N ) and SO(N ) are matrix groups
the Lie bracket of su(N ) and so(N ) respectively is given by the commutator in the matrix
algebras. For fixed X ∈ MN (C), we let adX : MN (C) → MN (C), Y 7→ adX (Y ) :=
XY − Y X. For X ∈ m and t ∈ R, we may write etadX (W BW ∗ ) = (etX W )B(etX W )∗ , where
we used that X ∗ = −X. Further note that
d tadX
(6.29)
(W BW ∗ ) = etadX adX (W BW ∗ ) .
e
dt
For X ∈ m with kXk2 = 1, we let
−1

GH (z, tX) := A + etadX (W BW ∗ ) − z
,
t ∈ R,

and denote accordingly

mH (z, tX) := tr GH (z, tX) ,

χ(z, tX) := χ
b(Im mH (z, tX)) ,
⌈− log2 η
b⌉

e
h(z, tX) := tr QGH (z, tX)

with χ(z, 0) ≡ χ(z), e
h(z, 0) ≡ e
h(0), etc.

Y
l=0

χ(E + i2l η, tX) ,

23

Evaluating the derivative of e
h(b
z , tX) with respect to t at t = 0 we get
log2 η
b⌉


 ⌈− Y
∂e

∗
h(b
z , tX)
= − tr QGH (b
z )adX (W BW )GH (b
z)
χ(E + i2l ηb)
∂t
t=0
l=0

 ⌈− X
log2 η
b⌉ h ⌈− log2 η
i
Y b⌉

χ(E + i2l ηb) · φ(E + i2j ηb)
− tr QGH (b
z)
j=0

l=0
l6=j



j
∗
j
× Im tr GH (E + i2 ηb) adX (W BW )GH (E + i2 ηb)
,
′

(6.30)

′

where we used (6.29) and where we introduced φ(z) := χ
b (Im mH (z)), with χ
b the derivative
b, we note the bounds
of χ
b. Recalling (6.16) and the definition of the cutoff χ
⌈− log2 η
⌈− log2 η
i
Y b⌉
X b⌉ h Y
l
χ(E + i2 ηb) ≤ 1 ,
χ(E + i2l ηb) · φ(E + i2j ηb) = O(log N ) . (6.31)
j=0

l=0

l6=j

On the event Ωc (b
η ), the complementary event to Ω(b
η ), we further have the identities
⌈− log2 η
b⌉
b⌉
⌈− log2 η
b⌉ h ⌈− log2 η
i
Y
Y
X
χ(E + i2l ηb) = 0 ,
χ(E + i2l ηb) · φ(E + i2j ηb) = 0 .
(6.32)
j=0

l=0

l=0
l6=j

η ). We bound the first term on the right side
It thus suffices to bound (6.30) on the event Ω(b
of (6.30) as
log2 η
b⌉
 

 ⌈− Y


∗
1(Ω(b
η ))tr QGH (b
z )adX (W BW ) GH (b
z)
χ(E + i2l ηb)
l=0

≤ 1(Ω(b
η ))

1
kadX (W BW ∗ )k2 kGH (b
z )QGH (b
z )k2
N

⌈− log2 η
b⌉

Y
l=0

χ(E + i2l ηb) ,

(6.33)

where we used cyclicity of the trace and Cauchy–Schwarz inequality. Next, note that
kadX (W BW ∗ )k2 ≤ 2kBkkXk2 ≤ 2kBk, where we used the definition of adX , kW k ≤ 1 and
kXk2 = 1. Similarly, we have kGH (b
z )QGH (b
z )k2 ≤ kQkkGH (b
z )G∗H (b
z )k2 . Thus from (6.33),
⌈−
log
η
b
⌉
 

 Y2


1(Ω(b
η ))tr QGH (b
z )adX (W BW ∗ ) GH (b
z)
χ(E + i2l ηb)
l=0

≤ 2kBkkQk1(Ω(b
η))


ε

 21



N
,
N ηb3
where we used (6.28) with k = 4 in the last step.
.

tr |GH (b
z )|4
N

 21

⌈− log2 η
b⌉

Y
l=0

χ(E + i2l ηb)

(6.34)

24

To handle the second term on the right side of (6.30), we use (6.31) and (6.26) to get
⌈− log η
b⌉ ⌈− log2 η

Y b⌉
 X2

χ(E + i2l ηb) · φ(E + i2j ηb)
1(Ω(b
η ))tr QGH (b
z)
j=0

l=0
l6=j




× Im tr GH (E + i2j ηb)adX (W BW ∗ ) GH (E + i2j ηb) 
b⌉
⌈− log2 η
b⌉ ⌈− log2 η

X

≤ 1(Ω(b
η ))kQktr |GH (b
z )|

× 2kBkkQk




j=0

Y
l=0
l6=j

tr |GH (E + i2j ηb)|4
N

χ(E + i2l ηb) |φ(E + i2l ηb)|

 12

1
N 4ε 2
.
.
(6.35)
N ηb3
Combining (6.35) and (6.34) we obtain, for any X ∈ su(N ) or so(N ) with kXk2 = 1, that

   N 4ε  21
∂
 
 e
h(b
z
,
tX)
,
(6.36)
 .
 ∂t
N ηb3
t=0
 4ε 1/2
N
i.e., the Lipschitz constant of e
h(b
z ) as a function of W is bounded by C N
, for some
η
b3

constant C depending only on kBk and kQk. Thus, taking
 4ε  21
p
N
,
δ = N 3ε / N 2 ηb3
g=e
h(z) − Ee
h(z) ,
L=C
3
N ηb
in (6.22), and choosing ε > 0 sufficiently small, we get (6.21). Together with (6.19) and (6.20)

this implies (6.13).

6.3. Continuity argument. In this subsection, we often omit z ∈ C+ from the notation.
Let U and V be independent and both Haar distributed on either U (N ) or O(N ). Recalling
the notation in Section 6.1, we set
∆A (z) := −(IE[mH (z)])GHe (z) − (IE[fBe (z)])GAe(z)GHe (z) ,

∆B (z) := −(IE[mH (z)])GHe (z) − (IE[fAe(z)])GBe (z)GHe (z) ,

z ∈ C+ ,

(6.37)

where we introduced IE X := X −EX, for any random variables X. Using the left-invariance
of Haar measure, one derives the identities
e e ] = E[AG
e e ⊗ Ge],
E[GHe ⊗ AG
H
H
H

e e ] = E[BG
e e ⊗ Ge];
E[GHe ⊗ BG
H
H
H

see Theorem 7 in [33] or Appendix A of [31] for proofs. Taking the partial trace for the first
component of the tensor products, we get
c
c
EGHe (z) = EGAe(ωB
(z)) + δA
(z) ,

c
δA
(z) :=

1
c
e − z)∆A (z)] ,
E[GAe(ωB
(z))(A
EmH (z)
(6.38)

c
where ωB
(z) is defined in (6.5), we used (6.6), and where we implicitly assumed that
c
Im ωB (z) > 0. This last assumption will be verified along the continuity argument. Then,
we set
c
tr δA
(z)
c
(6.39)
rA
(z) := −
c
c (z)) + tr δ c (z)) ,
tr GAe(ωB (z))(tr GAe(ωB
A

25
c
c
and define δB
(z) and rB
(z) in the same way by swapping the rôles of A and B. Usc
(z) > 0 and
ing (6.38), (6.6), we eventually obtain, under the assumption that Im ωA
c
Im ωB
(z) > 0,
c
c
(z), ωB
(z), z) = rc (z) ,
ΦµA ,µB (ωA
c

with r (z) =

z ∈ C+ ,

(6.40)

c
c
(rA
(z), rB
(z))⊤ .

Lemma 6.3. Fix E ∈ I and any ηb ∈ [ηm , ηM ]. Set the notation z = E + iη and zb = E + ib
η.
Suppose that
c
c
|ωA
(z) − ωA (z)| + |ωB
(z) − ωB (z)| ≤ N −γ ,

∀η = Im z ∈ [b
η , ηM ] .

Moreover, assume that for the event
n
Ξ(b
η ) ≡ ΞE (b
η ) := |mH (z) − mA⊞B (z)| ≤ N −γ : z = E + iη,
we have

∀η ∈ [b
η , ηM ]



P Ξ(b
η ) ≥ 1 − N −D 1 + N 5 (ηM − ηb) ,

(6.41)
o
(6.42)

for any D > 0 if N ≥ N1 (D).
Then, for any ǫ > 0, the estimates

Nǫ
,
N 2 ηb3
Nǫ
c
c
|ωA
(b
z ) − ωA (b
z )| + |ωB
(b
z ) − ωB (b
z )| ≤ 2 3 ,
N ηb
Nǫ
|EmH (b
z ) − mA⊞B (b
z )| ≤ 2 3 ,
N ηb
c
c
(b
z )| ≤
(b
z )| + |rB
|rA

hold for any N ≥ N2 (ǫ). Moreover, for any ǫ, D > 0, the event
n
Nǫ o
Θ(b
η ) ≡ ΘE (b
η ) := ΞE (b
η ) ∩ |mH (b
z ) − mA⊞B (b
z )| ≥ p
N 2 ηb3

satisfies


P Θ(b
η ) ≤ N −D ,

(6.43)
(6.44)
(6.45)

(6.46)

(6.47)

if N ≥ N3 (ǫ, D). The threshold functions N1 , N2 , N3 depend only on µα , µβ , the speed of
convergence in (2.25) and they are uniform in ηb ∈ [ηm , ηM ] and E ∈ I.
We postpone the proof of Lemma 6.3 and prove Theorem 2.8 first.

Proof of Theorem 2.8. We start with observing that it is sufficient to prove a version of (2.28)
where the real part of the spectral parameter E is fixed. This version asserts that there is a
large (N -independent) ηM , to be fixed below, such that for any (small) ǫ > 0 and (large) D,
and any fixed E ∈ I,



[


1
Nǫ
mH (z) − mµ ⊞µ (z) >
(6.48)
≤ D,
P
A
B
3/2
N
N (Im z)
z∈SE (ηm ,ηM )

holds for N ≥ N0 , i.e., the set SI (ηm , ηM ) in (2.28) is replaced with SE (ηm , ηM ) := {E + iη :
η ∈ [ηm , ηM ]}. The threshold N0 depends on ǫ, D, µα , µβ , I and on the speed of convergence
in (2.25).
Indeed, by introducing the discretized lattice version
SbI (a, b) := SI (a, b) ∩ N −5 {Z × iZ}

26

of the spectral domain SI (a, b) (c.f., (2.13)) and by taking a union bound, we see that (6.48)
implies



[


Nǫ
C


P
mH (z) − mµA ⊞µB (z) >
≤ D−5 .
(6.49)
3/2
N
N (Im z)
z∈SbI (ηm ,ηM )

Thanks to the Lipschitz continuity of the Stieltjes transforms mH (z) and mµA ⊞µB (z) with
Lipschitz constant η −2 = (Im z)−2 ≤ N 2 , for any Im z ≥ ηm , we see that (2.28) follows
from (6.49) after a small adjustment of ǫ and D that were anyway arbitrary.
From now on we fix E ∈ I and our goal is to prove (6.48). We will use Lemma 6.3. In
the first step we verify that the assumptions of this lemma hold for ηb = ηM , i.e., that (6.41)
and (6.42) hold for z = E + iηM . In the second step, we successively use Lemma 6.3 to
reduce ηb steps by steps of size N −5 until we have verified (6.41)–(6.42) down to ηb = ηm .
Then (6.48) will follow from a final application of Lemma 6.3 combined with discretization
argument similar to the one above, but this time the η variable instead of the E variable.
Step 1. Initial bound. First we note that since µA and µB are compactly supported, kHk
is deterministically bounded, we thus have Im mH (E +iηM ) ≤ (ηM )−1 ≤ 1 assuming ηM ≥ 1.
Following the main argument in the proof of Proposition 6.2, we have the concentration
inequality
1
|fV QV ∗ (E + iηM ) − EfV QV ∗ (E + iηM )| ≺ p
,
(6.50)
3
N 2 ηM
uniformly for any deterministic Q with kQk . 1. The analog concentration holds with V
replaced by U . Using (6.50) with Q = I (I the identity matrix), we have | IE[mH (E+iηM )]| ≺
N −1 . Hence, it suffices to show that
1
|EmH (E + iηM ) − mA⊞B (E + iηM )| ≺
.
(6.51)
N
c
c
Recalling the definitions of ωA
and ωB
in (6.5), we have, with z = E + iηM , the expansion
c
ωA
(z) = z −

e e (z)
eA
e + B)z
e −2
E trAG
tr Az −1 + E tr A(
H
+ O(z −2 ) ,
=z−
E tr GHe (z)
z −1

as ηM ր ∞. Thus using the assumption tr A = 0 we get
c
Im ωA
(E + iηM ) − Im ηM =



eBη
e M
tr A2 ηM + E tr A
1
,
+
O
2
|E + iηM |2
ηM

as ηM ր ∞. Next, since V and U are independent, we have

E tr V AV ∗ U BU ∗ = tr E[V AV ∗ ] E[U BU ∗ ] = tr A tr B = 0 ,

since tr A = tr B = 0 by assumption. Thus
c
Im ωA
(E + iηM ) − Im ηM =

tr A2 ηM
+O
|E + iηM |2



1
2
ηM



,

(6.52)

as ηM ր ∞. Since tr A2 > 0, we achieve by choosing ηM sufficiently large (but independent
of N ) that
1 tr A2 ηM
,
(6.53)
2 |E + iηM |2
and the analogue estimate holds with A replaced by B. In particular, we have, for such ηM ,
c
Im ωA
(E + iηM ) − Im ηM ≥

c
Im ωA
(E + iηM ) & 1 ,
c
c
and ωA
(E + iηM ) ∼ 1, ωB
(E + iηM ) ∼ 1.

c
Im ωB
(E + iηM ) & 1 ,

(6.54)

27

To show (6.51), we apply Lemma 4.2 to the system (6.40). Having established (6.53), it
suffices to show that
1
1
c
c
|rA
(E + iηM )| ≺
,
|rB
(E + iηM )| ≺
,
(6.55)
N
N
since then we have, for N sufficiently large and ηM as above that, for any fixed ε ∈ [0, 1),
Nε
1 tr A2 ηM
c
≤ Im ωA
(E + iηM ) − Im ηM ,
≤
N
2 |E + iηM |2

(6.56)

and similarly with B replacing A. In particular, combining (6.55) and (6.56), we see that
assumption (4.14) of Lemma 4.2 (with the choice re = rc ) is satisfied for N sufficiently large
(with high probability). Consequently, we see that (6.41) (even with N −1+ǫ instead of N −γ
in the latter) hold for z = E + iηM . Finally, the equations
EmH (z) =

1
z−

c (z)
ωA

−

c (z)
ωB

,

mA⊞B (z) =

1
,
z − ωA (z) − ωB (z)

(6.57)

together with the concentration estimate (6.50) yield (6.42).
−1
It remains to justify (6.55). Since iηM mH (E + iηM ) = O(ηM
), we have EmH (E + iηM ) ∼
c
c
(E + iηM )) ∼ 1.
1. In addition, from (6.54) it follows that mA (ωB (E + iηM )) ∼ 1 and mB (ωA
Recalling the definition in (6.39), we see that (6.55) is equivalent to
1
1
c
,
|tr δB
(E + iηM )| ≺
.
(6.58)
N
N
c
c
By the definitions of δA
, δB
in (6.38), and ∆A , ∆B in (6.37), it is easy to obtain (6.58) by
using (6.50) and Cauchy–Schwarz. This completes Step 1, i.e., the verification of (6.41)–
(6.42) for ηb = ηM .
Step 2. Induction. Recall that ωA , ωB and mA⊞B (see Lemma 5.1) are uniformly bounded
c
c
and ωA
(z), ωB
(z), mH (z), ωA (z), ωB (z) and mA⊞B (z) are Lipschitz continuous with a
Lipschitz constant bounded by (Im z)−2 ≤ N 2 , for any Im z ≥ ηm . Applying Lemma 6.3 to
conclude (6.44) with the choice ǫ = γ/10, we see that if (6.41) and (6.42) hold for some ηb,
then (6.41) also holds for ηb replaced with ηb − N −5 as long as ηb ≥ ηm . Moreover, by the
Lipschitz continuity of mH and mA⊞B , notice that
c
|tr δA
(E + iηM )| ≺

Ξ(b
η − N −5 ) ⊃ Ξ(b
η ) \ Θ(b
η) .

(6.59)

Thus, if (6.42) holds for some ηb, then (6.59) and (6.47) imply that (6.42) also holds for ηb
replaced with ηb − N −5 . Using Step 1 as an initial input with the choice ηb = ηM , and
applying the above induction argument O(N 5 ) times by reducing ηb with stepsize N −5 , we
see that (6.41) and (6.42) hold for all ηbk ∈ [ηm , ηM ] of the form ηbk = ηM − k · N −5 with some
integer k. Applying Lemma 6.3 once more for these ηbk , but now with an arbitrary ǫ > 0,
we conclude from (6.42) and (6.47) that
1
|mH (E + ib
ηk ) − mA⊞B (E + ib
ηk )| ≺ p
,
N 2 ηbk3

k = 0, 1, . . . , k0 ,

(6.60)

where k0 is the largest integer with ηbk0 ≥ ηm . The uniformity of (6.60) in k follows from the
fact that the threshold functions Nj in Lemma 6.3 are independent of ηb. Clearly k0 = O(N 5 ),
so taking a union bound of (6.60), compensating the combinatorial factor CN 5 by replacing
D by D−5, and slightly adjusting ǫ to extend the control from the set {z = E+ib
ηk : k ≤ k0 }

to all z ∈ SE (ηm , ηM ), we obtain (6.48).
It remains to prove Lemma 6.3.

28

Proof of Lemma 6.3. First we notice that E ∈ I and (2.25) imply that for all sufficiently
large N , the bounds (5.3)-(5.4) hold. Together with (6.41) they imply that
c
c
ωA
(b
z ) , ωB
(b
z) ∼ 1 ,

c
c
Im ωA
(b
z ) , Im ωB
(b
z) & 1 ,

(6.61)

moreover, using (6.6) we also get
1
. 1.
(6.62)
EmH (b
z)
c
We start with (6.43). Thanks to symmetry, we only need to estimate |rA
(b
z )|. By (6.61)
we have
c
ωB
(b
z)

c
c
kGAe(ωB
(b
z ))k = kGA (ωB
(b
z ))k . 1 .
c
Im ωB
(b
z)

(6.63)

c
mA (ωB
(b
z ))

Furthermore,
∼ 1 and
& 1 imply
∼ 1.
We next claim that
 

Nǫ

c
(b
z ))(Ae − zb)∆A (b
z)  ≤ 2 3 ,
E tr GAe(ωB
N ηb

(6.64)

for any ǫ > 0 if N ≥ N0 (ǫ) is large enough, uniformly for ηb ∈ [ηm , ηM ]. Assuming (6.64) and
c
c
recalling the definition of δA
and rA
in (6.38)-(6.39), from (6.62) we get the first estimate
in (6.43).
Next, we prove (6.64). By the definitions in (6.37), we have
h
h
i
i
c
c
E tr GAe(ωB
(b
z ))(Ae − zb)∆A (b
z ) = − E IE[mH (b
z )] tr GAe(ωB
(b
z ))(Ae − zb)GHe (b
z)
h
i
c
(6.65)
− E IE[fB (b
z )] tr GAe(ωB
(b
z ))GHe (b
z) .

We rewrite the two terms on the right side separately as covariances,



h
i
c
c
e − zb)G e (b
e z )G e (b
= Cov mH (b
z ), tr GAe(ωB
(b
z ))(A
,
E IE[mH (b
z )] tr GAe(ωB
(b
z ))(A−b
H z)
H z)

respectively,

h

i
c
c
z ), tr GAe(ωB
(b
z ))GHe (b
z) ,
E IE[fBe (b
z )]tr GAe(ωB
(b
z ))GHe (b
z ) = Cov fBe (b

where Cov(X, Y ) := E(IE[X] · IE[Y ]), for arbitrary random variables X and Y .
Given (6.42) and the uniform boundedness of mA⊞B (z) from (5.16), we see that (6.12)
is satisfied and we can apply Proposition 6.2 using different choices for Q. Together with
Cauchy–Schwarz inequality |Cov(X, Y )|2 ≤ E|IE[X]|2 · E|IE[Y ]|2 , we get



 
1


c
e − zb)G e (b
z ), tr GAe(ωB
(b
z ))(A
Cov mH (b
≺ 2 3,
H z)
N ηb

 
1

c
(6.66)
z ), tr GAe(ωB
(b
z ))GHe (b
z)  ≺ 2 3 .
Cov fBe (b
N ηb

c
More specifically, for the first line of (6.66), we chose Q = I and Q = GA (ωB
(b
z ))(A − zb);
c
for the second line we chose Q = B and Q = GA (ωB (b
z )), where we also used the facts
e = V AV ∗ and B
e = U BU ∗ . Here, we also implicitly used (6.63). Then, (6.64) follows
A
from (6.66), which in turn proves (6.43).
Next, using Proposition 4.1, (6.40) and (6.43) we immediately get (6.44). Moreover,
since Im ωA (z) , Im ωB (z) ≥ Im z, we have |z − ωA (z) − ωB (z)| ≥ Im ωB (z) & 1. Together
with (6.44) and (6.57) this implies (6.45). Notice that (6.42) together with the uniform bound
on mA⊞B imply the condition (6.12) in Proposition 6.2. Thus, finally (6.46) and (6.47)
follow from (6.45) and the concentration inequality (6.13). This completes the proof of

Lemma 6.3.

29

7. Two point mass case
In this section, we discuss stability properties of the free additive convolution µα ⊞ µβ
when both µα and µβ are convex combinations of two point masses. The analogous result
to Theorem 2.5 is given in Proposition 7.2 below. Applications of that result in the spirit of
Theorems 2.7 and 2.8 are then stated in Proposition 7.3 and Proposition 7.4. When we refer
to the results in Sections 2-4, we will henceforth regard µ1 and µ2 as µα and µβ , respectively,
unless specified otherwise.
7.1. Stability in the two point mass case. Without loss of generality (up to shifting
and scaling), we assume that
µα = ξδ1 + (1 − ξ)δ0 ,
1
ξ, ζ ∈ (0, ] ,
ξ ≤ ζ,
2

µβ = ζδθ + (1 − ζ)δ0 ,
1 1
(θ, ξ, ζ) 6= (−1, , ) .
2 2

θ 6= 0 ,
(7.1)

Here we exclude the case (θ, ξ, ζ) = (−1, 12 , 12 ) since it is equivalent to (θ, ξ, ζ) = (1, 21 , 12 )
under a shift. Note that the latter is a special case of µα = µβ .
Set
 1
o
n1
p
p
ℓ1 := min
1 + θ − (1 − θ)2 + 4θr+ ,
1 + θ − (1 − θ)2 + 4θr− ,
2
2
n1
 1
o
p
p
2
ℓ2 := max
1 + θ − (1 − θ) + 4θr+ ,
1 + θ − (1 − θ)2 + 4θr− ,
2
2
n1
 1
o
p
p
2
ℓ3 := min
1 + θ + (1 − θ) + 4θr+ ,
1 + θ + (1 − θ)2 + 4θr− ,
2
2
n1
 1
o
p
p
2
1 + θ + (1 − θ) + 4θr+ ,
1 + θ + (1 − θ)2 + 4θr− ,
ℓ4 := max
2
2
where we introduced

r± := ξ + ζ − 2ξζ ±

p
4ξζ(1 − ξ)(1 − ζ) .

(7.2)

Note that ℓ1 < ℓ2 ≤ ℓ3 < ℓ4 . The following result, taken from [28], describes the regular
bulk of µα ⊞µβ in the setting of (7.1). Recall that fµα ⊞µβ denotes the density of (µα ⊞µβ )ac .
Lemma 7.1. Let µα and µβ be as in (7.1). Then the regular bulk is given by
Bµα ⊞µβ = (ℓ1 , ℓ2 ) ∪ (ℓ3 , ℓ4 ) ,

(7.3)

in case µα 6= µβ , while in case µα = µβ it is given by
Bµα ⊞µα = (ℓ1 , ℓ4 ) .

(7.4)

Proof. Choose the diagonal matrices A and B with spectral distribution µA = ξN δ1 + (1 −
ξN )δ0 and µB = ζN δθ + (1 − ζN )δ0 respectively, with ξN := ⌊ξN ⌋/N and ζN := ⌊ζN ⌋/N ,
where ⌊ · ⌋ denotes the integer part. Recall from (7.1) that ξ ≤ ζ and ξ + ζ ≤ 1. From
Theorem 1.1 of [28], we first observe that the θ and 0 are eigenvalues of the matrix H =
A+U BU ∗ , U a Haar unitary, with multiplicities N (ζN −ξN ) and N (1−ζN −ξN ), respectively.
The remaining 2ξN N eigenvalues of H may be obtained via a two-fold transformation from
the eigenvalues, (ti ), of a ξN N -dimensional Jacobi ensemble as
q

1
j = 1, . . . , ξN N ,
(7.5)
1 + θ ± (1 − θ)2 + 4tj ,
τj± :=
2

30

and then identifying the eigenvalues of H as the set {τj+ } ∪ {τj− } ∪ {0, θ}. In addition, the
P
weak limit of ξN1N j δtj , as N → ∞, admits a density given by
p
(r+ − x)(x − r− )
1
f (x) =
1[r− ,r+ ] (x) ,
x ∈ R,
(7.6)
2πξ
x(1 − x)

where r+ and r− are defined in (7.2). Since the limiting spectral distribution of H is
ac
given
P by µα ⊞ µβ , we see that (µα ⊞ µβ ) agrees with the weak limit of the measure
1
j (δτj+ + δτj− ), as N → ∞. Using this information together with (7.5) and (7.6), one
N
deduces that supp (µα ⊞ µβ )ac = [ℓ1 , ℓ2 ] ∪ [ℓ3 , ℓ4 ]. It then follows from the explicit form of
the limiting distribution of the Jacobi ensemble that fµα ⊞µβ is bounded and strictly positive
inside its support. This proves (7.3).
ac
In the special
p case µα = µβ , we havepℓ2 = ℓ3 = 1 and thus supp (µα ⊞ µβ ) =ac[ℓ1 , ℓ4 ],
with ℓ1 = 1 − 2 ξ(1 − ξ) and ℓ4 = 1 + 2 ξ(1 − ξ). In fact, the density of (µα ⊞ µα ) equals
p
1 (ℓ4 − x)(x − ℓ1 )
fµα ⊞µα (x) =
,
x ∈ (ℓ1 , ℓ4 ) ;
(7.7)
π
x(2 − x)

see (5.5) of [33] for instance. Then (7.4) follows directly



Our main task in this section is to show the following result on the stability of the system
Φµα ,µβ (ωα , ωβ , z) = 0 in the setting (7.1). Recall the definition of Γµα ,µβ in (2.12).
Proposition 7.2. Let µα and µβ be as in (7.1). Let I ⊂ Bµα ⊞µβ be a compact non-empty
interval. Fix 0 < ηM < ∞. Then, there are constants k > 0, K < ∞ and S < ∞, depending
on the constants ξ, ζ, θ, ηM and on the interval I, such that the subordination functions
possess the following bounds:
min

z∈SI (0,ηM )

Im ωα (z) ≥ 2k ,

K
,
2
Moreover, we have the following bounds:
(i) If µα 6= µβ ,
max

z∈SI (0,ηM )

|ωα (z)| ≤

max

z∈SI (0,ηM )

min

Im ωα (z) ≥ 2k ,

max

|ωβ (z)| ≤

z∈SI (0,ηM )

z∈SI (0,ηM )

K
.
2

Γµα ,µβ (ωα (z), ωβ (z)) ≤ S .

(7.8)
(7.9)

(7.10)

(ii) If µα = µβ ,
Γµα ,µα (ωα (z), ωα (z)) ≤
holds uniformly on SI (0, ηM ).

S
,
|z − 1|

(7.11)

Remark 7.1. As an immediate consequence of Proposition 7.2 and (3.28), we obtain for
µα 6= µβ the bounds maxz∈SI (0,ηM ) |ωα′ (z)| ≤ 2S, maxz∈SI (0,ηM ) |ωβ′ (z)| ≤ 2S with I as
2S
, uniformly on SI (0, ηM ) as in (7.11).
in (7.10). For µα = µβ , we get |ωα′ (z)| ≤ |z−1|
Remark 7.2. In the case µα = µβ , we note from Lemma 7.1 (c.f., (7.7)) that the point
E = 1 is in the regular bulk Bµα ⊞µα . However, mµα ⊞µβ (1 + i0) is unstable under small
perturbations. For instance, let
µA = µα = ξδ1 + (1 − ξ)δ0 ,

µB = (ξ − ε)δ1 + (1 − ξ + ε)δ0 ,

for some small ε > 0. Then, according to Theorem 7.4 of [11], µA ⊞ µB has a point mass εδ1 .
Hence, even though (2.25) (i.e., dL (µB , µβ ) → 0, as ε → 0) is satisfied, mµA ⊞µB (z) contains

31
ε
a singular part (1−z)
, which blows up as |z − 1| = o(ε). This explains, on a heuristic level,
the bound in (7.11) and shows why the µα = µβ case at energy E = 1 is special even though
the density fµα ⊞µα is real analytic in a neighborhood of E = 1.

Remark 7.3. Consider a more general setup with µα = ξδa + µ
eα and µβ = (1 − ξ)δb + µ
eβ , for
some constants ξ ∈ (0, 1), a, b ∈ R and for some Borel measures µ
eα and µ
eβ with µ
eα (R) = 1−ξ
and µ
eβ (R) = ξ. Analogously to the discussion in Remark 7.2, we note that mµα ⊞µβ (a+b+i0)
is unstable under small perturbations. However, from Lemma 3.4, we know that the system
Φµα ,µβ (ωα , ωβ , z) = 0 is linearly S-stable in the regular bulk under the assumptions of
Theorem 2.5. That means, if neither µα nor µβ is supported at a single point and at least
one of them is supported at more than two points, then the point E = a + b cannot lie in the
regular bulk Bµα ⊞µβ . Thus, only in the special case µα = µβ with µα as in (7.1), there is an
unstable point, up to scaling and shifting given by E = 1, inside the regular bulk Bµα ⊞µα .
Proof of Proposition 7.2. Estimates (7.8) and (7.9) follow from Lemma 3.2 and Lemma 3.3.
To show statement (i), we recall from the proof of Lemma 3.4 that Φµα ,µβ (ωα , ωβ , z) = 0
is linearly S-stable at (ωα , ωβ ) if


1 − (Fµ′ (ωβ ) − 1)(Fµ′ (ωα ) − 1) ≥ c ,
(7.12)
α
β

for some strictly positive constant c. We now show that (7.12) holds for the case µα 6= µβ
in the setup of (7.1). Using henceforth the shorthand Fα ≡ Fµα , Fβ ≡ Fµβ , we compute
Fα (z) =

z(1 − z)
,
1−ξ−z

Fβ (z) =

Then it is easy to obtain

Fα′ (z) − 1 =
and

ξ − ξ2
,
(1 − ξ − z)2

z(θ − z)
,
θ − θζ − z
Fβ′ (z) − 1 =

z ∈ C+ .
θ2 (ζ − ζ 2 )
,
(θ − θζ − z)2

Im Fα (z) − Im z
Im Fβ (z) − Im z
,
|Fβ′ (z) − 1| =
.
Im z
Im z
Consequently, we have (c.f., (3.18))


 (Im ωα (z) − Im z)(Im ωβ (z) − Im z)
 ′
 Fα (ωβ (z)) − 1 Fβ′ (ωα (z)) − 1  =
Im ωα (z)Im ωβ (z)

(7.13)

(7.14)

|Fα′ (z) − 1| =

(7.15)

for any z ∈ C+ . Hence, for z ∈ SI (η0 , ηM ) with some small but fixed η0 > 0 to be chosen
below, we trivially get (7.12) from (7.15). It remains to discuss the regime z ∈ SI (0, η0 ).
Then (7.13) together with (2.5) implies that
ωα (θ − ωα )
ωβ (1 − ωβ )
=
,
1 − ξ − ωβ
θ − θζ − ωα

ωβ (1 − ωβ )
= ωα + ωβ − z .
1 − ξ − ωβ

(7.16)

Denote s := 1 − ξ − ωβ and t := θ − θζ − ωα . From (7.14) we then have

 (ξ − ξ 2 )(θ2 ζ − (θζ)2 )
Fα′ (ωβ ) − 1 Fβ′ (ωα ) − 1 =
.
(st)2

(7.17)

Using (7.16), some algebra reveals that
ξ + θ − θζ − z
1
1
+
=−
,
st
ξ − ξ2
(ξ − ξ 2 )t

1
1
θζ + 1 − ξ − z
=− 2
+ 2
.
st
θ (ζ − ζ 2 )
θ (ζ − ζ 2 )s

(7.18)

32

Owing to (7.15) and (ξ − ξ 2 )(θ2 ζ − (θζ)2 ) > 0 (recall that ξ, ζ ∈ (0, 1/2] and θ 6= 0), it
suffices to show that
|Im (st)| ≥ c ,

(7.19)

in order to prove (7.12). Note that, from the definitions of s and t, together with (7.8)
and (7.9), we have
|Im s| , |Im t| ≥ c ,

|s| , |t| ≤ C .

(7.20)

Since µα 6= µβ , there exists a positive constant d such that max{|ξ − ζ|, |θ − 1|} ≥ d. It is
then elementary to work out that
max{|(ξ − ξ 2 ) − θ2 (ζ − ζ 2 )| , |(2ξ − 2θζ + θ − 1)|} ≥ d1 ,

(7.21)

for some positive constant d1 ≡ d1 (ξ, ζ, θ) > 0, since the special case (θ, ξ, ζ) = (−1, 21 , 12 ) is
also excluded in the setting (7.1). For brevity, we adopt the notation
θζ + 1 − ξ − z
ξ + θ − θζ − z
ϕ :=
,
ψ :=
.
2
2
θ (ζ − ζ )s
(ξ − ξ 2 )t

Then, according to (7.18) we have
1
1
1
Re
= Re ψ −
= Re ϕ − 2
,
st
ξ − ξ2
θ (ζ − ζ 2 )

Im

1
= Im ψ = Im ϕ .
st

If |(ξ − ξ 2 ) − θ2 (ζ − ζ 2 )| ≥ d1 holds in (7.21), then (7.22) implies that
|Re ψ − Re ϕ| ≥ d2 ,

(7.22)

(7.23)

for some positive constant d2 ≡ d2 (ξ, ζ, θ). For small enough η0 = η0 (ξ, ζ, θ), we then get
Re ψ − Re ϕ =

(ξ + θ − θζ − E)Re t + O(η0 ) (θζ + 1 − ξ − E)Re s + O(η0 )
−
,
(ξ − ξ 2 )|t|2
θ2 (ζ − ζ 2 )|s|2

which, together with (7.20) and (7.23), implies that

	
max |θζ + 1 − ξ − E| , |ξ + θ − θζ − E| ≥ d3 ,

(7.24)

for some positive constant d3 ≡ d3 (ξ, ζ, θ). If, on the other hand, |(2ξ − 2θζ + θ − 1)| ≥ d1
holds in (7.21), we get (7.24) by triangle inequality. Either way, (7.24) follows from (7.21),
for sufficiently small, but fixed, η0 > 0.
Next, using (7.20) and (7.24), we see that there is a constant c > 0 such that, for
sufficiently small η0 , for all z ∈ SI (0, η0 ), we have max{|Im ϕ|, |Im ψ|} ≥ c. Since Im ϕ =
Im ψ by (7.22), (7.19) holds on SI (0, η0 ). Therefore, (7.19) holds on all of SI (0, ηM ). So, if
µα 6= µβ , the system Φµα ,µβ (ωα , ωβ , z) = 0 is linearly S-stable with some finite S.
We next prove statement (ii) where µα = µβ and thus θ = 1, ξ = ζ. From (7.16), we see
that ωα = ωβ satisfies the equation
ωα (1 − ωα )
= 2ωα − z .
1 − ξ − ωα

(7.25)

Solving (7.25) for ωα (z) we get

p
1
ωα (z) = ωβ (z) =
(7.26)
z − 1 + 2(1 − ξ) + (z − 1)2 − 4ξ(1 − ξ) ,
2
p
where the square root is chosen such that ωβ (z) → i ξ(1 − ξ), as z → 1. Substituting (7.26)
into (7.17), together with the θ = 1, ζ = ξ, s = t = 1 − ξ − ωα , yields


4(ξ − ξ 2 )2
Fα′ (ωβ (z)) − 1 Fβ′ (ωα (z)) − 1 =
p
4 .
z − 1 + (z − 1)2 − 4(ξ − ξ 2 )

33

Then it is elementary to check that



1 − F ′ (ωβ (z)) − 1 F ′ (ωα (z)) − 1  & |z − 1| ,
α
β

z ∈ S(0, ηM ) ,

which further implies Γµα ,µβ (ωα (z), ωβ (z)) . 1/|z − 1|. Hence (7.11) is proved.



7.2. Applications of Proposition 7.2. Analogously to Theorem 2.5, we have two main
applications of Proposition 7.2. The first one is the following modification of Theorem 2.7.
Let µα , µβ be as in (7.1) and let µA , µB be arbitrary probability measures on R. Recall the
domain SI (a, b) introduced in (2.13). For given (small) ς > 0, we set

q
o
np
dL (µA , µα ), dL (µB , µβ )
.
(7.27)
SIς (a, b) := z ∈ SI (a, b) : ς|z − 1| ≥ max

Proposition 7.3. Let µα , µβ be as in (7.1). Let I ⊂ Bµα ⊞µβ be a compact non-empty
interval. Let µA , µB be two probability measures on R. Fix 0 < ηM < ∞. Then there are
constants b > 0 and Z < ∞ such that the condition
dL (µA , µα ) + dL (µB , µβ ) ≤ b

(7.28)

implies
max

z∈SI (0,ηM )


 mµ

A ⊞µB


(z) − mµα ⊞µβ (z) ≤ Z (dL (µA , µα ) + dL (µB , µβ )) ,

(7.29)

in case µα 6= µβ , respectively

 mµ

A ⊞µB


(z) − mµα ⊞µα (z) ≤

Z
(dL (µA , µα ) + dL (µB , µα )) ,
|z − 1|

(7.30)

uniformly on SIς (0, ηM ) with ς ≤ ς0 , for some ς0 > 0, in case µα = µβ . The constants b
and Z depend only on the constants ξ, ζ, θ and on the interval I, while ς0 also depends on b.
Proof. Having established Proposition 7.2, the proof of (7.29) is the same as that of TheoS
rem 2.7. To establish (7.30), we mimic the proof of Theorem 2.7 with S replaced by |z−1|
.
We only give a sketch here. Similarly to (5.9), using (7.8) and (7.11), we have with b in (7.28)
sufficiently small that
ΓµA ,µB (ωα (z), ωα (z)) .

1
,
|z − 1|

z ∈ SIς (0, ηM ) .

(7.31)

As in the proof of Lemma 5.1, we rewrite the system Φµα ,µα (ωα (z), ωα (z), z) = 0 as
ΦµA ,µB (ωα (z), ωα (z), z) = r(z) with kr(z)k satisfying the bound (5.8). From the uniqueness
of the solution to ΦµA ,µB (ωA , ωB , z) = 0 and (7.31), we get
|ωA (z) − ωα (z)| . kr(z)k/|z − 1| ,

|ωB (z) − ωα (z)| . kr(z)k/|z − 1| ,

z ∈ SIς (0, ηM ) ,

(7.32)

via the Newton-Kantorovich theorem. Note that the inequality kr(z)k . ς 2 |z − 1|2 is needed
to guarantee that the first order term dominates over the higher order terms in the Taylor
expansion of ΦµA ,µB (ωA , ωB , z) around ΦµA ,µB (ωα , ωβ , z). This is the reason why we restrict
our discussion on the set SIς (0, ηM ). In addition, thanks to (7.32) we see that (5.3) and (5.4)
still hold with SI (0, ηM ) replaced by SIς (0, ηM ). Then the remaining parts of the proof

of (7.30) are the same as the counterparts in the proof of Theorem 2.7.

34

The second application of Proposition 7.2 gives the following local law for the Green
function in the random matrix setup from Subsection 2.3.2. Fix any γ > 0. We introduce a
sub-domain of SIς (a, b) by setting
n
Nγ o
SeIς (a, b) := SIς (a, b) ∩ z ∈ C : |z − 1| ≥ p
.
(7.33)
N η 3/2

Proposition 7.4. Let µα , µβ be as in (7.1). Assume that the empirical eigenvalue distributions µA , µB of the sequences of matrices A, B satisfy (2.25). Fix any 0 < ηM < ∞, any
2
small γ > 0 and set ηm = N − 3 +γ . Let I ⊂ Bµα ⊞µβ be a compact non-empty interval. Then
we have the following conclusions.
(i) If µα 6= µβ , then


mH (z) − mA⊞B (z) ≺ 1 .
max
z∈SI (ηm ,ηM )
N η 3/2
(ii) If µα = µβ , then, for any fixed (small) ς > 0,


1
1
mH (z) − mA⊞B (z) ≺
,
|z − 1| N η 3/2
uniformly on SeIς (ηm , ηM ).

Proof of Proposition 7.4. Note that, in the proof of Theorem 2.8, the only place where we
use the assumption that at least one of µα and µβ is supported at more than two points
is Lemma 3.4; in particular in (3.25). Hence, it suffices to mimic the proof of Theorem 2.8
with Lemma 3.4 replaced by Proposition 7.2. Then the proof of the case µα 6= µβ is exactly
the same as that of Theorem 2.8. It suffices to discuss the case µα = µβ below.
Analogously to Corollary 5.2, with the aid of (7.31) and (7.32), we show that
1
,
z ∈ SIς (0, ηM ) .
(7.34)
ΓµA ,µB (ωA (z), ωB (z)) .
|z − 1|
Then, we use a continuity argument, based on Lemma 4.2 and Proposition 4.1 with S
S
replaced by |z−1|
therein, to deduce from (6.40) that |ωic (z) − ωi (z)| ≺ krc (z)k/|z − 1|,
i = A, B, on SeIς (ηm , ηM ). The remaining parts of the proof are the same as in Theorem 2.8.
This completes the proof of part (ii) of Proposition 7.4.

References

[1] Akhieser, N. I.: The classical moment problem and some related questions in analysis, Hafner Publishing Co., New York, 1965.
[2] Anderson, G., Guionnet, A., Zeitouni, O.: An introduction to random matrices, Cambridge Stud. Adv.
Math. 118, Cambridge Univ. Press, Cambridge, 2010.
[3] Bao Z. G., Erdős, L., Schnelli K.: Local law of addition of random matrices on optimal scale,
arXiv:1509.07080 (2015).
[4] Belinschi, S., Bercovici, H.: A new approach to subordination results in free probability, J. Anal. Math.
101(1), 357-365 (2007).
[5] Belinschi, S.: A note on regularity for free convolutions, Ann. Inst. Henri Poincaré Probab. Stat. 42(5),
635-648 (2006).
[6] Belinschi, S.: The Lebesgue decomposition of the free additive convolution of two probability distributions, Probab. Theory Related Fields 142(1-2), 125-150 (2008).
[7] Belinschi, S.: L∞ -boundedness of density for free additive convolutions, Rev. Roumaine Math. Pures
Appl. 59(2), 173-184 (2014).
[8] Belinschi, S., Bercovici, H., Capitaine, M., Février, M.: Outliers in the spectrum of large deformed
unitarily invariant models, arXiv:1412.4916 (2014).
[9] Benaych-Georges, F., Nadakuditi, R. R.: The eigenvalues and eigenvectors of finte, low rank perturbbations of large random matrices, Adv. Math. 227(1), 494-521 (2011).

35

[10] Bercovici, H, Voiculescu, D.: Free convolution of measures with unbounded support, Indiana Univ.
Math. J. 42, 733-773 (1993).
[11] Bercovici, H., Voiculescu, D.: Regularity questions for free convolution, nonselfadjoint operator algebras, operator theory, and related topics, Oper. Theory Adv. Appl. 104, 37-47 (1998).
[12] Bercovici, H., Wang, J.-C.: On freely indecomposable measures, Indiana Univ. Math. J. 57(6), 26012610 (2008).
[13] Biane, P.: On the free convolution with a semi-circular distribution, Indiana Univ. Math. J. 46, 705-718
(1997).
[14] Biane, P.: Processes with free increments, Math. Z. 227(1), 143-174 (1998).
[15] Biane, P.: Representations of symmetric groups and free probability, Adv. Math. 138(1), 126-181
(1998).
[16] Capitaine, M.: Additive/multiplicative free subordination property and limiting eigenvectors of spiked
additive deformations of Wigner matrices and spiked sample covariance matrices, J. Theoret. Probab.
26.3, 595-648 (2013).
[17] Chatterjee, S.: Concentration of Haar measures, with an application to random matrices, J. Funct.
Anal. 245(2), 379-389 (2007).
[18] Chistyakov, G. P., Götze, F.: The arithmetic of distributions in free probability theory, Cent. Euro. J.
Math. 9, 997-1050 (2011).
[19] Collins, B.: Moments and cumulants of polynomial random variables on unitary groups, the ItzyksonZuber integral, and free probability, Int. Math. Res. Not. 2003(17), 953-982 (2003).
[20] Dykema, K.: On certain free product factors via an extended matrix model, J. Funct. Anal. 112(1),
31-60 (1993).
[21] Erdős, L., Knowles, A., Yau, H.-T.: Averaging fluctuations in resolvents of random band matrices,
Ann. Henri Poincaré 14, 1837-1926 (2013).
[22] Erdős, L., Knowles, A., Yau, H.-T., Yin, J.: The local semicircle law for a general class of random
matrices. Electron. J. Probab. 18(59), 1-58 (2013).
[23] Erdős, L., Schlein, B., Yau, H.-T.: Local semicircle law and complete delocalization for Wigner random
matrices, Ann. Probab. 37(3), 815-852 (2009).
[24] Erdős, L., Yau, H.-T., Yin, J.: Bulk universality for generalized Wigner matrices, Probab. Theory
Related Fields 154(1-2), 341-407 (2012).
[25] Ferreira, O. P., Svaiter, B. F.: Kantorovich’s theorem on Newton’s method, arXiv:1209.5704 (2012).
[26] Gromov, M., Milman V. D.: A topological application of the isoperimetric inequality, Amer. J. Math.
105(4), 843-854 (1983).
[27] Hiai, F., Petz, D.: The semicircle law, free random variables and entropy, Math. Surveys Monogr. 77,
Amer. Math. Soc., Providence RI, 2000.
[28] Kargin, V.: On eigenvalues of the sum of two random projections, J. Stat. Phys. 149(2), 246-258
(2012).
[29] Kargin, V.: A concentration inequality and a local law for the sum of two random matrices, Probab.
Theory Related Fields 154, 677-702 (2012).
[30] Kargin, V.: An inequality for the distance between densities of free convolutions, Ann. Probab. 41(5),
3241-3260 (2013).
[31] Kargin, V.: Subordination for the sum of two random matrices, Ann. Probab. 43(4), 2119-2150 (2015).
[32] Maassen, H.: Addition of freely independent random variables. J. Funct. Anal. 106(2), 409-438 (1992).
[33] Pastur, L., Vasilchuk. V: On the law of addition of random matrices, Comm. Math. Phys. 214(2),
249-286 (2000).
[34] Speicher, R.: Free convolution and the random sum of matrices, Pub. Res. Inst. Math. Sc. 29(5),
731-744 (1993).
[35] Speicher, R.: Multiplicative functions on the lattice of non-crossing partitions and free convolution,
Math. Ann. 298.1, 611-628 (1994).
[36] Voiculescu, D.: Addition of certain non-commuting random variables, J. Funct. Anal. 66(3), 323-346
(1986).
[37] Voiculescu, D.: Limit laws for random matrices and free products, Invent. Math. 104(1), 201-220
(1991).
[38] Voiculescu, D.: The analogues of entropy and of Fisher’s information measure in free probability
theory I, Comm. Math. Phys. 155(1), 71-92 (1993).
[39] Voiculescu, D., Dykema, K. J., Nica, A.: Free random variables, CRM Monogr. Ser., Amer. Math. Soc.,
Providence RI, 1992.

36

[40] Xu, F.: A random matrix model from two-dimensional Yang-Mills theory, Comm. Math. Phys. 190,
287-307 (1997).

