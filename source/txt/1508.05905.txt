1

arXiv:1508.05905v3 [math.PR] 2 Jan 2016

Local Stability of the Free Additive Convolution

Zhigang Baoâ€ 

LaÌszloÌ ErdoÌ‹sâˆ—

Kevin Schnelliâ€ 

IST Austria
zhigang.bao@ist.ac.at

IST Austria
lerdos@ist.ac.at

IST Austria
kevin.schnelli@ist.ac.at

We prove that the system of subordination equations, defining the free additive convolution of two probability measures, is stable away from the edges of the support
and blow-up singularities by showing that the recent smoothness condition of Kargin
is always satisfied. As an application, we consider the local spectral statistics of the
random matrix ensemble A + U BU âˆ— , where U is a Haar distributed random unitary
or orthogonal matrix, and A and B are deterministic matrices. In the bulk regime,
we prove that the empirical spectral distribution of A + U BU âˆ— concentrates around
the free additive convolution of the spectral distributions of A and B on scales down
to N âˆ’2/3 .
Keywords: Free convolution, subordination, local eigenvalue density
AMS Subject Classification (2010): 46L54, 60B20

1. Introduction
One of the basic concepts of free probability theory is the free additive convolution of two
probability laws in a non-commutative probability space; it describes the law of the sum of
two free random variables. In the case of a bounded self-adjoint random variable, its law
can be identified with a probability measure of compact support on the real line. Hence
the free additive convolution of two probability measures is a well-defined concept and it is
characteristically different from the classical convolution.
In this paper, we prove a local stability result of the free additive convolution. A direct
consequence is the continuity of the free additive convolution in a much stronger topology
than established earlier by Bercovici and Voiculescu [10]. A second application of our stability result is to establish a local law on a very small scale for the eigenvalue density of a
random matrix ensemble A + U BU âˆ— where U is a Haar distributed unitary or orthogonal
matrix and A, B are deterministic N by N hermitian matrices.
The free additive convolution was originally introduced by Voiculescu [36] for the sum
of free bounded noncommutative random variables in an algebraic setup (see Maassen [32]
and by Bercovici and Voiculescu [10] for extensions to the unbounded case). The Stieltjes
transform of the free additive convolution is related to the Cauchy-Stieltjes transforms of the
original measures by an elegant analytic change of variables. This subordination phenomenon
was first observed by Voiculescu [38] in a generic situation and extended to full generality by
Biane [14]. In fact, the subordination equations, see (2.5)-(2.6) below, may directly be used
âˆ—Partially supported by ERC Advanced Grant RANMAT No. 338804.
â€ 

Supported by ERC Advanced Grant RANMAT No. 338804.

2

to define the free additive convolution. This analytic definition was given independently by
Belinschi and Bercovici [4] and by Chistyakov and GoÌˆtze [18]; for further details we refer to,
e.g., [39, 27, 2].
Kargin [30] pointed out that the analytic approach to the subordination equations, in
contrast to the algebraic one, allows one to effectively study how free additive convolution
is affected by small perturbations; this is especially useful to treat various error terms in the
random matrix problem [31]. The basic tool is a local stability analysis of the subordination
equations. In [30], Kargin assumed a lower bound on the imaginary part of the subordination
functions and a certain non-degeneracy condition on the Jacobian that holds for generic
values of the spectral parameter. While these so-called smoothness conditions hold in many
examples, a general characterization was lacking. Our first result, Theorem 2.5, shows
that the smoothness conditions hold wherever the absolutely continuous part of the free
convolution measure is finite and nonzero. In particular, local stability holds unconditionally
(Corollary 2.6) and, following Karginâ€™s argument [30], we immediately obtain the continuity
of the free additive convolution in a stronger sense; see Theorem 2.7.
The random matrix application of this stability result, however, goes well beyond Karginâ€™s
analysis [31] since our proof is valid on a much smaller scale. To explain the new elements,
we recall how free probability connects to random matrices.
The following fundamental observation was made by Voiculescu [37] (later extended by
Dykema [20] and Speicher [35]): if A = A(N ) and B = B (N ) are two sequences of Hermitian
matrices that are asymptotically free with eigenvalue distributions converging to probability
measures ÂµÎ± and ÂµÎ² , then the eigenvalue density of A + B is asymptotically given by the
free additive convolution ÂµÎ± âŠ ÂµÎ² . One of the most natural ways to ensure asymptotic
freeness is to consider conjugation by independent unitary matrices. Indeed, if A and B
are deterministic (may even be chosen diagonal) with limit laws ÂµÎ± and ÂµÎ² , then A and
U BU âˆ— are asymptotically free if U = U (N ) is a Haar distributed matrix; see [37] and many
subsequent works, e.g., [34, 40, 15, 33, 19]. In particular, the limiting spectral density of
the eigenvalues of H = A + U BU âˆ— is given by ÂµÎ± âŠ ÂµÎ² .
The conventional setup of free probability operates with moment calculations. An alternative approach [33] proves the convergence of the resolvent at any fixed spectral parameter z âˆˆ C+ . Both approaches give rise to weak convergence of measures, in particular they
identify the limiting spectral density on macroscopic scale.
Armed with these macroscopic results, it is natural to ask for a local law, i.e., for the
smallest possible (N -dependent) scale so that the local eigenvalue density on that scale still
converges as N tends to infinity. Local laws have been somewhat outside of the focus of free
probability before Karginâ€™s recent works. After having improved a concentration result for
the Haar measure by Chatterjee [17] by using the Gromov-Milman concentration inequality,
Kargin obtained a local law for the ensemble H = A + U BU âˆ— on scale Î· â‰« (log N )âˆ’1/2 [29],
i.e., slightly below the macroscopic scale. Recently in [31], he improved this result down
to scale Î· â‰« N âˆ’1/7 under the above mentioned smoothness condition. In Theorem 2.8 we
prove the local law down to scale Î· = Im z â‰« N âˆ’2/3 without any additional assumption.
To achieve this short scale, we effectively use the positivity of the imaginary parts of the
subordination functions by localizing the Gromovâ€“Milman concentration inequality within
the spectrum. Since the subordination functions are obtained as the solution of a system
of self-consistent equations whose derivation itself requires bounds on the subordination
functions, the reasoning seems circular. We break this circularity by a continuity argument
(similarly as in [23]) in which we reduce the imaginary part of the spectral parameter in
very small steps, use the previous step as an a priori bound and show that the bound does
not deteriorate by using the local stability result, Theorem 2.6.

3

Finally, we remark that the local stability result is also a key ingredient in [3], where we
were able to prove a local law down to the smallest possible scale Î· â‰« N âˆ’1 , but with a
weaker error bound than in Theorem 2.8; see Remark 2.4 for details.
1.1. Notation. We use the symbols O( Â· ) and o( Â· ) for the standard big-O and little-o
notation. We use c and C to denote positive numerical constants. Their values may change
from line to line. For a, b > 0, we write a . b, a & b if there is C â‰¥ 1 such that a â‰¤ Cb,
a â‰¥ C âˆ’1 b respectively. We write a âˆ¼ b, if a . b and a & b both hold. We denote by kvk the
Euclidean norm of v âˆˆ p
CN . For an N Ã—N matrix A âˆˆ MN (C), we denote by kAk its operator
norm and by kAk2 := hA, Ai its Hilbert-Schmidt norm, where hA, Bi := Trace(AB âˆ— ), for
A, B âˆˆ MN (C). Finally, we denote by trA the normalized trace of A, i.e., trA = N1 Trace A.
Acknowledgment. We thank an anonymous referee for many useful comments and remarks, and bringing references [7, 12] to our attention.
2. Main results
2.1. Free additive convolution. In this subsection, we recall the definition of the free
additive convolution. Given a probability measureâˆ— Âµ on R, its Stieltjes transform, mÂµ , on
the complex upper half-plane C+ := {z âˆˆ C : Im z > 0} is defined by
Z
dÂµ(x)
,
z âˆˆ C+ .
(2.1)
mÂµ (z) :=
R xâˆ’z
We denote by FÂµ the negative reciprocal Stieltjes transform of Âµ, i.e.,
FÂµ (z) := âˆ’

1
,
mÂµ (z)

z âˆˆ C+ .

(2.2)

Observe that
lim

Î·Ö€âˆ

FÂµ (iÎ·)
= 1,
iÎ·

(2.3)

as follows easily from (2.1). Note, moreover, that FÂµ is an analytic function on C+ with
non-negative imaginary part. Conversely, if F : C+ â†’ C+ is an analytic function such that
limÎ·Ö€âˆ F (iÎ·)/iÎ· = 1, then F is the negative reciprocal Stieltjes transform of a probability
measure Âµ, i.e., F (z) = FÂµ (z), for all z âˆˆ C+ ; see, e.g., [1].
The free additive convolution is the binary operation on probability measures on R characterized by the following result.
Proposition 2.1 (Theorem 4.1 in [4], Theorem 2.1 in [18]). Given two probability measures
Âµ1 and Âµ2 on R, there exist unique analytic functions, Ï‰1 , Ï‰2 : C+ â†’ C+ , such that,
(i) for all z âˆˆ C+ , Im Ï‰1 (z), Im Ï‰2 (z) â‰¥ Im z, and
lim

Î·Ö€âˆ

Ï‰2 (iÎ·)
Ï‰1 (iÎ·)
= lim
= 1;
Î·Ö€âˆ
iÎ·
iÎ·

(2.4)

(ii) for all z âˆˆ C+ ,
FÂµ1 (Ï‰2 (z)) âˆ’ Ï‰1 (z) âˆ’ Ï‰2 (z) + z = 0 ,

FÂµ2 (Ï‰1 (z)) âˆ’ Ï‰1 (z) âˆ’ Ï‰2 (z) + z = 0 .
âˆ—

All probability measures considered will be assumed to be Borel.

(2.5)

4

It follows from (2.4) that the analytic function F : C+ â†’ C+ defined by
F (z) := FÂµ1 (Ï‰2 (z)) = FÂµ2 (Ï‰1 (z)) ,

(2.6)

satisfies (2.3). Thus F is the negative reciprocal Stieltjes transform of a probability measure Âµ, called the free additive convolution of Âµ1 and Âµ2 , usually denoted by Âµ â‰¡ Âµ1 âŠ Âµ2 .
Note that (2.6) shows that the roÌ‚les of Âµ1 and Âµ2 are symmetric and thus Âµ1 âŠ Âµ2 = Âµ2 âŠ Âµ1 .
The functions Ï‰1 and Ï‰2 of Proposition 2.1 are called subordination functions and F is said
to be subordinated to FÂµ1 , respectively to FÂµ2 .
We mention that Voiculescu [36] originally introduced the free additive convolution in
a different, algebraic manner. The equivalent analytic definition based on the existence of
subordination functions (taken up in Proposition 2.1 above) was introduced in [4, 18].
We next recall some basic examples. Choosing Âµ1 arbitrary and Âµ2 as a single point
mass at b âˆˆ R, it is easy to check that Âµ1 âŠ Âµ2 simply is Âµ1 shifted by b. We exclude this
uninteresting case by henceforth assuming that Âµ1 and Âµ2 are both supported at more than
one point. Choosing Âµ1 = Âµ2 = Âµ as the Bernoulli distribution
Âµ = (1 âˆ’ Î¾)Î´0 + Î¾Î´1 ,

Î¾ âˆˆ (0, 1) ,

the free additive convolution is explicitly given by (see e.g., (5.5) of [33])
p
(â„“+ âˆ’ x)+ (x âˆ’ â„“âˆ’ )+
+ (1 âˆ’ 2Î¾)+ Î´0 (x) + (2Î¾ âˆ’ 1)+ Î´2 (x) ,
(2.7)
(Âµ âŠ Âµ)(x) =
Ï€x(2 âˆ’ x)
p
x âˆˆ R, where â„“Â± := 1 Â± 2 Î¾(1 âˆ’ Î¾) and where ( Â· )+ denotes the positive part. Observe that
Âµ âŠ Âµ has a nonzero absolutely continuous part and, depending on the choice of Î¾, a point
mass. Another important choice for Âµ2 is Wignerâ€™s semicircle law Âµsc . For arbitrary Âµ1 ,
Âµ1 âŠ Âµsc is then purely absolutely continuous with a bounded densityâ€  that is real analytic
wherever positive [13].
Returning to the generic setting, the atoms of Âµ1 âŠ Âµ2 are identified as follows. A point
c âˆˆ R is an atom of Âµ1 âŠ Âµ2 , if and only if there exist a, b âˆˆ R such that c = a + b and
Âµ1 ({a}) + Âµ2 ({b}) > 1; see [Theorem 7.4, [11]]. For another interesting properties of the
atoms of Âµ1 âŠ Âµ2 we refer the reader to [12]. The boundary behavior of the functions
FÂµ1 âŠÂµ2 , Ï‰1 and Ï‰2 has been studied by Belinschi [5, 6, 7] who proved the next two results.
For simplicity, we restrict the discussion to compactly supported probability measures.
Proposition 2.2 (Theorem 2.3 in [5], Theorem 3.3 in [6]). Let Âµ1 and Âµ2 be compactly
supported probability measures on R, none of them being a single point mass. Then the
functions FÂµ1 âŠÂµ2 , Ï‰1 , Ï‰2 : C+ â†’ C+ extend continuously to R.
Belinschi further showed in Theorem 4.1 in [6] that the singular continuous part of Âµ1 âŠÂµ2
is always zero and that the absolutely continuous part, (Âµ1 âŠ Âµ2 )ac , of Âµ1 âŠ Âµ2 is always
nonzero. We denote the density function of (Âµ1 âŠ Âµ2 )ac by fÂµ1 âŠÂµ2 .
We are now ready to introduce our notion of regular bulk, BÂµ1 âŠÂµ2 , of Âµ1 âŠ Âµ2 . Informally,
we let BÂµ1 âŠÂµ2 be the open set on which Âµ1 âŠ Âµ2 admits a continuous density that is strictly
positive and bounded from above. For a formal definition we first introduce the set



ac
(2.8)
{x âˆˆ R : lim FÂµ1 âŠÂµ2 (x + iÎ·) = 0} .
UÂµ1 âŠÂµ2 := int supp (Âµ1 âŠ Âµ2 )
Î·Ö0

Note that UÂµ1 âŠÂµ2 does not contain any atoms of Âµ1 âŠ Âµ2 . By Privalovâ€™s theorem the set
{x âˆˆ R : limÎ·Ö0 FÂµ1 âŠÂµ2 (x + iÎ·) = 0} has Lebesgue measure zero. In fact, an even stronger
statement applies for the case at hand. Belinschi [7] showed that if x âˆˆ R is such that
â€ 

All densities are with respect to Lebesgue measure on R.

5

limÎ·Ö0 FÂµ1 âŠÂµ2 (x + iÎ·) = 0, then it must be of the form x = a + b with Âµ1 ({a}) + Âµ2({b}) â‰¥ 1,
a, b âˆˆ R. There could only be finitely many such x, thus UÂµ1 âŠÂµ2 must contain an open nonempty interval.
Proposition 2.3 (Theorem 3.3 in [6]). Let Âµ1 and Âµ2 be as above and fix any x âˆˆ UÂµ1 âŠÂµ2 .
Then FÂµ1 âŠÂµ2 , Ï‰1 , Ï‰2 : C+ â†’ C+ extend analytically around x. In particular, the density
function fÂµ1 âŠÂµ2 is real analytic in UÂµ1 âŠÂµ2 wherever positive.
The regular bulk is obtained from UÂµ1 âŠÂµ2 by removing the zeros of fÂµ1 âŠÂµ2 inside UÂµ1 âŠÂµ2 .
Definition 2.4. The regular bulk of the measure Âµ1 âŠ Âµ2 is defined as the set
	

BÂµ1 âŠÂµ2 := UÂµ1 âŠÂµ2 \ x âˆˆ UÂµ1 âŠÂµ2 : fÂµ1 âŠÂµ2 (x) = 0 .

(2.9)

Note that BÂµ1 âŠÂµ2 is an open non-empty set on which Âµ1 âŠ Âµ2 admits the density fÂµ1 âŠÂµ2 .
The density is strictly positive and thus (by Proposition 2.3) real analytic on BÂµ1 âŠÂµ2 .

2.2. Stability Result. To present our results it is convenient to recast (2.5) in a compact
form: For generic probability measures Âµ1 , Âµ2 as above, let the function Î¦Âµ1 ,Âµ2 : (C+ )3 â†’ C2
be given by


FÂµ1 (Ï‰2 ) âˆ’ Ï‰1 âˆ’ Ï‰2 + z
.
(2.10)
Î¦Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) :=
FÂµ2 (Ï‰1 ) âˆ’ Ï‰1 âˆ’ Ï‰2 + z
Considering Âµ1 , Âµ2 as fixed, the equation
Î¦Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) = 0 ,

(2.11)

is equivalent to (2.5) and, by Proposition 2.1, there are unique analytic functions Ï‰1 , Ï‰2 :
C+ â†’ C+ , z 7â†’ Ï‰1 (z), Ï‰2 (z) satisfying (2.4) that solve (2.11) in terms of z. We use the
following conventions: We denote by Ï‰1 and Ï‰2 generic variables on C+ and we denote, with
a slight abuse of notation, by Ï‰1 (z) and Ï‰2 (z) the subordination functions solving (2.11) in
terms of z. When no confusion can arise, we simply write Î¦ for Î¦Âµ1 ,Âµ2 .
We call the system (2.11) linearly S-stable at (Ï‰1 , Ï‰2 ) if

âˆ’1 


âˆ’1
FÂµâ€² 1 (Ï‰2 ) âˆ’ 1


Î“Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 ) := 
(2.12)
â‰¤S,
â€²
âˆ’1
 FÂµ2 (Ï‰1 ) âˆ’ 1

for some constant S. Especially, the partial Jacobian matrix, DÎ¦(Ï‰1 , Ï‰2 ), of (2.10) given by

 

âˆ‚Î¦
âˆ‚Î¦
âˆ’1
FÂµâ€² 1 (Ï‰2 ) âˆ’ 1
,
(Ï‰1 , Ï‰2 , z) ,
(Ï‰1 , Ï‰2 , z) =
DÎ¦(Ï‰1 , Ï‰2 ) :=
âˆ’1
FÂµâ€² 2 (Ï‰1 ) âˆ’ 1
âˆ‚Ï‰1
âˆ‚Ï‰2

admits a bounded inverse at (Ï‰1 , Ï‰2 ). Note that DÎ¦(Ï‰1 , Ï‰2 ) is independent of z.
Our first main result shows that the system (2.11) is linearly stable and that the imaginary
parts of the subordination functions are bounded below in the regular bulk. We require some
more notation: For a, b â‰¥ 0, b â‰¥ a, and an interval I âŠ‚ R, we introduce the domain
SI (a, b) := {z = E + iÎ· âˆˆ C+ : E âˆˆ I , a â‰¤ Î· â‰¤ b} .

(2.13)

Theorem 2.5. Let Âµ1 and Âµ2 be compactly supported probability measures on R, and assume
that neither is supported at a single point and that at least one of them is supported at more
than two points. Let I âŠ‚ BÂµ1 âŠÂµ2 be a compact non-empty interval and fix some 0 < Î·M < âˆ.
Then there are two constants k > 0 and S < âˆ, both depending on the measures Âµ1
and Âµ2 , on the interval I as well as on the constant Î·M , such that following statements hold.

6

(i) The imaginary parts Im Ï‰1 and Im Ï‰2 of the subordination functions associated
with Âµ1 and Âµ2 satisfy
min

zâˆˆSI (0,Î·M )

Im Ï‰1 (z) â‰¥ 2k ,

min

zâˆˆSI (0,Î·M )

Im Ï‰2 (z) â‰¥ 2k .

(2.14)

(ii) The system Î¦Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) = 0 is linearly S-stable at (Ï‰1 (z), Ï‰2 (z)) uniformly in
SI (0, Î·M ), i.e.,
max

zâˆˆSI (0,Î·M )

Î“Âµ1 ,Âµ2 (Ï‰1 (z), Ï‰2 (z)) â‰¤ S .

(2.15)

Remark 2.1. The assumption that neither of Âµ1 , Âµ2 is a point mass guarantees that the
free additive convolution is not a simple translate. The case when both, Âµ1 and Âµ2 are
combinations of two point masses is special and its discussion is postponed to Section 7.
Theorem 2.5 has the following local stability result as corollary.
Corollary 2.6. Let Âµ1 , Âµ2 and SI (0, Î·M ) be as in Theorem 2.5. Fix z0 âˆˆ C+ . Assume that
the functions Ï‰
e1 , Ï‰
e2 , re1 , re2 : C+ â†’ C satisfy Im Ï‰
e1 (z0 ) > 0, Im Ï‰
e2 (z0 ) > 0 and
Ï‰1 (z0 ), Ï‰
e2 (z0 ), z0 ) = re(z0 ) ,
Î¦Âµ1 ,Âµ2 (e

(2.16)

with re(z) := (e
r1 (z), re2 (z))âŠ¤ . Let Ï‰1 , Ï‰2 be the subordination functions solving the system
Î¦Âµ1 ,Âµ2 (Ï‰1 (z), Ï‰2 (z), z) = 0, z âˆˆ C+ .
Then there exists a (small) constant Î´0 > 0 such that whenever we have
we also have

|e
Ï‰1 (z0 ) âˆ’ Ï‰1 (z0 )| â‰¤ Î´0 ,

|e
Ï‰1 (z0 ) âˆ’ Ï‰1 (z0 )| â‰¤ 2Ske
r(z0 )k ,

|e
Ï‰1 (z0 ) âˆ’ Ï‰1 (z0 )| â‰¤ Î´0 ,

(2.17)

|e
Ï‰2 (z0 ) âˆ’ Ï‰2 (z0 )| â‰¤ 2Ske
r(z0 )k .

(2.18)

The constant Î´0 > 0 depends on Âµ1 and Âµ2 , on the interval I as well as on Î·M .
We omit the proof of Corollary 2.6 from Theorem 2.5, since it follows directly from
Proposition 4.1 in Section 4 below.
2.3. Applications. We next explain two main applications of the stability estimates obtained in Theorem 2.5.
2.3.1. Continuity of the free additive convolution. Our first application shows that the free
additive convolution is a continuous operation when the image is equipped with the topology
of local uniform convergence of the density in the regular bulk; see (2.23). Bercovici and
Voiculescu (Proposition 4.13 of [10]) showed that the free additive convolution is continuous
with respect to weak convergence of measures. More precisely, given two pairs of probability
measures ÂµA , ÂµB and ÂµÎ± , ÂµÎ² on R, the measures ÂµA âŠ ÂµB and ÂµÎ± âŠ ÂµÎ² satisfy
dL (ÂµA âŠ ÂµB , ÂµÎ± âŠ ÂµÎ² ) â‰¤ dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² ) ,

(2.19)

where dL denotes the LeÌvy distance. In particular, weak convergence of ÂµA to ÂµÎ± and weak
convergence of ÂµB to ÂµÎ² imply weak convergence of ÂµA âŠ ÂµB to ÂµÎ± âŠ ÂµÎ² .
Using the Stieltjes transform, we can easily link (2.19) to the systems of equations in (2.5),
respectively in (2.10). Using integration by parts and the definition of the Stieltjes transform,
a direct computation reveals that there is a numerical constant C such that
C
1
|mÂµA âŠÂµB (z) âˆ’ mÂµÎ± âŠÂµÎ² (z)| â‰¤
1+
dL (ÂµA âŠ ÂµB , ÂµÎ± âŠ ÂµÎ² )
Î·
Î·
1
C
1+
(dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² )) ,
Î· = Im z , (2.20)
â‰¤
Î·
Î·

7

for all z âˆˆ C+ , where we used (2.19) to get the second line. Note that the estimate in (2.20)
deteriorates as Î· approaches the real line. Our next result strengthens (2.20) as follows. We
consider the measure ÂµÎ± âŠ ÂµÎ² as â€œreferenceâ€ measure (in the sense that it locates the regular
bulk) while ÂµA , ÂµB are arbitrary probability measures and show that the LeÌvy distances
bound |mÂµA âŠÂµB (E + iÎ·) âˆ’ mÂµÎ± âŠÂµÎ² (E + iÎ·)| uniformly in Î·, for all E inside the regular bulk
of ÂµÎ± âŠ ÂµÎ² .
Theorem 2.7. Let ÂµÎ± and ÂµÎ² be compactly supported probability measures on R, and assume
that neither is supported at a single point and that at least one of them is supported at more
than two points. Let I âŠ‚ BÂµÎ± âŠÂµÎ² be a compact non-empty interval and fix some 0 < Î·M < âˆ.
Let ÂµA and ÂµB be two arbitrary probability measures on R.
Then there are constants b > 0 and Z < âˆ, both depending on the measures ÂµÎ± and ÂµÎ² ,
on the interval I as well as on the constant Î·M , such that whenever
dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² ) â‰¤ b
holds, then
max

zâˆˆSI (0,Î·M )

holds, too.


 mÂµ

A âŠÂµB


(z) âˆ’ mÂµÎ± âŠÂµÎ² (z) â‰¤ Z (dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² )) ,

(2.21)

(2.22)

Note that maxzâˆˆSI (0,Î·M ) |mÂµÎ± âŠÂµÎ² (z)| < âˆ by compactness of I and analyticity of mÂµÎ± âŠÂµÎ²
in I. Thus the Stieltjes-Perron inversion formula directly implies that (ÂµA âŠ ÂµB )ac has a
density, fÂµA âŠÂµB , inside I and that
max |fÂµA âŠÂµB (x) âˆ’ fÂµÎ± âŠÂµÎ² (x)| â‰¤ Z (dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² )) ,
xâˆˆI

(2.23)

provided that (2.21) holds, where fÂµÎ± âŠÂµÎ² is the density of (ÂµÎ± âŠ ÂµÎ² )ac .
Remark 2.2. The estimate (2.22) was recently given by Kargin [30] under the assumption
that (2.14) and (2.15) hold for all z âˆˆ SI (0, Î·M ), i.e., under the assumption that the conclusions of our Theorem 2.5 hold. It is quite surprising that one can directly set Im z = 0
in (2.22). As first noted by Kargin, this is due to the regularizing effect of Ï‰Î± , Ï‰Î² and to
the global uniqueness of solutions to (2.5) for arbitrary probability measures.
2.3.2. Application to random matrix theory. We now turn to an application of Theorem 2.5
in random matrix theory. Let A â‰¡ A(N ) and B â‰¡ B (N ) be two sequences of N Ã— N deterministic real diagonal matrices, whose empirical spectral distributions are denoted by ÂµA
and ÂµB respectively, i.e.,
N
1 X
Î´a ,
ÂµA :=
N i=1 i

N
1 X
ÂµB :=
Î´b ,
N i=1 i

(2.24)

where A = diag(ai ), B = diag(bi ). The matrices A and B depend on N , but we omit
this fact from the notation. Let Ï‰A and Ï‰B denote the subordination functions associated
with ÂµA and ÂµB by Proposition 2.1.
We assume that there are deterministic probability measures ÂµÎ± and ÂµÎ² on R, neither
of them being a single point mass, such that the empirical spectral distributions ÂµA , ÂµB
converge weakly to ÂµÎ± , ÂµÎ² , as N â†’ âˆ. More precisely, we assume that
dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² ) â†’ 0 ,

(2.25)

as N â†’ âˆ. Let Ï‰Î± , Ï‰Î² denote the subordination functions associated with ÂµÎ± and ÂµÎ² .

8

Let U be an independent N Ã— N Haar distributed unitary matrix (in short Haar unitary)
and consider the random matrix
H â‰¡ H (N ) := A + U BU âˆ— .

(2.26)

We introduce the Green function, GH , of H and its normalized trace, mH , by setting
1
GH (z) :=
,
mH (z) := tr GH (z) ,
(2.27)
H âˆ’z
z âˆˆ C+ . We refer to z as the spectral parameter and we often write z = E + iÎ·, E âˆˆ R,
Î· > 0. Recall the definition of SI (a, b) in (2.13). We have the following local law for mH .
Theorem 2.8. Let ÂµÎ± and ÂµÎ² be two compactly supported probability measures on R, and
assume that neither is only supported at one point and that at least one of them is supported
at more than two points. Let I âŠ‚ BÂµÎ± âŠÂµÎ² be a compact non-empty interval and fix some
0 < Î·M < âˆ. Assume that the sequences of matrices A and B in (2.26) are such that their
empirical eigenvalue distributions ÂµA and ÂµB satisfy (2.25). Fix any small Î³ > 0 and set
Î·m := N âˆ’2/3+Î³ .
Then we have the following uniform estimate: For any (small) Ç« > 0 and any (large) D,



Ç«
[


1
mH (z) âˆ’ mÂµ âŠÂµ (z) > N
(2.28)
P
â‰¤ D,
A
B
3/2
N
NÎ·
zâˆˆSI (Î·m ,Î·M )

holds for N â‰¥ N0 , with some N0 sufficiently large, where we write z = E + iÎ·.

Using standard techniques of random matrix theory, we can translate the estimate (2.28)
on the Green function into an estimate on the empirical spectral distribution of the matrix H.
Let Î»1 , . . . , Î»N denote the ordered eigenvalues of H and denote by
ÂµH :=

N
1 X
Î´Î»
N i=1 i

(2.29)

its empirical spectral distribution. Our result on the rate of convergence of ÂµH is as follows.
Corollary 2.9. Let I âŠ‚ BÂµÎ± âŠÂµÎ² be a compact non-empty interval. Then, for any E1 < E2
in I, we have the following estimate. For any (small) Ç« > 0 and any (large) D we have



NÇ«


P ÂµH ([E1 , E2 )) âˆ’ ÂµAâŠB ([E1 , E2 )) > 2/3 â‰¤ N âˆ’D ,
(2.30)
N
for N â‰¥ N0 , with some N0 sufficiently large.
We omit the proof of Corollary 2.9 from Theorem 2.8, but mention that the normalized
trace mH of the Green function and the empirical spectral distribution ÂµH of H are linked by
Z
N
dÂµH (x)
1 X 1
=
,
z âˆˆ C+ .
mH (z) = tr GH (z) =
N i=1 Î»i âˆ’ z
x
âˆ’
z
R

Corollary 2.9 then follows from a standard application of the Helffer-SjoÌˆstrand functional
calculus; see e.g., Section 7.1 of [22] for a similar argument.
Note that assumption (2.25) does not exclude that the matrix H has outliers in the
large N limit. In fact, the model H = A + U BU âˆ— shows a rich phenomenology when, say, A
has a finite number of large spikes; we refer to the recent works in [8, 9, 16, 31].
Remark 2.3. Our results in Theorem 2.8 and Corollary 2.9 are stated for U Haar distributed
on the unitary group U (N ). However, they also hold true (with the same proofs) when U
is Haar distributed on the orthogonal group O(N ).

9

Remark 2.4. In [3], we derive, with a different approach, the estimate (with the notation
of (2.28))



Ç«
[


1
mH (z) âˆ’ mÂµ âŠÂµ (z) > âˆšN
P
â‰¤ D,
(2.31)
A
B
N
NÎ·
zâˆˆSI (Î·m ,Î·M )

for N â‰¥ N0 , with some N0 sufficiently large, and with Î·m = N âˆ’1+Î³ . In fact, we obtain
estimates for individual matrix elements of the resolvent GH as well. Comparing with (2.28),
we see âˆšthat we can choose Î· in (2.31) almost as small as N âˆ’1 at the price of losing a
factor N . The stability and perturbation analysis in [3] rely on the optimal results in
Theorem 2.5 and Theorem 2.7 as well as in Sections 3-5 of the present paper.

2.4. Organization of the paper. In Section 3, we consider the stability of the system (2.5)
when at least one of the measures Âµ1 and Âµ2 is supported at more than two points and we
give the proof of Theorem 2.5. In Section 4, we consider perturbations of the system (2.5)
and derive results that will be used in the proof of Theorem 2.8 and also in [3]. In Section 5, we prove Theorem 2.7. In Section 6 we consider the random matrix setup and prove
Theorem 2.8. In the final Section 7, we separately settle the special case when both Âµ1
and Âµ2 are combinations of two point masses and give the results analogous to Theorem 2.5,
Theorem 2.7 and Theorem 2.8 for that case.
3. Stability of the system (2.11) and proof of Theorem 2.5
In this section, we discuss stability properties of the system (2.11), with Âµ1 , Âµ2 two
compactly supported probability measures satisfying the assumptions of Theorem 2.5.
Lemma 3.1. Let Âµ1 , Âµ2 be two probability measures on R neither of them being supported
at a single point. Then there is, for any compact set K âŠ‚ C+ , a strictly positive constant
0 < Ïƒ(Âµ1 , K) < 1 such that the reciprocal Stieltjes transform FÂµ1 (see (2.2)) satisfies
Im z â‰¤ (1 âˆ’ Ïƒ(Âµ1 , K)) Im FÂµ1 (z) ,

âˆ€z âˆˆ K .

(3.1)

Similarly, there is 0 < Ïƒ(Âµ2 , K) < 1 such that (3.1) holds with Âµ2 and FÂµ2 , respectively.
Assume in addition that Âµ1 is supported at more than two points. Then there is, for any
compact set K âŠ‚ C+ , a strictly positive constant 0 < Ïƒ
e(Âµ1 , K) < 1 such that
e(Âµ1 , K))
|FÂµâ€² 1 (z) âˆ’ 1| â‰¤ (1 âˆ’ Ïƒ

Im FÂµ1 (z) âˆ’ Im z
,
Im z

âˆ€z âˆˆ K ,

(3.2)

where FÂµâ€² 1 (z) â‰¡ âˆ‚z FÂµ1 (z).

Proof of Lemma 3.1. Assuming by contradiction that inequality (3.1) saturates (with vanishing constant Ïƒ(Âµ1 , K) = 0, for some z âˆˆ K âŠ‚ C+ ), we have Im FÂµ1 (z) = Im z for some z,
thus FÂµ1 (z) = z âˆ’ a, a âˆˆ R, i.e., Âµ1 = Î´a . This shows (3.1).
To establish (3.2), we first note that the analytic functions FÂµj : C+ â†’ C+ , j = 1, 2,
have the Nevanlinna representations
Z
1 + zx
FÂµj (z) = aFÂµj + z +
j = 1, 2 ,
z âˆˆ C+ ,
(3.3)
dÏFÂµj (x) ,
x
âˆ’
z
R
where aFÂµj âˆˆ R and ÏÂµFj are finite Borel measures on R. Note that the coefficients of z on
the right-hand side are determined by (2.3). From (3.3) we see that

Z


1 + x2
,
(x)
z âˆˆ C+ ,
(3.4)
dÏ
|FÂµâ€² 1 (z) âˆ’ 1| = 
FÂµ1

2
(x
âˆ’
z)
R

10

as well as
Im FÂµ1 (z) âˆ’ Im z
=
Im z

Z

R

1 + x2
dÏFÂµ1 (x) ,
|x âˆ’ z|2

z âˆˆ C+ .

(3.5)

e (Âµ1 , K) = 0, for
Hence, assuming by contradiction that inequality (3.2) saturates (with Ïƒ
some z âˆˆ K), we must have
Z

Z


1 + x2
1 + x2

,
(x)
=
(x)
dÏ
dÏ
(3.6)
F
F
Âµ
Âµ


1
1
2
2
R |x âˆ’ z|
R (x âˆ’ z)
for some z âˆˆ K, implying that ÏFÂµ1 is either a single point mass or ÏFÂµ1 = 0. In the latter
case, we have FÂµ1 (z) = aÂµ1 + z and we conclude that Âµ1 must be single point measure, but
this is excluded by assumption. Thus ÏFÂµ1 is a single point mass, i.e., there is a constant
dÂµ1 âˆˆ R such that FÂµ1 (z) = aFÂµ1 + z + (1 + zd2Âµ1 )/(dÂµ1 âˆ’ z), z âˆˆ K. It follows that Âµ1 is a

convex combination of two point measures yielding a contradiction. This shows (3.2).
3.1. Bounds on the subordination functions. Let Âµ1 , Âµ2 be as above and let Ï‰1 (z),
Ï‰2 (z) be the associated subordination functions. Recall that we rewrite the defining equations (2.5) for Ï‰1 and Ï‰2 in the compact form Î¦Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) = 0 introduced in (2.11).
We first provide upper bounds on the subordination functions Ï‰1 (z), Ï‰2 (z). Our proof
relies on the assumption that Âµ1 , Âµ2 are compactly supported, i.e., that there is a constant
L < âˆ such that
supp Âµ1 âŠ‚ [âˆ’L, L] ,

supp Âµ2 âŠ‚ [âˆ’L, L] .

(3.7)

Recall from Theorem 2.5 that we fixed a compact non-empty interval I âŠ‚ BÂµ1 âŠÂµ2 . Since
the density fÂµ1 âŠÂµ2 is real analytic inside the regular bulk by Proposition 2.3 and since I is
compact, there exists a constant Îº0 > 0 such that
0 < Îº0 â‰¤ min fÂµ1 âŠÂµ2 (x) .
xâˆˆI

(3.8)

Fixing a constant 0 < Î·M < âˆ, it further follows that there is a constant M < âˆ such that
max

zâˆˆSI (0,Î·M )

|mÂµ1 âŠÂµ2 (z)| â‰¤ M .

(3.9)

Lemma 3.2. Let Âµ1 , Âµ2 be two compactly supported probability measures on R satisfying (3.7), for some L < âˆ, and assume that both are supported at more than one point. Let
I âŠ‚ BÂµ1 âŠÂµ2 be a compact non-empty interval. Then there is a constant K < âˆ such that

K
K
,
max |Ï‰2 (z)| â‰¤
.
(3.10)
2
zâˆˆSI (0,Î·M )
2
zâˆˆSI (0,Î·M )
The constant K depends on the constant Î·M and on the interval I as well as on the measures
Âµ1 , Âµ2 through the constants Îº0 in (3.8) and the constant L in (3.7).
max

|Ï‰1 (z)| â‰¤

Proof. We start by noticing that there is a constant Îº1 > 0 such that
Z
Z
Î· fÂµ1 âŠÂµ2 (x)dx
Î· d(Âµ1 âŠ Âµ2 )(x)
â‰¥
â‰¥ Îº1 ,
Im mÂµ1 âŠÂµ2 (z) =
2
2
2
2
I (x âˆ’ E) + Î·
R (x âˆ’ E) + Î·

(3.11)

uniformly in z = E + iÎ· âˆˆ SI (0, Î·M ), where we used (3.8). Thus by subordination we have

Z

dÂµ1 (a) 
â‰¥ Îº1 ,
(3.12)
min 
min |mÂµ1 âŠÂµ2 (z)| =
a âˆ’ Ï‰2 (z) 
zâˆˆSI (0,Î·M )
zâˆˆSI (0,Î·M )
R

since mÂµ1 âŠÂµ2 (z) = âˆ’1/FÂµ1 âŠÂµ2 (z) by (2.6).
On the other hand, Âµ1 is supported on the interval [âˆ’L, L]; see (3.7). Hence, using (3.12),
|Ï‰2 (z)| must be bounded from above on SI (0, Î·M ). Interchanging the roÌ‚les of the indices 1
and 2, we also get that |Ï‰1 (z)| is bounded from above on SI (0, Î·M ).


11

Having established upper bounds on the subordination functions, we show that their
imaginary parts are uniformly bounded from below on the domain SI (0, Î·M ). The proof
relies on inequality (3.1).
Lemma 3.3. Let Âµ1 , Âµ2 be two probability measures on R satisfying (3.7), for some L < âˆ,
and assume that neither of them is only supported at a single point. Let I âŠ‚ BÂµ1 âŠÂµ2 be a
compact non-empty interval. Then there is a strictly positive constant k > 0 such that
min

zâˆˆSI (0,Î·M )

Im Ï‰1 (z) â‰¥ 2k ,

min

zâˆˆSI (0,Î·M )

Im Ï‰2 (z) â‰¥ 2k .

(3.13)

Remark 3.1. The constant k in (3.13) depends on the interval I through the constants Îº0
in (3.8) and M in (3.9). It further depends on Î·M , as well as on Ïƒ(Âµ1 , K2 ) and Ïƒ(Âµ2 , K1 )
in (3.1), with
Ki = {u âˆˆ C+ : u = Ï‰i (z) , z âˆˆ SI (0, Î·M )} ,

i = 1, 2 .

(3.14)

Proof of Lemma 3.3. First note that there is Îº1 > 0 such that Im mÂµ1 âŠÂµ2 (z) â‰¥ Îº1 for all
z âˆˆ SI (0, Î·M ); c.f., (3.11). Moreover, there is M < âˆ such that |mÂµ1 âŠÂµ2 (z)| â‰¤ M for all
z âˆˆ SI (0, Î·M ); c.f., (3.9). Recall from (2.5) and (2.6) that
Ï‰1 (z) + Ï‰2 (z) = z âˆ’

1

mÂµ1 âŠÂµ2 (z)

,

z âˆˆ C+ .

(3.15)

Hence, considering the imaginary part, we notice from (3.9) that there is Îº2 > 0 such that
min

zâˆˆSI (0,Î·M )

(Im Ï‰1 (z) + Im Ï‰2 (z)) â‰¥ Îº2 .

(3.16)

It remains to show that Im Ï‰1 and Im Ï‰2 are separately bounded from below. To do so we
invoke (3.1) and assume by contradiction that Im Ï‰1 (z) â‰¤ Ç«, for some small 0 â‰¤ Ç« < Îº2 /2.
We must thus have Im Ï‰2 (z) â‰¥ Îº2 /2. Since Âµ1 is assumed not to be a single point mass,
Lemma 3.1 assures that
Im Ï‰2 (z)
,
z âˆˆ SI (0, Î·M ) ,
(3.17)
Im FÂµ1 (Ï‰2 (z)) â‰¥
1 âˆ’ Ïƒ(Âµ1 , K2 )
with 0 < Ïƒ(Âµ1 , K2 ) < 1, where K2 denotes the image of SI (0, Î·M ) under the map Ï‰2 (which
is necessarily compact by Lemma 3.2). On the other hand, (2.11) implies
Im FÂµ1 (Ï‰2 (z)) = Im Ï‰2 (z) + Im Ï‰1 (z) âˆ’ Im z ,

z âˆˆ C+ .

(3.18)

Since Im Ï‰1 (z) â‰¥ Im z, by Proposition 2.1, we get, by comparing (3.18) and (3.17), a contradiction with the assumption that Im Ï‰1 (z) â‰¤ Ç«, for sufficiently small Ç«. Repeating the
argument with the roÌ‚les of the indices 1 and 2 interchanged, we get (3.13).

3.2. Linear stability of (2.11). Having established lower and upper bounds on the subordination functions Ï‰1 , Ï‰2 , we now turn to the stability of the system Î¦Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) = 0.
Remember that we call the system linearly S-stable at (Ï‰1 , Ï‰2 ) if Î“Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 ) â‰¤ S,
where Î“Âµ1 ,Âµ2 is defined in (2.12).
Lemma 3.4. Let Âµ1 , Âµ2 be two probability measures on R satisfying (3.7) for some L < âˆ.
Assume that neither of them is a single point mass and that at least one of them is supported
at more than two points. Let I âŠ‚ BÂµ1 âŠÂµ2 be a compact non-empty interval.
Then, there is a finite constant S such that
max

zâˆˆSI (0,Î·M )

Î“Âµ1 ,Âµ2 (Ï‰1 (z), Ï‰2 (z)) â‰¤ S ,

(3.19)

12

and
max

zâˆˆSI (0,Î·M )

|Ï‰1â€² (z)| â‰¤ 2S ,

max

zâˆˆSI (0,Î·M )

|Ï‰2â€² (z)| â‰¤ 2S ,

(3.20)

where Ï‰1 (z), Ï‰2 (z) are the solutions to Î¦Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) = 0.
Remark 3.2. Lemma 3.4 is the first instance where we use that at least one of Âµ1 and Âµ2
is supported at more than two points. For definiteness, we assume that Âµ1 is supported
at more than two points. The constant S in (3.19) depends on the interval I through the
constant Îº0 in (3.8), on the constants Î·M , L in (3.7), Ïƒ(Âµ1 , K2 ) and Ïƒ(Âµ2 , K2 ), as well as on
Ïƒ
e(Âµ1 , K2 ) of (3.2) with K2 defined in (3.14).
Proof of Lemma 3.4. Using (2.12) and Cramerâ€™s rule, Î“ â‰¡ Î“Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) equals


1
âˆ’1

Î“ = 
â€²
â€²
â€²

1 âˆ’ (FÂµ1 (Ï‰2 ) âˆ’ 1)(FÂµ2 (Ï‰1 ) âˆ’ 1)  âˆ’FÂµ2 (Ï‰1 (z)) + 1

âˆ’FÂµâ€² 1 (Ï‰2 (z)) + 1
âˆ’1



.


(3.21)

As above, we assume for definiteness that Âµ1 is supported at more than two points. We first
focus on FÂµâ€² 1 (Ï‰2 ). Recalling the definition of K2 from Remark 3.1 and invoking (3.2), we
obtain
 Im FÂµ1 (Ï‰2 (z)) âˆ’ Im Ï‰2 (z)
,
(3.22)
e(Âµ1 , K2 )
|FÂµâ€² 1 (Ï‰2 (z)) âˆ’ 1| â‰¤ 1 âˆ’ Ïƒ
Im Ï‰2 (z)
for all z âˆˆ SI (0, Î·M ), where 0 < Ïƒ
e (Âµ1 , K2 ) < 1. Abbreviating Ïƒ
e â‰¡ Ïƒ
e(Âµ1 , K2 ) and using
Î¦Âµ1 ,Âµ2 (Ï‰1 (z), Ï‰2 (z), z) = 0, we thus have
e)
|FÂµâ€² 1 (Ï‰2 (z)) âˆ’ 1| â‰¤ (1 âˆ’ Ïƒ

Im Ï‰1 (z)
,
Im Ï‰2 (z)

z âˆˆ SI (0, Î·M ) .

(3.23)

z âˆˆ C+ ,

(3.24)

Reasoning in the similar way (c.f., (4.9)), we also obtain
|FÂµâ€² 2 (Ï‰1 (z)) âˆ’ 1| â‰¤

Im Ï‰2 (z)
,
Im Ï‰1 (z)

where the inequality may saturate here since we do not exclude Âµ2 being supported at two
points only. Multiplying (3.23) and (3.24), we get
max

zâˆˆSI (0,Î·M )

e.
|FÂµâ€² 1 (Ï‰2 (z)) âˆ’ 1| |FÂµâ€² 2 (Ï‰1 (z)) âˆ’ 1| â‰¤ 1 âˆ’ Ïƒ

(3.25)

Using Lemma 3.2 and Lemma 3.3, we also have from (3.23) and (3.24) that
max

zâˆˆSI (0,Î·M )

|FÂµâ€² i (Ï‰j (z)) âˆ’ 1| â‰¤

K
,
4k

{i, j} = {1, 2} .

(3.26)

Hence, bounding the operator norm by the Hilbert-Schmidt norm in (3.21), we obtain
by (3.26) and (3.25) that
âˆš 
 K 2 1/2
2
max Î“Âµ1 ,Âµ2 (Ï‰1 (z), Ï‰2 (z)) â‰¤
1+
=: S ,
(3.27)
zâˆˆSI (0,Î·M )
Ïƒ
e
4k

with finite constant S. This proves (3.19).
The estimates in (3.20) follow by differentiating the equation Î¦Âµ1 ,Âµ2 (Ï‰1 (z), Ï‰2 (z), z) = 0
with respect to z. We get
 â€²

 

âˆ’1
FÂµâ€² 1 (Ï‰2 (z)) âˆ’ 1
Ï‰1 (z)
1
=
.
(3.28)
âˆ’1
FÂµâ€² 2 (Ï‰1 (z)) âˆ’ 1
Ï‰2â€² (z)
1
From (3.19) we know that Î¦ is uniformly S-stable and we get (3.20) by inverting (3.28). 

13

Remark 3.3. The crucial estimate in the proof above is (3.25). An alternative proof of (3.25)
under the assumptions that both Âµ1 and Âµ2 are supported at more than two points was
pointed out by an anonymous referee. From (2.5) we observe that the subordination function Ï‰1 (z) appears, for fixed z âˆˆ C+ , as the fixed point of the map Fz : C+ â†’ C+ ,
u 7â†’ Fz (u) := FÂµ1 (FÂµ2 (u) âˆ’ u + z) âˆ’ FÂµ2 (u) âˆ’ u + z .

(3.29)

+

Indeed, assuming that Ï‰1 âˆˆ C and that Âµ1 , Âµ2 are supported at least at three points
(so that FÂµ1 (z) âˆ’ z and FÂµ2 (z) âˆ’ z are not MoÌˆbius transformations), the fixed point Ï‰1 (z)
is attracting as was shown in [4]. Thus, for any fixed k > 0, the Schwarzâ€“Pick Theorem
b of {z âˆˆ C+ âˆª R : Im Ï‰1 (z), Im Ï‰2 (z) â‰¥ 2k}
and (2.5) imply that for any compact subset K
b < 1 such that |F â€² (Ï‰2 (z) âˆ’ 1||F â€² (Ï‰1 (z) âˆ’ 1| â‰¤ Ïƒ
b < 1, for any
there is a constant Ïƒ
b(K)
b(K)
1
2
b
z âˆˆ K. Thus, under the assumption that Âµ1 and Âµ2 are both supported at least at three
points, (3.25) follows from Lemma 3.2 and Lemma 3.3.
Collecting the results of this section, we obtain the proof of Theorem 2.5.

Proof of Theorem 2.5. Lemma 3.3 proves (2.14). Lemma 3.4 proves (2.15).



4. Perturbations of the system (2.11)
In this section, we study perturbations of the system Î¦Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) = 0, where Âµ1 ,
Âµ2 denote general compactly supported probability measures on R. The main results of
this section, Proposition 4.1 below, is used repeatedly in the continuity argument to prove
Theorem 2.8. Yet, as noted in Corollary 2.6, it is of interest itself and it is also used in [3].
Proposition 4.1. Fix z0 âˆˆ C+ . Assume that the functions Ï‰
e1 , Ï‰
e2 , re1 , re2 : C+ â†’ C satisfy
Im Ï‰
e1 (z0 ) > 0, Im Ï‰
e2 (z0 ) > 0 and
Ï‰1 (z0 ), Ï‰
e2 (z0 ), z0 ) = re(z0 ) ,
Î¦Âµ1 ,Âµ2 (e

(4.1)

where re(z) := (e
r1 (z), re2 (z))âŠ¤ . Assume moreover that there is Î´ âˆˆ [0, 1] such that
|e
Ï‰1 (z0 ) âˆ’ Ï‰1 (z0 )| â‰¤ Î´ ,

|e
Ï‰2 (z0 ) âˆ’ Ï‰2 (z0 )| â‰¤ Î´ ,

(4.2)

where Ï‰1 (z), Ï‰2 (z) solve the unperturbed system Î¦Âµ1 ,Âµ2 (Ï‰1 , Ï‰2 , z) = 0. Assume that there
is a constant S such that Î¦ is linearly S-stable at (Ï‰1 (z0 ), Ï‰2 (z0 )), and assume in addition
that there are strictly positive constants K and k with k > Î´ and with k 2 > Î´KS such that
0 < 2k â‰¤ Im Ï‰1 (z0 ) â‰¤ K ,

0 < 2k â‰¤ Im Ï‰2 (z0 ) â‰¤ K .

Then we have the bounds

|e
Ï‰1 (z0 ) âˆ’ Ï‰1 (z0 )| â‰¤ 2Ske
r(z0 )k ,

|e
Ï‰2 (z0 ) âˆ’ Ï‰2 (z0 )| â‰¤ 2Ske
r(z0 )k .

(4.3)
(4.4)

Proof. Combining (4.3) and (4.2) with Î´ < k, we get
Im Ï‰
e1 (z0 ) â‰¥ k ,

Im Ï‰
e2 (z0 ) â‰¥ k .

(4.5)

Next, we bound higher derivatives of Fi â‰¡ FÂµi , i = 1, 2. We first note that by the Nevanlinna
representation (3.3) we have
Z
Im Fi (Ï‰)
1 + x2
Ï‰ âˆˆ C+ ,
i = 1, 2 .
(4.6)
dÏFi (x) ,
=1+
2
Im Ï‰
R |x âˆ’ Ï‰|
On the other hand, we also have from (3.3) that
Z
1 + x2
dÏFi (x) ,
|Fiâ€² (Ï‰) âˆ’ 1| â‰¤
2
R |x âˆ’ Ï‰|

Ï‰ âˆˆ C+ ,

i = 1, 2 ,

(4.7)

14

and analogously for higher derivatives, n â‰¥ 1,
Z
Z
1 + x2
1
1 + x2
(n)
|Fi (Ï‰)| â‰¤
(x)
â‰¤
dÏ
dÏFi (x) ,
Fi
n+1
nâˆ’1
2
(Im Ï‰)
R |x âˆ’ Ï‰|
R |x âˆ’ Ï‰|

(4.8)

Ï‰ âˆˆ C+ , i = 1, 2. Thus, combining (4.7), (4.6) and (2.11) we get
|Fiâ€² (Ï‰j (z)) âˆ’ 1| â‰¤

Im Ï‰i (z) âˆ’ Im z
Im Fi (Ï‰j (z)) âˆ’ Im Ï‰j (z)
=
,
Im Ï‰j (z)
Im Ï‰j (z)

{i, j} = {1, 2} , (4.9)

z âˆˆ C+ , and similarly, starting from (4.8),
(n)

|Fi

(Ï‰j (z))| â‰¤

Im Ï‰i (z) âˆ’ Im z
,
(Im Ï‰j (z))n

z âˆˆ C+ ,

{i, j} = {1, 2} .

(4.10)

Let â„¦i (z) := Ï‰
ei (z) âˆ’ Ï‰i (z), i = 1, 2, and â„¦ := (â„¦1 , â„¦2 )âŠ¤ . Fixing z = z0 and Taylor
expanding F1 (e
Ï‰2 (z0 )) around Ï‰2 (z0 ) we get
X 1 (n)
F1â€² (Ï‰2 (z0 ))â„¦2 (z0 ) âˆ’ â„¦1 (z0 ) âˆ’ â„¦2 (z0 ) = re1 (z) âˆ’
F (Ï‰2 (z0 ))â„¦2 (z0 )n .
(4.11)
n! 1
nâ‰¥2

Recalling that kâ„¦(z0 )k/2k â‰¤ Î´/k < 1 and using (4.10) together with (4.3), we obtain
from (4.11) the estimate

K
kâ„¦(z0 )k2 ,
(4.12)
4k 2
and the analogous expansion with the roÌ‚les of the indices 1 and 2 interchanged. We therefore
obtain from (2.12) and from solving the linearized equation that
|F1â€² (Ï‰2 (z0 ))â„¦2 (z0 ) âˆ’ â„¦1 (z0 ) âˆ’ â„¦2 (z0 )| â‰¤ ke
r(z0 )k +

KS
kâ„¦(z0 )k2 .
(4.13)
4k 2
Thus, we have the dichotomy that either kâ„¦(z0 )k â‰¤ 2S ke
r k or 2(KS)âˆ’1 k 2 â‰¤ kâ„¦(z0 )k. Since
2
k > Î´KS by assumption, the second alternative contradicts kâ„¦(z0 )k â‰¤ 2Î´. This proves the

estimates in (4.4).
kâ„¦(z0 )k â‰¤ Ske
r(z0 )k +

Ï‰i âˆ’ Ï‰i | â‰¤ Î´; see (4.2). The next lemma
In Proposition 4.1 we assumed the apriori bound |e
shows that we may drop this assumption, for spectral parameters z with sufficiently large
imaginary part, at the price of assuming effective lower bounds on Im Ï‰
ei . This statement
will be used as an initial input to start the continuity argument in Section 6.
Lemma 4.2. Assume there is a (large) Î·e0 > 0 such that for any z âˆˆ C+ with Im z â‰¥ Î·e0 the
analytic functions Ï‰
e1 , Ï‰
e2 , re1 , re2 : C+ â†’ C satisfy
and

Im Ï‰
e1 (z) âˆ’ Im z â‰¥ 2ke
r(z)k ,

Im Ï‰
e2 (z) âˆ’ Im z â‰¥ 2ke
r(z)k .

Ï‰1 (z), Ï‰
e2 (z), z) = re(z) ,
Î¦Âµ1 ,Âµ2 (e

where re(z) := (e
r1 (z), re2 (z))âŠ¤ .
Then there is a constant Î·0 > 0, with Î·0 â‰¥ Î·e0 , such that
|e
Ï‰1 (z) âˆ’ Ï‰1 (z)| â‰¤ 2ke
r(z)k ,

|e
Ï‰2 (z) âˆ’ Ï‰2 (z)| â‰¤ 2ke
r(z)k ,

(4.14)

(4.15)

(4.16)

on the domain {z âˆˆ C+ : Im z â‰¥ Î·0 }, where Ï‰1 and Ï‰2 are the subordination functions
associated with Âµ1 and Âµ2 . The constant Î·0 depends on the measures Âµ1 and Âµ2 , and on the
function re through the constant Î·e0 > 0.

15

Proof. Recall the Nevanlinna representation (3.3) for FÂµ1 and FÂµ2 . Since Âµ1 and Âµ2 are
compactly supported, we have, as Im Ï‰ Ö€ âˆ,
FÂµ2 (Ï‰) âˆ’ Ï‰ = a2 + O(|Ï‰|âˆ’1 ) ,

(4.17)

with a1 â‰¡ aFÂµ1 and a2 â‰¡ aFÂµ2 . There are thus se1 , se2 : C+ â†’ C such that

 

a1 + se1 (z) âˆ’ Ï‰
e1 (z) + z
re1 (z)
Ï‰1 (z), Ï‰
e2 (z), z) =
Î¦Âµ1 ,Âµ2 (e
=
,
a2 + se2 (z) âˆ’ Ï‰
e2 (z) + z
re2 (z)

(4.18)

FÂµ1 (Ï‰) âˆ’ Ï‰ = a1 + O(|Ï‰|âˆ’1 ) ,

with

se1 (z) = O(|e
Ï‰2 (z)|âˆ’1 ) ,

se2 (z) = O(|e
Ï‰1 (z)|âˆ’1 ) ,

(4.19)

as Im z Ö€ âˆ. It follows immediately that Ï‰
e1 (z) = O(Im z) and Ï‰
e2 (z) = O(Im z), as
Im z Ö€ âˆ. Thus, recalling the definition of Î“Âµ1 ,Âµ2 in (2.12), we get
Ï‰1 (z), Ï‰
e2 (z)) = 1 + O(Î· âˆ’2 ) ,
Î“Âµ1 ,Âµ2 (e

(4.20)

as Î· = Im z Ö€ âˆ. In particular, we obtain

Ï‰1 (z), Ï‰
e2 (z))kkÎ¦(e
Ï‰1 (z), Ï‰
e2 (z), z)k
k((DÎ¦)âˆ’1 Î¦)(e
Ï‰1 (z), Ï‰
e2 (z), z)k â‰¤ kÎ“Âµ1 ,Âµ2 (e
â‰¤ 2ke
r(z)k ,

(4.21)

for Im z sufficiently large. From (4.8) and (4.17), we also get
(Ï‰)| â‰¤
|FÂµ(2)
i

Im FÂµi (Ï‰) âˆ’ Im Ï‰
= O((Im Ï‰)âˆ’3 ) ,
(Im Ï‰)2

Ï‰ âˆˆ C+ ,

i = 1, 2 ,

(4.22)

as Im Ï‰ Ö€ âˆ. Thus the matrix of second derivatives of Î¦ given by
!

 2
(2)
âˆ‚2Î¦
âˆ‚ Î¦
0
FÂµ1 (Ï‰2 )
2
,
(Ï‰1 , Ï‰2 , z) ,
(Ï‰1 , Ï‰2 , z) =
D Î¦(Ï‰1 , Ï‰2 ) :=
(2)
âˆ‚Ï‰12
âˆ‚Ï‰22
0
FÂµ2 (Ï‰1 )
satisfies kD2 Î¦(e
Ï‰1 (z), Ï‰
e2 (z))k = O(Im z)âˆ’3 , as Im z Ö€ âˆ. Hence, choosing Î·0 > 0 sufficiently
large, we achieve that
r(z)k kD2 Î¦(e
Ï‰1 (z), Ï‰
e2 (z))k <
s0 := 2ke

1
,
2

on the domain {z âˆˆ C+ : Im z â‰¥ Î·0 }. Thus, by the Newton-Kantorovich theorem
(see, e.g., Theorem 1 in [25]), there are for every such z unique Ï‰
b1 (z), Ï‰
b2 (z) such that
Ï‰1 (z), Ï‰
b2 (z), z) = 0, with
Î¦Âµ1 ,Âµ2 (b
âˆš
1 âˆ’ 1 âˆ’ 2s0
ke
r(z)k â‰¤ 2ke
r(z)k ,
i = 1, 2 .
(4.23)
|e
Ï‰i (z) âˆ’ Ï‰
bi (z)| â‰¤
s0

Finally, we note that Im Ï‰
b1 (z) = Im Ï‰
b1 (z)âˆ’Im Ï‰
e1 (z)+Im Ï‰
e1 â‰¥ Im z, by (4.14), for Im z â‰¥ Î·0 .
Ï‰1 (z), Ï‰
b2 (z)) 6= 0,
Similarly, Im Ï‰
b2 (z) â‰¥ Im z, for Im z â‰¥ Î·0 . It further follows that Î“Âµ1 ,Âµ2 (b
for all z âˆˆ C+ with Im z â‰¥ Î·0 , thus Ï‰
b1 (z) and Ï‰
b2 (z) are analytic on {z âˆˆ C : Im z > Î·0 }
since FÂµ1 and FÂµ2 are. Finally, using (4.17) with Ï‰ = Ï‰
b1 , Ï‰ = Ï‰
b2 respectively, we see that
Im Ï‰
b1 (iÎ·)
Im Ï‰
b1 (iÎ·)
= lim
= 1.
Î·Ö€âˆ
Î·Ö€âˆ
iÎ·
iÎ·
lim

b1 (z), Ï‰
b2 (z) agree with Ï‰1 (z), Ï‰2 (z) on
Thus, by the uniqueness claim in Proposition 2.1, Ï‰

the domain {z âˆˆ C+ : Im z â‰¥ Î·0 }. This proves (4.16) from (4.23).

16

5. Proof of Theorem 2.7
In the setup of Theorem 2.7 we have two pairs of probability measures on R, ÂµÎ± , ÂµÎ² and
ÂµA , ÂµB , where we consider ÂµÎ± , ÂµÎ² as â€œreferenceâ€ measures (in the sense that they satisfy
the assumptions of Theorem 2.7), while ÂµA , ÂµB are arbitrary. Under the assumptions of
Theorem 2.7 we can apply Theorem 2.5 with the choices ÂµÎ± = Âµ1 and ÂµÎ² = Âµ2 .
Recall from (2.13) the definition of the domain SI (a, b), a â‰¤ b.

Lemma 5.1. Let ÂµA , ÂµB and ÂµÎ± , ÂµÎ² be the probability measures from (2.24) and (2.25)
satisfying the assumptions of Theorem 2.7. Let Ï‰A , Ï‰B and Ï‰Î± , Ï‰Î² denote the associated subordination functions by Proposition 2.1. Let I âŠ‚ BÂµÎ± âŠÂµÎ² be a compact non-empty interval.
Fix 0 < Î·M < âˆ.
Then there are a (small) constant b0 > 0 and a (large) constant K1 < âˆ, both depending
on the measures ÂµÎ± and ÂµÎ² , on the interval I and on the constant Î·M , such that whenever
dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² ) â‰¤ b0 ,

holds, then

(5.1)

dL (ÂµA , ÂµÎ± )
dL (ÂµB , ÂµÎ² )
+ K1
,
(Im Ï‰Î² (z))2
(Im Ï‰Î± (z))2
dL (ÂµB , ÂµÎ² )
dL (ÂµA , ÂµÎ± )
+ K1
,
|Ï‰B (z) âˆ’ Ï‰Î² (z)| â‰¤ K1
(Im Ï‰Î² (z))2
(Im Ï‰Î± (z))2
|Ï‰A (z) âˆ’ Ï‰Î± (z)| â‰¤ K1

(5.2)

hold uniformly on SI (0, Î·M ). In particular, choosing b â‰¤ b0 sufficiently small and assuming
that dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² ) â‰¤ b, we have,
max

|Ï‰A (z)| â‰¤ K ,

zâˆˆSI (0,Î·M )

Im Ï‰A (z) â‰¥ k ,

zâˆˆSI (0,Î·M )

zâˆˆSI (0,Î·M )

min

zâˆˆSI (0,Î·M )

max

|Ï‰B (z)| â‰¤ K ,

(5.3)

min

Im Ï‰B (z) â‰¥ k ,

(5.4)

where K and k are the constant from Lemma 3.2 and Lemma 3.3, respectively.
Remark 5.1. Armed with the conclusions of Theorem 2.5, our proof follows closely the arguments of [30]. We further remark that the main argument in the proof of Lemma 5.1 is different from the ones given in Section 4: it crucially relies on the global uniqueness of solutions
on the upper half plane for both systems, Î¦ÂµÎ± ,ÂµÎ² (Ï‰Î± , Ï‰Î² , z) = 0 and Î¦ÂµA ,ÂµB (Ï‰A , Ï‰B , z) = 0,
asserted by Proposition 2.1.
Proof of Lemma 5.1. We first write the system Î¦ÂµÎ± ,ÂµÎ² (Ï‰Î± (z), Ï‰Î² (z), z) = 0 as
Î¦ÂµA ,ÂµB (Ï‰Î± (z), Ï‰Î² (z), z) = r(z) ,
with
r(z) â‰¡



rA (z)
rB (z)



:=



z âˆˆ C+ ,

FÂµA (Ï‰Î² (z)) âˆ’ FÂµÎ± (Ï‰Î² (z))
FÂµB (Ï‰Î± (z)) âˆ’ FÂµÎ² (Ï‰Î± (z))



.

(5.5)

From Lemma 3.3, we know that the imaginary parts of the subordination functions Ï‰Î± , Ï‰Î²
are uniformly bounded from below on SI (0, Î·M ). Next, integration by parts reveals that for
any probability measures Âµ1 and Âµ2 ,


1
dL (Âµ1 , Âµ2 )
1+
,
z âˆˆ C+ ,
(5.6)
|mÂµ1 (z) âˆ’ mÂµ2 (z)| â‰¤ c
Im z
Im z
with some numerical constant c; see, e.g., [31]. Thus,
|FÂµA (Ï‰Î² (z)) âˆ’ FÂµÎ± (Ï‰Î² (z))| =

dL (ÂµA , ÂµÎ± )
|mÂµA (Ï‰Î² (z))) âˆ’ mÂµÎ± (Ï‰Î² (z))|
,
â‰¤C
|mÂµA (Ï‰Î² (z))mÂµÎ± (Ï‰Î² (z))|
(Im Ï‰Î² (z))2

(5.7)

17

with a new constant C that depends on the lower bound of Im mÂµÎ± (Ï‰Î² (z)) = Im mÂµÎ± âŠÂµÎ² (z)
which is strictly positive on SI (0, Î·M ); c.f., (3.12). Here we used
Im mÂµA (Ï‰Î² (z)) â‰¥ Im mÂµÎ± (Ï‰Î² (z)) âˆ’ |Im mÂµA (Ï‰Î² (z)) âˆ’ Im mÂµÎ± (Ï‰Î² (z))| â‰¥

1
Im mÂµÎ± (Ï‰Î² (z)) ,
2

as follows from (5.6) for small enough dL (ÂµA , ÂµÎ± ) â‰¤ b0 . Repeating the argument with the
roÌ‚les of A and B interchanged, we arrive at
|rA (z)| â‰¤ C

dL (ÂµA , ÂµÎ± )
,
(Im Ï‰Î² (z))2

|rB (z)| â‰¤ C

dL (ÂµB , ÂµÎ² )
,
(Im Ï‰Î± (z))2

z âˆˆ SI (0, Î·M ) ,

(5.8)

for some constant C. Recalling the definition of Î“ in (2.12), we get for sufficiently small b0 ,
Î“ÂµA ,ÂµB (Ï‰Î± , Ï‰Î² ) â‰¤ 2Î“ÂµÎ± ,ÂµÎ² (Ï‰Î± , Ï‰Î² ) â‰¤ 2S ,

(5.9)

where S is from Lemma 3.4, and where we also use Lemma 3.3 and the assumption dL (ÂµA , ÂµÎ± )+
dL (ÂµB , ÂµÎ² ) â‰¤ b0 . The Newtonâ€“Kantorovich theorem then implies (c.f., the proof of Lemma 4.2
for a similar application) that there are Ï‰
bA (z), Ï‰
bB (z) satisfying
and

Ï‰A (z), Ï‰
bB (z), z) = 0 ,
Î¦ÂµA ,ÂµB (b

|Ï‰Î± (z) âˆ’ Ï‰
bA (z)| â‰¤ 2kr(z)k ,

z âˆˆ SI (0, Î·M ) ,

(5.10)

|Ï‰Î² (z) âˆ’ Ï‰
bB (z)| â‰¤ 2kr(z)k ,

(5.11)

z âˆˆ SI (0, Î·M ). Invoking (5.8), (5.11) and Lemma 3.3, we see that Ï‰
bA (z) âˆˆ C+ and Ï‰
bB (z) âˆˆ
+
C , for any z âˆˆ SI (0, Î·M ) if b0 is sufficiently small. Yet, by the global uniqueness of solutions
bA (z) = Ï‰A (z), Ï‰
bB (z) = Ï‰B (z), z âˆˆ C+ . Together
asserted in Proposition 2.1, we must have Ï‰
with (5.11) and (5.8) this implies (5.2) and concludes the proof. Then, choosing b0 sufficiently
small, (5.3) and (5.4) are direct consequences of (5.2), Lemma 3.2 and Lemma 3.3.

With the aid of Lemma 3.4, we prove the stability of the system Î¦ÂµA ,ÂµB (Ï‰A , Ï‰B , z) = 0.
Corollary 5.2. Under the assumptions of Lemma 5.1, there is a (small) constant b1 > 0,
depending on the measures ÂµÎ± and ÂµÎ² , on the interval I and on the constant Î·M , such that
dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² ) â‰¤ b1

(5.12)

implies
max

zâˆˆSI (0,Î·M )

Î“ÂµA ,ÂµB (Ï‰A (z), Ï‰B (z)) â‰¤ 2S

(5.13)

and
max

zâˆˆSI (0,Î·M )

â€²
|Ï‰A
(z)| â‰¤ 4S ,

max

zâˆˆSI (0,Î·M )

â€²
|Ï‰B
(z)| â‰¤ 4S ,

(5.14)

where Ï‰A (z), Ï‰B (z) satisfy Î¦ÂµA ,ÂµB (Ï‰A (z), Ï‰B (z), z) = 0 and S is the constant in Lemma 3.4.
Proof. Let Î“ â‰¡ Î“ÂµA ,ÂµB (Ï‰A (z), Ï‰B (z)). Analogously to (3.21), we have


1
âˆ’1

Î“ = 
â€²
â€²
â€²

1 âˆ’ (FÂµA (Ï‰B ) âˆ’ 1)(FÂµB (Ï‰A ) âˆ’ 1)  âˆ’FÂµB (Ï‰A (z)) + 1

âˆ’FÂµâ€² A (Ï‰B (z)) + 1
âˆ’1



.


(5.15)

Using the bounds (5.3) and (5.4) for sufficiently small b1 , we follow, mutatis mutandis, the
proof of Lemma 3.4 to get (5.13). The estimates in (5.14) then follow as in Lemma 3.4. 
We are now ready to complete the proof of Theorem 2.7.

18

Proof of Theorem 2.7. Recall that mÂµA âŠÂµB (z) = mÂµA (Ï‰B (z)), z âˆˆ C+ . We first note that


dL (ÂµA , ÂµÎ± )
1
|mÂµA (Ï‰B (z)) âˆ’ mÂµÎ± (Ï‰B (z))| â‰¤ C
1+
,
Im Ï‰Î² (z)
Im Ï‰Î² (z)
for some numerical constant C; c.f., (5.6). Thus using (5.4) we get
|mÂµA (Ï‰B (z)) âˆ’ mÂµÎ± (Ï‰B (z))| â‰¤ K2 k âˆ’2 dL (ÂµA , ÂµÎ± ) ,

z âˆˆ SI (0, Î·M ) ,

for some numerical constant K2 . Choosing b as in Lemma 5.1 and assuming that dL (ÂµA , ÂµÎ± )+
dL (ÂµA , ÂµÎ² ) â‰¤ b, we get from (5.2) that
|mÂµÎ± (Ï‰B (z)) âˆ’ mÂµÎ± (Ï‰Î² (z))| â‰¤ K1 k âˆ’4 ((dL (ÂµA , ÂµÎ± ) + dL (ÂµA , ÂµÎ² )) ,

Setting Z := K1 k

âˆ’4

+ K2 k

âˆ’2

z âˆˆ SI (0, Î·M ) .

we thus obtain (2.22).



Remark 5.2. Note that under the assumptions of Theorem 2.7, we have, for dL (ÂµA , ÂµÎ± ) +
dL (ÂµA , ÂµÎ² ) â‰¤ b, the bounds
Îº1 /2 â‰¤ |mÂµA âŠÂµB (z)| â‰¤ 1/k ,

(5.16)

uniformly on SI (0, Î·M ) with Îº1 > 0 from (3.12) and k > 0 from (5.4).
6. Proof of Theorem 2.8
Before we immerse into the details of the proof of Theorem 2.8, we outline how Theorem 2.5 and the local stability results of Section 4 in combination with concentration
estimates for the unitary groups lead to the local law in (2.28).
6.1. Outline of proof. We briefly outline of our proof when U is Haar distributed on U (N ).
Since we are interested in the tracial quantity mH of H = A + U BU âˆ— , we may replace H
by the matrix
e := V AV âˆ— + U BU âˆ— ,
H

(6.1)

where V is another Haar unitary independent from U . By cyclicity of the trace we have mH =
mHe and we study mHe below. We emphasize that this replacement is a convenient technicality which is not essential to our proof.
Using the shorthand
e := V AV âˆ— ,
A

we introduce the Green functions
e âˆ’ z)âˆ’1 ,
G e(z) := (A
A

e := U BU âˆ— ,
B

(6.2)

e âˆ’ z)âˆ’1 ,
GBe (z) := (B

For a given N Ã— N matrix Q, we introduce the function
fQ (z) := tr QGHe (z) ,

z âˆˆ C+ .

z âˆˆ C+ ,

(6.3)
(6.4)

e âˆ’ z)âˆ’1 is the Green function of H.
e We define the approximate subordination
where GHe = (H
c
c
functions, Ï‰A and Ï‰B , by setting
c
Ï‰A
(z) := z âˆ’

EfAe(z)
,
EmHe (z)

c
Ï‰B
(z) := z âˆ’

EfBe (z)
,
EmHe (z)

z âˆˆ C+ ,

(6.5)

where the expectation E is with respect to both Haar unitaries U and V . From the identity
e âˆ’ z)G e (z) = 1, z âˆˆ C+ , we then obtain the relation
(H
H
c
c
Ï‰A
(z) + Ï‰B
(z) âˆ’ z = âˆ’

1

EmHe (z)

,

z âˆˆ C+ ,

(6.6)

19

reminiscent to (c.f., (2.5)â€“(2.6))
Ï‰A (z) + Ï‰B (z) âˆ’ z = âˆ’

1
mAâŠB (z)

z âˆˆ C+ .

,

For the proof of Theorem 2.8, we decompose



mHe (z) âˆ’ mAâŠB (z) = mHe (z) âˆ’ EmHe (z) + EmHe (z) âˆ’ mAâŠB (z) ,

(6.7)

where we abbreviate mAâŠB â‰¡ mÂµA âŠÂµB . To control the fluctuation part, mHe (z) âˆ’ EmHe (z),
we rely on the Gromovâ€“Milman concentration inequality [26] for the unitary group; see (6.22)
below. To control the deterministic part, we first note that, by (6.6) and mAâŠB (z) =
c
mA (Ï‰B ((z)), bounding |EmHe (z) âˆ’ mAâŠB (z)| amounts to bounding |Ï‰A
(z) âˆ’ Ï‰A (z)| and
c
c
c
|Ï‰B (z) âˆ’ Ï‰B (z)|. We then show that Ï‰A (z) and Ï‰B (z) are both in the upper-half plane and
satisfy
c
c
(z), Ï‰B
(z), z) = r(z) ,
Î¦ÂµA ,ÂµB (Ï‰A

z âˆˆ SI (Î·m , Î·M ) ,

(6.8)

for some small error r(z) âˆˆ C+ , i.e., we consider (6.8) as a perturbation of the system Î¦ÂµA ,ÂµB (Ï‰A (z), Ï‰B (z), z) = 0; c.f., (2.10). The formal derivation of (6.8) goes back
to Pastur and Vasilchuk [33]. Using Proposition 4.1 (with rough a priori estimates on
c
c
|Ï‰A
(z) âˆ’ Ï‰A (z)| and |Ï‰B
(z) âˆ’ Ï‰B (z)| obtained from the continuity argument below) and
c
stability results of Theorem 2.5 and of Section 5, we then bound |Ï‰A
(z) âˆ’ Ï‰A (z)| and
c
|Ï‰B (z) âˆ’ Ï‰B (z)| in terms of r(z).
In sum, for fixed z âˆˆ C+ , our proof includes two parts: (i) estimation of the error r(z)
in (6.8) and (ii) concentration for mHe (z) around EmHe (z). Both parts rely on the estimates
c
c
EmHe (z) , Ï‰A
(z) , Ï‰B
(z) âˆ¼ 1 ,

c
c
Im Ï‰A
(z) , Im Ï‰B
(z) & 1 ,

z âˆˆ SI (Î·m , Î·M ) .

(6.9)

e by averaging
Note that the quantities in (6.9) are obtained from the Green function of H
with respect to the Haar measure. Similar bounds for mAâŠB , Ï‰A and Ï‰B were obtained in
Section 5. These latter quantities are defined directly from ÂµA and ÂµB via Proposition 2.1
To establish (6.9), we use a similar continuity argument as was used for Wigner matrices
in [24]: For Im z = Î·M sufficiently large, the estimates in (6.9) directly follow from definitions.
For z = E + iÎ·, with E âˆˆ I fixed, we decrease Î· = Î·M down to Î· = Î·m in steps of size
O(N âˆ’5 ), where, at each step, we invoke parts (i) and (ii). However, a direct application of
the Gromovâ€“Milman concentration inequality for part (i) does not allow to push Î· below
the mesoscopic scale Î· = N âˆ’1/2 . Indeed, the Gromovâ€“Milman inequality is effective if
L2 /N = o(1), where L is the Lipschitz constant of mHe (z) with respect to the Haar unitary V .
p
p
It is roughly bounded by tr |GHe (z)|4 /N , which in turn is trivially bounded by 1/ N Î· 4 ,
giving
the Î· â‰¥ N âˆ’1/2+Î³ , Î³ > 0, threshold.
However, in reality, the random quantity
p
p
tr |GHe (z)|4 /N is typically of order 1/ N Î· 3 as follows by combining the deterministic
estimate tr |GHe (z)|4 â‰¤ Î· âˆ’3 Im mHe (z) with a probabilistic order one bound for Im mHe (z).
Our key novelty here is to capitalize on this latter information. We introduce a smooth
cutoff that regularizes mHe (z) and then apply the Gromovâ€“Milman inequality for this regup
larized quantity. With the bound 1/ N Î· 3 for the Lipschitz constant, we get concentration
estimates down to scales Î· â‰¥ N âˆ’2/3+Î³ , Î³ > 0.
6.1.1. Notation. The following notation for high-probability estimates is suited for our purposes. A slightly different form was first used in [21].
Definition 6.1. Let
X = (X (N ) (v) : N âˆˆ N , v âˆˆ V (N ) ) ,

Y = (Y (N ) (v) : N âˆˆ N , v âˆˆ V (N ) )

(6.10)

20

be two families of nonnegative random variables where V (N ) is a possibly N -dependent parameter set. We say that Y stochastically dominates X, uniformly in v, if for all (small)
Ç« > 0 and (large) D > 0,

 [ 
(N )
Ç« (N )
X (v) > N Y
(v)
â‰¤ N âˆ’D ,
(6.11)
P
vâˆˆV (N )

for sufficiently large N â‰¥ N0 (Ç«, D). If Y stochastically dominates X, uniformly in v, we
write X â‰º Y . If we wish to indicate the set V (N ) explicitly, we write that X(v) â‰º Y (v) for
all v âˆˆ V (N ) .
6.2. Localized Gromovâ€“Milman concentration estimate. In this subsection, we derive concentration bounds for some key tracial quantities. They are tailored for the continuity
argument of Subsection 6.3 used to complete the proof of Theorem 2.8. The argument works
with U , V independent and both Haar distributed on U (N ) or on O(N ). Below, E denotes
the expectation with respect Haar measure.
In the rest of this section, we let I âŠ‚ BÂµÎ± âŠÂµÎ² denote the compact non-empty subset fixed
in Theorem 2.8. Also recall from Theorem 2.8 that we set Î·m = N âˆ’2/3+Î³ , Î³ > 0. Below we
choose the constant Î·M âˆ¼ 1 to be sufficiently large at first, but from the proof it will be clear
that we can eventually choose 0 < Î·M < âˆ arbitrary. Recall from (6.4) the notation fQ ,
where Q is an arbitrary N Ã— N matrix.
Proposition 6.2. Let Q be a given N Ã— N deterministic matrix with kQk . 1. Fix E âˆˆ I
and Î·b âˆˆ [Î·m , Î·M ]. Then
Im mHe (E + iÎ·) â‰º 1 ,

âˆ€Î· âˆˆ [b
Î· , Î·M ] ,

(6.12)

implies the concentration bound
1
.
Î· )| â‰º p
Î· ) âˆ’ EfV QV âˆ— (E + ib
|fV QV âˆ— (E + ib
N 2 Î·b3

(6.13)

The same concentration holds with V QV âˆ— replaced by U QU âˆ— .

Proof. For fixed E âˆˆ I, we consider z = E + iÎ· âˆˆ C+ as a varying spectral parameter and
use zb = E + ib
Î· for the specific choice in the lemma. By the definition of f(Â·) and cyclicity of
the trace, we have
âˆ’1
âˆ’1
= tr Q A + V âˆ— U BU âˆ— V âˆ’ z
,
(6.14)
fV QV âˆ— (z) = tr V QV âˆ— V AV âˆ— + U BU âˆ— âˆ’ z
where tr ( Â· ) stands for the normalized trace. For simplicity, we denote
W := V âˆ— U,

H := A + W BW âˆ— ,

GH (z) := (H âˆ’ z)âˆ’1 .

(6.15)

Observe that W is Haar distributed on U (N ), respectively O(N ), too. By cyclicity of the
trace we have tr GH (z) = tr GH (z) = mH (z). According to (6.14) and (6.15), we may regard
in the sequel fV QV âˆ— as a function of the Haar unitary matrix W by writing
h(z) = hW (z) := fV QV âˆ— (z) .
For any fixed (small) Îµ > 0, let Ï‡
b be a smooth cutoff supported on [0, 2N Îµ ], with Ï‡
b(x) = 1,
Îµ
x âˆˆ [0, N ], and with bounded derivatives. Since mH (z) = tr GH (z), we can regard mH (z)
as a function of W and write
Ï‡(z) = Ï‡W (z) := Ï‡
b(Im mH (z)) .

(6.16)

21

We then introduce a regularization, e
hW , of hW by setting
âŒˆâˆ’ log2 Î·âŒ‰

Y

e
h(z) = e
hW (z) := hW (z)

Ï‡W (E + i2n Î·) .

(6.17)

n=0

We will often drop the W subscript from the notations hW (z), e
hW (z) and Ï‡W (z) but
remember that these are random variables depending on the Haar unitary W .
We will use assumption (6.12) at dyadic points, i.e., that
Im mH (E + i2l Î·b) â‰º 1 ,

0 â‰¤ l â‰¤ âŒˆâˆ’ log2 Î·bâŒ‰ ,

(6.18)

(recall that mH (z) = mHe (z) so we may drop the tilde in the subscript of m). Hence,
by (6.16) and (6.18) we see that, for arbitrary large D > 0,
âŒˆâˆ’ log2 Î·
bâŒ‰

Y

l=0

Ï‡(E + i2l Î·b) = 1 ,

i.e.,

e
h(b
z ) = h(b
z) ,

(6.19)

with probability larger than 1 âˆ’ N âˆ’D , for N sufficiently large (depending on Îµ and D).
Taking the trivial bound kQk/b
Î· for h(b
z ) and for e
h(b
z ) into account, we also have

(6.20)
Ee
h(b
z ) âˆ’ E h(b
z ) = O N âˆ’D+1 .

To prove (6.13), it therefore suffices to establish the concentration estimate


1
e

,
z ) âˆ’ Ee
h(b
z ) â‰º p
h(b
N 2 Î·b3

(6.21)

for the regularized quantity e
h(b
z ).
To verify (6.21), we use the Gromovâ€“Milman concentration inequality [26] (see Theorem 4.4.27 in [2] for similar applications) which states the following. Let M(N ) = SO(N )
or SU(N ) endowed with the Riemann metric kdsk2 inherited from MN (C) (equipped with
the Hilbert-Schmidt norm). If g : (M(N ), kdsk2 ) â†’ R is an L-Lipschitz function satisfying
Eg = 0, then
P (|g| > Î´) â‰¤ eâˆ’c

N Î´2
L2

,

âˆ€Î´ > 0,

(6.22)

with some numerical constant c > 0 (depending only on the symmetry type and not on N ).
Here P and E are with respect Haar measure on M(N ).
hW (b
z) = e
h(b
z ), we need to control its
In order to apply (6.22) to the function W 7â†’ e
Lipschitz constant. To that end, we define the event
	

(6.23)
â„¦(b
Î· ) â‰¡ â„¦E (b
Î· ) := Im mH (E + i2n Î·b) â‰¤ 2N Îµ : âˆ€n âˆˆ N0 .

To bound the Lipschitz constant, we need to bound quantities of the form tr |GH (b
z )|k restricted to the event â„¦(b
Î· ). Let (Î»i (H)) denote the eigenvalues of H and introduce
In := [E âˆ’ 2n Î·b, E + 2n Î·b] âˆ© I ,

Nn := |{i : Î»i (H) âˆˆ In }| ,

n âˆˆ N0 .

Since H and H are unitarily equivalent, their empirical eigenvalue distributions are the
same, ÂµH ; c.f., (2.29). Using the definition of the Stieltjes transform we have, for all n âˆˆ N0 ,
the estimate
Z E+2n Î·b
Z
Î·b dÂµH (x)
3
n+1
â‰¤ 3N Â· 2n Î·b Im mH (b
z) .
Î·b
dÂµH â‰¤ N Â· 2
Nn = N
2
(x
âˆ’ E)2 + Î·b2
n
Eâˆ’2 Î·
b
In
Thus we have on the event â„¦(b
Î· ) that

Nn . 2n N 1+Îµ Î·b ,

âˆ€n âˆˆ N0 .

(6.24)

22

By the spectral theorem, we can bound
N
1
1 X
.
N i=1 |Î»i (H) âˆ’ E| + Î·b

tr |GH (b
z )| .

(6.25)

Then we observe (with the convention Iâˆ’1 = âˆ…) that

N
N âˆ
1 X
1
1 XX
1
=
1(Î»i âˆˆ In \ Inâˆ’1 )
N i=1 |Î»i (H) âˆ’ E| + Î·b
N i=1 n=0
|Î»i (H) âˆ’ E| + Î·b

1
=
N

âŒˆc log N âŒ‰

X

n=0

X

Î»i âˆˆIn \Inâˆ’1

1
,
|Î»i (H) âˆ’ E| + Î·b

where we used kHk â‰¤ C to truncate the sum over n at âŒˆc log N âŒ‰. We then bound
1(â„¦(b
Î· ))

1
N

âŒˆc log N âŒ‰

X

n=0

X

Î»i âˆˆIn \Inâˆ’1

1
1
â‰¤ 1(â„¦(b
Î· ))
|Î»i (H) âˆ’ E| + Î·b
N

âŒˆc log N âŒ‰

X

n=0

where we used (6.24), i.e., with (6.25) we arrive at

Nn
. N Îµ log N ,
2n Î·b

1(â„¦(b
Î· ))tr |GH (b
z )| . N Îµ log N .

(6.26)

Using the spectral decomposition of H we see that
tr |GH (b
z )|2 =

N
N
1
Î·b
1 X
Im mH (b
z)
1 X
=
=
, (6.27)
N i=1 |Î»i (H) âˆ’ E|2 + Î·b2
N Î·b i=1 |Î»i (H) âˆ’ E|2 + Î·b2
Î·b

where we also used that tr GH (b
z ) = tr GH (b
z ) = mH (b
z ). Thus, we bound
1(â„¦(b
Î· ))tr |GH (b
z )|k â‰¤ 1(â„¦(b
Î· ))b
Î· âˆ’k+1 Im mH (b
z ) . N Îµ Î·bâˆ’k+1 ,

âˆ€k â‰¥ 2 .

(6.28)

Having established (6.26) and (6.28), we proceed to estimate the Lipschitz constant of e
h(b
z)
as a function of W . Let su(N ) and so(N ) denote the (fundamental representations in MN (C)
of the) Lie algebras of SU (N ) and SO(N ) respectively. Let m stand for either su(N ) or
so(N ). Note that X âˆˆ m satisfies X âˆ— = âˆ’X. Since SU (N ) and SO(N ) are matrix groups
the Lie bracket of su(N ) and so(N ) respectively is given by the commutator in the matrix
algebras. For fixed X âˆˆ MN (C), we let adX : MN (C) â†’ MN (C), Y 7â†’ adX (Y ) :=
XY âˆ’ Y X. For X âˆˆ m and t âˆˆ R, we may write etadX (W BW âˆ— ) = (etX W )B(etX W )âˆ— , where
we used that X âˆ— = âˆ’X. Further note that
d tadX
(6.29)
(W BW âˆ— ) = etadX adX (W BW âˆ— ) .
e
dt
For X âˆˆ m with kXk2 = 1, we let
âˆ’1

GH (z, tX) := A + etadX (W BW âˆ— ) âˆ’ z
,
t âˆˆ R,

and denote accordingly

mH (z, tX) := tr GH (z, tX) ,

Ï‡(z, tX) := Ï‡
b(Im mH (z, tX)) ,
âŒˆâˆ’ log2 Î·
bâŒ‰

e
h(z, tX) := tr QGH (z, tX)

with Ï‡(z, 0) â‰¡ Ï‡(z), e
h(z, 0) â‰¡ e
h(0), etc.

Y
l=0

Ï‡(E + i2l Î·, tX) ,

23

Evaluating the derivative of e
h(b
z , tX) with respect to t at t = 0 we get
log2 Î·
bâŒ‰


 âŒˆâˆ’ Y
âˆ‚e

âˆ—
h(b
z , tX)
= âˆ’ tr QGH (b
z )adX (W BW )GH (b
z)
Ï‡(E + i2l Î·b)
âˆ‚t
t=0
l=0

 âŒˆâˆ’ X
log2 Î·
bâŒ‰ h âŒˆâˆ’ log2 Î·
i
Y bâŒ‰

Ï‡(E + i2l Î·b) Â· Ï†(E + i2j Î·b)
âˆ’ tr QGH (b
z)
j=0

l=0
l6=j



j
âˆ—
j
Ã— Im tr GH (E + i2 Î·b) adX (W BW )GH (E + i2 Î·b)
,
â€²

(6.30)

â€²

where we used (6.29) and where we introduced Ï†(z) := Ï‡
b (Im mH (z)), with Ï‡
b the derivative
b, we note the bounds
of Ï‡
b. Recalling (6.16) and the definition of the cutoff Ï‡
âŒˆâˆ’ log2 Î·
âŒˆâˆ’ log2 Î·
i
Y bâŒ‰
X bâŒ‰ h Y
l
Ï‡(E + i2 Î·b) â‰¤ 1 ,
Ï‡(E + i2l Î·b) Â· Ï†(E + i2j Î·b) = O(log N ) . (6.31)
j=0

l=0

l6=j

On the event â„¦c (b
Î· ), the complementary event to â„¦(b
Î· ), we further have the identities
âŒˆâˆ’ log2 Î·
bâŒ‰
bâŒ‰
âŒˆâˆ’ log2 Î·
bâŒ‰ h âŒˆâˆ’ log2 Î·
i
Y
Y
X
Ï‡(E + i2l Î·b) = 0 ,
Ï‡(E + i2l Î·b) Â· Ï†(E + i2j Î·b) = 0 .
(6.32)
j=0

l=0

l=0
l6=j

Î· ). We bound the first term on the right side
It thus suffices to bound (6.30) on the event â„¦(b
of (6.30) as
log2 Î·
bâŒ‰
 

 âŒˆâˆ’ Y


âˆ—
1(â„¦(b
Î· ))tr QGH (b
z )adX (W BW ) GH (b
z)
Ï‡(E + i2l Î·b)
l=0

â‰¤ 1(â„¦(b
Î· ))

1
kadX (W BW âˆ— )k2 kGH (b
z )QGH (b
z )k2
N

âŒˆâˆ’ log2 Î·
bâŒ‰

Y
l=0

Ï‡(E + i2l Î·b) ,

(6.33)

where we used cyclicity of the trace and Cauchyâ€“Schwarz inequality. Next, note that
kadX (W BW âˆ— )k2 â‰¤ 2kBkkXk2 â‰¤ 2kBk, where we used the definition of adX , kW k â‰¤ 1 and
kXk2 = 1. Similarly, we have kGH (b
z )QGH (b
z )k2 â‰¤ kQkkGH (b
z )Gâˆ—H (b
z )k2 . Thus from (6.33),
âŒˆâˆ’
log
Î·
b
âŒ‰
 

 Y2


1(â„¦(b
Î· ))tr QGH (b
z )adX (W BW âˆ— ) GH (b
z)
Ï‡(E + i2l Î·b)
l=0

â‰¤ 2kBkkQk1(â„¦(b
Î·))


Îµ

 21



N
,
N Î·b3
where we used (6.28) with k = 4 in the last step.
.

tr |GH (b
z )|4
N

 21

âŒˆâˆ’ log2 Î·
bâŒ‰

Y
l=0

Ï‡(E + i2l Î·b)

(6.34)

24

To handle the second term on the right side of (6.30), we use (6.31) and (6.26) to get
âŒˆâˆ’ log Î·
bâŒ‰ âŒˆâˆ’ log2 Î·

Y bâŒ‰
 X2

Ï‡(E + i2l Î·b) Â· Ï†(E + i2j Î·b)
1(â„¦(b
Î· ))tr QGH (b
z)
j=0

l=0
l6=j




Ã— Im tr GH (E + i2j Î·b)adX (W BW âˆ— ) GH (E + i2j Î·b) 
bâŒ‰
âŒˆâˆ’ log2 Î·
bâŒ‰ âŒˆâˆ’ log2 Î·

X

â‰¤ 1(â„¦(b
Î· ))kQktr |GH (b
z )|

Ã— 2kBkkQk




j=0

Y
l=0
l6=j

tr |GH (E + i2j Î·b)|4
N

Ï‡(E + i2l Î·b) |Ï†(E + i2l Î·b)|

 12

1
N 4Îµ 2
.
.
(6.35)
N Î·b3
Combining (6.35) and (6.34) we obtain, for any X âˆˆ su(N ) or so(N ) with kXk2 = 1, that

   N 4Îµ  21
âˆ‚
 
 e
h(b
z
,
tX)
,
(6.36)
 .
 âˆ‚t
N Î·b3
t=0
 4Îµ 1/2
N
i.e., the Lipschitz constant of e
h(b
z ) as a function of W is bounded by C N
, for some
Î·
b3

constant C depending only on kBk and kQk. Thus, taking
 4Îµ  21
p
N
,
Î´ = N 3Îµ / N 2 Î·b3
g=e
h(z) âˆ’ Ee
h(z) ,
L=C
3
N Î·b
in (6.22), and choosing Îµ > 0 sufficiently small, we get (6.21). Together with (6.19) and (6.20)

this implies (6.13).

6.3. Continuity argument. In this subsection, we often omit z âˆˆ C+ from the notation.
Let U and V be independent and both Haar distributed on either U (N ) or O(N ). Recalling
the notation in Section 6.1, we set
âˆ†A (z) := âˆ’(IE[mH (z)])GHe (z) âˆ’ (IE[fBe (z)])GAe(z)GHe (z) ,

âˆ†B (z) := âˆ’(IE[mH (z)])GHe (z) âˆ’ (IE[fAe(z)])GBe (z)GHe (z) ,

z âˆˆ C+ ,

(6.37)

where we introduced IE X := X âˆ’EX, for any random variables X. Using the left-invariance
of Haar measure, one derives the identities
e e ] = E[AG
e e âŠ— Ge],
E[GHe âŠ— AG
H
H
H

e e ] = E[BG
e e âŠ— Ge];
E[GHe âŠ— BG
H
H
H

see Theorem 7 in [33] or Appendix A of [31] for proofs. Taking the partial trace for the first
component of the tensor products, we get
c
c
EGHe (z) = EGAe(Ï‰B
(z)) + Î´A
(z) ,

c
Î´A
(z) :=

1
c
e âˆ’ z)âˆ†A (z)] ,
E[GAe(Ï‰B
(z))(A
EmH (z)
(6.38)

c
where Ï‰B
(z) is defined in (6.5), we used (6.6), and where we implicitly assumed that
c
Im Ï‰B (z) > 0. This last assumption will be verified along the continuity argument. Then,
we set
c
tr Î´A
(z)
c
(6.39)
rA
(z) := âˆ’
c
c (z)) + tr Î´ c (z)) ,
tr GAe(Ï‰B (z))(tr GAe(Ï‰B
A

25
c
c
and define Î´B
(z) and rB
(z) in the same way by swapping the roÌ‚les of A and B. Usc
(z) > 0 and
ing (6.38), (6.6), we eventually obtain, under the assumption that Im Ï‰A
c
Im Ï‰B
(z) > 0,
c
c
(z), Ï‰B
(z), z) = rc (z) ,
Î¦ÂµA ,ÂµB (Ï‰A
c

with r (z) =

z âˆˆ C+ ,

(6.40)

c
c
(rA
(z), rB
(z))âŠ¤ .

Lemma 6.3. Fix E âˆˆ I and any Î·b âˆˆ [Î·m , Î·M ]. Set the notation z = E + iÎ· and zb = E + ib
Î·.
Suppose that
c
c
|Ï‰A
(z) âˆ’ Ï‰A (z)| + |Ï‰B
(z) âˆ’ Ï‰B (z)| â‰¤ N âˆ’Î³ ,

âˆ€Î· = Im z âˆˆ [b
Î· , Î·M ] .

Moreover, assume that for the event
n
Î(b
Î· ) â‰¡ ÎE (b
Î· ) := |mH (z) âˆ’ mAâŠB (z)| â‰¤ N âˆ’Î³ : z = E + iÎ·,
we have

âˆ€Î· âˆˆ [b
Î· , Î·M ]



P Î(b
Î· ) â‰¥ 1 âˆ’ N âˆ’D 1 + N 5 (Î·M âˆ’ Î·b) ,

(6.41)
o
(6.42)

for any D > 0 if N â‰¥ N1 (D).
Then, for any Ç« > 0, the estimates

NÇ«
,
N 2 Î·b3
NÇ«
c
c
|Ï‰A
(b
z ) âˆ’ Ï‰A (b
z )| + |Ï‰B
(b
z ) âˆ’ Ï‰B (b
z )| â‰¤ 2 3 ,
N Î·b
NÇ«
|EmH (b
z ) âˆ’ mAâŠB (b
z )| â‰¤ 2 3 ,
N Î·b
c
c
(b
z )| â‰¤
(b
z )| + |rB
|rA

hold for any N â‰¥ N2 (Ç«). Moreover, for any Ç«, D > 0, the event
n
NÇ« o
Î˜(b
Î· ) â‰¡ Î˜E (b
Î· ) := ÎE (b
Î· ) âˆ© |mH (b
z ) âˆ’ mAâŠB (b
z )| â‰¥ p
N 2 Î·b3

satisfies


P Î˜(b
Î· ) â‰¤ N âˆ’D ,

(6.43)
(6.44)
(6.45)

(6.46)

(6.47)

if N â‰¥ N3 (Ç«, D). The threshold functions N1 , N2 , N3 depend only on ÂµÎ± , ÂµÎ² , the speed of
convergence in (2.25) and they are uniform in Î·b âˆˆ [Î·m , Î·M ] and E âˆˆ I.
We postpone the proof of Lemma 6.3 and prove Theorem 2.8 first.

Proof of Theorem 2.8. We start with observing that it is sufficient to prove a version of (2.28)
where the real part of the spectral parameter E is fixed. This version asserts that there is a
large (N -independent) Î·M , to be fixed below, such that for any (small) Ç« > 0 and (large) D,
and any fixed E âˆˆ I,



[


1
NÇ«
mH (z) âˆ’ mÂµ âŠÂµ (z) >
(6.48)
â‰¤ D,
P
A
B
3/2
N
N (Im z)
zâˆˆSE (Î·m ,Î·M )

holds for N â‰¥ N0 , i.e., the set SI (Î·m , Î·M ) in (2.28) is replaced with SE (Î·m , Î·M ) := {E + iÎ· :
Î· âˆˆ [Î·m , Î·M ]}. The threshold N0 depends on Ç«, D, ÂµÎ± , ÂµÎ² , I and on the speed of convergence
in (2.25).
Indeed, by introducing the discretized lattice version
SbI (a, b) := SI (a, b) âˆ© N âˆ’5 {Z Ã— iZ}

26

of the spectral domain SI (a, b) (c.f., (2.13)) and by taking a union bound, we see that (6.48)
implies



[


NÇ«
C


P
mH (z) âˆ’ mÂµA âŠÂµB (z) >
â‰¤ Dâˆ’5 .
(6.49)
3/2
N
N (Im z)
zâˆˆSbI (Î·m ,Î·M )

Thanks to the Lipschitz continuity of the Stieltjes transforms mH (z) and mÂµA âŠÂµB (z) with
Lipschitz constant Î· âˆ’2 = (Im z)âˆ’2 â‰¤ N 2 , for any Im z â‰¥ Î·m , we see that (2.28) follows
from (6.49) after a small adjustment of Ç« and D that were anyway arbitrary.
From now on we fix E âˆˆ I and our goal is to prove (6.48). We will use Lemma 6.3. In
the first step we verify that the assumptions of this lemma hold for Î·b = Î·M , i.e., that (6.41)
and (6.42) hold for z = E + iÎ·M . In the second step, we successively use Lemma 6.3 to
reduce Î·b steps by steps of size N âˆ’5 until we have verified (6.41)â€“(6.42) down to Î·b = Î·m .
Then (6.48) will follow from a final application of Lemma 6.3 combined with discretization
argument similar to the one above, but this time the Î· variable instead of the E variable.
Step 1. Initial bound. First we note that since ÂµA and ÂµB are compactly supported, kHk
is deterministically bounded, we thus have Im mH (E +iÎ·M ) â‰¤ (Î·M )âˆ’1 â‰¤ 1 assuming Î·M â‰¥ 1.
Following the main argument in the proof of Proposition 6.2, we have the concentration
inequality
1
|fV QV âˆ— (E + iÎ·M ) âˆ’ EfV QV âˆ— (E + iÎ·M )| â‰º p
,
(6.50)
3
N 2 Î·M
uniformly for any deterministic Q with kQk . 1. The analog concentration holds with V
replaced by U . Using (6.50) with Q = I (I the identity matrix), we have | IE[mH (E+iÎ·M )]| â‰º
N âˆ’1 . Hence, it suffices to show that
1
|EmH (E + iÎ·M ) âˆ’ mAâŠB (E + iÎ·M )| â‰º
.
(6.51)
N
c
c
Recalling the definitions of Ï‰A
and Ï‰B
in (6.5), we have, with z = E + iÎ·M , the expansion
c
Ï‰A
(z) = z âˆ’

e e (z)
eA
e + B)z
e âˆ’2
E trAG
tr Az âˆ’1 + E tr A(
H
+ O(z âˆ’2 ) ,
=zâˆ’
E tr GHe (z)
z âˆ’1

as Î·M Ö€ âˆ. Thus using the assumption tr A = 0 we get
c
Im Ï‰A
(E + iÎ·M ) âˆ’ Im Î·M =



eBÎ·
e M
tr A2 Î·M + E tr A
1
,
+
O
2
|E + iÎ·M |2
Î·M

as Î·M Ö€ âˆ. Next, since V and U are independent, we have

E tr V AV âˆ— U BU âˆ— = tr E[V AV âˆ— ] E[U BU âˆ— ] = tr A tr B = 0 ,

since tr A = tr B = 0 by assumption. Thus
c
Im Ï‰A
(E + iÎ·M ) âˆ’ Im Î·M =

tr A2 Î·M
+O
|E + iÎ·M |2



1
2
Î·M



,

(6.52)

as Î·M Ö€ âˆ. Since tr A2 > 0, we achieve by choosing Î·M sufficiently large (but independent
of N ) that
1 tr A2 Î·M
,
(6.53)
2 |E + iÎ·M |2
and the analogue estimate holds with A replaced by B. In particular, we have, for such Î·M ,
c
Im Ï‰A
(E + iÎ·M ) âˆ’ Im Î·M â‰¥

c
Im Ï‰A
(E + iÎ·M ) & 1 ,
c
c
and Ï‰A
(E + iÎ·M ) âˆ¼ 1, Ï‰B
(E + iÎ·M ) âˆ¼ 1.

c
Im Ï‰B
(E + iÎ·M ) & 1 ,

(6.54)

27

To show (6.51), we apply Lemma 4.2 to the system (6.40). Having established (6.53), it
suffices to show that
1
1
c
c
|rA
(E + iÎ·M )| â‰º
,
|rB
(E + iÎ·M )| â‰º
,
(6.55)
N
N
since then we have, for N sufficiently large and Î·M as above that, for any fixed Îµ âˆˆ [0, 1),
NÎµ
1 tr A2 Î·M
c
â‰¤ Im Ï‰A
(E + iÎ·M ) âˆ’ Im Î·M ,
â‰¤
N
2 |E + iÎ·M |2

(6.56)

and similarly with B replacing A. In particular, combining (6.55) and (6.56), we see that
assumption (4.14) of Lemma 4.2 (with the choice re = rc ) is satisfied for N sufficiently large
(with high probability). Consequently, we see that (6.41) (even with N âˆ’1+Ç« instead of N âˆ’Î³
in the latter) hold for z = E + iÎ·M . Finally, the equations
EmH (z) =

1
zâˆ’

c (z)
Ï‰A

âˆ’

c (z)
Ï‰B

,

mAâŠB (z) =

1
,
z âˆ’ Ï‰A (z) âˆ’ Ï‰B (z)

(6.57)

together with the concentration estimate (6.50) yield (6.42).
âˆ’1
It remains to justify (6.55). Since iÎ·M mH (E + iÎ·M ) = O(Î·M
), we have EmH (E + iÎ·M ) âˆ¼
c
c
(E + iÎ·M )) âˆ¼ 1.
1. In addition, from (6.54) it follows that mA (Ï‰B (E + iÎ·M )) âˆ¼ 1 and mB (Ï‰A
Recalling the definition in (6.39), we see that (6.55) is equivalent to
1
1
c
,
|tr Î´B
(E + iÎ·M )| â‰º
.
(6.58)
N
N
c
c
By the definitions of Î´A
, Î´B
in (6.38), and âˆ†A , âˆ†B in (6.37), it is easy to obtain (6.58) by
using (6.50) and Cauchyâ€“Schwarz. This completes Step 1, i.e., the verification of (6.41)â€“
(6.42) for Î·b = Î·M .
Step 2. Induction. Recall that Ï‰A , Ï‰B and mAâŠB (see Lemma 5.1) are uniformly bounded
c
c
and Ï‰A
(z), Ï‰B
(z), mH (z), Ï‰A (z), Ï‰B (z) and mAâŠB (z) are Lipschitz continuous with a
Lipschitz constant bounded by (Im z)âˆ’2 â‰¤ N 2 , for any Im z â‰¥ Î·m . Applying Lemma 6.3 to
conclude (6.44) with the choice Ç« = Î³/10, we see that if (6.41) and (6.42) hold for some Î·b,
then (6.41) also holds for Î·b replaced with Î·b âˆ’ N âˆ’5 as long as Î·b â‰¥ Î·m . Moreover, by the
Lipschitz continuity of mH and mAâŠB , notice that
c
|tr Î´A
(E + iÎ·M )| â‰º

Î(b
Î· âˆ’ N âˆ’5 ) âŠƒ Î(b
Î· ) \ Î˜(b
Î·) .

(6.59)

Thus, if (6.42) holds for some Î·b, then (6.59) and (6.47) imply that (6.42) also holds for Î·b
replaced with Î·b âˆ’ N âˆ’5 . Using Step 1 as an initial input with the choice Î·b = Î·M , and
applying the above induction argument O(N 5 ) times by reducing Î·b with stepsize N âˆ’5 , we
see that (6.41) and (6.42) hold for all Î·bk âˆˆ [Î·m , Î·M ] of the form Î·bk = Î·M âˆ’ k Â· N âˆ’5 with some
integer k. Applying Lemma 6.3 once more for these Î·bk , but now with an arbitrary Ç« > 0,
we conclude from (6.42) and (6.47) that
1
|mH (E + ib
Î·k ) âˆ’ mAâŠB (E + ib
Î·k )| â‰º p
,
N 2 Î·bk3

k = 0, 1, . . . , k0 ,

(6.60)

where k0 is the largest integer with Î·bk0 â‰¥ Î·m . The uniformity of (6.60) in k follows from the
fact that the threshold functions Nj in Lemma 6.3 are independent of Î·b. Clearly k0 = O(N 5 ),
so taking a union bound of (6.60), compensating the combinatorial factor CN 5 by replacing
D by Dâˆ’5, and slightly adjusting Ç« to extend the control from the set {z = E+ib
Î·k : k â‰¤ k0 }

to all z âˆˆ SE (Î·m , Î·M ), we obtain (6.48).
It remains to prove Lemma 6.3.

28

Proof of Lemma 6.3. First we notice that E âˆˆ I and (2.25) imply that for all sufficiently
large N , the bounds (5.3)-(5.4) hold. Together with (6.41) they imply that
c
c
Ï‰A
(b
z ) , Ï‰B
(b
z) âˆ¼ 1 ,

c
c
Im Ï‰A
(b
z ) , Im Ï‰B
(b
z) & 1 ,

(6.61)

moreover, using (6.6) we also get
1
. 1.
(6.62)
EmH (b
z)
c
We start with (6.43). Thanks to symmetry, we only need to estimate |rA
(b
z )|. By (6.61)
we have
c
Ï‰B
(b
z)

c
c
kGAe(Ï‰B
(b
z ))k = kGA (Ï‰B
(b
z ))k . 1 .
c
Im Ï‰B
(b
z)

(6.63)

c
mA (Ï‰B
(b
z ))

Furthermore,
âˆ¼ 1 and
& 1 imply
âˆ¼ 1.
We next claim that
 

NÇ«

c
(b
z ))(Ae âˆ’ zb)âˆ†A (b
z)  â‰¤ 2 3 ,
E tr GAe(Ï‰B
N Î·b

(6.64)

for any Ç« > 0 if N â‰¥ N0 (Ç«) is large enough, uniformly for Î·b âˆˆ [Î·m , Î·M ]. Assuming (6.64) and
c
c
recalling the definition of Î´A
and rA
in (6.38)-(6.39), from (6.62) we get the first estimate
in (6.43).
Next, we prove (6.64). By the definitions in (6.37), we have
h
h
i
i
c
c
E tr GAe(Ï‰B
(b
z ))(Ae âˆ’ zb)âˆ†A (b
z ) = âˆ’ E IE[mH (b
z )] tr GAe(Ï‰B
(b
z ))(Ae âˆ’ zb)GHe (b
z)
h
i
c
(6.65)
âˆ’ E IE[fB (b
z )] tr GAe(Ï‰B
(b
z ))GHe (b
z) .

We rewrite the two terms on the right side separately as covariances,



h
i
c
c
e âˆ’ zb)G e (b
e z )G e (b
= Cov mH (b
z ), tr GAe(Ï‰B
(b
z ))(A
,
E IE[mH (b
z )] tr GAe(Ï‰B
(b
z ))(Aâˆ’b
H z)
H z)

respectively,

h

i
c
c
z ), tr GAe(Ï‰B
(b
z ))GHe (b
z) ,
E IE[fBe (b
z )]tr GAe(Ï‰B
(b
z ))GHe (b
z ) = Cov fBe (b

where Cov(X, Y ) := E(IE[X] Â· IE[Y ]), for arbitrary random variables X and Y .
Given (6.42) and the uniform boundedness of mAâŠB (z) from (5.16), we see that (6.12)
is satisfied and we can apply Proposition 6.2 using different choices for Q. Together with
Cauchyâ€“Schwarz inequality |Cov(X, Y )|2 â‰¤ E|IE[X]|2 Â· E|IE[Y ]|2 , we get



 
1


c
e âˆ’ zb)G e (b
z ), tr GAe(Ï‰B
(b
z ))(A
Cov mH (b
â‰º 2 3,
H z)
N Î·b

 
1

c
(6.66)
z ), tr GAe(Ï‰B
(b
z ))GHe (b
z)  â‰º 2 3 .
Cov fBe (b
N Î·b

c
More specifically, for the first line of (6.66), we chose Q = I and Q = GA (Ï‰B
(b
z ))(A âˆ’ zb);
c
for the second line we chose Q = B and Q = GA (Ï‰B (b
z )), where we also used the facts
e = V AV âˆ— and B
e = U BU âˆ— . Here, we also implicitly used (6.63). Then, (6.64) follows
A
from (6.66), which in turn proves (6.43).
Next, using Proposition 4.1, (6.40) and (6.43) we immediately get (6.44). Moreover,
since Im Ï‰A (z) , Im Ï‰B (z) â‰¥ Im z, we have |z âˆ’ Ï‰A (z) âˆ’ Ï‰B (z)| â‰¥ Im Ï‰B (z) & 1. Together
with (6.44) and (6.57) this implies (6.45). Notice that (6.42) together with the uniform bound
on mAâŠB imply the condition (6.12) in Proposition 6.2. Thus, finally (6.46) and (6.47)
follow from (6.45) and the concentration inequality (6.13). This completes the proof of

Lemma 6.3.

29

7. Two point mass case
In this section, we discuss stability properties of the free additive convolution ÂµÎ± âŠ ÂµÎ²
when both ÂµÎ± and ÂµÎ² are convex combinations of two point masses. The analogous result
to Theorem 2.5 is given in Proposition 7.2 below. Applications of that result in the spirit of
Theorems 2.7 and 2.8 are then stated in Proposition 7.3 and Proposition 7.4. When we refer
to the results in Sections 2-4, we will henceforth regard Âµ1 and Âµ2 as ÂµÎ± and ÂµÎ² , respectively,
unless specified otherwise.
7.1. Stability in the two point mass case. Without loss of generality (up to shifting
and scaling), we assume that
ÂµÎ± = Î¾Î´1 + (1 âˆ’ Î¾)Î´0 ,
1
Î¾, Î¶ âˆˆ (0, ] ,
Î¾ â‰¤ Î¶,
2

ÂµÎ² = Î¶Î´Î¸ + (1 âˆ’ Î¶)Î´0 ,
1 1
(Î¸, Î¾, Î¶) 6= (âˆ’1, , ) .
2 2

Î¸ 6= 0 ,
(7.1)

Here we exclude the case (Î¸, Î¾, Î¶) = (âˆ’1, 12 , 12 ) since it is equivalent to (Î¸, Î¾, Î¶) = (1, 21 , 12 )
under a shift. Note that the latter is a special case of ÂµÎ± = ÂµÎ² .
Set
 1
o
n1
p
p
â„“1 := min
1 + Î¸ âˆ’ (1 âˆ’ Î¸)2 + 4Î¸r+ ,
1 + Î¸ âˆ’ (1 âˆ’ Î¸)2 + 4Î¸râˆ’ ,
2
2
n1
 1
o
p
p
2
â„“2 := max
1 + Î¸ âˆ’ (1 âˆ’ Î¸) + 4Î¸r+ ,
1 + Î¸ âˆ’ (1 âˆ’ Î¸)2 + 4Î¸râˆ’ ,
2
2
n1
 1
o
p
p
2
â„“3 := min
1 + Î¸ + (1 âˆ’ Î¸) + 4Î¸r+ ,
1 + Î¸ + (1 âˆ’ Î¸)2 + 4Î¸râˆ’ ,
2
2
n1
 1
o
p
p
2
1 + Î¸ + (1 âˆ’ Î¸) + 4Î¸r+ ,
1 + Î¸ + (1 âˆ’ Î¸)2 + 4Î¸râˆ’ ,
â„“4 := max
2
2
where we introduced

rÂ± := Î¾ + Î¶ âˆ’ 2Î¾Î¶ Â±

p
4Î¾Î¶(1 âˆ’ Î¾)(1 âˆ’ Î¶) .

(7.2)

Note that â„“1 < â„“2 â‰¤ â„“3 < â„“4 . The following result, taken from [28], describes the regular
bulk of ÂµÎ± âŠÂµÎ² in the setting of (7.1). Recall that fÂµÎ± âŠÂµÎ² denotes the density of (ÂµÎ± âŠÂµÎ² )ac .
Lemma 7.1. Let ÂµÎ± and ÂµÎ² be as in (7.1). Then the regular bulk is given by
BÂµÎ± âŠÂµÎ² = (â„“1 , â„“2 ) âˆª (â„“3 , â„“4 ) ,

(7.3)

in case ÂµÎ± 6= ÂµÎ² , while in case ÂµÎ± = ÂµÎ² it is given by
BÂµÎ± âŠÂµÎ± = (â„“1 , â„“4 ) .

(7.4)

Proof. Choose the diagonal matrices A and B with spectral distribution ÂµA = Î¾N Î´1 + (1 âˆ’
Î¾N )Î´0 and ÂµB = Î¶N Î´Î¸ + (1 âˆ’ Î¶N )Î´0 respectively, with Î¾N := âŒŠÎ¾N âŒ‹/N and Î¶N := âŒŠÎ¶N âŒ‹/N ,
where âŒŠ Â· âŒ‹ denotes the integer part. Recall from (7.1) that Î¾ â‰¤ Î¶ and Î¾ + Î¶ â‰¤ 1. From
Theorem 1.1 of [28], we first observe that the Î¸ and 0 are eigenvalues of the matrix H =
A+U BU âˆ— , U a Haar unitary, with multiplicities N (Î¶N âˆ’Î¾N ) and N (1âˆ’Î¶N âˆ’Î¾N ), respectively.
The remaining 2Î¾N N eigenvalues of H may be obtained via a two-fold transformation from
the eigenvalues, (ti ), of a Î¾N N -dimensional Jacobi ensemble as
q

1
j = 1, . . . , Î¾N N ,
(7.5)
1 + Î¸ Â± (1 âˆ’ Î¸)2 + 4tj ,
Ï„jÂ± :=
2

30

and then identifying the eigenvalues of H as the set {Ï„j+ } âˆª {Ï„jâˆ’ } âˆª {0, Î¸}. In addition, the
P
weak limit of Î¾N1N j Î´tj , as N â†’ âˆ, admits a density given by
p
(r+ âˆ’ x)(x âˆ’ râˆ’ )
1
f (x) =
1[râˆ’ ,r+ ] (x) ,
x âˆˆ R,
(7.6)
2Ï€Î¾
x(1 âˆ’ x)

where r+ and râˆ’ are defined in (7.2). Since the limiting spectral distribution of H is
ac
given
P by ÂµÎ± âŠ ÂµÎ² , we see that (ÂµÎ± âŠ ÂµÎ² ) agrees with the weak limit of the measure
1
j (Î´Ï„j+ + Î´Ï„jâˆ’ ), as N â†’ âˆ. Using this information together with (7.5) and (7.6), one
N
deduces that supp (ÂµÎ± âŠ ÂµÎ² )ac = [â„“1 , â„“2 ] âˆª [â„“3 , â„“4 ]. It then follows from the explicit form of
the limiting distribution of the Jacobi ensemble that fÂµÎ± âŠÂµÎ² is bounded and strictly positive
inside its support. This proves (7.3).
ac
In the special
p case ÂµÎ± = ÂµÎ² , we havepâ„“2 = â„“3 = 1 and thus supp (ÂµÎ± âŠ ÂµÎ² ) =ac[â„“1 , â„“4 ],
with â„“1 = 1 âˆ’ 2 Î¾(1 âˆ’ Î¾) and â„“4 = 1 + 2 Î¾(1 âˆ’ Î¾). In fact, the density of (ÂµÎ± âŠ ÂµÎ± ) equals
p
1 (â„“4 âˆ’ x)(x âˆ’ â„“1 )
fÂµÎ± âŠÂµÎ± (x) =
,
x âˆˆ (â„“1 , â„“4 ) ;
(7.7)
Ï€
x(2 âˆ’ x)

see (5.5) of [33] for instance. Then (7.4) follows directly



Our main task in this section is to show the following result on the stability of the system
Î¦ÂµÎ± ,ÂµÎ² (Ï‰Î± , Ï‰Î² , z) = 0 in the setting (7.1). Recall the definition of Î“ÂµÎ± ,ÂµÎ² in (2.12).
Proposition 7.2. Let ÂµÎ± and ÂµÎ² be as in (7.1). Let I âŠ‚ BÂµÎ± âŠÂµÎ² be a compact non-empty
interval. Fix 0 < Î·M < âˆ. Then, there are constants k > 0, K < âˆ and S < âˆ, depending
on the constants Î¾, Î¶, Î¸, Î·M and on the interval I, such that the subordination functions
possess the following bounds:
min

zâˆˆSI (0,Î·M )

Im Ï‰Î± (z) â‰¥ 2k ,

K
,
2
Moreover, we have the following bounds:
(i) If ÂµÎ± 6= ÂµÎ² ,
max

zâˆˆSI (0,Î·M )

|Ï‰Î± (z)| â‰¤

max

zâˆˆSI (0,Î·M )

min

Im Ï‰Î± (z) â‰¥ 2k ,

max

|Ï‰Î² (z)| â‰¤

zâˆˆSI (0,Î·M )

zâˆˆSI (0,Î·M )

K
.
2

Î“ÂµÎ± ,ÂµÎ² (Ï‰Î± (z), Ï‰Î² (z)) â‰¤ S .

(7.8)
(7.9)

(7.10)

(ii) If ÂµÎ± = ÂµÎ² ,
Î“ÂµÎ± ,ÂµÎ± (Ï‰Î± (z), Ï‰Î± (z)) â‰¤
holds uniformly on SI (0, Î·M ).

S
,
|z âˆ’ 1|

(7.11)

Remark 7.1. As an immediate consequence of Proposition 7.2 and (3.28), we obtain for
ÂµÎ± 6= ÂµÎ² the bounds maxzâˆˆSI (0,Î·M ) |Ï‰Î±â€² (z)| â‰¤ 2S, maxzâˆˆSI (0,Î·M ) |Ï‰Î²â€² (z)| â‰¤ 2S with I as
2S
, uniformly on SI (0, Î·M ) as in (7.11).
in (7.10). For ÂµÎ± = ÂµÎ² , we get |Ï‰Î±â€² (z)| â‰¤ |zâˆ’1|
Remark 7.2. In the case ÂµÎ± = ÂµÎ² , we note from Lemma 7.1 (c.f., (7.7)) that the point
E = 1 is in the regular bulk BÂµÎ± âŠÂµÎ± . However, mÂµÎ± âŠÂµÎ² (1 + i0) is unstable under small
perturbations. For instance, let
ÂµA = ÂµÎ± = Î¾Î´1 + (1 âˆ’ Î¾)Î´0 ,

ÂµB = (Î¾ âˆ’ Îµ)Î´1 + (1 âˆ’ Î¾ + Îµ)Î´0 ,

for some small Îµ > 0. Then, according to Theorem 7.4 of [11], ÂµA âŠ ÂµB has a point mass ÎµÎ´1 .
Hence, even though (2.25) (i.e., dL (ÂµB , ÂµÎ² ) â†’ 0, as Îµ â†’ 0) is satisfied, mÂµA âŠÂµB (z) contains

31
Îµ
a singular part (1âˆ’z)
, which blows up as |z âˆ’ 1| = o(Îµ). This explains, on a heuristic level,
the bound in (7.11) and shows why the ÂµÎ± = ÂµÎ² case at energy E = 1 is special even though
the density fÂµÎ± âŠÂµÎ± is real analytic in a neighborhood of E = 1.

Remark 7.3. Consider a more general setup with ÂµÎ± = Î¾Î´a + Âµ
eÎ± and ÂµÎ² = (1 âˆ’ Î¾)Î´b + Âµ
eÎ² , for
some constants Î¾ âˆˆ (0, 1), a, b âˆˆ R and for some Borel measures Âµ
eÎ± and Âµ
eÎ² with Âµ
eÎ± (R) = 1âˆ’Î¾
and Âµ
eÎ² (R) = Î¾. Analogously to the discussion in Remark 7.2, we note that mÂµÎ± âŠÂµÎ² (a+b+i0)
is unstable under small perturbations. However, from Lemma 3.4, we know that the system
Î¦ÂµÎ± ,ÂµÎ² (Ï‰Î± , Ï‰Î² , z) = 0 is linearly S-stable in the regular bulk under the assumptions of
Theorem 2.5. That means, if neither ÂµÎ± nor ÂµÎ² is supported at a single point and at least
one of them is supported at more than two points, then the point E = a + b cannot lie in the
regular bulk BÂµÎ± âŠÂµÎ² . Thus, only in the special case ÂµÎ± = ÂµÎ² with ÂµÎ± as in (7.1), there is an
unstable point, up to scaling and shifting given by E = 1, inside the regular bulk BÂµÎ± âŠÂµÎ± .
Proof of Proposition 7.2. Estimates (7.8) and (7.9) follow from Lemma 3.2 and Lemma 3.3.
To show statement (i), we recall from the proof of Lemma 3.4 that Î¦ÂµÎ± ,ÂµÎ² (Ï‰Î± , Ï‰Î² , z) = 0
is linearly S-stable at (Ï‰Î± , Ï‰Î² ) if


1 âˆ’ (FÂµâ€² (Ï‰Î² ) âˆ’ 1)(FÂµâ€² (Ï‰Î± ) âˆ’ 1) â‰¥ c ,
(7.12)
Î±
Î²

for some strictly positive constant c. We now show that (7.12) holds for the case ÂµÎ± 6= ÂµÎ²
in the setup of (7.1). Using henceforth the shorthand FÎ± â‰¡ FÂµÎ± , FÎ² â‰¡ FÂµÎ² , we compute
FÎ± (z) =

z(1 âˆ’ z)
,
1âˆ’Î¾âˆ’z

FÎ² (z) =

Then it is easy to obtain

FÎ±â€² (z) âˆ’ 1 =
and

Î¾ âˆ’ Î¾2
,
(1 âˆ’ Î¾ âˆ’ z)2

z(Î¸ âˆ’ z)
,
Î¸ âˆ’ Î¸Î¶ âˆ’ z
FÎ²â€² (z) âˆ’ 1 =

z âˆˆ C+ .
Î¸2 (Î¶ âˆ’ Î¶ 2 )
,
(Î¸ âˆ’ Î¸Î¶ âˆ’ z)2

Im FÎ± (z) âˆ’ Im z
Im FÎ² (z) âˆ’ Im z
,
|FÎ²â€² (z) âˆ’ 1| =
.
Im z
Im z
Consequently, we have (c.f., (3.18))


 (Im Ï‰Î± (z) âˆ’ Im z)(Im Ï‰Î² (z) âˆ’ Im z)
 â€²
 FÎ± (Ï‰Î² (z)) âˆ’ 1 FÎ²â€² (Ï‰Î± (z)) âˆ’ 1  =
Im Ï‰Î± (z)Im Ï‰Î² (z)

(7.13)

(7.14)

|FÎ±â€² (z) âˆ’ 1| =

(7.15)

for any z âˆˆ C+ . Hence, for z âˆˆ SI (Î·0 , Î·M ) with some small but fixed Î·0 > 0 to be chosen
below, we trivially get (7.12) from (7.15). It remains to discuss the regime z âˆˆ SI (0, Î·0 ).
Then (7.13) together with (2.5) implies that
Ï‰Î± (Î¸ âˆ’ Ï‰Î± )
Ï‰Î² (1 âˆ’ Ï‰Î² )
=
,
1 âˆ’ Î¾ âˆ’ Ï‰Î²
Î¸ âˆ’ Î¸Î¶ âˆ’ Ï‰Î±

Ï‰Î² (1 âˆ’ Ï‰Î² )
= Ï‰Î± + Ï‰Î² âˆ’ z .
1 âˆ’ Î¾ âˆ’ Ï‰Î²

(7.16)

Denote s := 1 âˆ’ Î¾ âˆ’ Ï‰Î² and t := Î¸ âˆ’ Î¸Î¶ âˆ’ Ï‰Î± . From (7.14) we then have

 (Î¾ âˆ’ Î¾ 2 )(Î¸2 Î¶ âˆ’ (Î¸Î¶)2 )
FÎ±â€² (Ï‰Î² ) âˆ’ 1 FÎ²â€² (Ï‰Î± ) âˆ’ 1 =
.
(st)2

(7.17)

Using (7.16), some algebra reveals that
Î¾ + Î¸ âˆ’ Î¸Î¶ âˆ’ z
1
1
+
=âˆ’
,
st
Î¾ âˆ’ Î¾2
(Î¾ âˆ’ Î¾ 2 )t

1
1
Î¸Î¶ + 1 âˆ’ Î¾ âˆ’ z
=âˆ’ 2
+ 2
.
st
Î¸ (Î¶ âˆ’ Î¶ 2 )
Î¸ (Î¶ âˆ’ Î¶ 2 )s

(7.18)

32

Owing to (7.15) and (Î¾ âˆ’ Î¾ 2 )(Î¸2 Î¶ âˆ’ (Î¸Î¶)2 ) > 0 (recall that Î¾, Î¶ âˆˆ (0, 1/2] and Î¸ 6= 0), it
suffices to show that
|Im (st)| â‰¥ c ,

(7.19)

in order to prove (7.12). Note that, from the definitions of s and t, together with (7.8)
and (7.9), we have
|Im s| , |Im t| â‰¥ c ,

|s| , |t| â‰¤ C .

(7.20)

Since ÂµÎ± 6= ÂµÎ² , there exists a positive constant d such that max{|Î¾ âˆ’ Î¶|, |Î¸ âˆ’ 1|} â‰¥ d. It is
then elementary to work out that
max{|(Î¾ âˆ’ Î¾ 2 ) âˆ’ Î¸2 (Î¶ âˆ’ Î¶ 2 )| , |(2Î¾ âˆ’ 2Î¸Î¶ + Î¸ âˆ’ 1)|} â‰¥ d1 ,

(7.21)

for some positive constant d1 â‰¡ d1 (Î¾, Î¶, Î¸) > 0, since the special case (Î¸, Î¾, Î¶) = (âˆ’1, 21 , 12 ) is
also excluded in the setting (7.1). For brevity, we adopt the notation
Î¸Î¶ + 1 âˆ’ Î¾ âˆ’ z
Î¾ + Î¸ âˆ’ Î¸Î¶ âˆ’ z
Ï• :=
,
Ïˆ :=
.
2
2
Î¸ (Î¶ âˆ’ Î¶ )s
(Î¾ âˆ’ Î¾ 2 )t

Then, according to (7.18) we have
1
1
1
Re
= Re Ïˆ âˆ’
= Re Ï• âˆ’ 2
,
st
Î¾ âˆ’ Î¾2
Î¸ (Î¶ âˆ’ Î¶ 2 )

Im

1
= Im Ïˆ = Im Ï• .
st

If |(Î¾ âˆ’ Î¾ 2 ) âˆ’ Î¸2 (Î¶ âˆ’ Î¶ 2 )| â‰¥ d1 holds in (7.21), then (7.22) implies that
|Re Ïˆ âˆ’ Re Ï•| â‰¥ d2 ,

(7.22)

(7.23)

for some positive constant d2 â‰¡ d2 (Î¾, Î¶, Î¸). For small enough Î·0 = Î·0 (Î¾, Î¶, Î¸), we then get
Re Ïˆ âˆ’ Re Ï• =

(Î¾ + Î¸ âˆ’ Î¸Î¶ âˆ’ E)Re t + O(Î·0 ) (Î¸Î¶ + 1 âˆ’ Î¾ âˆ’ E)Re s + O(Î·0 )
âˆ’
,
(Î¾ âˆ’ Î¾ 2 )|t|2
Î¸2 (Î¶ âˆ’ Î¶ 2 )|s|2

which, together with (7.20) and (7.23), implies that

	
max |Î¸Î¶ + 1 âˆ’ Î¾ âˆ’ E| , |Î¾ + Î¸ âˆ’ Î¸Î¶ âˆ’ E| â‰¥ d3 ,

(7.24)

for some positive constant d3 â‰¡ d3 (Î¾, Î¶, Î¸). If, on the other hand, |(2Î¾ âˆ’ 2Î¸Î¶ + Î¸ âˆ’ 1)| â‰¥ d1
holds in (7.21), we get (7.24) by triangle inequality. Either way, (7.24) follows from (7.21),
for sufficiently small, but fixed, Î·0 > 0.
Next, using (7.20) and (7.24), we see that there is a constant c > 0 such that, for
sufficiently small Î·0 , for all z âˆˆ SI (0, Î·0 ), we have max{|Im Ï•|, |Im Ïˆ|} â‰¥ c. Since Im Ï• =
Im Ïˆ by (7.22), (7.19) holds on SI (0, Î·0 ). Therefore, (7.19) holds on all of SI (0, Î·M ). So, if
ÂµÎ± 6= ÂµÎ² , the system Î¦ÂµÎ± ,ÂµÎ² (Ï‰Î± , Ï‰Î² , z) = 0 is linearly S-stable with some finite S.
We next prove statement (ii) where ÂµÎ± = ÂµÎ² and thus Î¸ = 1, Î¾ = Î¶. From (7.16), we see
that Ï‰Î± = Ï‰Î² satisfies the equation
Ï‰Î± (1 âˆ’ Ï‰Î± )
= 2Ï‰Î± âˆ’ z .
1 âˆ’ Î¾ âˆ’ Ï‰Î±

(7.25)

Solving (7.25) for Ï‰Î± (z) we get

p
1
Ï‰Î± (z) = Ï‰Î² (z) =
(7.26)
z âˆ’ 1 + 2(1 âˆ’ Î¾) + (z âˆ’ 1)2 âˆ’ 4Î¾(1 âˆ’ Î¾) ,
2
p
where the square root is chosen such that Ï‰Î² (z) â†’ i Î¾(1 âˆ’ Î¾), as z â†’ 1. Substituting (7.26)
into (7.17), together with the Î¸ = 1, Î¶ = Î¾, s = t = 1 âˆ’ Î¾ âˆ’ Ï‰Î± , yields


4(Î¾ âˆ’ Î¾ 2 )2
FÎ±â€² (Ï‰Î² (z)) âˆ’ 1 FÎ²â€² (Ï‰Î± (z)) âˆ’ 1 =
p
4 .
z âˆ’ 1 + (z âˆ’ 1)2 âˆ’ 4(Î¾ âˆ’ Î¾ 2 )

33

Then it is elementary to check that



1 âˆ’ F â€² (Ï‰Î² (z)) âˆ’ 1 F â€² (Ï‰Î± (z)) âˆ’ 1  & |z âˆ’ 1| ,
Î±
Î²

z âˆˆ S(0, Î·M ) ,

which further implies Î“ÂµÎ± ,ÂµÎ² (Ï‰Î± (z), Ï‰Î² (z)) . 1/|z âˆ’ 1|. Hence (7.11) is proved.



7.2. Applications of Proposition 7.2. Analogously to Theorem 2.5, we have two main
applications of Proposition 7.2. The first one is the following modification of Theorem 2.7.
Let ÂµÎ± , ÂµÎ² be as in (7.1) and let ÂµA , ÂµB be arbitrary probability measures on R. Recall the
domain SI (a, b) introduced in (2.13). For given (small) Ï‚ > 0, we set

q
o
np
dL (ÂµA , ÂµÎ± ), dL (ÂµB , ÂµÎ² )
.
(7.27)
SIÏ‚ (a, b) := z âˆˆ SI (a, b) : Ï‚|z âˆ’ 1| â‰¥ max

Proposition 7.3. Let ÂµÎ± , ÂµÎ² be as in (7.1). Let I âŠ‚ BÂµÎ± âŠÂµÎ² be a compact non-empty
interval. Let ÂµA , ÂµB be two probability measures on R. Fix 0 < Î·M < âˆ. Then there are
constants b > 0 and Z < âˆ such that the condition
dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² ) â‰¤ b

(7.28)

implies
max

zâˆˆSI (0,Î·M )


 mÂµ

A âŠÂµB


(z) âˆ’ mÂµÎ± âŠÂµÎ² (z) â‰¤ Z (dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ² )) ,

(7.29)

in case ÂµÎ± 6= ÂµÎ² , respectively

 mÂµ

A âŠÂµB


(z) âˆ’ mÂµÎ± âŠÂµÎ± (z) â‰¤

Z
(dL (ÂµA , ÂµÎ± ) + dL (ÂµB , ÂµÎ± )) ,
|z âˆ’ 1|

(7.30)

uniformly on SIÏ‚ (0, Î·M ) with Ï‚ â‰¤ Ï‚0 , for some Ï‚0 > 0, in case ÂµÎ± = ÂµÎ² . The constants b
and Z depend only on the constants Î¾, Î¶, Î¸ and on the interval I, while Ï‚0 also depends on b.
Proof. Having established Proposition 7.2, the proof of (7.29) is the same as that of TheoS
rem 2.7. To establish (7.30), we mimic the proof of Theorem 2.7 with S replaced by |zâˆ’1|
.
We only give a sketch here. Similarly to (5.9), using (7.8) and (7.11), we have with b in (7.28)
sufficiently small that
Î“ÂµA ,ÂµB (Ï‰Î± (z), Ï‰Î± (z)) .

1
,
|z âˆ’ 1|

z âˆˆ SIÏ‚ (0, Î·M ) .

(7.31)

As in the proof of Lemma 5.1, we rewrite the system Î¦ÂµÎ± ,ÂµÎ± (Ï‰Î± (z), Ï‰Î± (z), z) = 0 as
Î¦ÂµA ,ÂµB (Ï‰Î± (z), Ï‰Î± (z), z) = r(z) with kr(z)k satisfying the bound (5.8). From the uniqueness
of the solution to Î¦ÂµA ,ÂµB (Ï‰A , Ï‰B , z) = 0 and (7.31), we get
|Ï‰A (z) âˆ’ Ï‰Î± (z)| . kr(z)k/|z âˆ’ 1| ,

|Ï‰B (z) âˆ’ Ï‰Î± (z)| . kr(z)k/|z âˆ’ 1| ,

z âˆˆ SIÏ‚ (0, Î·M ) ,

(7.32)

via the Newton-Kantorovich theorem. Note that the inequality kr(z)k . Ï‚ 2 |z âˆ’ 1|2 is needed
to guarantee that the first order term dominates over the higher order terms in the Taylor
expansion of Î¦ÂµA ,ÂµB (Ï‰A , Ï‰B , z) around Î¦ÂµA ,ÂµB (Ï‰Î± , Ï‰Î² , z). This is the reason why we restrict
our discussion on the set SIÏ‚ (0, Î·M ). In addition, thanks to (7.32) we see that (5.3) and (5.4)
still hold with SI (0, Î·M ) replaced by SIÏ‚ (0, Î·M ). Then the remaining parts of the proof

of (7.30) are the same as the counterparts in the proof of Theorem 2.7.

34

The second application of Proposition 7.2 gives the following local law for the Green
function in the random matrix setup from Subsection 2.3.2. Fix any Î³ > 0. We introduce a
sub-domain of SIÏ‚ (a, b) by setting
n
NÎ³ o
SeIÏ‚ (a, b) := SIÏ‚ (a, b) âˆ© z âˆˆ C : |z âˆ’ 1| â‰¥ p
.
(7.33)
N Î· 3/2

Proposition 7.4. Let ÂµÎ± , ÂµÎ² be as in (7.1). Assume that the empirical eigenvalue distributions ÂµA , ÂµB of the sequences of matrices A, B satisfy (2.25). Fix any 0 < Î·M < âˆ, any
2
small Î³ > 0 and set Î·m = N âˆ’ 3 +Î³ . Let I âŠ‚ BÂµÎ± âŠÂµÎ² be a compact non-empty interval. Then
we have the following conclusions.
(i) If ÂµÎ± 6= ÂµÎ² , then


mH (z) âˆ’ mAâŠB (z) â‰º 1 .
max
zâˆˆSI (Î·m ,Î·M )
N Î· 3/2
(ii) If ÂµÎ± = ÂµÎ² , then, for any fixed (small) Ï‚ > 0,


1
1
mH (z) âˆ’ mAâŠB (z) â‰º
,
|z âˆ’ 1| N Î· 3/2
uniformly on SeIÏ‚ (Î·m , Î·M ).

Proof of Proposition 7.4. Note that, in the proof of Theorem 2.8, the only place where we
use the assumption that at least one of ÂµÎ± and ÂµÎ² is supported at more than two points
is Lemma 3.4; in particular in (3.25). Hence, it suffices to mimic the proof of Theorem 2.8
with Lemma 3.4 replaced by Proposition 7.2. Then the proof of the case ÂµÎ± 6= ÂµÎ² is exactly
the same as that of Theorem 2.8. It suffices to discuss the case ÂµÎ± = ÂµÎ² below.
Analogously to Corollary 5.2, with the aid of (7.31) and (7.32), we show that
1
,
z âˆˆ SIÏ‚ (0, Î·M ) .
(7.34)
Î“ÂµA ,ÂµB (Ï‰A (z), Ï‰B (z)) .
|z âˆ’ 1|
Then, we use a continuity argument, based on Lemma 4.2 and Proposition 4.1 with S
S
replaced by |zâˆ’1|
therein, to deduce from (6.40) that |Ï‰ic (z) âˆ’ Ï‰i (z)| â‰º krc (z)k/|z âˆ’ 1|,
i = A, B, on SeIÏ‚ (Î·m , Î·M ). The remaining parts of the proof are the same as in Theorem 2.8.
This completes the proof of part (ii) of Proposition 7.4.

References

[1] Akhieser, N. I.: The classical moment problem and some related questions in analysis, Hafner Publishing Co., New York, 1965.
[2] Anderson, G., Guionnet, A., Zeitouni, O.: An introduction to random matrices, Cambridge Stud. Adv.
Math. 118, Cambridge Univ. Press, Cambridge, 2010.
[3] Bao Z. G., ErdoÌ‹s, L., Schnelli K.: Local law of addition of random matrices on optimal scale,
arXiv:1509.07080 (2015).
[4] Belinschi, S., Bercovici, H.: A new approach to subordination results in free probability, J. Anal. Math.
101(1), 357-365 (2007).
[5] Belinschi, S.: A note on regularity for free convolutions, Ann. Inst. Henri PoincareÌ Probab. Stat. 42(5),
635-648 (2006).
[6] Belinschi, S.: The Lebesgue decomposition of the free additive convolution of two probability distributions, Probab. Theory Related Fields 142(1-2), 125-150 (2008).
[7] Belinschi, S.: Lâˆ -boundedness of density for free additive convolutions, Rev. Roumaine Math. Pures
Appl. 59(2), 173-184 (2014).
[8] Belinschi, S., Bercovici, H., Capitaine, M., FeÌvrier, M.: Outliers in the spectrum of large deformed
unitarily invariant models, arXiv:1412.4916 (2014).
[9] Benaych-Georges, F., Nadakuditi, R. R.: The eigenvalues and eigenvectors of finte, low rank perturbbations of large random matrices, Adv. Math. 227(1), 494-521 (2011).

35

[10] Bercovici, H, Voiculescu, D.: Free convolution of measures with unbounded support, Indiana Univ.
Math. J. 42, 733-773 (1993).
[11] Bercovici, H., Voiculescu, D.: Regularity questions for free convolution, nonselfadjoint operator algebras, operator theory, and related topics, Oper. Theory Adv. Appl. 104, 37-47 (1998).
[12] Bercovici, H., Wang, J.-C.: On freely indecomposable measures, Indiana Univ. Math. J. 57(6), 26012610 (2008).
[13] Biane, P.: On the free convolution with a semi-circular distribution, Indiana Univ. Math. J. 46, 705-718
(1997).
[14] Biane, P.: Processes with free increments, Math. Z. 227(1), 143-174 (1998).
[15] Biane, P.: Representations of symmetric groups and free probability, Adv. Math. 138(1), 126-181
(1998).
[16] Capitaine, M.: Additive/multiplicative free subordination property and limiting eigenvectors of spiked
additive deformations of Wigner matrices and spiked sample covariance matrices, J. Theoret. Probab.
26.3, 595-648 (2013).
[17] Chatterjee, S.: Concentration of Haar measures, with an application to random matrices, J. Funct.
Anal. 245(2), 379-389 (2007).
[18] Chistyakov, G. P., GoÌˆtze, F.: The arithmetic of distributions in free probability theory, Cent. Euro. J.
Math. 9, 997-1050 (2011).
[19] Collins, B.: Moments and cumulants of polynomial random variables on unitary groups, the ItzyksonZuber integral, and free probability, Int. Math. Res. Not. 2003(17), 953-982 (2003).
[20] Dykema, K.: On certain free product factors via an extended matrix model, J. Funct. Anal. 112(1),
31-60 (1993).
[21] ErdoÌ‹s, L., Knowles, A., Yau, H.-T.: Averaging fluctuations in resolvents of random band matrices,
Ann. Henri PoincareÌ 14, 1837-1926 (2013).
[22] ErdoÌ‹s, L., Knowles, A., Yau, H.-T., Yin, J.: The local semicircle law for a general class of random
matrices. Electron. J. Probab. 18(59), 1-58 (2013).
[23] ErdoÌ‹s, L., Schlein, B., Yau, H.-T.: Local semicircle law and complete delocalization for Wigner random
matrices, Ann. Probab. 37(3), 815-852 (2009).
[24] ErdoÌ‹s, L., Yau, H.-T., Yin, J.: Bulk universality for generalized Wigner matrices, Probab. Theory
Related Fields 154(1-2), 341-407 (2012).
[25] Ferreira, O. P., Svaiter, B. F.: Kantorovichâ€™s theorem on Newtonâ€™s method, arXiv:1209.5704 (2012).
[26] Gromov, M., Milman V. D.: A topological application of the isoperimetric inequality, Amer. J. Math.
105(4), 843-854 (1983).
[27] Hiai, F., Petz, D.: The semicircle law, free random variables and entropy, Math. Surveys Monogr. 77,
Amer. Math. Soc., Providence RI, 2000.
[28] Kargin, V.: On eigenvalues of the sum of two random projections, J. Stat. Phys. 149(2), 246-258
(2012).
[29] Kargin, V.: A concentration inequality and a local law for the sum of two random matrices, Probab.
Theory Related Fields 154, 677-702 (2012).
[30] Kargin, V.: An inequality for the distance between densities of free convolutions, Ann. Probab. 41(5),
3241-3260 (2013).
[31] Kargin, V.: Subordination for the sum of two random matrices, Ann. Probab. 43(4), 2119-2150 (2015).
[32] Maassen, H.: Addition of freely independent random variables. J. Funct. Anal. 106(2), 409-438 (1992).
[33] Pastur, L., Vasilchuk. V: On the law of addition of random matrices, Comm. Math. Phys. 214(2),
249-286 (2000).
[34] Speicher, R.: Free convolution and the random sum of matrices, Pub. Res. Inst. Math. Sc. 29(5),
731-744 (1993).
[35] Speicher, R.: Multiplicative functions on the lattice of non-crossing partitions and free convolution,
Math. Ann. 298.1, 611-628 (1994).
[36] Voiculescu, D.: Addition of certain non-commuting random variables, J. Funct. Anal. 66(3), 323-346
(1986).
[37] Voiculescu, D.: Limit laws for random matrices and free products, Invent. Math. 104(1), 201-220
(1991).
[38] Voiculescu, D.: The analogues of entropy and of Fisherâ€™s information measure in free probability
theory I, Comm. Math. Phys. 155(1), 71-92 (1993).
[39] Voiculescu, D., Dykema, K. J., Nica, A.: Free random variables, CRM Monogr. Ser., Amer. Math. Soc.,
Providence RI, 1992.

36

[40] Xu, F.: A random matrix model from two-dimensional Yang-Mills theory, Comm. Math. Phys. 190,
287-307 (1997).

