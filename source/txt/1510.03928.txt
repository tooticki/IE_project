Weakly chained matrices,
policy iteration, and impulse control
arXiv:1510.03928v4 [math.NA] 24 Sep 2017

P. Azimzadeh∗

P. A. Forsyth∗

Abstract
This work is motivated by numerical solutions to Hamilton-Jacobi-Bellman quasivariational inequalities (HJBQVIs) associated with combined stochastic and impulse
control problems. In particular, we consider (i) direct control, (ii) penalized, and (iii)
semi-Lagrangian discretization schemes applied to the HJBQVI problem. Scheme (i)
takes the form of a Bellman problem involving an operator which is not necessarily
contractive. We consider the well-posedness of the Bellman problem and give sufficient
conditions for convergence of the corresponding policy iteration. To do so, we use weakly
chained diagonally dominant matrices, which give a graph-theoretic characterization
of weakly diagonally dominant M-matrices. We compare schemes (i)–(iii) under the
following examples: (a) optimal control of the exchange rate, (b) optimal consumption
with fixed and proportional transaction costs, and (c) pricing guaranteed minimum
withdrawal benefits in variable annuities. We find that one should abstain from using
scheme (i).

Keywords. Hamilton-Jacobi-Bellman equation, combined stochastic and impulse control,
policy iteration, weakly chained diagonally dominant matrix, optimal exchange rate, optimal
consumption, GMWB
AMS subject classifications. 65N06, 93E20

1

Introduction

This work is motivated by the computation of numerical solutions to Hamilton-Jacobi-Bellman
quasi-variational inequalities (HJBQVI) associated with combined stochastic and impulse
control. These problems are of the form:
Problem. Find a viscosity solution (see [17, Definition 2.2]) of the HJBQVI
0 = F (t, x, u, Du(t, x), D2 u(t, x))





(

)

!

∂u
+ Łw u − ρu + f w , Mu − u
max supw∈W
∂t
:= −


max (g − u, Mu − u)
∗

on [0, T ) × (Ω \ Λ)

(1.1)

+

on ∂ Ω

David R. Cheriton School of Computer Science, University of Waterloo, Waterloo ON, Canada N2L 3G1
pazimzad@uwaterloo.ca and paforsyt@uwaterloo.ca

1

where Ω ⊂ Rd is open, Λ ⊂ ∂Ω, ∂ + Ω := ([0, T ) × Λ) ∪ ({T } × Ω), Łw := Ł(t, x, w) is the
(possibly degenerate) generator of an SDE, f w := f (t, x, w) is a forcing term, and M is the
impulse (a.k.a. intervention) operator
Mu(t, x) := sup {u(t, x + Γ(t, x, z)) + K(t, x, z)} .

(1.2)

z∈Z(t,x)

If Z(t, x) is empty at a particular point (t, x), Mu(t, x) is understood to take the value −∞,
corresponding to no impulses being allowed at that point.
We focus on implicit discretization schemes for the HJBQVI problem that do not suffer
from the usual timestep restrictions of explicit schemes. In particular, we consider (i) direct
control, (ii) penalized and (iii) semi-Lagrangian schemes. The semi-Lagrangian scheme (used
for HJBQVIs in [12]) differs from its counterparts in that it handles controlled terms using
information from the previous timestep. As such, computing the solution of this scheme
does not require an iterative method. However, this scheme requires that the control w in
Łw appears only in the coefficient of the first-order term. For the other two schemes, an
iterative method is needed. The particular iterative method analyzed herein is Howard’s
policy iteration algorithm. Not considered is the alternative value iteration algorithm, due
to its poor performance as the numerical grid is refined [15, §6.1]. Convergence of policy
iteration applied to the penalized scheme turns out to be a trivial consequence of the strict
diagonal dominance of the input matrices to policy iteration (5.2). Convergence of policy
iteration applied to the direct control scheme is a more delicate matter, as discussed below.
The direct control scheme takes the form of the fixed point problem
!

find v ∈ R

M

such that v = max sup L(w)v + c(w), sup B(z)v + k(z)
w∈W

(1.3)

z∈Z

where L(w) and B(z) are contractive and nonexpansive matrices, respectively. It is understood
that the supremum and maximum are element-wise and controls are “row-decoupled” (see §2).
[10] gives sufficient conditions for convergence of a policy iteration to the unique solution of
(1.3). However, convergence in [10] is conditional on the choice of initial guess [10, Theorem
2 (iii)]. We remove this constraint.
More importantly, [10] restricts the admissible set of controls and imposes a strong
assumption on B(z) (of which assumption (H2) in this work is an analogue) to ensure
convergence of policy iteration applied to (1.3). Unfortunately, reasonable instances of
problem (1.3) (including examples in this work) do not necessarily satisfy this condition.
We show that, under a much weaker assumption, a solution to (1.3) is unique. Moreover,
when (H2) is not satisfied directly, we provide a way to construct this solution by considering
a “modified problem” that satisfies (H2). Roughly speaking, one arrives at the modified
problem by removing some suboptimal controls from the control set. However, this procedure
is ad hoc (i.e. problem dependent).
To establish the above relaxations, we use weakly chained diagonally dominant (WCDD)
matrices. WCDD matrices give a graph-theoretic characterization of weakly diagonally
dominant M-matrices (Theorem 3.5). The WCDD matrix approach to the convergence of
policy iteration applied to (1.3) is intuitive and established using well-known results on policy
iteration (Proposition 2.2).
2

The ad hoc removal of suboptimal controls makes the direct control scheme less robust
than its counterparts, for which control sets need not be altered to ensure convergence. It is
thus natural to ask if there is an advantage to using a direct control scheme. To answer this,
we apply each scheme to the following examples:
• optimal control of the exchange rate;
• optimal consumption with fixed and proportional transaction costs;
• pricing guaranteed minimum withdrawal benefits in variable annuities.
The semi-Lagrangian scheme only requires a single linear solve per timestep since no iterative
method is needed. However, as mentioned above, such a scheme cannot be used if the control
w appears in the diffusion coefficient of Łw (or if the underlying process is Lévy with controlled
arrival rate). We find that the penalized scheme performs at least as well the direct control
scheme. Both produce nearly identical results and often require roughly the same amount of
computation. In the specific case of the optimal consumption problem, the penalized scheme
even outperforms the direct control scheme, taking only a few policy iterations to converge
per timestep.
We mention that in the infinite-horizon setting (T = ∞), optimal consumption with fixed
and proportional transaction costs was considered numerically in [11] using iterated optimal
stopping, a theoretical tool [24, Chapter 7, Lemma 7.1] for the construction of solutions that
has found its way into numerical implementations [20, 5]. Computationally, for finite-horizon
problems (T < ∞), iterated optimal stopping has high space complexity [3], and is thus not
considered here. Also not considered here is the simulation of penalized backward stochastic
differential equations [18], a recent alternative well-suited to high-dimensional problems.
In this work, we restrict our attention to problems of dimension three or lower. To keep
focus on the interesting aspects of impulse control, we assume that between impulses, the
underlying stochastic process associated with the HJBQVI is a Brownian motion with drift
µ := µ(t, x, w) and scaling σ := σ(t, x, w) (we can extend to a Lévy process with nontrivial
arrival rate by, e.g., [13]). This allows us to write
Łw u(t, x) :=



1
trace σ(t, x, w)σ | (t, x, w)Dx2 u(t, x) + hµ(t, x, w), Dx u(t, x)i .
2

We mention here that problem (1.3) can also be interpreted as a Bellman problem
associated with an infinite-horizon Markov decision process (MDP) with vanishing discount
(Example 4.2). In fact, (1.3) is a generalization of a reflecting boundary problem (see, e.g.,
the monograph of Kushner and Dupuis [19, pg. 39–40]). In the context of MDPs, L(w)
and B(z) capture the transition probabilities at states with nonvanishing and vanishing
discount factors, respectively. A WCDD matrix condition guarantees the convergence of
policy iteration to the unique solution of the Bellman problem (Corollary 4.4). Intuitively,
this condition ensures that the underlying Markov chain arrives (with positive probability) at
a state with nonvanishing discount independent of the initial state.
We summarize some of our main findings below:
• Policy iteration applied to a (monotone) direct control scheme frequently fails due to
the possible singularity of the matrix iterates.
3

• We establish provably convergent techniques to eliminate singularity. However, applying
these techniques is problem-dependent.
• We show that policy iteration applied to a (monotone) penalized scheme never fails.
Numerical tests on three problems confirm that such a scheme performs at least as well
as (and sometimes better than) its direct control counterpart.
The additional effort required to ensure the convergence in the direct control case along with
the comparable (if not better) performance in the penalized case suggests that one should
abstain from a direct control scheme.
An outline of this work is as follows. §2 reminds the reader of a well-known result on the
convergence of policy iteration. §3 discusses WCDD matrices. §4 gives conditions for the
convergence of policy iteration applied to problem (1.3) and its well-posedness under weaker
assumptions. A self-contained MDP example is given therein (Example 4.2). §5 introduces
numerical schemes for the HJBQVI problem (1.1), with numerical examples given in §6.

2

Policy iteration

In the sequel, we will see that each of the discretization schemes for (1.1) take the form of a
Bellman problem:
find v ∈ RM such that sup {−A(P )v + b(P )} = 0

(2.1)

P ∈P

where A : P → RM ×M and b : P → RM . It is understood that (i) P :=
product of nonempty sets, (ii) controls are row-decoupled:

QM

i=1

Pi is a finite

[A(P )]ij and [b(P )]i depend only on Pi ∈ Pi ,
(iii) the order on RM (resp. RM ×M ) is element-wise:
for x, y ∈ RM , x ≥ y if and only if xi ≥ yi for all i,
and (iv) the supremum is induced by this order:
for {x(P )}P ∈P ⊂ RM , sup x(P ) is a vector with components sup [x(P )]i .
P ∈P

P ∈P

Let Solve(A, b, x0 ) denote a call to a linear solver for Ax = b with initial guess x0
(algebraically, Solve computes x exactly; in practice, an iterative solver is used and the
choice of x0 affects performance). A policy iteration algorithm is given by:
Policy-Iteration(P, A(·), b(·), v 0 )
1 for ` = 1, 2, . . .
2
Pick P ` such that −A(P ` )v `−1 + b(P ` ) = supP ∈P {−A(P )v `−1 + b(P )}
3
v ` := Solve(A(P ` ), b(P ` ), v `−1 )

4

Definition 2.1 (Monotone matrix). A real square matrix A is monotone (in the sense of
Collatz) if for all real vectors v, Av ≥ 0 implies v ≥ 0.
We use the following assumptions:
(H0) P 7→ A(P )−1 is bounded on the set {P ∈ P : A(P ) is nonsingular}.
(H1) (i) A and b are bounded and (ii) for all x in RM , there exists Px in P such that
−A(Px )x + b(Px ) = supP ∈P {−A(P )x + b(P )}.
Proposition 2.2 (Convergence of policy iteration). Suppose (H0), (H1), and that A(P ) is a
monotone matrix for all P in P. (v ` )`≥1 defined by Policy-Iteration is nondecreasing
and converges to the unique solution v of (2.1). Moreover, if P is finite, convergence occurs
in at most |P| iterations (i.e. v |P| = v |P|+1 = · · · ).
The monotone convergence of (v ` )`≥1 to the unique solution of (2.1) can be proven similarly
to Theorem A.3 of Appendix A. See [7, Theorem 2.1] for a proof of the finite termination
when P is finite. In practice, P is often finite, in which case (H0) and (H1) are trivial.
Remark 2.3. Theorem A.3 establishes the existence and uniqueness of solutions to (2.1)
independent of (H1.ii). Owing to this, results that rely on Proposition 2.2 can be relaxed to
exclude (H1.ii), with the caveat that when P is infinite, Policy-Iteration be replaced by
-Policy-Iteration (see Appendix A). In this case, the resulting sequence (v ` )`≥1 is not
necessarily nondecreasing.

3

Weakly chained diagonally dominant matrices

We say row i of a complex matrix A := (aij ) is strictly diagonally dominant (SDD) if
P
|aii | > j6=i |aij |. We say A is SDD if all of its rows are SDD. Weakly diagonally dominant
(WDD) is defined with weak inequality instead.
Definition 3.1. A complex square matrix A is said to be a weakly chained diagonally
dominant (WCDD) if:
(i) A is WDD;
(ii) for each row r, there exists a path in the graph of A from r to an SDD row p.
Recall that the directed graph of an M × M complex matrix A := (aij ) is given by the
vertices {1, . . . , M } and edges defined as follows: there exists an edge from i to j if and only
if aij 6= 0. Note that if r is itself an SDD row, the trivial path r → r satisfies the requirement
of (ii) in the above.
The nonsingularity of WCDD matrices is proven in [27]. We provide an elementary proof
for the convenience of the reader:
Lemma 3.2. A WCDD matrix is nonsingular.

5

Proof. Suppose λ = 0 is an eigenvalue of A := (aij ). Let v 6= 0 be an associated eigenvector
with components of modulus at most unity. Let r be such that |vr | = 1 ≥ |vj | for all j. By
the Gershgorin circle theorem,
|λ − arr | = |arr | ≤

X

|arj | |vj | ≤

j6=r

X

|arj | .

j6=r

Since A is WDD, it follows that |arr | = j6=r |arj |, and hence r is not an SDD row. Therefore,
there exists a path r → p1 → · · · → pk where pk is an SDD row. Since
P

|arr | =

X

|arj | |vj | =

j6=r

X

|arj | ,

j6=r

it follows that |vj | = 1 whenever |arj | =
6 0. Because |arp1 | =
6 0, |vp1 | = 1. Repeating the same
P
argument as above with r = p1 yields |ap1 p1 | = j6=p1 |ap1 j |, and hence p1 is not an SDD row.
Continuing the procedure, pk is not SDD, a contradiction.

We recall some well-known classes of matrices:
Definition 3.3. A Z-matrix is a real matrix with nonpositive off-diagonals.
Definition 3.4. An M-matrix is a monotone Z-matrix.
We are now ready to state a fundamental characterization of WDD M-matrices:
Theorem 3.5 (Characterization theorem). The following are equivalent:
(i) A is a WCDD Z-matrix with positive diagonals;
(ii) A is a WDD M-matrix.
Proof. Since a nonsingular WDD Z-matrix with positive diagonals is an M-matrix (a consequence of, e.g., [25, Theorem 1.A3 ]), (i) implies (ii) follows by Lemma 3.2.
As for the converse, since an M-matrix has positive diagonal elements (a consequence
of, e.g., [25, Theorem 1.K35 ]), it is sufficient to show that a WDD Z-matrix A ∈ Rn×n with
positive diagonals not satisfying Definition 3.1 (ii) is singular. Let R ⊂ {1, . . . , n} be the set
of rows r of A violating Definition 3.1 (ii). Due to our assumptions, there is at least one such
row, and hence R is nonempty. Without loss of generality, we can assume R = {1, . . . , m}
for some 1 ≤ m ≤ n (otherwise, reorder A). Let e ∈ Rm denote the column vector whose
elements are all unity. If m = n, each row sum of A is zero (i.e., Ae = 0), implying that A is
singular. If m < n, A has the block structure
A=

B 0
C D

!

where B ∈ Rm×m .

Because rows that violate Definition 3.1 (ii) were “isolated” to the block B, the partition
above ensures that D is WCDD. Therefore, by Lemma 3.2, the linear system Dx = −Ce has
a unique solution x. Moreover, since the row sums of B are zero, Be = 0. It follows that
!

!

e
Be
A
=
= 0,
x
Ce + Dx
and hence A is singular.


6





This characterization is tight: an M-matrix need not be WCDD (e.g. 10 −21 ).
We mention that (i) implies (ii) of Theorem 3.5 appears in [8]. Therein, WCDD Z-matrices
with positive diagonals are referred to as matrices of positive type. To the authors’ best
knowledge, the converse does not appear in the literature.

4
4.1

The fixed point problem (1.3)
Convergence of policy iteration

We assume W := M
i=1 Wi and Z :=
of nonempty sets. Let
Q

P :=

QM

i=1 Pi

QM

i=1

Zi appearing in problem (1.3) are finite products

where Pi := Wi × Zi × Di and ∅ =
6 Di ⊂ {0, 1} .

(4.1)

We associate with each ψ := (ψ1 , . . . , ψM ) in D := M
i=1 Di a diagonal matrix Ψ := diag(ψ).
We use ψ and Ψ interchangeably. We write P := (w, z, ψ) ∈ P where w ∈ W and z ∈ Z. We
can transform problem (1.3) into the form (2.1) by taking
Q

A(P ) := (I − Ψ) (I − L(w)) + δΨ (I − B(z))
b(P ) := (I − Ψ) c(w) + δΨk(z)

(4.2)

where δ = 1 (L(w) and B(z) are matrices; c(w) and k(z) are vectors). To keep the material
general, we henceforth assume the less restrictive condition δ > 0 instead of δ = 1. Before
considering the well-posedness of
problem (2.1) subject to (4.1) and (4.2),

(4.3)

we establish that the set of solutions to (4.3) is independent of the choice of δ:
Lemma 4.1. v is a solution of (4.3) with δ = 1 if and only if it is a solution of (4.3) with
arbitrary δ = δ0 > 0.
A proof of the above is given in Appendix B. In the sequel, we exploit the fact that policy
iteration may converge more rapidly for particular choices of δ. We now visit, as a motivating
example, an infinite-horizon MDP with vanishing discount:
Example 4.2. Let (X n )n≥0 be a controlled homogeneous Markov chain on a finite state space
{1, . . . , M }. A control at state i is a member of Pi in (4.1) and written Pi := (wi , zi , ψi ). The
transition probabilities of the Markov chain are
P(X n+1 = j | X n = i) =


w

ij

zij

if ψi = 0
if ψi = 1

where wi := (wi1 , . . . , wiM ) ≥ 0 and wi e = 1 (similarly for zi ). That is, members of Wi and
Zi are M -dimensional probability vectors. Let
vi := sup E
P ∈P

"∞
X
n=0

U (X n , P )

n−1
Y
m=0



D(X m , P )  X 0


7

#

=i

for all 1 ≤ i ≤ M

(4.4)

1
ψ1 = 0

2

···

3

1

M

ψi = 1

2

ψ1 = 0

(a)

···

3

M

ψi = 1

(b)

Figure 4.1.1: Graphs of possible matrices B(z) from Example 4.5
where


c



1/ (1 + ρ)
i (wi ) if ψi = 0
U (i, P ) :=
and D(i, P ) :=
ki (zi ) if ψi = 1
1

if ψi = 0;
if ψi = 1.

In the above, ρ > 0 is a discount factor. [10, Lemma 5] establishes that the dynamic
programming equation associated with (4.4) is exactly (4.3) with [L(w)]ij := wij /(1 + ρ),
[B(z)]ij := zij , [c(w)]i := ci (wi ), and [k(z)]i := ki (zi ).
In the above, states i on which ψi = 1 are the “trouble” states with vanishing discount
factor. In fact, requiring ψi = 0 for all i returns us to a nonvanishing discount factor problem
whose well-posedness is easy to establish.
The following assumptions will prove paramount:
(H2) For each P := (w, z, ψ) in P and state i with ψi = 1, there exists a path in the graph
of B(z) from i to some state j(i) with ψj(i) = 0.
(H3) For each P := (w, z, ψ) in P, I − L(w) is an SDD Z-matrix with positive diagonals and
I − B(z) is a WDD Z-matrix whose diagonals satisfy 0 ≤ [B(z)]ii ≤ 1.
Theorem 4.3. Suppose (H0)–(H3). (v ` )`≥1 defined by Policy-Iteration is nondecreasing
and converges to the unique solution v of (4.3). Moreover, if P is finite, convergence occurs
in at most |P| iterations.
Proof. (H2) and (H3) ensure that A(P ) is a WCDD Z-matrix with positive diagonals. The
desired result follows from Theorem 3.5 and Proposition 2.2.

Corollary 4.4. Consider Example 4.2.
Suppose (H0)–(H2).
M
Policy-Iteration converges to v in R satisfying (4.4).

(v ` )`≥1 defined by

An example satisfying (H2) is given:
Example 4.5. Consider Example 4.2. Suppose all P := (w, z, ψ) in P satisfy
ψ1 = 0 and zij = 0 if 1 < i ≤ j.

(4.5)

This corresponds to (i) a nonvanishing discount at state 1 and that (ii) transitions from a
state with vanishing discount are unidirectional (if ψX n = 1, X n+1 < X n a.s.). See Figure
4.1.1 for example graphs of B(z) subject to (4.5).

8

4.2

Uniqueness

Let
Lv := sup {L(w)v + c(w)} and Bv := sup {B(z)v + k(z)} .
w∈W

(4.6)

z∈Z

The condition (H2) turns out to be too restrictive for some problems of interest. However,
the following weaker property of B is not unusual:
(H4) For each solution v of (4.3) and each state i, there exist integers m(i) and n(i) such
that 0 ≤ n(i) < m(i) and [Bm(i) v]i < [Bn(i) v]i .
Lemma 4.6. Suppose (H3) and (H4). Let (P ` )`≥0 := (w` , z ` , ψ ` )`≥0 be a sequence in P and
v a solution of (4.3) satisfying
−A(P ` )v + b(P ` ) → sup {−A(P )v + b(P )} = 0.
P ∈P

There exists `0 ≥ 0 such that for each ` ≥ `0 and state i with ψi` = 1, there exists a path in
`
the graph of B(z ` ) from i to some state j(i, `) with ψj(i,`)
= 0.
Proof. Suppose the contrary. A pigeonhole principle argument yields the existence of a
subsequence (P `q )q≥0 := (w`q , z `q , ψ `q )q≥0 of (P ` )`≥0 such that
• ψ `q = ψ is a constant independent of q;
• the graph of B(z `q ) (call it G) is a constant independent of q;
• there exists i such that ψi = 1 and for all j reachable from i (in G), ψj = 1.
Let V := {j1 , . . . , jk } be the states reachable from i. Let r ∈ V ∪ {i} be arbitrary. Since the
limit of a convergent sequence equals to the limit of any of its subsequences,
h

i

B(z `q )v + k(z `q ) − vr =
r

i
1h
−A(P `q )v + b(P `q ) → 0,
r
δ

and hence [Bv]r ≥ vr . Now, since v is a solution of (4.3), it follows that Bv ≤ v. Therefore,
[Bv]r = vr . Moreover,
[B2 v]r = [B(Bv)]r ≥ [B(z `q )(Bv) + k(z `q )]r =

X

[B(z `q )]rj [Bv]j + [k(z `q )]r

j∈V

=

X

`q

[B(z )]rj vj + [k(z `q )]r = [B(z `q )v + k(z `q )]r → [Bv]r

j∈V

and hence [B2 v]r ≥ [Bv]r . Since B is a monotone operator by (H3), Bv ≤ v implies B2 v ≤ Bv,
and hence [B2 v]r = [Bv]r . We can continue this procedure to obtain
vr = [Bv]r = [B2 v]r = [B3 v]r = · · ·
Setting r = i in the above yields a contradiction to (H4).
9



If we take the trivial path i → i as having length zero, the proof above also implies that
for ` sufficiently large and for all i, there is a path of length < m(i) (where m(i) is specified
`
by (H4)) in the graph of B(z ` ) from i to some state j(i, `) with ψj(i,`)
= 0. An example is
given below:
Example 4.7. Consider Example 4.2 with Zi = Zj for all states i and j. For all states i,
let ki (zi ) := −C < 0. It follows that for all x in RM ,
B2 x = sup {B(z)B(z 0 )x} − 2C < sup {B(z)x} − C = Bx,
z,z 0 ∈Z

z∈Z

so that (H4) is satisfied with 1 = n(i) < m(i) = 2 for all i. Intuitively, the controller pays
twice the cost to apply B twice.
In this case, denoting by v a solution of (4.3), the control shown in Figure 4.1.1a cannot
correspond to some Pv satisfying −A(Pv )v + b(Pv ) = supP ∈P {−A(P )v + b(P )} = 0 since any
path from i > 2 to j = 1 is of length at least m(i) = 2.
We can now prove uniqueness independent of (H2):
Theorem 4.8. Suppose (H0), (H3), and (H4). A solution of (4.3) is unique.
Proof. Let x and y be two solutions and (P ` )`≥0 be a sequence in P such that
−A(P ` )y + b(P ` ) → sup {−A(P )y + b(P )} = 0.
P ∈P

It follows from (H3), (H4), and Lemma 4.6 that we can, without loss of generality, assume
A(P ` ) is a WCDD Z-matrix with positive diagonals, and hence an M-matrix by Theorem 3.5.
For some sequence (` )`≥0 in RM with ` → 0, we can write
−A(P ` )y + b(P ` ) + ` = 0 = sup {−A(P )x + b(P )} ≥ −A(P ` )x + b(P ` ),
P ∈P

so that A(P ` )(x − y) ≥ −` . Since the inverse of a monotone matrix has nonnegative elements
and P 7→ A(P )−1 is bounded by (H0), x − y ≥ 0. Similarly, y − x ≥ 0.

Unfortunately, the conditions of Theorem 4.8 cannot guarantee that the iterates (v ` )`≥1
given by policy iteration are well-defined, as A(P ` ) may be singular for some ` ≥ 1. This is
demonstrated in the following example, for which (H2) does not hold:
Example 4.9 (Failure of policy iteration). Consider Example 4.2. For all states i, let
Zi := {ej }M
j=1 be the set of standard basis vectors and
ki (zi ) := −C −

X

zij |i − j| < 0 where C > 0.

j

As in Example 4.7, (H4) is satisfied due to the fixed cost C.
Let δ := 1. Suppose there exists a state r with 1 ∈ Dr and cr (wr ) < −C for all controls w
in W. It is readily verified that Policy-Iteration initialized with the zero vector v 0 := 0
picks P 1 := (w1 , z 1 , ψ 1 ) with zr1 = er and ψr1 = 1. It follows that
[A(P 1 )]rj = [I − B(z 1 )]rj = [I]rj − [I]rj = 0 for all j
so that A(P 1 ) is singular, and hence v 1 is undefined.
For any ` ≥ 1, it is possible to construct more complicated examples in which the matrices
A(P 1 ), . . . , A(P `−1 ) are nonsingular while A(P ` ) is singular. That is, policy iteration can fail
at any iterate.
10

4.3

Policy iteration on a modified problem

As demonstrated in the previous section, if (H2) is not satisfied, policy iteration may fail.
We may, however, hope to construct a solution by performing policy iteration on a “modified
problem” with control set P 0 obtained by removing controls P in P that render A(P ) singular.
We define (H1)0 by replacing all occurrences of P with P 0 in the definition of (H1). (H2)0
and (H3)0 are defined similarly. We can now state the above idea precisely:
Theorem 4.10. Let P 0 :=
(H2)0 , (H3), (H4), and

QM

0
i=1 Pi

where each Pi0 ⊂ Pi is nonempty. Suppose (H0), (H1)0 ,

for all v in RM , sup {−A(P )v + b(P )} = 0 =⇒ sup {−A(P )v + b(P )} = 0.
P ∈P 0

(4.7)

P ∈P

(v ` )`≥1 defined by Policy-Iteration(P 0 , A(·), b(·), v 0 ) is nondecreasing and converges to
the unique solution of (4.3). Moreover, if P 0 is finite, convergence occurs in at most |P 0 |
iterations.
Proof. Since P 0 ⊂ P, it follows immediately that (H0)0 and (H3)0 are satisfied, so that by
Theorem 4.3, (v ` )`≥1 is well-defined and converges to the unique solution v of the modified
problem. That is, v ` → v and supP ∈P 0 {−A(P )v + b(P )} = 0. By (4.7), v solves the
original problem (4.3). Since solutions to (4.3) are unique by Theorem 4.8, the desired result
follows.

We now give a nontrivial example (in the sense that (H2) fails) for which we can apply
Theorem 4.10:
Example 4.11. Consider Example 4.2. Let (i) Z and k be given as in Example 4.9, (ii) Wi
be the set of all M -dimensional probability vectors wi with wij = 0 whenever |i − j| > 1, (iii)
c be continuous and bounded, and (iv) c := maxw∈W c(w) with ci−1 ≥ ci for all 1 < i ≤ M .
Let P 0 be all P := (w, z, ψ) in P satisfying (4.5). Then, the conditions of Theorem 4.10 are
satisfied.
Proof. It is straightforward to verify (H0), (H1)0 , (H2)0 , (H3), and (H4). Thus, it is sufficient
to show (4.7). We write Pi0 := Wi × Zi0 × Di0 and define [B0 x]i for i > 1 by replacing Z with
Q
0
Z 0 := M
i=1 Zi in (4.6).
We first show that the solution v to the modified problem is nonincreasing:
vi−1 ≥ vi for all 1 < i ≤ M.
Suppose the contrary. Let r > 1 be the minimal element such that vr−1 < vr . If vr = [B0 v]r ,
then vr = vj − C − |r − j| for some j < r. Either j = r − 1 or
vr−1 ≥ [B0 v]r−1 ≥ vj − C − |(r − 1) − j| ≥ vr
(both are contradictions). It follows that vr = [Lv]r . Letting w0j , v0 := 0 for notational
convenience, assumption (ii) implies
vr−1 ≥ [Lv]r−1


r
 X




wr−1,j
vr−1
= max
vj + [c(w)]r−1 ≥
+ cr−1

w∈W 
1+ρ
j=r−2 1 + ρ

11

so that vr−1 ≥ (1 + 1/ρ)cr−1 . If vr ≥ vr+1 , it follows similarly from vr = [Lv]r that
vr ≤ (1 + 1/ρ)cr so that vr−1 ≥ vr (a contradiction) and hence it must be the case that
vr < vr+1 . We can repeat this argument inductively to arrive at the contradiction
vr−1 < vr < · · · < vM and vr−1 ≥ (1 + 1/ρ)cr−1 ≥ (1 + 1/ρ)cM ≥ vM .
Since v is nonincreasing, v ≥ Bv (it is suboptimal to take ψi = 1 and zij = 1 for states i
and j with j ≥ i), and hence (4.7) holds.


5

Numerical schemes for the HJBQVI problem

All numerical schemes herein are on a rectilinear grid
o

n

n

o

n

o

t1 , . . . , tN × x11 , x12 , . . . × · · · × xd1 , xd2 , . . .

where 0 =: t1 < · · · < tN := T and xj1 < xj2 < · · · for all j. Multi-indices are used (i.e.
xi := (xi1 , . . . , xid )). M denotes the number of spatial points xi . For functions q := q(t, x)
defined on [0, T ] × Rd , the shorthands qin := q(tn , xi ) and q n (x) := q(tn , x) are employed.
In the absence of ambiguity, we use q n to denote the vector with components qin and take
∆t := tn+1 − tn . It is understood that maxn {tn+1 − tn } → 0 and maxi {xi+1 − xi } → 0 as
h → 0, where h denotes a “global” discretization parameter that controls the coarseness of
the grid.
Control sets W and Z(t, x) are approximated by finite sets ∅ =
6 Wh ⊂ W and Zh (t, x) ⊂
Z(t, x). The reader concerned with consistency should impose some regularity to justify this
approximation, such as: (i) W is compact, (ii) Z is everywhere compact and continuous with
respect to the Hausdorff metric, and (iii) maxw∈W minwh ∈Wh |w − wh | → 0 as the discretization
parameter h → 0 along with an identical pointwise condition for Z and Zh .
The discretized impulse operator (1.2) is
[Mnh un ]i := maxn {un Jxi + Γni (z)K + Kin (z)}
z∈(Zh )i

where ϕJxK denotes linear interpolation using the value of ϕ on grid nodes. It is understood
that controls z that cause xi + Γni (z) to exit the numerical grid are not included in (Zh )ni .
We use Łnh (w) to denote a consistent discretization of Łw with coefficients frozen at t = tn .
Recall that in (1.1), Λ ⊂ ∂Ω is a special subset of the boundary at which a Dirichlet-like
condition is applied. To distinguish points, we denote by Φ a diagonal matrix satisfying
[Φ]ii = 0 whenever xi is in Λ and [Φ]ii = 1 otherwise.
Since the Dirichlet-like condition is imposed at the final time t = T , the numerical method
N
proceeds backwards in time (i.e. from tn+1 to tn ). More precisely, letting uN
i := gi , the
numerical solution un at timestep 1 ≤ n < N produced by each scheme (given the solution at
the previous timestep, un+1 ) is written as a solution of (2.1) with A and b picked appropriately.
Control sets are given by (4.1) and
Wi := Wh , Zi :=


(Z )n0
h i

{∅}



{0, 1} if (Z )n0 6= ∅
if (Zh )ni 0 6= ∅
h i
, and Di :=

otherwise
{0}
otherwise

12

(5.1)

where n0 is n + 1 for the semi-Lagrangian scheme (see §5.3) and n otherwise. As a technical
detail, we take Zi to be a nonempty set (we choose {∅} arbitrarily) whenever (Zh )ni 0 is empty
to ensure that the product Wi × Zi × Di of (4.1) is nonempty.
We make the following assumptions:
(A0) W :=

QM

i=1

Wi and Z :=

QM

i=1

Zi are finite.

(A1) For all w in W, −Łnh (w) is a WDD Z-matrix with nonnegative diagonals.
(A2) For all z in Z, B n (z) is a right stochastic (a.k.a. Markov) matrix with [B n (z)v]i =
vJxi + Γni (zi )K.
(A3) ρ ≥ 0 and δ,  > 0.
Since (A0) ensures that P is finite, all schemes in the sequel satisfy (H0) and (H1).
Remark 5.1. Barles and Souganidis [4] prove that a numerical scheme converges to the
unique viscosity solution of a fully nonlinear second order equation (such as (1.1)) satisfying
a comparison result if it is monotone in the viscosity sense, `∞ stable, and consistent.
Comparison results for the HJBQVI (1.1) are provided in [26, Theorem 5.11]. (A1) and (A2)
ensure monotonicity (see [23, Section 1.3] for an example of a stable nonmonotone scheme
that fails to converge). For brevity, we do not give proofs of consistency or discuss stability
here.

5.1

Direct control

In a direct control formulation, either the generator (supw∈W {∂u/∂t + Łw u − ρu + f w }) or
impulse (Mu − u) component is active at any grid point. Since these have different units,
comparing them in floating point arithmetic requires a scaling factor δ > 0 to ensure fast
convergence [16] (see also Lemma 4.1). Scaling by δ and discretizing (1.1) (ignoring boundary
conditions) yields
max max

( n+1
u
i

w∈Wh

− uni
+ [Łnh (w)un ]i − ρuni + fin (w) , δ ([Mnh un ]i − uni ) = 0.
∆t
)

!

Including boundary conditions, this is put in the form of (4.3) by taking




L(w) := Φ (Łnh (w) − ρI) ∆t;

c(w) := Φ un+1 + f n (w)∆t + (I − Φ) g n ;

B(z) := B n (z);

k(z) := K n (z).

(5.2)

With B and k given above, the operator Mnh is equivalent to B defined in (4.6).
L and B given above satisfy (H3) due to (A1)–(A3). Therefore, (H4) is a sufficient
condition for uniqueness of solutions (Theorem 4.8). Similarly, (H2) is a sufficient condition
for convergence of the corresponding policy iteration (Theorem 4.3).

13

5.2

Penalized

A penalized formulation (treated in detail in [28]) imposes a penalty scaled by 1/0  0
whenever Mu > u. The scheme is given by:
max

w∈Wh

( n+1
u
i

− uni
+ [Łnh (w)un ]i − ρuni + fin (w) + max ([Mnh un ]i − uni , 0) /0 = 0.
∆t
)

For simplicity, we take 0 := ∆t for some  > 0. Including boundary conditions, this is put
in the form (2.1) by taking
A(P ) := I + Φ (ρI − Łnh (w)) ∆t + Ψ (I − B n (z)) /;




b(P ) := Φ un+1 + f n (w)∆t + (I − Φ) g n + ΨK n (z)/.
Convergence of the corresponding policy iteration is trivial since A(P ) is an SDD Z-matrix
with positive diagonals (by virtue of (A1)–(A3)), and hence an M-matrix.

5.3

Semi-Lagrangian

The crux of a semi-Lagrangian scheme is the use of a Lagrangian derivative to remove the
Dx coefficient’s dependency on the control w. It is assumed that (i) σ is independent of the
control and (ii) the drift µ and forcing term f can be split into (sufficiently regular) controlled
and uncontrolled components:
ˆ(y, w) and f (y, w) = fˆ(y) + fˆ(y, w).
µ(y, w) = µ̂(y) + µ̂
We now give some intuition behind a semi-Lagrangian scheme. Consider a generator Ł̂
corresponding to an uncontrolled SDE:
D

E

ˆ(y, w), Dx u(y) .
Ł̂u(y) := Ł(w)u(y) − µ̂
Letting X := X(t) denote a d-dimensional trajectory satisfying
ˆ(t, X(t), w)dt on (tn , tn+1 ]
X(tn ) = xi and dX(t) = µ̂
ˆ(tn , X(tn ), w)∆t = xi + µ̂
ˆni (w)∆t, we define the Lagrangian
so that X(tn+1 ) ≈ X(tn ) + µ̂
derivative with respect to X as
D
E
Du
∂
∂u
ˆ(t, X(t), w), Dx u(t, X(t)) .
(t, X(t), w) :=
[u(t, X(t))] =
(t, X(t)) + µ̂
Dt
∂t
∂t

Ignoring boundary conditions, we substitute
(

max sup
w∈W

Du
into (1.1) to get
Dt

Du w
+ Ł̂u − ρu + f w , Mu − u = 0.
Dt
)

14

!

A discretization of the above is




max max u
w∈Wh

n+1

q

xi +

y

ˆni (w)∆t
µ̂

 h

n+1
+ fˆin+1 (w)∆t , Mn+1
h u

−

uni

+

h

i
i

i

Ł̂nh un
i



− ρuni + fˆin ∆t = 0.

ˆni (w)∆t to exit the numerical grid are not
It is understood that controls w that cause xi + µ̂
considered at node i. Consistency of this scheme (subject to some mild assumptions) can be
shown similarly to [12, Lemma 6.6].
In lieu of (A1), we assume:
(A10 ) −Ł̂nh is a WDD Z-matrix with nonnegative diagonals.
Let ~x denote a vector with components xi . Including boundary conditions, this is put in the
form (2.1) by taking




A := I + Φ ρI − Ł̂nh ∆t;



q
y
ˆn (w)∆t + fˆn+1 (w)∆t
b(P ) := Φ fˆn ∆t + (I − Ψ) un+1 ~x + µ̂




+ (I − Φ) g n + Ψ B n+1 (z)un+1 + K n+1 (z) .
Since A is independent of P , (2.1) becomes Av = maxP ∈P {b(P )}; no iterative method is
required. A is nonsingular since it is SDD (by virtue of (A10 ) and (A3)).

6

Examples

The remainder of this work focuses on numerical examples.

6.1

Optimal combined control of the exchange rate

The following is studied in [22, 9]. Consider a government able to influence the foreign
exchange (FEX) rate of its currency by:
• choosing the domestic interest rate (stochastic control);
• buying or selling foreign currency (impulse control).
Let (rt )t≥0 denote the domestic interest rate process and r the foreign interest rate. At any
point in time, the government can buy (z > 0) or sell (z < 0) foreign currency to influence
the FEX market. (Xt )t≥0 , the log of the FEX rate, follows
dXt = −a (rt − r) dt + σdWt
Xτj+1 = Xτj+1 − + zτj+1

if τj < t < τj+1

(stochastic control);
(impulse control).

(Wt )t≥0 is a standard Brownian motion. a > 0 parameterizes the effect of the interest rate
differential, wt := rt − r, on the FEX rate.
15

Parameter

Value

ρ
σ
T
x?
W
a
b
λ
C

2%
30%
10
0
0-7%
0.25
3
1
0.1

Discount factor
Volatility
Expiry
Optimal parity
Interest rate differential
Interest rate differential effect
Interest rate differential cost
Scaled transaction cost
Fixed transaction cost

per annum
per annum
years
per annum

Table 6.1.1: Optimal combined control of the exchange rate: parameters
Let θ := (w, τ1 , τ2 , . . . , zτ1 , zτ2 , . . .) where (i) (wt )t≥0 is an adapted process, (ii) τ1 , τ2 , . . .
are stopping times with 0 =: τ0 ≤ τ1 ≤ τ2 ≤ . . . ≤ T , and (iii) zτk is a τk -measurable random
variable taking values from some set Z(τk , Xτk ). Any such θ satisfying these properties is
referred to as a combined control.
A combined control is admissible if at all times t, wmin ≤ wt ≤ wmax (alternatively, we
could impose this up to null sets). Let Θ denote the set of all admissible controls. The
optimal cost at time t when Xt = x is given by


u(t, x) := eρt sup E(t,x) −
θ∈Θ

Z T
t





e−ρs p(Xs ) + bws2 ds −

X


  

 
e−ρτj λ zτj  + C  .

(6.1)

τj ≤T

The cost of the distance of the FEX rate to the optimal parity x? is parameterized by the
function p. We take p(x) := (max(x − x? , 0))2 . The constant b ≥ 0 parameterizes the cost
associated with a nonzero interest rate differential. λ ≥ 0 and C > 0 parameterize the cost of
an impulse. ρ ≥ 0 is a discount factor.
It is well-known [6] that the dynamic programming equation associated to (6.1) is the
HJBQVI on Ω := R and Λ := ∅ given by (1.1) with g(T, x) := 0 and
W := [wmin , wmax ];
∂u 1 2 ∂ 2 u
Ł(t, x, w) := −aw
;
+ σ
∂x 2 ∂x2
f (t, x, w) := −p(x) − bw2 ;
6.1.1

Z(t, x) := R;
Γ(t, x, z) := z;
K(t, x, z) := −λ|z| − C.

Convergence of the direct control scheme

Discretization requires that we truncate [0, T ] × R to [0, T ] × [x1 , xM ] and Z(t, x) = R to
[x1 , xM ] − x so that the exchange rate after an impulse, x + Γ(t, x, z) = x + z, remains in the
computational domain. Let ∆z > 0 divide xM − x1 . A discretization of the truncated Z(t, x)
is
(Zhn )i := {0, ∆z, 2∆z, . . . , xM − x1 } + (x1 − xi ) .
An artificial Neumann boundary condition ∂u/∂x = 0 is used at x1 and xM so that the
first and last rows of Łnh (w) are zero. In particular, we assume an upwind three-point stencil
16

Optimal cost (u(t = 0, x))

Optimal interest rate differential (w)

0.06

0.05

0.04

Impulse

0.03

0.02

0.01

x = η0
0.00
−3.0

−2.5

−2.0

−1.5

−1.0

−0.5

x=η
0.0

0.5

0.0

T

−0.5

T

−1.0

T

−1.5

T

−2.0

(a) Optimal control (T = 10)

=
=
=

−2.5
−3.0

1.0

Log-transformed FEX rate (x)

=

−2.5

−2.0

−1.5

−1.0

−0.5

0.0

2
10
32
∞

0.5

1.0

Log-transformed FEX rate (x)

(b) Values for several times-to-expiry

Figure 6.1.1: Optimal combined control of the exchange rate at initial time
[15, Appendix C] so that
[Łnh (w)v]i :=


0

if i = 1 or i = M
(vi−1 − vi ) αn (w) + (vi+1 − vi ) β n (w) otherwise
i
i

where αin (w) and βin (w) are nonnegative constants arising from the discretization.
The direct control problem is given by (4.3) subject to (5.1) and (5.2). It is easy to
verify that B2 x < Bx for all x so that (H4) is satisfied (recall B = Mnh ). By Theorem 4.8,
solutions to the problem are unique. However, policy iteration may fail since (H2) is not
satisfied. A trivial example violating (H2) is that of a cycle between two nodes xi 6= xj (e.g.
xi + Γ(t, xi , xj − xi ) = xj and xj + Γ(t, xj , xi − xj ) = xi ).
We perform policy iteration on a modified problem with control set P 0 ( P consisting of
all controls P := (w, z, ψ) in P satisfying
ψ1 = 0 and zi < 0 for all i > 1
n+1
so that (H2)0 holds. If un+1 is nonincreasing (i.e. un+1
), we can use the same
i−1 ≥ ui
n
arguments as in Example 4.11 to establish that the solution v = u of the modified problem
solves the original problem (i.e. (4.7) is satisfied) and is nonincreasing. Since uN = 0 is
nonincreasing, induction yields convergence of the scheme at each timestep.

Remark 6.1. The condition zi < 0 appeals to intuition: the domestic government should
never perform an impulse that weakens the domestic currency (i.e. zi ≥ 0).
6.1.2

Optimal control

If the currency is sufficiently weak, the government intervenes in the FEX market. That is,
at time t, the impulse occurs only on [η(t), ∞) for some η(t) (the region (−∞, η(t)) on which
the impulse is not applied is referred to as the continuation region, corresponding to nodes i
with ψi = 0 in the numerical solution). When the FEX rate at time t enters [η(t), ∞), the
government intervenes to bring it back to η0 (t) < η(t). This phenomenon is shown in Figure
6.1.1a. The optimal cost u for varying expiry times T is shown in Figure 6.1.1b.
17

h

x nodes

w nodes

z nodes

Timesteps

1
1/2
..
.

32
64
..
.

8
16
..
.

16
32
..
.

16
32
..
.

Table 6.1.2: Optimal combined control of the exchange rate: numerical grid
6.1.3

Convergence tests

Convergence tests are shown in Table 6.1.3. Times are normalized to the fastest semiLagrangian solve. The ratio of successive changes in the solution (at a point) is reported.
BiCGSTAB with an ILUT preconditioner is used for the Solve routine (line 3 of
Policy-Iteration) in this and all subsequent sections. In the specific case of the semiLagrangian scheme for the exchange rate problem, a simple tridiagonal solve can be used
since the problem is a one-dimensional diffusion.
Policy-Iteration is terminated upon achieving a desired error tolerance:



 k


vi − vik−1 

 
max
i  max v k  , scale 
i



< tol.

The scale parameter ensures that unrealistic levels of accuracy are not imposed on the solution.
We take tol = 10−6 and scale = 1 for this and all future tests. The initial guess v 0 is taken to
be the solution at the previous timestep, un+1 .
Following [16], we take  := D∆t and δ := 1/ with D = 10−2 .
For completeness, we mention that the obvious splitting with µ̂(t, x) := 0 and fˆ(t, x) :=
−p(x) is used in the semi-Lagrangian scheme. The numerical examples of the sequel (6.2 and
6.3) also use the obvious splittings.
The direct control and penalized schemes converge superlinearly. We speculate that
this occurs since x 7→ u(t, x) is linear to the right of x = η0 (t), and hence no error is
made in approximating the term Dx u and Dx2 u there. Assuming the solution un+1 of the
semi-Lagrangian scheme is linear to the right of η0 (tn+1 ), error is introduced due to the
approximation of η0 (tn ) by η0 (tn+1 ). This suggests that the direct control and penalized
schemes may outperform the semi-Lagrangian scheme for problems with simple continuation
regions and linear transaction costs.
Unsurprisingly, the direct control and penalized schemes are near-identical in performance
and accuracy since the scaling and penalty factors are chosen identically (i.e. δ = 1/). We
mention that the choice of δ = 1 (i.e. no scaling) yields poor performance in the direct control
setting (see [16] for an explanation).
Note that the average number of BiCGSTAB iterations per call to Solve can be less
than one, suggesting that sometimes, no BiCGSTAB iterations are required on line 3 of
Policy-Iteration. This occurs when the initial residual, b(P ` )−A(P ` )v `−1 , is small enough
in magnitude (i.e. at the last policy iteration before convergence).

18

h

u(t = 0, x = 0)

Avg. policy its.

Avg. BiCGSTAB its.

1
1/2
1/4
1/8
1/16
1/32

-0.60685256
-0.61187228
-0.61300925
-0.61317577
-0.61321292
-0.61321903

3.13
2.88
2.58
2.49
2.48
2.46

0.74
0.90
0.93
0.94
0.95
0.95

Ratio

Norm. time

4.42
6.83
4.48
6.08

1.32e+01
6.99e+01
3.98e+02
2.77e+03
2.09e+04
1.61e+05

Ratio

Norm. time

4.42
7.20
4.38
6.36

1.38e+01
6.96e+01
3.95e+02
2.76e+03
2.09e+04
1.61e+05

(a) Direct control
h

u(t = 0, x = 0)

Avg. policy its.

Avg. BiCGSTAB its.

1
1/2
1/4
1/8
1/16
1/32

-0.60717652
-0.61194960
-0.61302973
-0.61317966
-0.61321390
-0.61321928

3.19
2.88
2.55
2.48
2.48
2.46

0.71
0.76
0.91
1.28
1.33
0.99
(b) Penalized

h

u(t = 0, x = 0)

1
1/2
1/4
1/8
1/16
1/32
1/64

-0.69277804
-0.64806716
-0.62865965
-0.62027822
-0.61653511
-0.61480123
-0.61398311

Ratio

Norm. time

2.30
2.32
2.24
2.16
2.12

1.00e+00
6.49e+00
4.90e+01
3.86e+02
3.17e+03
2.64e+04
2.17e+05

(c) Semi-Lagrangian

Table 6.1.3: Optimal combined control of the exchange rate: convergence tests

19

6.2

Optimal consumption and portfolio with both fixed and proportional transaction costs

The following is studied in [11]. Consider an investor that, at any point in time, has two
investment opportunities: a stock and a bank account. Let (St )t≥0 and (Bt )t≥0 denote the
amount of money invested in these two, respectively. The investor is able to
• consume continuously (stochastic control);
• transfer money from the bank to the stock (or vice versa) subject to a transaction cost
(impulse control).
Denote by (wt )t≥0 the consumption rate with 0 ≤ wt ≤ wmax . At any point in time, the
investor can move money to (z > 0) or from (z < 0) the stock incurring a transaction cost of
λ|z| + C where C > 0 and 0 ≤ λ < 1. This is captured by
dSt = µSt dt + ξSt dWt
dBt = (rBt − wt ) dt
Sτj+1 = Sτj+1 − + zτj+1

if τj < t < τj+1
if τj < t < τj+1



(stochastic control);
(stochastic control);
(impulse control);




Bτj+1 = Bτj+1 − − zτj+1 − λ zτj+1  − C

(impulse control).

A combined control θ := (w, τ1 , τ2 , . . . , zτ1 , zτ2 , . . .) is admissible if at all times, the stock
holdings and bank account are nonnegative. Let Θ denote the set of all admissible controls.
The investor’s maximal expected utility at time t with amount St = s in the stock and
Bt = b in the bank account is given by
ρt

(t,s,b)

u(t, s, b) := e sup E

"Z
T

γ
−ρt0 wt0

e

γ

t

θ∈Θ

0

dt + e

−ρT

max (BT + (1 − λ) ST − C, 0)γ
γ

#

where 0 ≤ 1 − γ < 1 is the investor’s relative risk-aversion and ρ ≥ 0 is the rate of time
preference. The utility received at the expiry corresponds to liquidating the asset and
consuming everything instantaneously.
The associated HJBQVI on Ω := (0, ∞)2 and Λ := ∅ is given by (1.1) with g(T, x) :=
max(b + (1 − λ)s − C, 0)γ /γ and
Z(t, x) := {z : x + Γ(t, x, z) ≥ 0} ;

W := [0, wmax ] ;

(rb − w) ∂

1
∂2
∂
Łw := ξ 2 s2 2 + µs + 
2
∂s
∂s
0

w γ /γ

f w := 
0

∂b

if b > 0;
Γ(t, x, z) := (z, −z − λ|z| − C);
otherwise;

if b > 0;
otherwise;

K(t, x, z) := 0.

In the above, expressions such as s · ∂/∂s are to be interpreted as identically zero when s = 0.
The convention [q1 , q2 ] = ∅ if q1 > q2 is used.

20

Parameter
Discount factor
Interest rate
Drift
Volatility
Expiry
Relative risk aversion
Scaled transaction cost
Fixed transaction cost
Maximum withdrawal rate
Initial stock value
Initial bank account value

ρ
r
µ
ξ
T
1−γ
λ
C
wmax
s0
b0

Value
10%
7%
11%
30%
40
0.7
0.1
0.05
100
$45.20
$45.20

per annum
per annum
per annum
per annum
years

Table 6.2.1: Optimal consumption: parameters from [11]
6.2.1

Convergence of the direct control scheme

As in §6.1.1, the domain [0, T ] × [0, ∞)2 and Z(t, x) are truncated so that the state after an
impulse xi + Γ(t, xi , zi ) remains in the truncated domain. We use the notation xi = (si , bi ).
The direct control problem is given by (4.3) subject to (5.1) and (5.2).
Suppose there exists a grid node xi1 and P := (w, z, ψ) such that ψi1 = 1 and that there
exists no path in B(z) from i1 to some j with ψj = 0. Since C > 0, there exists a path
i1 → i2 → · · · of infinite length such that si1 + bi1 > si2 + bi2 > · · · and ψiq = 1 for all q.
Due to the finitude of the grid, xiq = xi` (and hence siq + biq = si` + bi` ) for some q < `, a
contradiction. It follows that no such xi1 exists: (H2) is satisfied.
6.2.2

Optimal control

As in [11], three regions are observed in an optimal control: the buy (B), sell (S), and
continuation/no transaction (NT) regions. In the B and S regions, the controller intervenes
by jumping back to the closest of the two lines marked ∆1 and ∆2 . In NT, the controller
consumes continuously.
6.2.3

Convergence tests

Convergence tests are shown in Table 6.2.3. We mention that artificial Neumann boundary
conditions ∂ q u/∂sq = 0 and ∂u/∂b = 0 are used at the truncated boundaries s = smax and
b = bmax . The results for the direct control and penalized schemes are near-identical, though
the former requires significantly more policy iterations per timestep. The rate of convergence
for the semi-Lagrangian scheme becomes sublinear for higher levels of refinement.

6.3

Guaranteed minimum withdrawal benefit (GMWB) in variable annuities

Guaranteed minimum withdrawal benefits (GMWB) in variable annuities provide investors
with the tax-deferred nature of variable annuities along with a guaranteed minimum payment.
GMWB pricing has been previously considered as a singular control problem in [21, 14] and
21

h

s nodes

b nodes

w nodes

z nodes

Timesteps

1
1/2
..
.

20
40
..
.

20
40
..
.

15
30
..
.

15
30
..
.

32
64
..
.

Table 6.2.2: Optimal consumption: numerical grid

h

u(t = 0, s0 , b0 )

Avg. policy its.

Avg. BiCGSTAB its.

1
1/2
1/4
1/8
1/16
1/32

56.062123
58.739224
59.420125
59.658413
59.754780
59.797206

7.63
8.80
10.4
11.8
13.3
14.2

1.28
1.90
2.28
3.28
4.45
6.54

Ratio

Norm. time

3.93
2.86
2.47
2.27

1.63e+01
2.93e+02
5.66e+03
1.03e+05
1.85e+06
3.05e+07

Ratio

Norm. time

3.94
2.86
2.47
2.27

1.03e+01
1.47e+02
1.99e+03
2.69e+04
4.02e+05
5.86e+06

(a) Direct control
h

u(t = 0, s0 , b0 )

Avg. policy its.

Avg. BiCGSTAB its.

1
1/2
1/4
1/8
1/16
1/32

56.058496
58.739041
59.420075
59.658399
59.754778
59.797215

4.09
3.95
3.40
3.04
2.80
2.58

1.43
1.77
2.35
3.69
5.50
5.98
(b) Penalized

h

u(t = 0, s0 , b0 )

Avg. BiCGSTAB its.

1
1/2
1/4
1/8
1/16
1/32
1/64

55.621632
58.782064
59.404576
59.569370
59.651186
59.705315
59.748325

1.00
2.00
3.00
4.00
6.00
8.00
10.8

Ratio

Norm. time

5.08
3.78
2.01
1.51
1.26

1.00e+00
1.55e+01
2.60e+02
4.05e+03
6.68e+04
1.11e+06
1.85e+07

(c) Semi-Lagrangian

Table 6.2.3: Optimal consumption: convergence tests

22

25

20

60

15

20

0

NT

∆1

40

10

5

∆2
B
0

20

40

60

80

100

100
80
60
40
20

Value (u(t = 0, s, b))

Stock holdings (s)

S
80

Optimal consumption (w)

100

0
100
0

80

20

Stoc

0

Bank account (b)

t
un
cco

60
40

40

k ho

(a) Optimal control

lding60
s (s) 80

20
100

0

nk
Ba

( b)

a

(b) Value

Figure 6.2.1: Optimal consumption at initial time (compare with [11, Figures 1 and 2])
as an impulse control problem in [12]. Optimal controls for GMWBs with annual withdrawals
is considered in [1].
A GMWB is composed of investment and guarantee accounts, (St )t≥0 and (At )t≥0 , respectively. It is bootstrapped via a lump sum payment s0 to an insurer, placed in the (risky)
investment account (i.e. S0 = s0 ). A GMWB promises to pay back at least the lump sum
s0 , assuming that the holder of the contract does not withdraw above a certain rate. This
is captured by setting A0 = s0 and reducing both investment and guarantee accounts on a
dollar-for-dollar basis upon withdrawals. The holder can continue to withdraw as long as the
guarantee account remains positive. In particular, at any point in time until the expiry of
the contract T , the holder may:
• withdraw continuously at a rate of G ≥ 0 per annum regardless of the performance of
the investment (stochastic control);
• withdraw a finite amount z instantaneously reduced by the excess withdrawal rate
0 ≤ κ ≤ 1 (impulse control).
The holder gets the larger of the investment account and a full withdrawal at expiry.
The guarantee account can be withdrawn from continuously or instantaneously:
dAt = −wt dt
Aτj+1 = Aτj+1 − − zτj+1

if τj < t < τj+1

(stochastic control);
(impulse control).

Let ρ ≥ 0 denote the risk-free rate. Consider an index (Yt )t≥0 following
dYt = ρYt dt + ξYt dWt
under the risk-neutral measure. The investment account tracks the index and is adjusted by
withdrawals from the guarantee account:




dSt = (ρ − η) St − wt 1{St >0} dt + ξSt dWt




Sτj+1 = max Sτj+1 − − zτj+1 , 0 .
23

if τj < t < τj+1 ;

Parameter

Value

ρ
η
ξ
T
G
κ
C
s0

5%
0%
30%
10
$10
10%
1/106
$100

Risk-free rate
Premium
Volatility
Expiry
Withdrawal rate
Excess withdrawal rate
Fixed transaction cost
Initial lump sum payment

per annum
per annum
per annum
years
per annum

Table 6.3.1: GMWB: parameters from [12]
0 ≤ η ≤ ρ is the proportional rate deducted from the investment account and serves as a
premium for the guarantee. A combined control θ := (w, τ1 , τ2 , . . . , z1 , z2 , . . .) is admissible if
at all times, the guarantee account is nonnegative. Let Θ denote the set of all admissible
controls.
The insurer’s worst-case cost of hedging (discussed in [2]) a GMWB at time t with amount
St = s in the risky account and amount At = a is
ρt

(t,s,a)

u(t, s, a) := e sup E
θ∈Θ

"Z
T
t

0

e−ρt wt0 dt0 + e−ρT max (ST , (1 − κ) AT − C)
+

X

e

−ρτj



(1 − κ) zτj − C



#

τj ≤T

where C > 0 is a fixed transaction cost. The terminal payoff corresponds to the maximum of
the investment account or withdrawing the entirety of the guarantee account at the excess
withdrawal rate.
Let x := (s, a) and ζ := ρ − η. The associated HJBQVI on Ω := (0, ∞)2 and Λ := ∅ is
given by (1.1) with g(T, x) := max(s, (1 − κ)a − C) and
W := [0, G] ;

Z(t, x) := [0, a] ;


∂

−w

∂a


ξ 2 s2 ∂ 2
∂
∂
Łw :=
+ ζs + −w ∂a
2
2 ∂s
∂s 

0
f w :=

6.3.1


w
0

+

∂
∂s



if s, a > 0;
if a > 0; Γ(t, x, z) := − (min (z, s) , z) ;
otherwise;

if a > 0;
otherwise;

K(t, x, z) := (1 − κ) z − C.

Convergence of the direct control scheme

We use the notation xi = (si , ai ) and assume the origin (0, 0) is part of the numerical grid.
The direct control problem is given by (4.3) subject to (5.1) and (5.2).
Suppose (H4) is not satisfied so that for some solution v, there exists i such that vi =
[Bv]i = [B2 v]i = · · · . Since C > 0, it follows that vi = −∞, a contradiction. Hence, (H4)
holds.
24

rat
e

70

raw
al a
t

60

60

50

Wi
thd

Guarantee account (a)

80

40

40
30
20

20

Withdraw finite amount z
0

0

50

100

150

200

250

10

300

0

Optimal impulse withdrawal (z)

80

G

100

Investment account (s)

Figure 6.3.1: GMWB: optimal control at initial time with η = 0.03126 from [12]
We perform policy iteration on a modified problem with control set P 0 consisting of all
controls P := (w, z, ψ) in P satisfying
ψi = 0 whenever ai = 0 and zi 6= 0 whenever ai 6= 0.
As in Example 4.5, (H2)0 follows from the unidirectionality of zi . (4.7) is established by
noting that zi = 0 incurs an infinite cost (and is therefore suboptimal). Convergence then
follows from an application of Theorem 4.10
Remark 6.2. The condition zi =
6 0 appeals to intuition: the holder should never pay C > 0
for a withdrawal of zero dollars.
6.3.2

Optimal control

Figure 6.3.1 shows an optimal control for a GMWB, corresponding to a worst-case cost of
hedging from the perspective of the insurer (optimality from the holder’s perspective, who
may have to take into consideration consumption, taxation, etc., is explored in [2]). We refer
to [12] for an explanation of the three distinct withdrawal regions.
6.3.3

Convergence tests

Convergence tests are shown in Table 6.3.3. Since w 7→ Ł(t, x, w) is linear, we take Wh =
{0, G} independent of h. An asymptotic boundary condition is used at the truncated boundary
s = smax (no boundary condition is needed at a = amax since the characteristics are outgoing
in the a direction). For details, see [12]. The direct control and penalized scheme produce
near-identical results and exhibit similar execution times.

7

Concluding remarks

This work establishes the well-posedness of (1.3) and gives sufficient conditions for convergence
of the corresponding policy iteration. (1.3) has applications to the numerical solutions of
25

h

w nodes

a nodes

z nodes

Timesteps

1
1/2
..
.

64
128
..
.

50
100
..
.

2
4
..
.

32
64
..
.

Table 6.3.2: GMWB: numerical grid

h

u(t = 0, s0 , s0 )

Avg. policy its.

Avg. BiCGSTAB its.

1
1/2
1/4
1/8
1/16
1/32

107.68342
107.70679
107.71878
107.72578
107.72964
107.73176

3.47
4.25
4.34
4.43
4.31
4.15

1.47
1.64
1.85
2.22
2.71
3.40

Ratio

Norm. time

1.95
1.71
1.81
1.83

1.71e+01
2.03e+02
2.60e+03
3.46e+04
4.75e+05
7.55e+06

Ratio

Norm. time

1.95
1.74
1.82
1.83

1.80e+01
2.06e+02
2.45e+03
3.22e+04
4.34e+05
6.62e+06

(a) Direct control
h

u(t = 0, s0 , s0 )

Avg. policy its.

Avg. BiCGSTAB its.

1
1/2
1/4
1/8
1/16
1/32

107.68243
107.70639
107.71870
107.72576
107.72964
107.73175

3.47
4.08
3.95
3.98
3.71
3.32

1.58
1.65
1.76
1.97
2.39
3.01
(b) Penalized

h

u(t = 0, s0 , s0 )

Avg. BiCGSTAB its.

1
1/2
1/4
1/8
1/16
1/32
1/64

107.42351
107.68443
107.70841
107.72257
107.73015
107.73224
107.73337

1.00
1.00
1.00
1.00
1.00
1.98
2.90

Ratio

Norm. time

10.9
1.70
1.87
3.62
1.85

1.00e+00
1.02e+01
1.39e+02
2.03e+03
3.31e+04
6.10e+05
1.13e+07

(c) Semi-Lagrangian

Table 6.3.3: GMWB: convergence tests

26

HJBQVIs (§5–6) and infinite-horizon MDPs with vanishing discount factor (Corollary 4.4).
A semi-Lagrangian scheme for the HJBQVI (1.1) is both easy to implement and requires
only one linear solve per timestep. However, it cannot be used if the diffusion or jump arrival
rate of the underlying stochastic process are control-dependent.
The direct control and penalized schemes do not suffer these limitations. Numerical
evidence suggests that both schemes perform similarly. However, policy iteration applied to
the direct control scheme can fail (Example 4.9) unless additional care is taken to remove
certain suboptimal controls. The removal of these controls is ad hoc (i.e. problem dependent).
Therefore, we recommend discretizing the problem with a penalized scheme, applying policy
iteration to solve the resulting nonlinear equations.

A

General well-posedness of the Bellman problem (2.1)

By modifying policy iteration, it is possible to arrive at a version of Proposition 2.2 independent
of (H1.ii). We can interpret this algorithm as taking into account the error from approximating
the supremum in Policy-Iteration. The algorithm, closely related to [7, Algorithm Ho-4],
is given below (subject to the convention that for x in RM and c in R, x + c is the vector x
with c added to each component):
-Policy-Iteration(P, A(·), b(·), v 0 )
P
1 Pick a positive sequence (` )`≥1 in R such that `≥1 ` < ∞
2 for ` = 1, 2, . . .
3
Pick P ` such that −A(P ` )v `−1 + b(P ` ) + ` ≥ supP ∈P {−A(P )v `−1 + b(P )}
4
v ` := Solve(A(P ` ), b(P ` ), v `−1 )
The following appears in [7]:
Lemma A.1. A bounded sequence (v ` )`≥0 in R converges if there exists a positive sequence
P
(` )`≥1 in R such that `≥1 ` < ∞ and v ` − v `−1 ≥ −` for ` ≥ 1.
We require the following lemma, whose proof is trivial and thus omitted:
Lemma A.2. Let X be a set, Y a normed linear space, T : X × Y → R, and Q : X → R
with Q bounded above. Suppose that for each x in X, Tx : Y → R defined by Tx (y) := T (x, y)
is linear and that Tx has operator norm bounded uniformly with respect to x. The map
y 7→ supx∈X {T (x, y) + Q(x)} is uniformly continuous.
Theorem A.3. Suppose (H0), (H1.i), and that A(P ) is a monotone matrix for all P in P.
(v ` )`≥1 defined by -Policy-Iteration converges to the unique solution v of (2.1).
Proof. First, note that




n

o

A(P ` ) v ` − v `−1 = −A(P ` )v `−1 + b(P ` ) ≥ sup −A(P )v `−1 + b(P ) − ` .
P ∈P

For ` > 1,
n

o

sup −A(P )v `−1 + b(P ) ≥ −A(P `−1 )v `−1 + b(P `−1 ) = 0.
P ∈P

27

(A.1)

Combining this with (A.1),
v ` − v `−1 ≥ −A(P ` )−1 (` , . . . , ` )| ≥ −C` for some C ≥ 0.
The last inequality follows from the boundedness of P 7→ A(P )−1 in (H0). By Lemma A.1,
v ` → v for some v in RM . Taking limits in (A.1) and applying Lemma A.2,
0 = lim

`→∞

!
o

n

sup −A(P )v `−1 + b(P )
P ∈P

= sup {−A(P )v + b(P )} .
P ∈P

Hence, v is a solution to (2.1). Uniqueness is proven similarly to Theorem 4.8.

B



Proof of Lemma 4.1

Proof. We write Aδ and bδ to stress dependence on δ. Let v be a solution of (4.3) with δ = 1. A
pigeonhole principle argument allows us to pick a sequence (P ` )`≥0 := (w` , z ` , ψ ` )`≥0 in P such
that ψ ` = ψ is constant and −A1 (P ` )v + b1 (P ` ) → 0. Multiplying both sides by I − Ψ + δ0 Ψ
(where Ψ := diag(ψ)) yields −Aδ0 (P ` )v + bδ0 (P ` ) → 0, and hence supP ∈P {−Aδ0 (P )v +
bδ0 (P )} ≥ 0. Supposing that this inequality is strict, it follows that for some P and i,
[−Aδ0 (P )v + bδ0 (P )]i > 0. Multiplying both sides by [I − Ψ + δ0−1 Ψ]i yields [−Aδ=1 (P )v +
bδ=1 (P )]i > 0, contradicting that v is a solution. The converse is handled similarly.


References
[1] P. Azimzadeh and P. A. Forsyth. The existence of optimal bang-bang controls for GMxB
contracts. SIAM J. Financial Math., 6(1):117–139, 2015.
[2] P. Azimzadeh, P. A. Forsyth, and K. R. Vetzal. Hedging costs for variable annuities
under regime-switching. In Hidden Markov Models in Finance, pages 133–166. Springer,
2014.
[3] J. Babbin, P. A. Forsyth, and G. Labahn. A comparison of iterated optimal stopping
and local policy iteration for American options under regime switching. J. Sci. Comput.,
58(2):409–430, 2014.
[4] G. Barles and P. E. Souganidis. Convergence of approximation schemes for fully nonlinear
second order equations. Asymptot. Anal., 4(3):271–283, 1991.
[5] E. Bayraktar and H. Xing. Pricing Asian options for jump diffusion. Math. Finance,
21(1):117–143, 2011.
[6] A. Bensoussan and J. L. Lions. Impulse control and quasi-variational inequalities.
Gaunthier-Villars, Paris, 1984.
[7] O. Bokanowski, S. Maroso, and H. Zidani. Some convergence results for Howard’s
algorithm. SIAM J. Numer. Anal., 47(4):3001–3026, 2009.
28

[8] J. H. Bramble and B. E. Hubbard. On a finite difference analogue of an elliptic boundary
problem which is neither diagonally dominant nor of non-negative type. J. Math. Phys.,
43(2):117, 1964.
[9] A. Cadenillas and F. Zapatero. Optimal central bank intervention in the foreign exchange
market. J. Econom. Theory, 87(1):218–242, 1999.
[10] J. P. Chancelier, M. Messaoud, and A. Sulem. A policy iteration algorithm for fixed
point problems with nonexpansive operators. Math. Methods Oper. Res., 65(2):239–259,
2007.
[11] J. P. Chancelier, B. Øksendal, and A. Sulem. Combined stochastic control and optimal
stopping, and application to numerical approximation of combined stochastic and impulse
control. Proc. Steklov Inst. Math., 237(0):149–172, 2002.
[12] Z. Chen and P. A. Forsyth. A numerical scheme for the impulse control formulation
for pricing variable annuities with a guaranteed minimum withdrawal benefit (GMWB).
Numer. Math., 109(4):535–569, 2008.
[13] R. Cont and E. Voltchkova. A finite difference scheme for option pricing in jump diffusion
and exponential lévy models. SIAM J. Numer. Anal., 43(4):1596–1626, 2005.
[14] M. Dai, Y. K. Kwok, and J. Zong. Guaranteed minimum withdrawal benefit in variable
annuities. Math. Finance, 18(4):595–611, 2008.
[15] P. A. Forsyth and G. Labahn. Numerical methods for controlled Hamilton-Jacobi-Bellman
PDEs in finance. J. Comput. Finance, 11(2):1, 2007.
[16] Y. Huang, P. A. Forsyth, and G. Labahn. Inexact arithmetic considerations for direct
control and penalty methods: American options under jump diffusion. Appl. Numer.
Math., 72:33–51, 2013.
[17] K. Ishii. Viscosity solutions of nonlinear second order elliptic PDEs associated with
impulse control problems. Funkcial. Ekvac., 36(1):123–141, 1993.
[18] I. Kharroubi, J. Ma, H. Pham, J. Zhang, et al. Backward SDEs with constrained jumps
and quasi-variational inequalities. Ann. Appl. Probab., 38(2):794–840, 2010.
[19] H. J. Kushner and P. G. Dupuis. Numerical methods for stochastic control problems in
continuous time. Springer-Verlag, New York, 1992.
[20] H. Le and C. Wang. A finite time horizon optimal stopping problem with regime
switching. SIAM J. Control Optim., 48(8):5193–5213, 2010.
[21] M. A. Milevsky and T. S. Salisbury. Financial valuation of guaranteed minimum
withdrawal benefits. Insurance Math. Econom., 38(1):21–38, 2006.
[22] G. Mundaca and B. Øksendal. Optimal stochastic intervention control with application
to the exchange rate. J. Math. Econom., 29(2):225–243, 1998.
29

[23] A. M. Oberman. Convergent difference schemes for degenerate elliptic and parabolic
equations: Hamilton-Jacobi equations and free boundary problems. SIAM J. Numer.
Anal., 44(2):879–895, 2006.
[24] B. Øksendal and A. Sulem. Applied stochastic control of jump diffusions, volume 498.
Springer, 2005.
[25] R. J. Plemmons. M-matrix characterizations.I–Nonsingular M-matrices. Linear Algebra
Appl., 18(2):175–188, 1977.
[26] R. C. Seydel. Existence and uniqueness of viscosity solutions for QVI associated with
impulse control of jump-diffusions. Stochastic Process. Appl., 119(10):3719–3748, 2009.
[27] P. N. Shivakumar and K. H. Chew. A sufficient condition for nonvanishing of determinants.
Proc. Amer. Math. Soc., pages 63–66, 1974.
[28] J. H. Witte and C. Reisinger. Penalty methods for the solution of discrete HJB equationscontinuous control and obstacle problems. SIAM J. Numer. Anal., 50(2):595–625, 2012.

30

