The Local Cut Lemma

arXiv:1601.05481v3 [math.CO] 12 Dec 2017

Anton Bernshteynâˆ—

Abstract
The LovaÌsz Local Lemma is a very powerful tool in probabilistic combinatorics, that is often used to prove
existence of combinatorial objects satisfying certain constraints. Moser and Tardos [26] have shown that the
LLL gives more than just pure existence results: there is an effective randomized algorithm that can be used
to find a desired object. In order to analyze this algorithm, Moser and Tardos developed the so-called entropy
compression method. It turned out that one could obtain better combinatorial results by a direct application of
the entropy compression method rather than simply appealing to the LLL. The aim of this paper is to provide
a generalization of the LLL which implies these new combinatorial results. This generalization, which we call
the Local Cut Lemma, concerns a random cut in a directed graph with certain properties. Note that our result
has a short probabilistic proof that does not use entropy compression. As a consequence, it not only shows that
a certain probability is positive, but also gives an explicit lower bound for this probability. As an illustration,
we present a new application (an improved lower bound on the number of edges in color-critical hypergraphs)
as well as explain how to use the Local Cut Lemma to derive some of the results obtained previously using the
entropy compression method.

Contents
1 Introduction

1

2 The Local Cut Lemma
2.1 Statement of the LCL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Proof of the LCL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2
2
4

3 Applications
3.1 A special version of the LCL . . . . . . .
3.2 The LCL implies the Lopsided LLL . . . .
3.3 First example: hypergraph coloring . . . .
3.4 Nonrepetitive sequences and nonrepetitive
3.5 Acyclic edge colorings . . . . . . . . . . .
3.6 Color-critical hypergraphs . . . . . . . . .
3.7 Choice functions . . . . . . . . . . . . . .

1

. . . . . .
. . . . . .
. . . . . .
colorings
. . . . . .
. . . . . .
. . . . . .

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

7
7
8
9
10
13
14
16

Introduction

One of the most useful tools in probabilistic combinatorics is the so-called LovaÌsz Local Lemma (the LLL for short),
which was proved by ErdoÌ‹s and LovaÌsz in their seminal paper [13]. Roughly speaking, the LLL asserts that, given
a family B of random events whose individual probabilities are small and whose dependency is somehow limited,
there is a positive probability that none of the events in B happen. More precisely:
Theorem 1.1 (LovaÌsz Local Lemma, [6]). Let B1 , . . . , Bn be random events in a probability space â„¦. For each
1 â‰¤ i â‰¤ n, let Î“(i) be a subset of {1, . . . , n} \ {i} such that the event Bi is independent from the algebra generated
by the events Bj with j < Î“(i) âˆª {i}. Suppose that there exists a function Âµ : {1, . . . , n} â†’ [0; 1) such that for every
1 â‰¤ i â‰¤ n,
Y
Pr(Bi ) â‰¤ Âµ(i)
(1 âˆ’ Âµ(j)).
jâˆˆÎ“(i)
âˆ— Department

of Mathematics, University of Illinois at Urbanaâ€“Champaign, IL, USA, bernsht2@illinois.edu. This research is
supported by the Illinois Distinguished Fellowship.

1

Then
Pr

n
\
i=1

!
Bi

â‰¥

n
Y

(1 âˆ’ Âµ(i)) > 0.

i=1


T
Note that the probability Pr iâˆˆI Bi , which the LLL bounds from below, is usually exponentially small (in the
parameter n). This is in contrast to the more common situation in the probabilistic method when the probability of
interest is not only positive, but separated from zero. Although this property of the LLL makes it an indispensable
tool in proving combinatorial existence results, it also makes these results seemingly nonconstructive, since sampling
the probability space to find an object with the desired properties would usually take an exponentially long expected
time. A major breakthrough was made by Moser and Tardos [26], who showed that, in a special framework for the
LLL called the variable version (the name is due to Kolipaka and Szegedy [23]), there exists a simple Las Vegas
algorithm with expected polynomial runtime that searches the probability space for a point which avoids all the
events in B. Their algorithm was subsequently refined and extended to other situations by several authors; see
e.g. [28], [23], [3], [11].
The key ingredient of Moser and Tardosâ€™s proof is the so-called entropy compression method (the name is due
to Tao [30]). The idea of this method is to encode the execution process of the algorithm in such a way that the
original sequence of random inputs can be uniquely recovered from the resulting encoding. One then proceeds to
show that if the algorithm runs for too long, the space of possible codes becomes smaller than the space of inputs,
which leads to a contradiction.
It was discovered lately (and somewhat unexpectedly) that applying the entropy compression method directly
can often produce better combinatorial results than simply using the LLL. The idea, first introduced by Grytczuk,
Kozik, and Micek in their study of nonrepetitive sequences [21], is to construct a randomized procedure that solves
a given combinatorial problem and then apply the entropy compression argument to show that it runs in expected
finite time. A wealth of new results have been obtained using this paradigm; see e.g. [12], [15], [17]. Some of these
examples are discussed in more detail in Section 3.
Note that the entropy compression method is indeed a â€œmethodâ€ that one can use to attack a problem rather
than a general theorem that contains various combinatorial results as its special cases. It is natural to ask if such a
theorem exists, i.e., if there is a generalization of the LLL that implies the new combinatorial results obtained using
the entropy compression method. The goal of this paper is to provide such a generalization, which we call the Local
Cut Lemma (the LCL for short). It is important to note that this result is purely probabilistic and similar to the
LLL in flavor. In particular, its short and simple probabilistic proof does not use the entropy compression method.
Instead, it estimates certain probabilities explicitly, in much the same way as the original (nonconstructive) proof of
the LLL does. We state and prove the LCL in Section 2. Section 3 is dedicated to applications of the LCL. We start
by introducing a simplified special case of the LCL (namely Theorem 3.1) in Subsection 3.1, which turns out to be
sufficient for most applications. In fact, Theorem 3.1 already implies the classical LLL, as we show in Subsection 3.2.
In Subsection 3.3, we discuss one simple example (namely hypergraph coloring), which provides the intuition behind
the LCL and serves as a model for more substantial applications described later. In Subsections 3.4 and 3.5 we
show how to use the LCL to prove several results obtained previously using the entropy compression method. We
also present a new application (an improved lower bound on the number of edges in color-critical hypergraphs) in
Subsection 3.6. The last application, discussed in Subsection 3.7, is a curious probabilistic corollary of the LCL.

2
2.1

The Local Cut Lemma
Statement of the LCL

To state our main result, we need to fix some notation and terminology. In what follows, a digraph always means
a finite directed multigraph. Let D be a digraph with vertex set V and edge set E. For x, y âˆˆ V , let E(x, y) âŠ† E
denote the set of all edges with tail x and head y.
A digraph D is simple if for all x, y âˆˆ V , |E(x, y)| â‰¤ 1. If D is simple and |E(x, y)| = 1, then the unique
edge with tail x and head y is denoted by xy (or sometimes (x, y)). For an arbitrary digraph D, let Ds denote
its underlying simple digraph, i.e., the simple digraph with vertex set V in which xy is an edge if and only if
E(x, y) , âˆ…. Denote the edge set of Ds by E s . For a set F âŠ† E, let F s âŠ† E s be the set of all edges xy âˆˆ E s such
that F âˆ© E(x, y) , âˆ…. A set A âŠ† V is out-closed (resp. in-closed) if for all xy âˆˆ E s , x âˆˆ A implies y âˆˆ A (resp.
y âˆˆ A implies x âˆˆ A).

2

Definition 2.1. Let D be a digraph with vertex set V and edge set E and let A âŠ† V be an out-closed set of
vertices. A set F âŠ† E of edges is an A-cut if A is in-closed in Ds âˆ’ F s . In other words, a set F âŠ† E is an A-cut if
it contains at least one edge e âˆˆ E(x, y) for all xy âˆˆ E s such that x < A and y âˆˆ A (see Fig. 1).

x0

e1

e2
x1

x2

e4

e5

e3
x4

x3

x5

x6

e6
x7
Figure 1: A digraph D with an out-closed set A = {x0 , x1 , x2 , x4 }. Any A-cut must contain the edges
{e2 , e5 , e6 } and at least one of {e3 , e4 }. For example, the set F = {e1 , e2 , e4 , e5 , e6 } consisting of the dashed
edges forms an A-cut.

We say that a vertex z âˆˆ V is reachable from x âˆˆ V if D (or, equivalently, Ds ) contains a directed xz-path. The
set of all vertices reachable from x is denoted by RD (x).
Definition 2.2. Let D be a digraph with vertex set V and edge set E. For a function Ï‰ : E s â†’ [1; +âˆ) and
vertices x âˆˆ V and z âˆˆ RD (x), define
( k
)
Y
s
Ï‰(ziâˆ’1 zi ) : x = z0 âˆ’â†’ z1 âˆ’â†’. . . âˆ’â†’ zk = z is a directed xz-path in D .
Ï‰(x, z) B min
i=1

For a set S, we use Pow(S) to denote the power set of S, i.e., the set of all subsets of S.
Definition 2.3. Let D be a digraph with vertex set V and edge set E. Let â„¦ be a probability space and let
A : â„¦ â†’ Pow(V ) and F : â„¦ â†’ Pow(E) be random variables such that with probability 1, A is an out-closed set of
vertices and F is an A-cut. Fix a function Ï‰ : E s â†’ [1; +âˆ). For xy âˆˆ E s , e âˆˆ E(x, y), and z âˆˆ RD (y), let
ÏA,F
Ï‰ (e, z) B Pr(e âˆˆ F |z âˆˆ A) Â· Ï‰(x, z).
For e âˆˆ E(x, y), define the risk to e as
ÏA,F
Ï‰ (e) B

min ÏA,F
Ï‰ (e, z).

zâˆˆRD (y)

Remark 2.4. For random events P , Q, the conditional probability Pr(P |Q) is only defined if Pr(Q) > 0. For
convenience, we adopt the following notational convention in Definition 2.3: If Q is a random event and Pr(Q) = 0,
then Pr(P |Q) = 0 for all events P . Note that this way the crucial equation Pr(P |Q) Â· Pr(Q) = Pr(P âˆ© Q) is satisfied
even when Pr(Q) = 0, and this is the only property of conditional probability we will use.
We are now ready to state the main result of this paper.
Theorem 2.5 (Local Cut Lemma). Let D be a digraph with vertex set V and edge set E. Let â„¦ be a probability
space and let A : â„¦ â†’ Pow(V ) and F : â„¦ â†’ Pow(E) be random variables such that with probability 1, A is an
out-closed set of vertices and F is an A-cut. If a function Ï‰ : E s â†’ [1; +âˆ) satisfies the following inequality for all
xy âˆˆ E s :
X
Ï‰(xy) â‰¥ 1 +
ÏA,F
(2.1.1)
Ï‰ (e),
eâˆˆE(x,y)
s

then for all xy âˆˆ E ,
Pr(y âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ï‰(xy).
3

The following immediate corollary is the main tool used in combinatorial applications of Theorem 2.5:
Corollary 2.6. Let D, A, F , Ï‰ be as in Theorem 2.5. Let x âˆˆ V , z âˆˆ RD (x), and suppose that Pr(z âˆˆ A) > 0.
Then
Pr(z âˆˆ A)
Pr(x âˆˆ A) â‰¥
> 0.
Ï‰(x, z)

2.2

Proof of the LCL

In this subsection we prove Theorem 2.5. Let D, A, F be as in the statement of Theorem 2.5 and assume that a
function Ï‰ : E s â†’ [1; +âˆ) satisfies
X
Ï‰(xy) â‰¥ 1 +
ÏA,F
(2.1.1)
Ï‰ (e)
eâˆˆE(x,y)
s

s

s

for all xy âˆˆ E . For each Ï… : E â†’ [1; +âˆ), let f (Ï…) : E â†’ [1; +âˆ) be defined by
X
ÏA,F
f (Ï…)(xy) B 1 +
(e).
Ï…
eâˆˆE(x,y)

Also, let f (0) B 1, where 0 and 1 denote the constant 0 and 1 functions respectively. Then (2.1.1) is equivalent to
Ï‰(xy) â‰¥ f (Ï‰)(xy).

(2.2.1)

Note that the map f is monotone increasing, i.e., if Ï…(xy) â‰¤ Ï… 0 (xy) for all xy âˆˆ E s , then f (Ï…)(xy) â‰¤ f (Ï… 0 )(xy) for
all xy âˆˆ E s as well.
Let Ï‰0 B 0 and let Ï‰n+1 B f (Ï‰n ) for all n âˆˆ Zâ‰¥0 . To simplify the notation, let Ïn B ÏA,F
Ï‰n .
Claim 2.7. For all n âˆˆ Zâ‰¥0 and xy âˆˆ E s ,
Ï‰n (xy) â‰¤ Ï‰n+1 (xy).

(2.2.2)

Proof. Proof is by induction on n. If n = 0, then (2.2.2) asserts that 0 â‰¤ 1. Now suppose that (2.2.2) holds for
some n âˆˆ Zâ‰¥0 . Then we have
Ï‰n+1 (xy) = f (Ï‰n )(xy) â‰¤ f (Ï‰n+1 )(xy) = Ï‰n+2 (xy),
as desired.



Claim 2.8. For all n âˆˆ Zâ‰¥0 and xy âˆˆ E s ,
Ï‰n (xy) â‰¤ Ï‰(xy).

(2.2.3)

Proof. Proof is again by induction on n. If n = 0, then (2.2.3) says that 0 â‰¤ Ï‰(xy). Now suppose that (2.2.3) holds
for some n âˆˆ Zâ‰¥0 . Then, using (2.2.1), we get
Ï‰n+1 (xy) = f (Ï‰n )(xy) â‰¤ f (Ï‰)(xy) â‰¤ Ï‰(xy),
as desired.



Since the sequence {Ï‰n (xy)}âˆ
n=0 is monotone increasing and bounded by Ï‰(xy), it has a limit, so let
Ï‰âˆ (xy) B lim Ï‰n (xy).
nâ†’âˆ

Note that we still have Ï‰âˆ (xy) â‰¤ Ï‰(xy) for all xy âˆˆ E s . Hence it is enough to prove that for all xy âˆˆ E s ,
Pr(y âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ï‰âˆ (xy).

(2.2.4)

We will derive (2.2.4) from the following lemma.
Lemma 2.9. For every n âˆˆ Zâ‰¥0 and xy âˆˆ E s ,
Pr(y âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ï‰n (xy) + Ï‰n+1 (xy) âˆ’ Ï‰n (xy).
4

(2.2.5)

If Lemma 2.9 holds, then we are done, since it implies that
Pr(y âˆˆ A) â‰¤ lim (Pr(x âˆˆ A) Â· Ï‰n (xy) + Ï‰n+1 (xy) âˆ’ Ï‰n (xy)) = Pr(x âˆˆ A) Â· Ï‰âˆ (xy),
nâ†’âˆ

as desired.
To establish Lemma 2.9, we need the following claim.
Claim 2.10. Let n âˆˆ Zâ‰¥0 and suppose that for all xy âˆˆ E s , (2.2.5) holds. Then for all x âˆˆ V and z âˆˆ RD (x),
Pr(z âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ï‰n (x, z) + Ï‰n+1 (x, z) âˆ’ Ï‰n (x, z).

(2.2.6)

The proof of Claim 2.10 uses the following simple algebraic inequality.
Claim 2.11. Let a1 , . . . , ak , b1 , . . . , bk be nonnegative real numbers with bi â‰¥ max{ai , 1} for all 1 â‰¤ i â‰¤ k. Then
ï£«
ï£¶
k
iâˆ’1
k
k
X
Y
Y
Y
ï£­
ï£¸
aj (bi âˆ’ ai ) â‰¤
bi âˆ’
ai .
(2.2.7)
i=1

j=1

i=1

i=1

Proof. Proof is by induction on k. If k = 1, then both sides of (2.2.7) are equal to b1 âˆ’ a1 . If the claim is established
for some k, then for k + 1 we get
ï£«
ï£¶
ï£«
ï£¶
!
k+1
k
iâˆ’1
k
k+1
X iâˆ’1
X
Y
Y
Y
Y
ï£­
ï£¸
ï£­
ï£¸
aj (bi âˆ’ ai ) =
aj (bi âˆ’ ai ) +
ai bk+1 âˆ’
ai
i=1

j=1

i=1

â‰¤

=

k
Y

j=1

bi âˆ’

i=1

k+1
Y

k+1
Y

bi âˆ’

k+1
Y
i=1

i=1

!
ai

bk+1 âˆ’

k+1
Y

i=1

ai âˆ’

i=1

bi âˆ’

k
Y

ai +

i=1

i=1

â‰¤

i=1

k
Y

k+1
Y

ai

i=1

k
Y

bi âˆ’

i=1

k
Y

!
ai

(bk+1 âˆ’ 1)

i=1

ai ,

i=1

as desired.



Proof of Claim 2.10. Let x = z0 âˆ’â†’ z1 âˆ’â†’. . . âˆ’â†’ zk = z be some directed xz-path in Ds . For 1 â‰¤ i â‰¤ k, let
ai B Ï‰n (zkâˆ’i zkâˆ’i+1 ) and bi B Ï‰n+1 (zkâˆ’i zkâˆ’i+1 ). Note that bi â‰¥ max{ai , 1}.
Due to (2.2.5), we have
Pr(z âˆˆ A) â‰¤ Pr(zkâˆ’1 âˆˆ A) Â· a1 + b1 âˆ’ a1 .
Similarly,
Pr(zkâˆ’1 âˆˆ A) â‰¤ Pr(zkâˆ’2 âˆˆ A) Â· a2 + b2 âˆ’ a2 ,
so
Pr(z âˆˆ A) â‰¤ Pr(zkâˆ’2 âˆˆ A) Â· a1 a2 + b1 âˆ’ a1 + a1 (b2 âˆ’ a2 ).
Continuing such substitutions, we finally obtain
Pr(z âˆˆ A) â‰¤ Pr(x âˆˆ A) Â·

k
Y

ai +

i=1

k
X

ï£«

iâˆ’1
Y

ï£­
i=1

ï£¶
aj ï£¸ (bi âˆ’ ai ).

j=1

Using Claim 2.11, we get
Pr(z âˆˆ A) â‰¤ Pr(x âˆˆ A) Â·

k
Y
i=1

Note that

k
Y
i=1

ai =

k
Y

ai +

k
Y

bi âˆ’

i=1

Ï‰n (ziâˆ’1 zi ) â‰¥ Ï‰n (x, z).

i=1

5

k
Y
i=1

ai .

Since Pr(x âˆˆ A) â‰¤ 1, this implies
Pr(z âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ï‰n (x, z) +

k
Y

bi âˆ’ Ï‰n (x, z).

(2.2.8)

i=1

It remains to observe that inequality (2.2.8) holds for all directed xz-paths, so we can replace
obtaining
Pr(z âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ï‰n (x, z) + Ï‰n+1 (x, z) âˆ’ Ï‰n (x, z),

Qk

i=1 bi

by Ï‰n+1 (x, z),

as desired.



Proof of Lemma 2.9. Proof is by induction on n. For n = 0, the lemma simply asserts that Pr(y âˆˆ A) â‰¤ 1. Now
assume that (2.2.5) holds for some n âˆˆ Zâ‰¥0 and consider an edge xy âˆˆ E s . Since A is out-closed, x âˆˆ A implies
y âˆˆ A, so
Pr(y âˆˆ A) = Pr(x âˆˆ A) + Pr(x < A âˆ§ y âˆˆ A).
Since F is an A-cut, it contains at least one edge e âˆˆ E(x, y) whenever x < A and y âˆˆ A. Using the union bound,
we obtain
X
Pr(x < A âˆ§ y âˆˆ A) â‰¤
Pr(e âˆˆ F âˆ§ y âˆˆ A).
eâˆˆE(x,y)

Thus,
X

Pr(y âˆˆ A) â‰¤ Pr(x âˆˆ A) +

Pr(e âˆˆ F âˆ§ y âˆˆ A).

(2.2.9)

eâˆˆE(x,y)

Let us now estimate Pr(e âˆˆ F âˆ§ y âˆˆ A) for each e âˆˆ E(x, y). Consider any z âˆˆ RD (y). Since A is out-closed, y âˆˆ A
implies z âˆˆ A, so
Pr(e âˆˆ F âˆ§ y âˆˆ A) â‰¤ Pr(e âˆˆ F âˆ§ z âˆˆ A) = Pr(e âˆˆ F |z âˆˆ A) Â· Pr(z âˆˆ A).
Due to Claim 2.10,
Pr (z âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ï‰n (x, z) + Ï‰n+1 (x, z) âˆ’ Ï‰n (x, z) ,
so


Pr(e âˆˆ F âˆ§ y âˆˆ A) â‰¤ Pr (e âˆˆ F |z âˆˆ A) Â· Pr(x âˆˆ A) Â· Ï‰n (x, z) + Ï‰n+1 (x, z) âˆ’ Ï‰n (x, z)
= Pr(x âˆˆ A) Â· Ïn (e, z) + Ïn+1 (e, z) âˆ’ Ïn (e, z).
Since Pr(x âˆˆ A) â‰¤ 1 and Ïn (e, z) â‰¥ Ïn (e), we get
Pr(e âˆˆ F âˆ§ y âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ïn (e) + Ïn+1 (e, z) âˆ’ Ïn (e).
The last inequality holds for every z âˆˆ RD (y), so we can replace Ïn+1 (e, z) in it by Ïn+1 (e), obtaining
Pr(e âˆˆ F âˆ§ y âˆˆ A) â‰¤ Pr(x âˆˆ A) Â· Ïn (e) + Ïn+1 (e) âˆ’ Ïn (e).

(2.2.10)

Plugging (2.2.10) into (2.2.9), we get
Pr(y âˆˆ A) â‰¤ Pr(x âˆˆ A) +

X

(Pr(x âˆˆ A) Â· Ïn (e) + Ïn+1 (e) âˆ’ Ïn (e)) .

eâˆˆE(x,y)

The right hand side of the last inequality can be rewritten as
ï£«
ï£¶
X
X
Pr(x âˆˆ A) Â· ï£­1 +
Ïn (e)ï£¸ +
eâˆˆE(x,y)

Ïn+1 (e) âˆ’

eâˆˆE(x,y)

X

Ïn (e)

eâˆˆE(x,y)

= Pr(x âˆˆ A) Â· f (Ï‰n )(xy) + f (Ï‰n+1 )(xy) âˆ’ f (Ï‰n )(xy)
= Pr(x âˆˆ A) Â· Ï‰n+1 (xy) + Ï‰n+2 (xy) âˆ’ Ï‰n+1 (xy),
as desired.



6

3

Applications

3.1

A special version of the LCL

In this subsection we introduce a particular and perhaps more intuitive set-up for the LCL, that will be sufficient
for almost all applications discussed in this paper.
Let I be a finite set. A family A âˆˆ Pow(Pow(I)) of subsets of I is downwards-closed if for each S âˆˆ A,
Pow(S) âŠ† A. The boundary âˆ‚A of a downwards-closed family is defined to be
âˆ‚A B {i âˆˆ I : S âˆˆ A and S âˆª {i} < A for some S âŠ† I \ {i}}.
Suppose that â„¦ is a probability space and A : â„¦ â†’ Pow(Pow(I)) is a random variable such that A is downwardsclosed with probability 1. Let B be a random event and let Ï„ : I â†’ [1; +âˆ) be a function. For a subset X âŠ† I,
let
Y
Ï„ (X) B
Ï„ (i),
iâˆˆX

and
ÏƒÏ„A (B, X) B max Pr(B|Z âˆˆ A) Â· Ï„ (X).
ZâŠ†I\X

Finally, for an element i âˆˆ I, let
ÏƒÏ„A (B, i) B min ÏƒÏ„A (B, X).
iâˆˆXâŠ†I

The following statement is a straightforward, yet useful, corollary of the LCL:
Theorem 3.1. Let I be a finite set. Let â„¦ be a probability space and let A : â„¦ â†’ Pow(Pow(I)) be a random variable
such that with probability 1, A is a nonempty downwards-closed family of subsets of I. For each i âˆˆ I, let B(i) be a
finite collection of random events such that whenever i âˆˆ âˆ‚A, at least one of the events in B(i) holds. Suppose that
there is a function Ï„ : I â†’ [1; +âˆ) such that for all i âˆˆ I, we have
X
Ï„ (i) â‰¥ 1 +
ÏƒÏ„A (B, i).
(3.1.1)
BâˆˆB(i)

Then Pr(I âˆˆ A) â‰¥ 1/Ï„ (I) > 0.
Proof. For convenience, we may assume that for each i âˆˆ I, the set B(i) is nonempty (we can arrange that by
adding the empty event to each B(i)). Let D be the digraph with vertex set Pow(I) and edge set
E B {ei,S,B : i âˆˆ I, S âŠ† I \ {i}, B âˆˆ B(i)},
where the edge ei,S,B goes from S âˆª {i} to S. Thus, we have
E s = {(S âˆª {i}, S) : i âˆˆ I, S âŠ† I \ {i}},
which implies that for S, Z âŠ† I,
Z âˆˆ RD (S) â‡â‡’ Z âŠ† S.
Moreover, if Z âŠ† S âŠ† I, then all directed (S, Z)-paths have length exactly |S \ Z|.
Since A is downwards-closed, it is out-closed in D. Let F : â„¦ â†’ Pow(E) be a random set of edges defined by
ei,S,B âˆˆ F â‡â‡’ B holds.
We claim that F is an A-cut. Indeed, consider any edge (S âˆª {i}, S) âˆˆ E s and suppose that we have S âˆª {i} < A
and S âˆˆ A. By definition, this means that i âˆˆ âˆ‚A, so at least one event B âˆˆ B(i) holds. But then ei,S,B âˆˆ
F âˆ© E(S âˆª {i}, S), as desired.
Let Ï„ : I â†’ [1; +âˆ) be a function satisfying (3.1.1) and let Ï‰ : E s â†’ [1; +âˆ) be given by Ï‰((S âˆª {i}, S)) B Ï„ (i).
Note that for any Z âŠ† S âŠ† I, we have Ï‰(S, Z) = Ï„ (S \ Z).
Claim 3.1.1. Let i âˆˆ I, S âŠ† I \ {i}, and B âˆˆ B(i). Then
A
ÏA,F
Ï‰ (ei,S,B ) â‰¤ ÏƒÏ„ (B, i).

7

Proof. Let X be a set with i âˆˆ X âŠ† I such that ÏƒÏ„A (B, i) = ÏƒÏ„A (B, X) and let Z B S \ X. We have
A,F
ÏA,F
Ï‰ (ei,S,B ) â‰¤ ÏÏ‰ (ei,S,B , Z) = Pr(ei,S,B âˆˆ F |Z âˆˆ A) Â· Ï‰(S âˆª {i}, Z) = Pr(B|Z âˆˆ A) Â· Ï„ ((S âˆª {i}) \ Z).

Since (S âˆª {i}) \ Z âŠ† X and Ï„ takes values in [1; +âˆ), we have Ï„ ((S âˆª {i}) \ Z) â‰¤ Ï„ (X), so
Pr(B|Z âˆˆ A) Â· Ï„ ((S âˆª {i}) \ Z) â‰¤ Pr(B|Z âˆˆ A) Â· Ï„ (X) â‰¤ ÏƒÏ„A (B, X) = ÏƒÏ„A (B, i).
Let (S âˆª {i}, S) âˆˆ E s . Using (3.1.1) and Claim 3.1.1, we obtain
X
X
Ï‰((S âˆª {i}, S)) = Ï„ (i) â‰¥ 1 +
ÏƒÏ„A (B, i) â‰¥ 1 +
ÏA,F
Ï‰ (ei,S,B ) = 1 +
BâˆˆB(i)

BâˆˆB(i)

X

a

ÏA,F
Ï‰ (e),

eâˆˆE(Sâˆª{i},S)

i.e., Ï‰ satisfies (2.1.1). Thus, by Corollary 2.6,
Pr(I âˆˆ A) â‰¥

1
Pr(âˆ… âˆˆ A)
=
> 0,
Ï‰(I, âˆ…)
Ï„ (I)

as desired. (Here we are using that Pr(âˆ… âˆˆ A) = 1, which follows from the fact that with probability 1, A is
nonempty and downwards-closed.)


3.2

The LCL implies the Lopsided LLL

In this subsection we use the LCL to prove the Lopsided LLL, which is a strengthening of the standard LLL.
Theorem 3.2 (Lopsided LovaÌsz Local Lemma, [14]). Let B1 , . . . , Bn be random events in a probability space â„¦.
For each 1 â‰¤ i â‰¤ n, let Î“(i) be a subset of {1, . . . , n} \ {i} such that for all Z âŠ† {1, . . . , n} \ (Î“(i) âˆª {i}), we have
ï£¶
ï£« 

\
Bj ï£¸ â‰¤ Pr(Bi ).
(3.2.1)
Pr ï£­Bi 
jâˆˆZ
Suppose that there exists a function Âµ : {1, . . . , n} â†’ [0; 1) such that for every 1 â‰¤ i â‰¤ n, we have
Y
Pr(Bi ) â‰¤ Âµ(i)
(1 âˆ’ Âµ(j)).

(3.2.2)

jâˆˆÎ“(i)

Then
Pr

n
\

!
Bi

i=1

â‰¥

n
Y

(1 âˆ’ Âµ(i)) > 0.

i=1

Proof. We will use Theorem 3.1. Set I B {1, . . . , n} and let I0 : â„¦ â†’ Pow(I) and I1 : â„¦ â†’ Pow(I) be random
variables defined by
I1 B {i âˆˆ I : Bi holds} and I0 B I \ I1 .
T
Set A B Pow(I0 ). In other words, a set S âŠ† I belongs A if and only if iâˆˆS Bi holds. It follows that A is a
nonempty downwards-closed family of subsets of I and âˆ‚A = I1 (i.e., i âˆˆ âˆ‚A if and only if Bi holds). Therefore, we
can apply Theorem 3.1 with B(i) B {Bi } for each i âˆˆ I.
By (3.2.1), if i âˆˆ I and Z âŠ† I \ (Î“(i) âˆª {i}), then
ï£« 
ï£¶
\

Pr(Bi |Z âˆˆ A) = Pr ï£­Bi 
Bj ï£¸ â‰¤ Pr(Bi ).
jâˆˆZ
Thus, for any i âˆˆ I and Ï„ : I â†’ [1; +âˆ), we have
ÏƒÏ„A (Bi , i) â‰¤ ÏƒÏ„A (Bi , Î“(i) âˆª {i}) =

max

ZâŠ†I\(Î“(i)âˆª{i})

Pr(Bi |Z âˆˆ A) Â· Ï„ (Î“(i) âˆª {i}) â‰¤ Pr(Bi ) Â· Ï„ (Î“(i) âˆª {i}).

Therefore, (3.1.1) holds as long as for each i âˆˆ I, we have
Ï„ (i) â‰¥ 1 + Pr(Bi ) Â· Ï„ (Î“(i) âˆª {i}).
8

(3.2.3)

Suppose that Âµ : I â†’ [0; 1) satisfies (3.2.2). We claim that Ï„ (i) B 1/(1 âˆ’ Âµ(i)) satisfies (3.2.3). Indeed,
Y
1 + Pr(Bi ) Â· Ï„ (Î“(i) âˆª {i}) = 1 + Pr(Bi ) Â·
Ï„ (j)
jâˆˆÎ“(i)âˆª{i}

[by (3.2.2)]

Pr(Bi )
=1+ Q
jâˆˆÎ“(i)âˆª{i} (1 âˆ’ Âµ(j))
Q
Âµ(Bi ) jâˆˆÎ“(i) (1 âˆ’ Âµ(j))
â‰¤1+ Q
jâˆˆÎ“(i)âˆª{i} (1 âˆ’ Âµ(j))
=1+

Âµ(i)
1
=
= Ï„ (i),
1 âˆ’ Âµ(i)
1 âˆ’ Âµ(i)

Theorem 3.1 now yields
Pr

n
\
i=1

n

!
Bi

= Pr(I âˆˆ A) â‰¥

Y
1
1
=
= Qn
(1 âˆ’ Âµ(i)),
Ï„ (I)
i=1 Ï„ (i)
i=1

as desired.



Remark 3.3. The above derivation of the Lopsided LLL from Theorem 3.1 clarifies the precise relationship between
the two statements. Essentially, Theorem 3.1 reduces to the classical LLL under the following two main assumptions:
(1) the set A contains an inclusion-maximum element; and (2) each of the sets B(i) is a singleton, containing only
one â€œbadâ€ event. Neither of these assumptions is satisfied in the applications discussed later, where the LCL
outperforms the LLL.

3.3

First example: hypergraph coloring

In this subsection we provide some intuition behind the LCL using a very basic example: coloring uniform hypergraphs with 2 colors.
Let H be a d-regular k-uniform hypergraph with vertex set V and edge set E, and suppose we want to establish
a relation between d and k that guarantees that H is 2-colorable. A straightforward application of the LLL gives
the bound
e
((d âˆ’ 1)k + 1) â‰¤ 1,
2kâˆ’1
which is equivalent to
2kâˆ’1
1
dâ‰¤
+1âˆ’ .
(3.3.1)
ek
k
Let us now explain how to apply the LCL (in the simplified form of Theorem 3.1) to this problem. Choose a
coloring Ï• : V â†’ {red, blue} uniformly at random. Define A âŠ† Pow(V ) by
A B {S âŠ† V : there is no Ï•-monochromatic edge H âŠ† S}.
Clearly, A is downwards-closed, and, since we always have âˆ… âˆˆ A, A is nonempty. Moreover, V âˆˆ A if and only
if Ï• is a proper coloring of H. Therefore, if we can apply Theorem 3.1 to show that Pr(V âˆˆ A) > 0, then H is
2-colorable.
In order to apply Theorem 3.1, we have to specify, for each v âˆˆ V , a finite family B(v) of â€œbadâ€ random events
such that whenever v âˆˆ âˆ‚A, at least one of the events in B(v) holds. Notice that if v âˆˆ âˆ‚A, i.e., for some S âŠ† V \{v},
we have S âˆˆ A and S âˆª {v} < A, then there must exist at least one Ï•-monochromatic edge H 3 v. Thus, we can set
B(v) B {BH : v âˆˆ H âˆˆ E},
where the event BH happens is and only if H is Ï•-monochromatic. Since H is d-regular, |B(v)| = d.
We will assume that Ï„ (v) = Ï„ âˆˆ [1; +âˆ) is a constant function. In that case, for any S âŠ† V , Ï„ (S) = Ï„ |S| . Let
v âˆˆ V and let H âˆˆ E be such that H 3 v. To verify (3.1.1), we require an upper bound on the quantity ÏƒÏ„A (BH , v).
By definition,
ÏƒÏ„A (BH , v) = min ÏƒÏ„A (BH , X),
vâˆˆXâŠ†V

9

so it is sufficient to upper bound ÏƒÏ„A (BH , X) for some set X 3 v. Since
ÏƒÏ„A (BH , X) = max Pr(BH |Z âˆˆ A) Â· Ï„ |X| ,
ZâŠ†V \X

we just need to find a set X 3 v such that the conditional probability Pr(BH |Z âˆˆ A) for Z âŠ† V \ X is easy to
bound. Moreover, we would like |X| to be as small as possible (to minimize the factor Ï„ |X| ).
Since the colors of distinct vertices are independent, the events BH and â€œZ âˆˆ Aâ€ are independent whenever
Z âˆ© H = âˆ…. Therefore, for Z âŠ† V \ H,
Pr(BH |Z âˆˆ A) â‰¤ Pr(BH ) =

1
.
2kâˆ’1

(3.3.2)

(The inequality might be strict if Pr(Z âˆˆ A) = 0, in which case Pr(BH |Z âˆˆ A) = 0 as well, due to our convention
regarding conditional probabilities; see Remark 2.4.) Thus, it is natural to take X = H, which gives
ÏƒÏ„A (BH , v) â‰¤ ÏƒÏ„A (BH , H) = max Pr(BH |Z âˆˆ A) Â· Ï„ |H| â‰¤
ZâŠ†V \H

Ï„k
.
2kâˆ’1

Hence it is enough to ensure that Ï„ satisfies
dÏ„ k
.
2kâˆ’1
A straightforward calculation shows that the following condition is sufficient:

kâˆ’1
2kâˆ’1
1
dâ‰¤
1âˆ’
,
k
k
Ï„ â‰¥1+

(3.3.3)

or, a bit more crudely,
2kâˆ’1
,
(3.3.4)
ek
which is almost identical to (3.3.1). Note that the precise bound (3.3.3) is, in fact, better than (3.3.1) for k â‰¥ 10.
We can improve (3.3.4) slightly by estimating ÏƒÏ„A (BH , v) more carefully. Observe that the inequality (3.3.2)
holds even if |Z âˆ© H| = 1 (because fixing the color of one of the vertices in H does not change the probability that
H is monochromatic). Therefore, upon choosing any vertex u âˆˆ H \ {v} and taking X = H \ {u}, we obtain
dâ‰¤

ÏƒÏ„A (BH , v) â‰¤ ÏƒÏ„A (BH , H \ {u}) =

max

ZâŠ†(V \H)âˆª{u}

Pr(BH |Z âˆˆ A) Â· Ï„ |H\{u}| â‰¤

Ï„ kâˆ’1
.
2kâˆ’1

Thus, it is enough to ensure that
Ï„ â‰¥1+

dÏ„ kâˆ’1
,
2kâˆ’1

which can be satisfied as long as
dâ‰¤

2kâˆ’1
.
e(k âˆ’ 1)

(3.3.5)

 
The bound (3.3.5) is better than (3.3.4) by a quantity of order â„¦ 2k k 2 . This is, of course, not a significant
improvement (and the bound is âˆš
still considerably weaker than the best known result due to Radhakrishnan and
Srinivasan [29], namely d â‰¤ 2k / k log k for some absolute constant  > 0). However, the observation that helped
us improve (3.3.4) to (3.3.5) highlights one of the important strengths of the LCL. The fact that Pr(BH |Z âˆˆ A) â‰¤
1/2kâˆ’1 for all Z such that |Z âˆ© H| â‰¤ 1 (and not only when Z âˆ© H = âˆ…) contains information beyond the individual
probabilities of â€œbadâ€ events and their dependencies, and the LCL has a mechanism for putting that additional
information to use. Similar ideas will reappear several times in later applications.

3.4

Nonrepetitive sequences and nonrepetitive colorings

A finite sequence a1 a2 . . . an is nonrepetitive if it does not contain the same nonempty substring twice in a row, i.e.,
if there are no s, 1 â‰¤ s â‰¤ n âˆ’ 1, and t, 1 â‰¤ t â‰¤ b(n âˆ’ s + 1)/2c, such that ak = ak+t for all s â‰¤ k â‰¤ s + t âˆ’ 1.
A well-known result by Thue [31] asserts that there exist arbitrarily long nonrepetitive sequences of elements from
{0, 1, 2}. The next theorem is a choosability version of Thueâ€™s result. It was the first example of a new combinatorial
bound obtained using the entropy compression method that surpasses the analogous bound provided by a direct
application of the LLL.
10

Theorem 3.4 (Grytczukâ€“PrzybyÅ‚oâ€“Zhu [20]; Grytczukâ€“Kozikâ€“Micek [21]). Let L1 , L2 , . . . , Ln be a sequence of
sets with |Li | â‰¥ 4 for all 1 â‰¤ i â‰¤ n. Then there exists a nonrepetitive sequence a1 a2 . . . an such that ai âˆˆ Li for all
1 â‰¤ i â‰¤ n.
Note that it is an open problem whether the same result holds for |Li | â‰¥ 3.
Proof. This is the only example in this paper where the LCL is applied directly, without reducing it to Theorem 3.1.
Let P be the directed path of length n with vertex set V B {v1 , . . . , vn } and with edges of the form (vi+1 , vi ) for all
1 â‰¤ i â‰¤ n âˆ’ 1. Choose a random sequence a1 a2 . . . an by selecting each ai âˆˆ Li uniformly and independently from
each other. Define a set A âŠ† V as follows:
vi âˆˆ A â‡â‡’ a1 a2 . . . ai is a nonrepetitive sequence.
Note that A is out-closed, Pr(v1 âˆˆ A) = 1, and vn âˆˆ A if and only if a1 a2 . . . an is a nonrepetitive sequence.
Consider an edge (vi+1 , vi ) of P . If vi âˆˆ A but vi+1 < A, then there exist s and t such that
s + 2t âˆ’ 1 = i + 1
and ak = ak+t for all s â‰¤ k â‰¤ s + t âˆ’ 1 (i.e., as as+1 . . . ai+1 is a repetition). This observation motivates the following
construction. Let D be the digraph such that Ds = P and for each (vi+1 , vi ) âˆˆ E(P ) and s, t with s + 2t âˆ’ 1 = i + 1,
there is a corresponding edge es,t âˆˆ E(D) going from vi+1 to vi . Let
es,t âˆˆ F â‡â‡’ ak = ak+t for all s â‰¤ k â‰¤ s + t âˆ’ 1.
Then F is an A-cut (see Fig. 2). Note that for each fixed t â‰¥ 1, there exists at most one s such that s+2tâˆ’1 = i+1,
so there is at most one edge of the form es,t âˆˆ E(vi+1 , vi ), where E denotes the edge set of D.
a

v1

b

e1,1

v2

a

e2,1

b

e3,1

v3

c

e4,1

v4

e1,2

e2,2

v5

c

e5,1
e3,2

v6

e1,3

a

e6,1
e4,2

v7

e2,3

Figure 2: For n = 7 and a sequence a1 a2 a3 a4 a5 a6 a7 = ababcca, we have A = {v1 , v2 , v3 } (since the first
cc
4 letters contain a repetition) and F = {e1,2 , e5,1 } (due to the repetitions abab
ababcca and ababcc
cca).

A vertex vj is reachable from vi if and only if j â‰¤ i. In particular, if s + 2t âˆ’ 1 = i + 1, then vs+tâˆ’1 is reachable
from vi . Observe that the probability of ak = ak+t is at most 1/|Lk+t |, even if the value of ak is fixed. Therefore,
for es,t âˆˆ E(vi+1 , vi ), we have
Pr (es,t âˆˆ F |vs+tâˆ’1 âˆˆ A) = Pr (ak = ak+t for all s â‰¤ k â‰¤ s + t âˆ’ 1|vs+tâˆ’1 âˆˆ A)
â‰¤

s+tâˆ’1
Y
k=s

1
1
â‰¤ t.
|Lk+t |
4

If Ï‰(vi+1 , vi ) = Ï‰ âˆˆ [1; +âˆ) is a fixed constant, then for all i â‰¥ j, Ï‰(vi , vj ) = Ï‰ iâˆ’j . In particular, if s+2tâˆ’1 = i+1,
then
Ï‰(vi+1 , vs+tâˆ’1 ) = Ï‰ t .
Thus,
A,F
ÏA,F
Ï‰ (es,t ) â‰¤ ÏÏ‰ (es,t , vs+tâˆ’1 ) = Pr (es,t âˆˆ F |vs+tâˆ’1 âˆˆ A) Â· Ï‰(vi+1 , vs+tâˆ’1 ) â‰¤

Ï‰t
.
4t

Hence, it is enough to find a constant Ï‰ âˆˆ [1; +âˆ) such that
Ï‰ â‰¥1+

âˆ
X
Ï‰t
t=1

4t

=

1
,
1 âˆ’ Ï‰/4

where the last equality is subject to Ï‰ < 4. Setting Ï‰ = 2 completes the proof.
11



A vertex coloring Ï• of a graph G is nonrepetitive if there is no path P in G with an even number of vertices
such that the first half of P receives the same sequence of colors as the second half of P , i.e., if there is no path v1 ,
v2 , . . . , v2t of length 2t such that Ï•(vk ) = Ï•(vk+t ) for all 1 â‰¤ k â‰¤ t. The least number of colors that is needed for
a nonrepetitive coloring of G is called the nonrepetitive chromatic number of G and is denoted by Ï€(G).
The first upper bound on Ï€(G) in terms of the maximum degree âˆ†(G) was given by Alon, Grytczuk, HaÅ‚uszczak,
and Riordan [4], who proved that there is a constant c such that Ï€(G) â‰¤ câˆ†(G)2 . Originally this result was obtained
with c = 2e16 . The constant was then improved to c = 16 by Grytczuk [19], and then to c = 12.92 by Harant and
Jendrolâ€™ [22]. All these results were based on the LLL.
DujmovicÌ, Joret, Kozik, and Wood [12] managed to decrease the value of the aforementioned constant c dramatically using the entropy compression method. Namely, they lowered the constant to 1, or, to be precise, they
showed that Ï€(G) â‰¤ (1 + o(1))âˆ†(G)2 (assuming âˆ†(G) â†’ âˆ).
The currently best known bound is given by the following theorem.
Theorem 3.5 (GoncÌ§alvesâ€“Montassierâ€“Pinlou [17]). For every graph G with maximum degree âˆ†,


22/3 âˆ†5/3
3
5/3
2
.
Ï€(G) â‰¤ âˆ† + 2/3 âˆ† + 1/3
2
âˆ† âˆ’ 21/3
Proof. Suppose that

22/3 âˆ†5/3
.
(3.4.1)
âˆ†1/3 âˆ’ 21/3
We will use Theorem 3.1 to show that G has a nonrepetitive k-coloring.
For brevity, let V B V (G) and E B E(G). Choose a k-coloring Ï• of G uniformly at random. Define a set
A âŠ† Pow(V ) by
A B {S âŠ† V : Ï• is a nonrepetitive coloring of G[S]},
3

k â‰¥ âˆ†2 +

22/3

âˆ†5/3 +

where G[S] denotes the induced subgraph of G with vertex set S. Note that A is downwards-closed and nonempty
with probability 1, and V âˆˆ A if and only if Ï• is a nonrepetitive coloring of G.
Consider any v âˆˆ V . If v âˆˆ âˆ‚A, then there exists a path P 3 v of even length that is colored repetitively by Ï•.
Thus, we can set
B(v) B {BP : P 3 v is a path of even length},
where the event BP happens if and only if P is colored repetitively by Ï•.
The number of events in B(v) corresponding to paths of some fixed length 2t is equal to the number of all
paths P of length 2t passing through v, which does not exceed tâˆ†2tâˆ’1 . Indeed, if P = v1 , v2 , . . . , v2t , then we can
assume v is one of the vertices v1 , v2 , . . . , vt , so there are t ways to choose the position of v on P . After the position
of v has been determined, we can select all other vertices one by one so that each time we are choosing only from
the neighbors of one of the previous vertices. Since the maximum degree of G is âˆ†, we get the bound tâˆ†2tâˆ’1 , as
desired.
We will assume Ï„ (v) = Ï„ âˆˆ [1; +âˆ) is a constant. We need to upper bound ÏƒÏ„A (BP , v) for each v âˆˆ V and a path
P 3 v of length 2t. Let P 0 be the half of P that contains v. Note that if Z âŠ† V \ P 0 , then Pr(BP |Z âˆˆ A) â‰¤ 1/k t ,
since the coloring of P 0 is independent from the coloring of Z. Therefore,
0

ÏƒÏ„A (BP , v) â‰¤ ÏƒÏ„A (BP , P 0 ) = max 0 Pr(BP |Z âˆˆ A) Â· Ï„ |P | â‰¤
ZâŠ†V \P

Ï„t
.
kt

Hence, it is enough to ensure that there exists Ï„ âˆˆ [1; +âˆ) such that
Ï„ â‰¥1+

âˆ
X

tâˆ†2tâˆ’1 Â·

t=1

âˆ†Ï„ /k
Ï„t
=1+
,
kt
(1 âˆ’ âˆ†2 Ï„ /k)2

(3.4.2)

where the last equality is subject to âˆ†2 Ï„ /k < 1. Setting y B âˆ†2 Ï„ /k, we can rewrite (3.4.2) as
k
1
1
â‰¥ +
.
âˆ†2
y âˆ†(1 âˆ’ y)2
1/3

Following GoncÌ§alves et al., we take y = 1 âˆ’ (2/âˆ†)

(3.4.3)

, and (3.4.3) becomes

k
3
22/3
â‰¥ 1 + 2/3 1/3 + 2/3
,
2
âˆ†
2 âˆ†
âˆ† âˆ’ (2âˆ†)1/3
which is true by (3.4.1).


12

3.5

Acyclic edge colorings

An edge coloring of a graph G is called an acyclic edge coloring if it is proper (i.e. adjacent edges receive different
colors) and every cycle in G contains edges of at least three different colors (there are no bichromatic cycles in G).
The least number of colors needed for an acyclic edge coloring of G is called the acyclic chromatic index of G and is
denoted by a0 (G). The notion of acyclic (vertex) coloring was first introduced by GruÌˆnbaum [18]. The edge version
was first considered by FiamcÌŒik [16], and independently by Alon, McDiarmid, and Reed [5].
As in the case of nonrepetitive colorings, it is quite natural to ask for an upper bound on the acyclic chromatic
index of a graph G in terms of its maximum degree âˆ†(G). Since a0 (G) â‰¥ Ï‡0 (G) â‰¥ âˆ†(G), where Ï‡0 (G) denotes the
ordinary chromatic index of G, this bound must be at least linear in âˆ†(G). The first linear bound was given by
Alon et al. [5], who showed that a0 (G) â‰¤ 64âˆ†(G). Although it resolved the problem of determining the order of
growth of a0 (G) in terms of âˆ†(G), it was conjectured that the sharp bound should be lower.
Conjecture 3.6 (FiamcÌŒik [16]; Alonâ€“Sudakovâ€“Zaks [7]). For every graph G, a0 (G) â‰¤ âˆ†(G) + 2.
Note that the bound in Conjecture 3.6 is only one more than Vizingâ€™s bound on the chromatic index of G.
However, this elegant conjecture is still far from being proven.
The first major improvement to the bound a0 (G) â‰¤ 64âˆ†(G) was made by Molloy and Reed [25], who proved that
a0 (G) â‰¤ 16âˆ†(G). This bound remained the best for a while, until Ndreca, Procacci, and Scoppola [27] managed to
improve it to a0 (G) â‰¤ d9.62(âˆ†(G) âˆ’ 1)e. Again, first bounds for a0 (G) were obtained using the LLL. The bound
a0 (G) â‰¤ d9.62(âˆ†(G) âˆ’ 1)e by Ndreca et al. used an improved version of the LLL due to Bissacot, FernaÌndez,
Procacci, and Scoppola [10].
The best current bound for a0 (G) in terms of âˆ†(G) was obtained by Esperet and Parreau via the entropy
compression method.
Theorem 3.7 (Esperetâ€“Parreau [15]). For every graph G with maximum degree âˆ†, a0 (G) â‰¤ 4(âˆ† âˆ’ 1).
Proof. We will apply Theorem 3.1. For brevity, let V B V (G) and E B E(G). Choose a 4(âˆ† âˆ’ 1)-edge coloring Ï•
of G uniformly at random. Call a cycle C of length 2t Ï•-bichromatic if C = e1 , e2 , . . . , e2t and Ï•(e2iâˆ’1 ) = Ï•(e2tâˆ’1 ),
Ï•(e2i ) = Ï•(e2t ) for all 1 â‰¤ i â‰¤ t âˆ’ 1.
Let
A B {S âŠ† E : Ï• is an acyclic edge coloring of G[S]},
where G[S] is the graph obtained from G by removing all the edges outside S. Note that with probability 1, A is a
nonempty downwards-closed family of subsets of E, and E âˆˆ A if and only if Ï• is an acyclic edge coloring of G.
Consider any e âˆˆ E. If e âˆˆ âˆ‚A, then either there exists an edge e0 adjacent to e such that Ï•(e) = Ï•(e0 ), or there
exists a Ï•-bichromatic cycle C 3 e of even length. The crucial idea of [15] (which is credited to Jakub Kozik by the
authors) is to handle 4-cycles and cycles of length at least 6 separately. Set
B(e) B {BC : C 3 e is a cycle of length 2t â‰¥ 6} âˆª {Be },
where
1. BC happens if and only if the cycle C is Ï•-bichromatic;
2. Be happens if and only if either there exists an edge e0 adjacent to e such that Ï•(e) = Ï•(e0 ), or there exists a
Ï•-bichromatic 4-cycle C 3 e.
Again, we will assume that Ï„ (e) = Ï„ âˆˆ [1; +âˆ) is a constant. Consider the event Be âˆˆ B(e) of the second kind.
We will estimate the probability Pr(Be |Z âˆˆ A) for Z âŠ† E \ {e} using the following claim, which also plays a crucial
role in the original proof by Esperet and Parreau.
Claim 3.7.1. Suppose that some edges of G are properly colored. If e âˆˆ E is uncolored, then there exist at most
2(âˆ† âˆ’ 1) ways to color e so that the resulting coloring either is not proper, or contains a bichromatic 4-cycle going
through e.
Proof. Indeed, denote the given proper partial coloring by Ïˆ and let e = uv. Let L1 (resp. L2 ) be the set of colors
appearing on the edges incident to u (resp. v). The coloring becomes not proper if e is colored using a color from
L1 âˆª L2 , so there are |L1 âˆª L2 | such options. Suppose that coloring e with color c creates a bichromatic 4-cycle
uvxy. Then c = Ïˆ(xy) and Ïˆ(vx) = Ïˆ(uy). Hence, the number of such colors c is at most the number of pairs of
edges vx, uy such that Ïˆ(vx) = Ïˆ(uy). Note that, since Ïˆ is proper, there can be at most one pair vx, uy such that
Ïˆ(vx) = Ïˆ(uy) = c0 for a particular color c0 . Therefore, the total number of such pairs is exactly |L1 âˆ© L2 |. Thus,
there are at most |L1 âˆª L2 | + |L1 âˆ© L2 | = |L1 | + |L2 | â‰¤ 2(âˆ† âˆ’ 1) â€œforbiddenâ€ colors for e, as desired.
a
13

Using Claim 3.7.1, we obtain
Pr(Be |Z âˆˆ A) â‰¤

2(âˆ† âˆ’ 1)
1
=
4(âˆ† âˆ’ 1)
2

for all Z âŠ† E \ {e}. Therefore,
ÏƒÏ„A (Be , e) â‰¤ ÏƒÏ„A (Be , {e}) =

max Pr(Be |Z âˆˆ A) Â· Ï„ |{e}| â‰¤

ZâŠ†E\{e}

Ï„
.
2

Now we need to deal with the events of the form BC âˆˆ B(e). Note that there are at most (âˆ† âˆ’ 1)2tâˆ’2 cycles
of length 2t passing through e. Therefore, the number of events in B(e) corresponding to cycles of length 2t is at
most (âˆ† âˆ’ 1)2tâˆ’2 . Consider any such event BC . Suppose that C = e1 , e2 , . . . , e2t , where e1 = e. Then BC happens
if and only if Ï•(e2iâˆ’1 ) = Ï•(e2tâˆ’1 ) and Ï•(e2i ) = Ï•(e2t ) for all 1 â‰¤ i â‰¤ t âˆ’ 1. Even if the colors of e2tâˆ’1 and e2t are
fixed, the probability of this happening is 1/(4(âˆ† âˆ’ 1))2tâˆ’2 . Due to this observation, if C 0 B {e1 , e2 , . . . , e2tâˆ’2 } and
Z âŠ† E \ C 0 , then Pr(BC |Z âˆˆ A) â‰¤ 1/(4(âˆ† âˆ’ 1))2tâˆ’2 . Therefore,
0

ÏƒÏ„A (BC , e) â‰¤ ÏƒÏ„A (BC , C 0 ) = max 0 Pr(BC |Z âˆˆ A) Â· Ï„ |C | â‰¤
ZâŠ†E\C

Ï„ 2tâˆ’2
.
(4(âˆ† âˆ’ 1))2tâˆ’2

Putting everything together, it is enough to find a constant Ï„ âˆˆ [1; +âˆ) such that
Ï„ â‰¥1+

âˆ
X

(âˆ† âˆ’ 1)2tâˆ’2 Â·

t=3

4

Ï„ 2tâˆ’2
Ï„
Ï„
(Ï„ /4)
+ =1+
2 + 2,
(4(âˆ† âˆ’ 1))2tâˆ’2
2
1 âˆ’ (Ï„ /4)

âˆš
where the last equality is valid if Ï„ /4 < 1. Setting Ï„ = 2( 5 âˆ’ 1) completes the proof.



Further applications of the LCL to acyclic edge coloring can be found in [8].

3.6

Color-critical hypergraphs

A hypergraph H is (k+1)-critical if it is not k-colorable, but each of its proper subhypergraphs is. Call a hypergraph
H true if all its edges have size at least 3. It is interesting to know what the least possible number of edges in a
(k + 1)-critical true hypergraph on n vertices is. The best known constructions due to Abbott and Hare [1] and
Abbott, Hare, and Zhou [2] contain roughly (k âˆ’ 1)n edges. This bound is asymptotically tight for k â†’ âˆ, as the
following theorem due to Kostochka and Stiebitz asserts.
Theorem 3.8 (Kostochkaâ€“Stiebitz [24]). Every (k + 1)-critical true hypergraph with n vertices contains at least
(k âˆ’ 3k 2/3 )n edges.
Here we improve this result, obtaining the following new bound.
Theorem 3.9. Every (k + 1)-critical true hypergraph with n vertices contains at least (k âˆ’ 4

âˆš

k)n edges.

Proof. Our proof is essentially the same as the proof of Theorem 3.8 given in [24]. The only difference is that we
replace the application of the LLL by an application of the LCL (in the form of Theorem 3.1).
âˆš
Let H be a (k + 1)-critical true hypergraph with n vertices. Denote V B V (H) and E B E(H). Let c B 4 k.
Fix some positive constant z (to be determined later). Let g : Zâ‰¥1 â†’ R be given by
(
1 âˆ’ z âˆ’1 if t = 1;
g(t) B
21âˆ’t z âˆ’1 if t > 1.
Inductively construct a sequence {Vi }m
i=0 , where 0 â‰¤ m â‰¤ n, of subsets of V according to the following rule. Let
V0 B V . If there is a vertex v âˆˆ Vi such that
X
g(|H âˆ© Vi |) â‰¥ k âˆ’ c,
(3.6.1)
HâˆˆE:
H3v

then select one such vertex, denote it by vi , and let Vi+1 B Vi \ {vi }. Otherwise let m B i and stop.

14

If m = n, then
X

|E| =

1>

HâˆˆE

|H|
XX

g(j) =

HâˆˆE j=1

nâˆ’1
X

X

g(|H âˆ© Vi |) â‰¥ (k âˆ’ c)n,

i=0 HâˆˆE:
H3vi

as desired.
Now suppose that m < n. We will prove that this cannot happen. Let V 0 B Vm . Since V 0 is nonempty, the
hypergraph H âˆ’ V 0 obtained from H by deleting the vertices in V 0 is k-colorable. Fix a proper k-coloring Ïˆ of
H âˆ’ V 0 and extend it to a k-coloring Ï• of H by choosing a color for each vertex in V 0 uniformly and independently
from all other vertices.
Let A âŠ† Pow(V 0 ) be given by
A B {S âŠ† V 0 : there is no Ï•-monochromatic edge H âŠ† (V \ V 0 ) âˆª S}.
Note that A is downwards-closed and Pr(âˆ… âˆˆ A) = 1 (because the coloring Ïˆ of V \ V 0 is proper). We will use
Theorem 3.1 to prove that Pr(V 0 âˆˆ A) > 0, which will be a contradiction since H is not k-colorable.
For v âˆˆ V 0 , let
B(v) B {BH : v âˆˆ H âˆˆ E},
where the event BH happens if and only if H is Ï•-monochromatic. Clearly, if v âˆˆ âˆ‚A, then at least one of the
events BH âˆˆ B(v) holds.
Let Ï„ (v) = Ï„ âˆˆ [1; +âˆ) be a constant function. Consider some BH âˆˆ B(v). There are two cases. First suppose
that H * V 0 . Note that such H is Ï•-monochromatic if and only if H \V 0 is Ïˆ-monochromatic and Ï•(u) = Ïˆ(w) for all
0
u âˆˆ H âˆ© V 0 and w âˆˆ H \ V 0 . Therefore, for each such H and for Z âŠ† V 0 \ H, Pr(BH |Z âˆˆ A) â‰¤ Pr(BH ) â‰¤ 1/k |Hâˆ©V | .
Thus,
0
Ï„ |Hâˆ©V |
A
A
0
|Hâˆ©V 0 |
ÏƒÏ„ (BH , v) â‰¤ ÏƒÏ„ (BH , H âˆ© V ) = max
Pr(BH |Z âˆˆ A) Â· Ï„
â‰¤ |Hâˆ©V 0 | .
ZâŠ†V 0 \H
k
If, on the other hand, H âŠ† V 0 , then choose an arbitrary vertex u âˆˆ H \ {v} and consider Z âŠ† (V 0 \ H) âˆª {u}.
(This idea is analogous to the one we discussed in Subsection 3.3.) Since fixing the color of u does not change the
probability that H is monochromatic, we have Pr(BH |Z âˆˆ A) â‰¤ 1/k |H|âˆ’1 , so
ÏƒÏ„A (BH , v) â‰¤ ÏƒÏ„A (BH , E \ {u}) =

max
0

ZâŠ†(V \H)âˆª{u}

Pr(BH |Z âˆˆ A) Â· Ï„ |H\{u}| â‰¤

Ï„ |H|âˆ’1
.
k |H|âˆ’1

For a vertex v âˆˆ V 0 , let
at (v) B |{H âˆˆ E : v âˆˆ H * V 0 , |H âˆ© V 0 | = t}|;
bt (v) B |{H âˆˆ E : v âˆˆ H âŠ† V 0 , |H| = t}|.
To apply Theorem 3.1, it is enough to guarantee that there exists a constant Ï„ âˆˆ [1; +âˆ) such that for all v âˆˆ V 0 ,
Ï„ â‰¥1+

âˆ
X

âˆ

at (v)

t=1

Ï„t X
Ï„ tâˆ’1
+
bt (v) tâˆ’1 .
t
k
k
t=3

(3.6.2)

0
0
Since V 0 is the last set in the sequence {Vi }m
i=0 , no vertex in V satisfies (3.6.1). In other words, for all v âˆˆ V ,
âˆ
X

at (v)g(t) +

t=1

âˆ
X

bt (v)g(t) < k âˆ’ c.

t=3

Let
Î±t (v) B at (v)g(t);
Î²t (v) B bt (v)g(t).
Then (3.6.3) can be rewritten as
Î³(v) B

âˆ
X
t=1

Î±t (v) +

âˆ
X
t=3

15

Î²t (v) < k âˆ’ c,

(3.6.3)

and (3.6.2) turns into
Ï„ â‰¥1+

âˆ
X
t=1

Î±t (v) Â·

âˆ
1  Ï„ t X
1  Ï„ tâˆ’1
+
,
Î²t (v) Â·
g(t) k
g(t) k
t=3

which, after substituting the actual values for g, becomes
âˆ

Ï„ â‰¥ 1 + Î±1 (v) Â·

z Ï„ X
1
+
Î±t (v) Â· z
z âˆ’ 1 k t=2
2



2Ï„
k

t
+

âˆ
X


Î²t (v) Â· z

t=3

2Ï„
k

tâˆ’1
.

(3.6.4)

We can view the right-hand side of (3.6.4) as a linear combination of variables Î±t (v), Î²t (v). If we assume that
4Ï„
1
â‰¥
,
k
zâˆ’1
2

then the largest coefficient in this linear combination is z (2Ï„ /k) (the coefficient of Î²3 (v)). Thus, it is enough to
find Ï„ , z satisfying the following two inequalities:
1
4Ï„
â‰¥
;
k
zâˆ’1

(3.6.5)

4zÏ„ 2 (k âˆ’ c)
.
(3.6.6)
k2
(Inequality (3.6.6) is obtained by replacing all coefficients on the right hand side of (3.6.4) by the largest one and
using the fact that Î³(v) < k âˆ’ c.) If we choose
k
+ 1,
z=
4Ï„
then (3.6.5) is satisfied, while (3.6.6) becomes


4Ï„ 2 (k âˆ’ c) k
kâˆ’c
4(k âˆ’ c) 2
Ï„ â‰¥1+
+1 =1+
Ï„+
Ï„ .
2
k
4Ï„
k
k2
Ï„ â‰¥1+

Thus, we just have to make sure that the following inequality has a solution Ï„ :
4(k âˆ’ c) 2 c
Ï„ âˆ’ Ï„ + 1 â‰¤ 0.
k2
k
âˆš
This is true if and only if c2 â‰¥ 16(k âˆ’ c); in particular, c = 4 k works. Therefore, Ï• is a proper k-coloring of H
with positive probability. This contradiction completes the proof.


3.7

Choice functions

Our last example is a probabilistic corollary of the
SnLCL. Let U1 , . . . , Un be a collection of pairwise disjoint nonempty
finite sets. A choice function
F
is
a
subset
of
i=1 Ui such that for all 1 â‰¤ i â‰¤ n, |F âˆ© Ui | = 1. A partial choice
Sn
function P is a subset of i=1 Ui such that for all 1 â‰¤ i â‰¤ n, |P âˆ© Ui | â‰¤ 1. For a partial choice function P , let
dom(P ) B {i : P âˆ© Ui , âˆ…}.
Thus, a choice function F is a partial choice function with dom(F ) = {1, . . . , n}.
Let F be a choice function and let P be a partial choice function. We say that P occurs in F if P âŠ† F , and
we say that F avoids P if P does not occur in F . Many natural combinatorial problems (especially ones related
to coloring) can be stated using the language of choice functions. For instance, consider a graph G with vertex set
{1, . . . , n}. Fix a positive integer k and let Ui B {(i, c) : 1 â‰¤ c â‰¤ k} for each 1 â‰¤ i â‰¤ n. For each edge ij âˆˆ E(G)
and 1 â‰¤ c â‰¤ k, define a partial choice function Pijc B {(i, c), (j, c)}. Then a proper vertex k-coloring of G can be
identified with a choice function F such that none of {Pijc }ijâˆˆE(G),1â‰¤câ‰¤k occur in F . Another problem that has
a straightforward formulation using choice functions is the k-SAT (which also serves as a standard example of a
problem that can be approached with the LLL). S
n
A multichoice function M is simply a subset of i=1 Ui (one should think of it as a generalized choice function
where one is allowed to choose multiple or zero elements from each set). For a multichoice function M , let Mi B
M âˆ© Ui . Again, we say that a partial choice function P occurs in a multichoice function M if P âŠ† M . Suppose that
16

we are given a family P1 , . . . , Pm of nonempty â€œforbiddenâ€ partial choice functions. For a multichoice function M ,
the ith defect of M (notation: def i (M )) is the number of indices j such that i âˆˆ dom(Pj ) and Pj occurs in M .
Observe that there exists a choice function F that avoids all of P1 , . . . , Pm if and only if there exists a multichoice
function M such that for all 1 â‰¤ i â‰¤ n,
|Mi | â‰¥ 1 + def i (M ).
(3.7.1)
Indeed, if F avoids all of P1 , . . . , Pm , then F itself satisfies (3.7.1). On the other hand, if M satisfies (3.7.1), then,
for every i, there is an element xi âˆˆ Mi that does not belong to any Pj occurring in M . Therefore, {xi }ni=1 is a
choice function that avoids all of P1 , . . . , Pm , as desired.
The main result of this subsection is that, in fact, it is enough to establish (3.7.1) on average for some random
multichoice function M .
Theorem 3.10. Let U1 , . . . , Un be a collection of pairwise disjoint nonempty finite sets and let P1 , . . . , Pm be a
family of nonempty partial choice functions. Let â„¦ be a probability
Snspace and let Mi : â„¦ â†’ Pow(Ui ), 1 â‰¤ i â‰¤ n, be
a collection of mutually independent random variables. Set M B i=1 Mi . If for all 1 â‰¤ i â‰¤ n,
E|Mi | â‰¥ 1 + E def i (M ),

(3.7.2)

then there exists a choice function F that avoids all of P1 , . . . , Pm .
Sn
Proof. For x âˆˆ i=1 Ui , let p(x) B Pr(x âˆˆ M ). Then
X
E|Mi | =
p(x).
xâˆˆUi

Since the variables

{Mi }ni=1

are independent,
Pr(Pj âŠ† M ) =

Y

p(x).

xâˆˆPj

Therefore, if Ni B {j : i âˆˆ dom(Pj )},
E def i (M ) =

X

X Y

Pr(Pj âŠ† M ) =

jâˆˆNi

p(x).

jâˆˆNi xâˆˆPj

Thus, (3.7.2) is equivalent to
X
xâˆˆUi

Let Ï„ (i) B

P

xâˆˆUi

X Y

p(x) â‰¥ 1 +

p(x).

(3.7.3)

jâˆˆNi xâˆˆPj

p(x) and let q(x) B p(x)/Ï„ (i) for all x âˆˆ Ui . Then (3.7.3) can be rewritten as
X Y
Ï„ (i) â‰¥ 1 +
q(x) Â· Ï„ (dom(Pj )).

(3.7.4)

jâˆˆNi xâˆˆPj

We will only use the numerical condition (3.7.4), ignoring its probabilistic meaning. Construct a random choice
function F (in a new probability space) as follows: Choose an element P
x âˆˆ Ui with probability q(x), making the
choices for different Ui â€™s independently (this definition is correct, since xâˆˆUi q(x) = 1). Set I B {1, . . . , n} and
define a random subset A âŠ† Pow(I) as follows:
A B {S âŠ† I : no Pj with dom(Pj ) âŠ† S occurs in F }.
Then A is a nonempty downwards-closed family of subsets of I, and I âˆˆ A if and only if F avoids all of P1 , . . . , Pm .
For i âˆˆ I, let
B(i) B {Bj : j âˆˆ Ni },
where the event Bj happens if and only if Pj âŠ† F . Clearly, if i âˆˆ âˆ‚A, then there is some j âˆˆ Ni such that Pj âŠ† F ,
so we can apply Theorem 3.1.
Q
Consider any i âˆˆ I and j âˆˆ Ni . Since Pr(Bj ) = xâˆˆPj q(x), we have
ÏƒÏ„A (Bj , i) â‰¤ ÏƒÏ„A (Bj , dom(Pj )) =

Pr(Bj |Z âˆˆ A) Â· Ï„ (dom(Pj ))
Y
â‰¤ Pr(Bj ) Â· Ï„ (dom(Pj )) =
q(x) Â· Ï„ (dom(Pj )).
max

ZâŠ†I\dom(Pj )

xâˆˆPj

Therefore, in this case (3.7.4) implies (3.1.1), yielding Pr (I âˆˆ A) > 0, as desired.
17



Theorem 3.10 can be used, for instance, to obtain condition (3.3.3) for 2-colorability of uniform hypergraphs,
or to prove that a0 (G) â‰¤ d9.53(âˆ†(G) âˆ’ 1)e (this bound, although considerably weaker than the one given by
Theorem 3.7, is still an improvement over the previous results derived using the LLL). Another application of
Theorem 3.10 can be found in [9].
Acknowledgments. This work is supported by the Illinois Distinguished Fellowship. I am grateful to Alexandr
Kostochka for his helpful conversations and encouragement and to the anonymous referees for their valuable comments.

References
[1] H.L. Abbott, D.R. Hare. Sparse color-critical hypergraphs, Combinatorica, Volume 9, 1989. Pages 233â€“243.
[2] H.L. Abbott, D.R. Hare, and B. Zhou, Sparse color-critical graphs and hypergraphs with no short cycles, J.
Graph Theory, Volume 18, 1994. Pages 373â€“388.
[3] D. Achlioptas, F. Iliopoulos. Random Walks That Find Perfect Objects and the LovaÌsz Local Lemma. FOCS â€™14
Proceedings of the 55th Annual Symposium on Foundations of Computer Science, 2014. Pages 494â€“503.
[4] N. Alon, J. Grytczuk, M. HaÅ‚uszczak, and O. Riordan. Nonrepetitive colorings of graphs. Random Structures
& Algorithms, Volume 21, Issue 3â€“4, 2002. Pages 336â€“346.
[5] N. Alon, C. McDiarmid, and B. Reed. Acyclic coloring of graphs. Random structures and algorithms, Volume
2, No. 3, 1991. Pages 277â€“288.
[6] N. Alon, J.H. Spencer. The Probabilistic Method. Wiley, New York, 1992.
[7] N. Alon, B. Sudakov, and A. Zaks. Acyclic edge colorings of graphs. J. Graph Theory, Volume 37, 2001. Pages
157â€“167.
[8] A. Bernshteyn. New bounds for the acyclic chromatic index. Discrete Mathematics, Volume 339, Issue 10, 2016.
Pages 2543â€“2552.
[9] A. Bernshteyn. The asymptotic behavior of the correspondence chromatic number. Discrete Mathematics, Volume 339, Issue 11, 2016. Pages 2680â€“2692.
[10] R. Bissacot, R. FernaÌndez, A. Procacci, and B. Scoppola. An improvement of the LovaÌsz Local Lemma via
cluster expansion. J. Combinatorics, Probability and Computing, Volume 20, Issue 5, 2011. Pages 709â€“719.
[11] K. Chandrasekaran, N. Goyal, and B. Haeupler. Deterministic Algorithms for the Lovasz Local Lemma. SIAM
J. Comput., Volume 42, No. 6, 2013. Pages 2132â€“2155.
[12] V. DujmovicÌ, G. Joret, J. Kozik, and D.R. Wood. Nonrepetitive Colouring via Entropy Compression. Combinatorica, 2015. Pages 1â€“26.
[13] P. ErdoÌ‹s, L. LovaÌsz. Problems and results on 3-chromatic hypergraphs and some related questions. Infinite and
finite sets, A. Hajnal, R. Rado, and V.T. SoÌs, editors, Colloq. Math. Soc. J. Bolyai, North Holland, 1975. Pages
609â€“627.
[14] P. ErdoÌ‹s, J. Spencer. Lopsided LovaÌsz Local Lemma and latin transversals. Discrete Applied Mathematics,
Volume 30, Issue 2â€“3, 1991. Pages 151â€“154.
[15] L. Esperet, A. Parreau. Acyclic edge-coloring using entropy compression. European J. Combin., Volume 34,
Issue 6, 2013. Pages 1019â€“1027.
[16] J. FiamcÌŒik. The acyclic chromatic class of a graph (in Russian). Math. Slovaca, Volume 28, 1978. Pages 139â€“145.
[17] D. GoncÌ§alves, M. Montassier, and A. Pinlou. Entropy compression method applied to graph colorings.
arXiv:1406.4380.
[18] B. GruÌˆnbaum. Acyclic colorings of planar graphs. Israel Journal of Mathematics, Volume 14, Issue 4, 1973.
Pages 390â€“408.
[19] J. Grytczuk. Nonrepetitive colorings of graphsâ€”a survey. International Journal of Mathematics and Mathematical Sciences, Volume 2007, 2007.
[20] J. Grytczuk, J. PrzybyÅ‚o, and X. Zhu. Nonrepetitive list colourings of paths, Random Structures & Algorithms,
Volume 38, Issue 1â€“2, 2011. Pages 162â€“173.
18

[21] J. Grytczuk, J. Kozik, and P. Micek. New approach to nonrepetitive sequences. Random Structures & Algorithms, Volume 42, Issue 2, 2013. Pages 214â€“225.
[22] J. Harant, S. Jendrolâ€™. Nonrepetitive vertex colorings of graphs. Discrete Mathematics, Volume 312, Issue 2,
2012. Pages 374â€“380.
[23] K. Kolipaka, M. Szegedy. Moser and Tardos meet LovaÌsz. STOC â€™11 Proceedings of the forty-third annual
ACM symposium on Theory of computing, 2011. Pages 235â€“244.
[24] A.V. Kostochka, M. Stiebitz. On the number of edges in colour-critical graphs and hypergraphs, Combinatorica,
Volume 20, 2000. Pages 521â€“530.
[25] M. Molloy, B. Reed. Further algorithmic aspects of the Local Lemma. Proceedings of the 30th Annual ACM
Symposium on Theory of Computing, 1998. Pages 524â€“529.
[26] R. Moser, G. Tardos. A constructive proof of the general LovaÌsz Local Lemma. J. ACM, Volume 57, Issue 2,
2010.
[27] S. Ndreca, A. Procacci, and B. Scoppola. Improved bounds on coloring of graphs. European J. Combin., Volume
33, Issue 4, 2012. Pages 592â€“609.
[28] W. Pegden. An extension of the Moserâ€“Tardos Algorithmic Local Lemma. SIAM J. Discrete Math., Volume
28, Issue 2, 2014. Pages 911â€“917.
[29] J. Radhakrishnan, A. Srinivasan. Improved bounds and algorithms for hypergraph two-coloring, Random Structures and Algorithms, Volume 16, 2000. Pages 4â€“32.
[30] T. Tao. Moserâ€™s entropy compression argument, Whatâ€™s New, 2009.
[31] A. Thue. UÌˆber unendliche Zeichenreichen. Norske Vid. Selsk. Skr., I Mat. Nat. Kl., 1906. Pages 1â€“22.

19

