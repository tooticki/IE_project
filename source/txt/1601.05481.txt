The Local Cut Lemma

arXiv:1601.05481v3 [math.CO] 12 Dec 2017

Anton Bernshteyn∗

Abstract
The Lovász Local Lemma is a very powerful tool in probabilistic combinatorics, that is often used to prove
existence of combinatorial objects satisfying certain constraints. Moser and Tardos [26] have shown that the
LLL gives more than just pure existence results: there is an effective randomized algorithm that can be used
to find a desired object. In order to analyze this algorithm, Moser and Tardos developed the so-called entropy
compression method. It turned out that one could obtain better combinatorial results by a direct application of
the entropy compression method rather than simply appealing to the LLL. The aim of this paper is to provide
a generalization of the LLL which implies these new combinatorial results. This generalization, which we call
the Local Cut Lemma, concerns a random cut in a directed graph with certain properties. Note that our result
has a short probabilistic proof that does not use entropy compression. As a consequence, it not only shows that
a certain probability is positive, but also gives an explicit lower bound for this probability. As an illustration,
we present a new application (an improved lower bound on the number of edges in color-critical hypergraphs)
as well as explain how to use the Local Cut Lemma to derive some of the results obtained previously using the
entropy compression method.

Contents
1 Introduction

1

2 The Local Cut Lemma
2.1 Statement of the LCL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.2 Proof of the LCL . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

2
2
4

3 Applications
3.1 A special version of the LCL . . . . . . .
3.2 The LCL implies the Lopsided LLL . . . .
3.3 First example: hypergraph coloring . . . .
3.4 Nonrepetitive sequences and nonrepetitive
3.5 Acyclic edge colorings . . . . . . . . . . .
3.6 Color-critical hypergraphs . . . . . . . . .
3.7 Choice functions . . . . . . . . . . . . . .

1

. . . . . .
. . . . . .
. . . . . .
colorings
. . . . . .
. . . . . .
. . . . . .

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

.
.
.
.
.
.
.

7
7
8
9
10
13
14
16

Introduction

One of the most useful tools in probabilistic combinatorics is the so-called Lovász Local Lemma (the LLL for short),
which was proved by Erdős and Lovász in their seminal paper [13]. Roughly speaking, the LLL asserts that, given
a family B of random events whose individual probabilities are small and whose dependency is somehow limited,
there is a positive probability that none of the events in B happen. More precisely:
Theorem 1.1 (Lovász Local Lemma, [6]). Let B1 , . . . , Bn be random events in a probability space Ω. For each
1 ≤ i ≤ n, let Γ(i) be a subset of {1, . . . , n} \ {i} such that the event Bi is independent from the algebra generated
by the events Bj with j < Γ(i) ∪ {i}. Suppose that there exists a function µ : {1, . . . , n} → [0; 1) such that for every
1 ≤ i ≤ n,
Y
Pr(Bi ) ≤ µ(i)
(1 − µ(j)).
j∈Γ(i)
∗ Department

of Mathematics, University of Illinois at Urbana–Champaign, IL, USA, bernsht2@illinois.edu. This research is
supported by the Illinois Distinguished Fellowship.

1

Then
Pr

n
\
i=1

!
Bi

≥

n
Y

(1 − µ(i)) > 0.

i=1


T
Note that the probability Pr i∈I Bi , which the LLL bounds from below, is usually exponentially small (in the
parameter n). This is in contrast to the more common situation in the probabilistic method when the probability of
interest is not only positive, but separated from zero. Although this property of the LLL makes it an indispensable
tool in proving combinatorial existence results, it also makes these results seemingly nonconstructive, since sampling
the probability space to find an object with the desired properties would usually take an exponentially long expected
time. A major breakthrough was made by Moser and Tardos [26], who showed that, in a special framework for the
LLL called the variable version (the name is due to Kolipaka and Szegedy [23]), there exists a simple Las Vegas
algorithm with expected polynomial runtime that searches the probability space for a point which avoids all the
events in B. Their algorithm was subsequently refined and extended to other situations by several authors; see
e.g. [28], [23], [3], [11].
The key ingredient of Moser and Tardos’s proof is the so-called entropy compression method (the name is due
to Tao [30]). The idea of this method is to encode the execution process of the algorithm in such a way that the
original sequence of random inputs can be uniquely recovered from the resulting encoding. One then proceeds to
show that if the algorithm runs for too long, the space of possible codes becomes smaller than the space of inputs,
which leads to a contradiction.
It was discovered lately (and somewhat unexpectedly) that applying the entropy compression method directly
can often produce better combinatorial results than simply using the LLL. The idea, first introduced by Grytczuk,
Kozik, and Micek in their study of nonrepetitive sequences [21], is to construct a randomized procedure that solves
a given combinatorial problem and then apply the entropy compression argument to show that it runs in expected
finite time. A wealth of new results have been obtained using this paradigm; see e.g. [12], [15], [17]. Some of these
examples are discussed in more detail in Section 3.
Note that the entropy compression method is indeed a “method” that one can use to attack a problem rather
than a general theorem that contains various combinatorial results as its special cases. It is natural to ask if such a
theorem exists, i.e., if there is a generalization of the LLL that implies the new combinatorial results obtained using
the entropy compression method. The goal of this paper is to provide such a generalization, which we call the Local
Cut Lemma (the LCL for short). It is important to note that this result is purely probabilistic and similar to the
LLL in flavor. In particular, its short and simple probabilistic proof does not use the entropy compression method.
Instead, it estimates certain probabilities explicitly, in much the same way as the original (nonconstructive) proof of
the LLL does. We state and prove the LCL in Section 2. Section 3 is dedicated to applications of the LCL. We start
by introducing a simplified special case of the LCL (namely Theorem 3.1) in Subsection 3.1, which turns out to be
sufficient for most applications. In fact, Theorem 3.1 already implies the classical LLL, as we show in Subsection 3.2.
In Subsection 3.3, we discuss one simple example (namely hypergraph coloring), which provides the intuition behind
the LCL and serves as a model for more substantial applications described later. In Subsections 3.4 and 3.5 we
show how to use the LCL to prove several results obtained previously using the entropy compression method. We
also present a new application (an improved lower bound on the number of edges in color-critical hypergraphs) in
Subsection 3.6. The last application, discussed in Subsection 3.7, is a curious probabilistic corollary of the LCL.

2
2.1

The Local Cut Lemma
Statement of the LCL

To state our main result, we need to fix some notation and terminology. In what follows, a digraph always means
a finite directed multigraph. Let D be a digraph with vertex set V and edge set E. For x, y ∈ V , let E(x, y) ⊆ E
denote the set of all edges with tail x and head y.
A digraph D is simple if for all x, y ∈ V , |E(x, y)| ≤ 1. If D is simple and |E(x, y)| = 1, then the unique
edge with tail x and head y is denoted by xy (or sometimes (x, y)). For an arbitrary digraph D, let Ds denote
its underlying simple digraph, i.e., the simple digraph with vertex set V in which xy is an edge if and only if
E(x, y) , ∅. Denote the edge set of Ds by E s . For a set F ⊆ E, let F s ⊆ E s be the set of all edges xy ∈ E s such
that F ∩ E(x, y) , ∅. A set A ⊆ V is out-closed (resp. in-closed) if for all xy ∈ E s , x ∈ A implies y ∈ A (resp.
y ∈ A implies x ∈ A).

2

Definition 2.1. Let D be a digraph with vertex set V and edge set E and let A ⊆ V be an out-closed set of
vertices. A set F ⊆ E of edges is an A-cut if A is in-closed in Ds − F s . In other words, a set F ⊆ E is an A-cut if
it contains at least one edge e ∈ E(x, y) for all xy ∈ E s such that x < A and y ∈ A (see Fig. 1).

x0

e1

e2
x1

x2

e4

e5

e3
x4

x3

x5

x6

e6
x7
Figure 1: A digraph D with an out-closed set A = {x0 , x1 , x2 , x4 }. Any A-cut must contain the edges
{e2 , e5 , e6 } and at least one of {e3 , e4 }. For example, the set F = {e1 , e2 , e4 , e5 , e6 } consisting of the dashed
edges forms an A-cut.

We say that a vertex z ∈ V is reachable from x ∈ V if D (or, equivalently, Ds ) contains a directed xz-path. The
set of all vertices reachable from x is denoted by RD (x).
Definition 2.2. Let D be a digraph with vertex set V and edge set E. For a function ω : E s → [1; +∞) and
vertices x ∈ V and z ∈ RD (x), define
( k
)
Y
s
ω(zi−1 zi ) : x = z0 −→ z1 −→. . . −→ zk = z is a directed xz-path in D .
ω(x, z) B min
i=1

For a set S, we use Pow(S) to denote the power set of S, i.e., the set of all subsets of S.
Definition 2.3. Let D be a digraph with vertex set V and edge set E. Let Ω be a probability space and let
A : Ω → Pow(V ) and F : Ω → Pow(E) be random variables such that with probability 1, A is an out-closed set of
vertices and F is an A-cut. Fix a function ω : E s → [1; +∞). For xy ∈ E s , e ∈ E(x, y), and z ∈ RD (y), let
ρA,F
ω (e, z) B Pr(e ∈ F |z ∈ A) · ω(x, z).
For e ∈ E(x, y), define the risk to e as
ρA,F
ω (e) B

min ρA,F
ω (e, z).

z∈RD (y)

Remark 2.4. For random events P , Q, the conditional probability Pr(P |Q) is only defined if Pr(Q) > 0. For
convenience, we adopt the following notational convention in Definition 2.3: If Q is a random event and Pr(Q) = 0,
then Pr(P |Q) = 0 for all events P . Note that this way the crucial equation Pr(P |Q) · Pr(Q) = Pr(P ∩ Q) is satisfied
even when Pr(Q) = 0, and this is the only property of conditional probability we will use.
We are now ready to state the main result of this paper.
Theorem 2.5 (Local Cut Lemma). Let D be a digraph with vertex set V and edge set E. Let Ω be a probability
space and let A : Ω → Pow(V ) and F : Ω → Pow(E) be random variables such that with probability 1, A is an
out-closed set of vertices and F is an A-cut. If a function ω : E s → [1; +∞) satisfies the following inequality for all
xy ∈ E s :
X
ω(xy) ≥ 1 +
ρA,F
(2.1.1)
ω (e),
e∈E(x,y)
s

then for all xy ∈ E ,
Pr(y ∈ A) ≤ Pr(x ∈ A) · ω(xy).
3

The following immediate corollary is the main tool used in combinatorial applications of Theorem 2.5:
Corollary 2.6. Let D, A, F , ω be as in Theorem 2.5. Let x ∈ V , z ∈ RD (x), and suppose that Pr(z ∈ A) > 0.
Then
Pr(z ∈ A)
Pr(x ∈ A) ≥
> 0.
ω(x, z)

2.2

Proof of the LCL

In this subsection we prove Theorem 2.5. Let D, A, F be as in the statement of Theorem 2.5 and assume that a
function ω : E s → [1; +∞) satisfies
X
ω(xy) ≥ 1 +
ρA,F
(2.1.1)
ω (e)
e∈E(x,y)
s

s

s

for all xy ∈ E . For each υ : E → [1; +∞), let f (υ) : E → [1; +∞) be defined by
X
ρA,F
f (υ)(xy) B 1 +
(e).
υ
e∈E(x,y)

Also, let f (0) B 1, where 0 and 1 denote the constant 0 and 1 functions respectively. Then (2.1.1) is equivalent to
ω(xy) ≥ f (ω)(xy).

(2.2.1)

Note that the map f is monotone increasing, i.e., if υ(xy) ≤ υ 0 (xy) for all xy ∈ E s , then f (υ)(xy) ≤ f (υ 0 )(xy) for
all xy ∈ E s as well.
Let ω0 B 0 and let ωn+1 B f (ωn ) for all n ∈ Z≥0 . To simplify the notation, let ρn B ρA,F
ωn .
Claim 2.7. For all n ∈ Z≥0 and xy ∈ E s ,
ωn (xy) ≤ ωn+1 (xy).

(2.2.2)

Proof. Proof is by induction on n. If n = 0, then (2.2.2) asserts that 0 ≤ 1. Now suppose that (2.2.2) holds for
some n ∈ Z≥0 . Then we have
ωn+1 (xy) = f (ωn )(xy) ≤ f (ωn+1 )(xy) = ωn+2 (xy),
as desired.



Claim 2.8. For all n ∈ Z≥0 and xy ∈ E s ,
ωn (xy) ≤ ω(xy).

(2.2.3)

Proof. Proof is again by induction on n. If n = 0, then (2.2.3) says that 0 ≤ ω(xy). Now suppose that (2.2.3) holds
for some n ∈ Z≥0 . Then, using (2.2.1), we get
ωn+1 (xy) = f (ωn )(xy) ≤ f (ω)(xy) ≤ ω(xy),
as desired.



Since the sequence {ωn (xy)}∞
n=0 is monotone increasing and bounded by ω(xy), it has a limit, so let
ω∞ (xy) B lim ωn (xy).
n→∞

Note that we still have ω∞ (xy) ≤ ω(xy) for all xy ∈ E s . Hence it is enough to prove that for all xy ∈ E s ,
Pr(y ∈ A) ≤ Pr(x ∈ A) · ω∞ (xy).

(2.2.4)

We will derive (2.2.4) from the following lemma.
Lemma 2.9. For every n ∈ Z≥0 and xy ∈ E s ,
Pr(y ∈ A) ≤ Pr(x ∈ A) · ωn (xy) + ωn+1 (xy) − ωn (xy).
4

(2.2.5)

If Lemma 2.9 holds, then we are done, since it implies that
Pr(y ∈ A) ≤ lim (Pr(x ∈ A) · ωn (xy) + ωn+1 (xy) − ωn (xy)) = Pr(x ∈ A) · ω∞ (xy),
n→∞

as desired.
To establish Lemma 2.9, we need the following claim.
Claim 2.10. Let n ∈ Z≥0 and suppose that for all xy ∈ E s , (2.2.5) holds. Then for all x ∈ V and z ∈ RD (x),
Pr(z ∈ A) ≤ Pr(x ∈ A) · ωn (x, z) + ωn+1 (x, z) − ωn (x, z).

(2.2.6)

The proof of Claim 2.10 uses the following simple algebraic inequality.
Claim 2.11. Let a1 , . . . , ak , b1 , . . . , bk be nonnegative real numbers with bi ≥ max{ai , 1} for all 1 ≤ i ≤ k. Then


k
i−1
k
k
X
Y
Y
Y


aj (bi − ai ) ≤
bi −
ai .
(2.2.7)
i=1

j=1

i=1

i=1

Proof. Proof is by induction on k. If k = 1, then both sides of (2.2.7) are equal to b1 − a1 . If the claim is established
for some k, then for k + 1 we get




!
k+1
k
i−1
k
k+1
X i−1
X
Y
Y
Y
Y




aj (bi − ai ) =
aj (bi − ai ) +
ai bk+1 −
ai
i=1

j=1

i=1

≤

=

k
Y

j=1

bi −

i=1

k+1
Y

k+1
Y

bi −

k+1
Y
i=1

i=1

!
ai

bk+1 −

k+1
Y

i=1

ai −

i=1

bi −

k
Y

ai +

i=1

i=1

≤

i=1

k
Y

k+1
Y

ai

i=1

k
Y

bi −

i=1

k
Y

!
ai

(bk+1 − 1)

i=1

ai ,

i=1

as desired.



Proof of Claim 2.10. Let x = z0 −→ z1 −→. . . −→ zk = z be some directed xz-path in Ds . For 1 ≤ i ≤ k, let
ai B ωn (zk−i zk−i+1 ) and bi B ωn+1 (zk−i zk−i+1 ). Note that bi ≥ max{ai , 1}.
Due to (2.2.5), we have
Pr(z ∈ A) ≤ Pr(zk−1 ∈ A) · a1 + b1 − a1 .
Similarly,
Pr(zk−1 ∈ A) ≤ Pr(zk−2 ∈ A) · a2 + b2 − a2 ,
so
Pr(z ∈ A) ≤ Pr(zk−2 ∈ A) · a1 a2 + b1 − a1 + a1 (b2 − a2 ).
Continuing such substitutions, we finally obtain
Pr(z ∈ A) ≤ Pr(x ∈ A) ·

k
Y

ai +

i=1

k
X



i−1
Y


i=1


aj  (bi − ai ).

j=1

Using Claim 2.11, we get
Pr(z ∈ A) ≤ Pr(x ∈ A) ·

k
Y
i=1

Note that

k
Y
i=1

ai =

k
Y

ai +

k
Y

bi −

i=1

ωn (zi−1 zi ) ≥ ωn (x, z).

i=1

5

k
Y
i=1

ai .

Since Pr(x ∈ A) ≤ 1, this implies
Pr(z ∈ A) ≤ Pr(x ∈ A) · ωn (x, z) +

k
Y

bi − ωn (x, z).

(2.2.8)

i=1

It remains to observe that inequality (2.2.8) holds for all directed xz-paths, so we can replace
obtaining
Pr(z ∈ A) ≤ Pr(x ∈ A) · ωn (x, z) + ωn+1 (x, z) − ωn (x, z),

Qk

i=1 bi

by ωn+1 (x, z),

as desired.



Proof of Lemma 2.9. Proof is by induction on n. For n = 0, the lemma simply asserts that Pr(y ∈ A) ≤ 1. Now
assume that (2.2.5) holds for some n ∈ Z≥0 and consider an edge xy ∈ E s . Since A is out-closed, x ∈ A implies
y ∈ A, so
Pr(y ∈ A) = Pr(x ∈ A) + Pr(x < A ∧ y ∈ A).
Since F is an A-cut, it contains at least one edge e ∈ E(x, y) whenever x < A and y ∈ A. Using the union bound,
we obtain
X
Pr(x < A ∧ y ∈ A) ≤
Pr(e ∈ F ∧ y ∈ A).
e∈E(x,y)

Thus,
X

Pr(y ∈ A) ≤ Pr(x ∈ A) +

Pr(e ∈ F ∧ y ∈ A).

(2.2.9)

e∈E(x,y)

Let us now estimate Pr(e ∈ F ∧ y ∈ A) for each e ∈ E(x, y). Consider any z ∈ RD (y). Since A is out-closed, y ∈ A
implies z ∈ A, so
Pr(e ∈ F ∧ y ∈ A) ≤ Pr(e ∈ F ∧ z ∈ A) = Pr(e ∈ F |z ∈ A) · Pr(z ∈ A).
Due to Claim 2.10,
Pr (z ∈ A) ≤ Pr(x ∈ A) · ωn (x, z) + ωn+1 (x, z) − ωn (x, z) ,
so


Pr(e ∈ F ∧ y ∈ A) ≤ Pr (e ∈ F |z ∈ A) · Pr(x ∈ A) · ωn (x, z) + ωn+1 (x, z) − ωn (x, z)
= Pr(x ∈ A) · ρn (e, z) + ρn+1 (e, z) − ρn (e, z).
Since Pr(x ∈ A) ≤ 1 and ρn (e, z) ≥ ρn (e), we get
Pr(e ∈ F ∧ y ∈ A) ≤ Pr(x ∈ A) · ρn (e) + ρn+1 (e, z) − ρn (e).
The last inequality holds for every z ∈ RD (y), so we can replace ρn+1 (e, z) in it by ρn+1 (e), obtaining
Pr(e ∈ F ∧ y ∈ A) ≤ Pr(x ∈ A) · ρn (e) + ρn+1 (e) − ρn (e).

(2.2.10)

Plugging (2.2.10) into (2.2.9), we get
Pr(y ∈ A) ≤ Pr(x ∈ A) +

X

(Pr(x ∈ A) · ρn (e) + ρn+1 (e) − ρn (e)) .

e∈E(x,y)

The right hand side of the last inequality can be rewritten as


X
X
Pr(x ∈ A) · 1 +
ρn (e) +
e∈E(x,y)

ρn+1 (e) −

e∈E(x,y)

X

ρn (e)

e∈E(x,y)

= Pr(x ∈ A) · f (ωn )(xy) + f (ωn+1 )(xy) − f (ωn )(xy)
= Pr(x ∈ A) · ωn+1 (xy) + ωn+2 (xy) − ωn+1 (xy),
as desired.



6

3

Applications

3.1

A special version of the LCL

In this subsection we introduce a particular and perhaps more intuitive set-up for the LCL, that will be sufficient
for almost all applications discussed in this paper.
Let I be a finite set. A family A ∈ Pow(Pow(I)) of subsets of I is downwards-closed if for each S ∈ A,
Pow(S) ⊆ A. The boundary ∂A of a downwards-closed family is defined to be
∂A B {i ∈ I : S ∈ A and S ∪ {i} < A for some S ⊆ I \ {i}}.
Suppose that Ω is a probability space and A : Ω → Pow(Pow(I)) is a random variable such that A is downwardsclosed with probability 1. Let B be a random event and let τ : I → [1; +∞) be a function. For a subset X ⊆ I,
let
Y
τ (X) B
τ (i),
i∈X

and
στA (B, X) B max Pr(B|Z ∈ A) · τ (X).
Z⊆I\X

Finally, for an element i ∈ I, let
στA (B, i) B min στA (B, X).
i∈X⊆I

The following statement is a straightforward, yet useful, corollary of the LCL:
Theorem 3.1. Let I be a finite set. Let Ω be a probability space and let A : Ω → Pow(Pow(I)) be a random variable
such that with probability 1, A is a nonempty downwards-closed family of subsets of I. For each i ∈ I, let B(i) be a
finite collection of random events such that whenever i ∈ ∂A, at least one of the events in B(i) holds. Suppose that
there is a function τ : I → [1; +∞) such that for all i ∈ I, we have
X
τ (i) ≥ 1 +
στA (B, i).
(3.1.1)
B∈B(i)

Then Pr(I ∈ A) ≥ 1/τ (I) > 0.
Proof. For convenience, we may assume that for each i ∈ I, the set B(i) is nonempty (we can arrange that by
adding the empty event to each B(i)). Let D be the digraph with vertex set Pow(I) and edge set
E B {ei,S,B : i ∈ I, S ⊆ I \ {i}, B ∈ B(i)},
where the edge ei,S,B goes from S ∪ {i} to S. Thus, we have
E s = {(S ∪ {i}, S) : i ∈ I, S ⊆ I \ {i}},
which implies that for S, Z ⊆ I,
Z ∈ RD (S) ⇐⇒ Z ⊆ S.
Moreover, if Z ⊆ S ⊆ I, then all directed (S, Z)-paths have length exactly |S \ Z|.
Since A is downwards-closed, it is out-closed in D. Let F : Ω → Pow(E) be a random set of edges defined by
ei,S,B ∈ F ⇐⇒ B holds.
We claim that F is an A-cut. Indeed, consider any edge (S ∪ {i}, S) ∈ E s and suppose that we have S ∪ {i} < A
and S ∈ A. By definition, this means that i ∈ ∂A, so at least one event B ∈ B(i) holds. But then ei,S,B ∈
F ∩ E(S ∪ {i}, S), as desired.
Let τ : I → [1; +∞) be a function satisfying (3.1.1) and let ω : E s → [1; +∞) be given by ω((S ∪ {i}, S)) B τ (i).
Note that for any Z ⊆ S ⊆ I, we have ω(S, Z) = τ (S \ Z).
Claim 3.1.1. Let i ∈ I, S ⊆ I \ {i}, and B ∈ B(i). Then
A
ρA,F
ω (ei,S,B ) ≤ στ (B, i).

7

Proof. Let X be a set with i ∈ X ⊆ I such that στA (B, i) = στA (B, X) and let Z B S \ X. We have
A,F
ρA,F
ω (ei,S,B ) ≤ ρω (ei,S,B , Z) = Pr(ei,S,B ∈ F |Z ∈ A) · ω(S ∪ {i}, Z) = Pr(B|Z ∈ A) · τ ((S ∪ {i}) \ Z).

Since (S ∪ {i}) \ Z ⊆ X and τ takes values in [1; +∞), we have τ ((S ∪ {i}) \ Z) ≤ τ (X), so
Pr(B|Z ∈ A) · τ ((S ∪ {i}) \ Z) ≤ Pr(B|Z ∈ A) · τ (X) ≤ στA (B, X) = στA (B, i).
Let (S ∪ {i}, S) ∈ E s . Using (3.1.1) and Claim 3.1.1, we obtain
X
X
ω((S ∪ {i}, S)) = τ (i) ≥ 1 +
στA (B, i) ≥ 1 +
ρA,F
ω (ei,S,B ) = 1 +
B∈B(i)

B∈B(i)

X

a

ρA,F
ω (e),

e∈E(S∪{i},S)

i.e., ω satisfies (2.1.1). Thus, by Corollary 2.6,
Pr(I ∈ A) ≥

1
Pr(∅ ∈ A)
=
> 0,
ω(I, ∅)
τ (I)

as desired. (Here we are using that Pr(∅ ∈ A) = 1, which follows from the fact that with probability 1, A is
nonempty and downwards-closed.)


3.2

The LCL implies the Lopsided LLL

In this subsection we use the LCL to prove the Lopsided LLL, which is a strengthening of the standard LLL.
Theorem 3.2 (Lopsided Lovász Local Lemma, [14]). Let B1 , . . . , Bn be random events in a probability space Ω.
For each 1 ≤ i ≤ n, let Γ(i) be a subset of {1, . . . , n} \ {i} such that for all Z ⊆ {1, . . . , n} \ (Γ(i) ∪ {i}), we have

 

\
Bj  ≤ Pr(Bi ).
(3.2.1)
Pr Bi 
j∈Z
Suppose that there exists a function µ : {1, . . . , n} → [0; 1) such that for every 1 ≤ i ≤ n, we have
Y
Pr(Bi ) ≤ µ(i)
(1 − µ(j)).

(3.2.2)

j∈Γ(i)

Then
Pr

n
\

!
Bi

i=1

≥

n
Y

(1 − µ(i)) > 0.

i=1

Proof. We will use Theorem 3.1. Set I B {1, . . . , n} and let I0 : Ω → Pow(I) and I1 : Ω → Pow(I) be random
variables defined by
I1 B {i ∈ I : Bi holds} and I0 B I \ I1 .
T
Set A B Pow(I0 ). In other words, a set S ⊆ I belongs A if and only if i∈S Bi holds. It follows that A is a
nonempty downwards-closed family of subsets of I and ∂A = I1 (i.e., i ∈ ∂A if and only if Bi holds). Therefore, we
can apply Theorem 3.1 with B(i) B {Bi } for each i ∈ I.
By (3.2.1), if i ∈ I and Z ⊆ I \ (Γ(i) ∪ {i}), then
 

\

Pr(Bi |Z ∈ A) = Pr Bi 
Bj  ≤ Pr(Bi ).
j∈Z
Thus, for any i ∈ I and τ : I → [1; +∞), we have
στA (Bi , i) ≤ στA (Bi , Γ(i) ∪ {i}) =

max

Z⊆I\(Γ(i)∪{i})

Pr(Bi |Z ∈ A) · τ (Γ(i) ∪ {i}) ≤ Pr(Bi ) · τ (Γ(i) ∪ {i}).

Therefore, (3.1.1) holds as long as for each i ∈ I, we have
τ (i) ≥ 1 + Pr(Bi ) · τ (Γ(i) ∪ {i}).
8

(3.2.3)

Suppose that µ : I → [0; 1) satisfies (3.2.2). We claim that τ (i) B 1/(1 − µ(i)) satisfies (3.2.3). Indeed,
Y
1 + Pr(Bi ) · τ (Γ(i) ∪ {i}) = 1 + Pr(Bi ) ·
τ (j)
j∈Γ(i)∪{i}

[by (3.2.2)]

Pr(Bi )
=1+ Q
j∈Γ(i)∪{i} (1 − µ(j))
Q
µ(Bi ) j∈Γ(i) (1 − µ(j))
≤1+ Q
j∈Γ(i)∪{i} (1 − µ(j))
=1+

µ(i)
1
=
= τ (i),
1 − µ(i)
1 − µ(i)

Theorem 3.1 now yields
Pr

n
\
i=1

n

!
Bi

= Pr(I ∈ A) ≥

Y
1
1
=
= Qn
(1 − µ(i)),
τ (I)
i=1 τ (i)
i=1

as desired.



Remark 3.3. The above derivation of the Lopsided LLL from Theorem 3.1 clarifies the precise relationship between
the two statements. Essentially, Theorem 3.1 reduces to the classical LLL under the following two main assumptions:
(1) the set A contains an inclusion-maximum element; and (2) each of the sets B(i) is a singleton, containing only
one “bad” event. Neither of these assumptions is satisfied in the applications discussed later, where the LCL
outperforms the LLL.

3.3

First example: hypergraph coloring

In this subsection we provide some intuition behind the LCL using a very basic example: coloring uniform hypergraphs with 2 colors.
Let H be a d-regular k-uniform hypergraph with vertex set V and edge set E, and suppose we want to establish
a relation between d and k that guarantees that H is 2-colorable. A straightforward application of the LLL gives
the bound
e
((d − 1)k + 1) ≤ 1,
2k−1
which is equivalent to
2k−1
1
d≤
+1− .
(3.3.1)
ek
k
Let us now explain how to apply the LCL (in the simplified form of Theorem 3.1) to this problem. Choose a
coloring ϕ : V → {red, blue} uniformly at random. Define A ⊆ Pow(V ) by
A B {S ⊆ V : there is no ϕ-monochromatic edge H ⊆ S}.
Clearly, A is downwards-closed, and, since we always have ∅ ∈ A, A is nonempty. Moreover, V ∈ A if and only
if ϕ is a proper coloring of H. Therefore, if we can apply Theorem 3.1 to show that Pr(V ∈ A) > 0, then H is
2-colorable.
In order to apply Theorem 3.1, we have to specify, for each v ∈ V , a finite family B(v) of “bad” random events
such that whenever v ∈ ∂A, at least one of the events in B(v) holds. Notice that if v ∈ ∂A, i.e., for some S ⊆ V \{v},
we have S ∈ A and S ∪ {v} < A, then there must exist at least one ϕ-monochromatic edge H 3 v. Thus, we can set
B(v) B {BH : v ∈ H ∈ E},
where the event BH happens is and only if H is ϕ-monochromatic. Since H is d-regular, |B(v)| = d.
We will assume that τ (v) = τ ∈ [1; +∞) is a constant function. In that case, for any S ⊆ V , τ (S) = τ |S| . Let
v ∈ V and let H ∈ E be such that H 3 v. To verify (3.1.1), we require an upper bound on the quantity στA (BH , v).
By definition,
στA (BH , v) = min στA (BH , X),
v∈X⊆V

9

so it is sufficient to upper bound στA (BH , X) for some set X 3 v. Since
στA (BH , X) = max Pr(BH |Z ∈ A) · τ |X| ,
Z⊆V \X

we just need to find a set X 3 v such that the conditional probability Pr(BH |Z ∈ A) for Z ⊆ V \ X is easy to
bound. Moreover, we would like |X| to be as small as possible (to minimize the factor τ |X| ).
Since the colors of distinct vertices are independent, the events BH and “Z ∈ A” are independent whenever
Z ∩ H = ∅. Therefore, for Z ⊆ V \ H,
Pr(BH |Z ∈ A) ≤ Pr(BH ) =

1
.
2k−1

(3.3.2)

(The inequality might be strict if Pr(Z ∈ A) = 0, in which case Pr(BH |Z ∈ A) = 0 as well, due to our convention
regarding conditional probabilities; see Remark 2.4.) Thus, it is natural to take X = H, which gives
στA (BH , v) ≤ στA (BH , H) = max Pr(BH |Z ∈ A) · τ |H| ≤
Z⊆V \H

τk
.
2k−1

Hence it is enough to ensure that τ satisfies
dτ k
.
2k−1
A straightforward calculation shows that the following condition is sufficient:

k−1
2k−1
1
d≤
1−
,
k
k
τ ≥1+

(3.3.3)

or, a bit more crudely,
2k−1
,
(3.3.4)
ek
which is almost identical to (3.3.1). Note that the precise bound (3.3.3) is, in fact, better than (3.3.1) for k ≥ 10.
We can improve (3.3.4) slightly by estimating στA (BH , v) more carefully. Observe that the inequality (3.3.2)
holds even if |Z ∩ H| = 1 (because fixing the color of one of the vertices in H does not change the probability that
H is monochromatic). Therefore, upon choosing any vertex u ∈ H \ {v} and taking X = H \ {u}, we obtain
d≤

στA (BH , v) ≤ στA (BH , H \ {u}) =

max

Z⊆(V \H)∪{u}

Pr(BH |Z ∈ A) · τ |H\{u}| ≤

τ k−1
.
2k−1

Thus, it is enough to ensure that
τ ≥1+

dτ k−1
,
2k−1

which can be satisfied as long as
d≤

2k−1
.
e(k − 1)

(3.3.5)

 
The bound (3.3.5) is better than (3.3.4) by a quantity of order Ω 2k k 2 . This is, of course, not a significant
improvement (and the bound is √
still considerably weaker than the best known result due to Radhakrishnan and
Srinivasan [29], namely d ≤ 2k / k log k for some absolute constant  > 0). However, the observation that helped
us improve (3.3.4) to (3.3.5) highlights one of the important strengths of the LCL. The fact that Pr(BH |Z ∈ A) ≤
1/2k−1 for all Z such that |Z ∩ H| ≤ 1 (and not only when Z ∩ H = ∅) contains information beyond the individual
probabilities of “bad” events and their dependencies, and the LCL has a mechanism for putting that additional
information to use. Similar ideas will reappear several times in later applications.

3.4

Nonrepetitive sequences and nonrepetitive colorings

A finite sequence a1 a2 . . . an is nonrepetitive if it does not contain the same nonempty substring twice in a row, i.e.,
if there are no s, 1 ≤ s ≤ n − 1, and t, 1 ≤ t ≤ b(n − s + 1)/2c, such that ak = ak+t for all s ≤ k ≤ s + t − 1.
A well-known result by Thue [31] asserts that there exist arbitrarily long nonrepetitive sequences of elements from
{0, 1, 2}. The next theorem is a choosability version of Thue’s result. It was the first example of a new combinatorial
bound obtained using the entropy compression method that surpasses the analogous bound provided by a direct
application of the LLL.
10

Theorem 3.4 (Grytczuk–Przybyło–Zhu [20]; Grytczuk–Kozik–Micek [21]). Let L1 , L2 , . . . , Ln be a sequence of
sets with |Li | ≥ 4 for all 1 ≤ i ≤ n. Then there exists a nonrepetitive sequence a1 a2 . . . an such that ai ∈ Li for all
1 ≤ i ≤ n.
Note that it is an open problem whether the same result holds for |Li | ≥ 3.
Proof. This is the only example in this paper where the LCL is applied directly, without reducing it to Theorem 3.1.
Let P be the directed path of length n with vertex set V B {v1 , . . . , vn } and with edges of the form (vi+1 , vi ) for all
1 ≤ i ≤ n − 1. Choose a random sequence a1 a2 . . . an by selecting each ai ∈ Li uniformly and independently from
each other. Define a set A ⊆ V as follows:
vi ∈ A ⇐⇒ a1 a2 . . . ai is a nonrepetitive sequence.
Note that A is out-closed, Pr(v1 ∈ A) = 1, and vn ∈ A if and only if a1 a2 . . . an is a nonrepetitive sequence.
Consider an edge (vi+1 , vi ) of P . If vi ∈ A but vi+1 < A, then there exist s and t such that
s + 2t − 1 = i + 1
and ak = ak+t for all s ≤ k ≤ s + t − 1 (i.e., as as+1 . . . ai+1 is a repetition). This observation motivates the following
construction. Let D be the digraph such that Ds = P and for each (vi+1 , vi ) ∈ E(P ) and s, t with s + 2t − 1 = i + 1,
there is a corresponding edge es,t ∈ E(D) going from vi+1 to vi . Let
es,t ∈ F ⇐⇒ ak = ak+t for all s ≤ k ≤ s + t − 1.
Then F is an A-cut (see Fig. 2). Note that for each fixed t ≥ 1, there exists at most one s such that s+2t−1 = i+1,
so there is at most one edge of the form es,t ∈ E(vi+1 , vi ), where E denotes the edge set of D.
a

v1

b

e1,1

v2

a

e2,1

b

e3,1

v3

c

e4,1

v4

e1,2

e2,2

v5

c

e5,1
e3,2

v6

e1,3

a

e6,1
e4,2

v7

e2,3

Figure 2: For n = 7 and a sequence a1 a2 a3 a4 a5 a6 a7 = ababcca, we have A = {v1 , v2 , v3 } (since the first
cc
4 letters contain a repetition) and F = {e1,2 , e5,1 } (due to the repetitions abab
ababcca and ababcc
cca).

A vertex vj is reachable from vi if and only if j ≤ i. In particular, if s + 2t − 1 = i + 1, then vs+t−1 is reachable
from vi . Observe that the probability of ak = ak+t is at most 1/|Lk+t |, even if the value of ak is fixed. Therefore,
for es,t ∈ E(vi+1 , vi ), we have
Pr (es,t ∈ F |vs+t−1 ∈ A) = Pr (ak = ak+t for all s ≤ k ≤ s + t − 1|vs+t−1 ∈ A)
≤

s+t−1
Y
k=s

1
1
≤ t.
|Lk+t |
4

If ω(vi+1 , vi ) = ω ∈ [1; +∞) is a fixed constant, then for all i ≥ j, ω(vi , vj ) = ω i−j . In particular, if s+2t−1 = i+1,
then
ω(vi+1 , vs+t−1 ) = ω t .
Thus,
A,F
ρA,F
ω (es,t ) ≤ ρω (es,t , vs+t−1 ) = Pr (es,t ∈ F |vs+t−1 ∈ A) · ω(vi+1 , vs+t−1 ) ≤

ωt
.
4t

Hence, it is enough to find a constant ω ∈ [1; +∞) such that
ω ≥1+

∞
X
ωt
t=1

4t

=

1
,
1 − ω/4

where the last equality is subject to ω < 4. Setting ω = 2 completes the proof.
11



A vertex coloring ϕ of a graph G is nonrepetitive if there is no path P in G with an even number of vertices
such that the first half of P receives the same sequence of colors as the second half of P , i.e., if there is no path v1 ,
v2 , . . . , v2t of length 2t such that ϕ(vk ) = ϕ(vk+t ) for all 1 ≤ k ≤ t. The least number of colors that is needed for
a nonrepetitive coloring of G is called the nonrepetitive chromatic number of G and is denoted by π(G).
The first upper bound on π(G) in terms of the maximum degree ∆(G) was given by Alon, Grytczuk, Hałuszczak,
and Riordan [4], who proved that there is a constant c such that π(G) ≤ c∆(G)2 . Originally this result was obtained
with c = 2e16 . The constant was then improved to c = 16 by Grytczuk [19], and then to c = 12.92 by Harant and
Jendrol’ [22]. All these results were based on the LLL.
Dujmović, Joret, Kozik, and Wood [12] managed to decrease the value of the aforementioned constant c dramatically using the entropy compression method. Namely, they lowered the constant to 1, or, to be precise, they
showed that π(G) ≤ (1 + o(1))∆(G)2 (assuming ∆(G) → ∞).
The currently best known bound is given by the following theorem.
Theorem 3.5 (Gonçalves–Montassier–Pinlou [17]). For every graph G with maximum degree ∆,


22/3 ∆5/3
3
5/3
2
.
π(G) ≤ ∆ + 2/3 ∆ + 1/3
2
∆ − 21/3
Proof. Suppose that

22/3 ∆5/3
.
(3.4.1)
∆1/3 − 21/3
We will use Theorem 3.1 to show that G has a nonrepetitive k-coloring.
For brevity, let V B V (G) and E B E(G). Choose a k-coloring ϕ of G uniformly at random. Define a set
A ⊆ Pow(V ) by
A B {S ⊆ V : ϕ is a nonrepetitive coloring of G[S]},
3

k ≥ ∆2 +

22/3

∆5/3 +

where G[S] denotes the induced subgraph of G with vertex set S. Note that A is downwards-closed and nonempty
with probability 1, and V ∈ A if and only if ϕ is a nonrepetitive coloring of G.
Consider any v ∈ V . If v ∈ ∂A, then there exists a path P 3 v of even length that is colored repetitively by ϕ.
Thus, we can set
B(v) B {BP : P 3 v is a path of even length},
where the event BP happens if and only if P is colored repetitively by ϕ.
The number of events in B(v) corresponding to paths of some fixed length 2t is equal to the number of all
paths P of length 2t passing through v, which does not exceed t∆2t−1 . Indeed, if P = v1 , v2 , . . . , v2t , then we can
assume v is one of the vertices v1 , v2 , . . . , vt , so there are t ways to choose the position of v on P . After the position
of v has been determined, we can select all other vertices one by one so that each time we are choosing only from
the neighbors of one of the previous vertices. Since the maximum degree of G is ∆, we get the bound t∆2t−1 , as
desired.
We will assume τ (v) = τ ∈ [1; +∞) is a constant. We need to upper bound στA (BP , v) for each v ∈ V and a path
P 3 v of length 2t. Let P 0 be the half of P that contains v. Note that if Z ⊆ V \ P 0 , then Pr(BP |Z ∈ A) ≤ 1/k t ,
since the coloring of P 0 is independent from the coloring of Z. Therefore,
0

στA (BP , v) ≤ στA (BP , P 0 ) = max 0 Pr(BP |Z ∈ A) · τ |P | ≤
Z⊆V \P

τt
.
kt

Hence, it is enough to ensure that there exists τ ∈ [1; +∞) such that
τ ≥1+

∞
X

t∆2t−1 ·

t=1

∆τ /k
τt
=1+
,
kt
(1 − ∆2 τ /k)2

(3.4.2)

where the last equality is subject to ∆2 τ /k < 1. Setting y B ∆2 τ /k, we can rewrite (3.4.2) as
k
1
1
≥ +
.
∆2
y ∆(1 − y)2
1/3

Following Gonçalves et al., we take y = 1 − (2/∆)

(3.4.3)

, and (3.4.3) becomes

k
3
22/3
≥ 1 + 2/3 1/3 + 2/3
,
2
∆
2 ∆
∆ − (2∆)1/3
which is true by (3.4.1).


12

3.5

Acyclic edge colorings

An edge coloring of a graph G is called an acyclic edge coloring if it is proper (i.e. adjacent edges receive different
colors) and every cycle in G contains edges of at least three different colors (there are no bichromatic cycles in G).
The least number of colors needed for an acyclic edge coloring of G is called the acyclic chromatic index of G and is
denoted by a0 (G). The notion of acyclic (vertex) coloring was first introduced by Grünbaum [18]. The edge version
was first considered by Fiamčik [16], and independently by Alon, McDiarmid, and Reed [5].
As in the case of nonrepetitive colorings, it is quite natural to ask for an upper bound on the acyclic chromatic
index of a graph G in terms of its maximum degree ∆(G). Since a0 (G) ≥ χ0 (G) ≥ ∆(G), where χ0 (G) denotes the
ordinary chromatic index of G, this bound must be at least linear in ∆(G). The first linear bound was given by
Alon et al. [5], who showed that a0 (G) ≤ 64∆(G). Although it resolved the problem of determining the order of
growth of a0 (G) in terms of ∆(G), it was conjectured that the sharp bound should be lower.
Conjecture 3.6 (Fiamčik [16]; Alon–Sudakov–Zaks [7]). For every graph G, a0 (G) ≤ ∆(G) + 2.
Note that the bound in Conjecture 3.6 is only one more than Vizing’s bound on the chromatic index of G.
However, this elegant conjecture is still far from being proven.
The first major improvement to the bound a0 (G) ≤ 64∆(G) was made by Molloy and Reed [25], who proved that
a0 (G) ≤ 16∆(G). This bound remained the best for a while, until Ndreca, Procacci, and Scoppola [27] managed to
improve it to a0 (G) ≤ d9.62(∆(G) − 1)e. Again, first bounds for a0 (G) were obtained using the LLL. The bound
a0 (G) ≤ d9.62(∆(G) − 1)e by Ndreca et al. used an improved version of the LLL due to Bissacot, Fernández,
Procacci, and Scoppola [10].
The best current bound for a0 (G) in terms of ∆(G) was obtained by Esperet and Parreau via the entropy
compression method.
Theorem 3.7 (Esperet–Parreau [15]). For every graph G with maximum degree ∆, a0 (G) ≤ 4(∆ − 1).
Proof. We will apply Theorem 3.1. For brevity, let V B V (G) and E B E(G). Choose a 4(∆ − 1)-edge coloring ϕ
of G uniformly at random. Call a cycle C of length 2t ϕ-bichromatic if C = e1 , e2 , . . . , e2t and ϕ(e2i−1 ) = ϕ(e2t−1 ),
ϕ(e2i ) = ϕ(e2t ) for all 1 ≤ i ≤ t − 1.
Let
A B {S ⊆ E : ϕ is an acyclic edge coloring of G[S]},
where G[S] is the graph obtained from G by removing all the edges outside S. Note that with probability 1, A is a
nonempty downwards-closed family of subsets of E, and E ∈ A if and only if ϕ is an acyclic edge coloring of G.
Consider any e ∈ E. If e ∈ ∂A, then either there exists an edge e0 adjacent to e such that ϕ(e) = ϕ(e0 ), or there
exists a ϕ-bichromatic cycle C 3 e of even length. The crucial idea of [15] (which is credited to Jakub Kozik by the
authors) is to handle 4-cycles and cycles of length at least 6 separately. Set
B(e) B {BC : C 3 e is a cycle of length 2t ≥ 6} ∪ {Be },
where
1. BC happens if and only if the cycle C is ϕ-bichromatic;
2. Be happens if and only if either there exists an edge e0 adjacent to e such that ϕ(e) = ϕ(e0 ), or there exists a
ϕ-bichromatic 4-cycle C 3 e.
Again, we will assume that τ (e) = τ ∈ [1; +∞) is a constant. Consider the event Be ∈ B(e) of the second kind.
We will estimate the probability Pr(Be |Z ∈ A) for Z ⊆ E \ {e} using the following claim, which also plays a crucial
role in the original proof by Esperet and Parreau.
Claim 3.7.1. Suppose that some edges of G are properly colored. If e ∈ E is uncolored, then there exist at most
2(∆ − 1) ways to color e so that the resulting coloring either is not proper, or contains a bichromatic 4-cycle going
through e.
Proof. Indeed, denote the given proper partial coloring by ψ and let e = uv. Let L1 (resp. L2 ) be the set of colors
appearing on the edges incident to u (resp. v). The coloring becomes not proper if e is colored using a color from
L1 ∪ L2 , so there are |L1 ∪ L2 | such options. Suppose that coloring e with color c creates a bichromatic 4-cycle
uvxy. Then c = ψ(xy) and ψ(vx) = ψ(uy). Hence, the number of such colors c is at most the number of pairs of
edges vx, uy such that ψ(vx) = ψ(uy). Note that, since ψ is proper, there can be at most one pair vx, uy such that
ψ(vx) = ψ(uy) = c0 for a particular color c0 . Therefore, the total number of such pairs is exactly |L1 ∩ L2 |. Thus,
there are at most |L1 ∪ L2 | + |L1 ∩ L2 | = |L1 | + |L2 | ≤ 2(∆ − 1) “forbidden” colors for e, as desired.
a
13

Using Claim 3.7.1, we obtain
Pr(Be |Z ∈ A) ≤

2(∆ − 1)
1
=
4(∆ − 1)
2

for all Z ⊆ E \ {e}. Therefore,
στA (Be , e) ≤ στA (Be , {e}) =

max Pr(Be |Z ∈ A) · τ |{e}| ≤

Z⊆E\{e}

τ
.
2

Now we need to deal with the events of the form BC ∈ B(e). Note that there are at most (∆ − 1)2t−2 cycles
of length 2t passing through e. Therefore, the number of events in B(e) corresponding to cycles of length 2t is at
most (∆ − 1)2t−2 . Consider any such event BC . Suppose that C = e1 , e2 , . . . , e2t , where e1 = e. Then BC happens
if and only if ϕ(e2i−1 ) = ϕ(e2t−1 ) and ϕ(e2i ) = ϕ(e2t ) for all 1 ≤ i ≤ t − 1. Even if the colors of e2t−1 and e2t are
fixed, the probability of this happening is 1/(4(∆ − 1))2t−2 . Due to this observation, if C 0 B {e1 , e2 , . . . , e2t−2 } and
Z ⊆ E \ C 0 , then Pr(BC |Z ∈ A) ≤ 1/(4(∆ − 1))2t−2 . Therefore,
0

στA (BC , e) ≤ στA (BC , C 0 ) = max 0 Pr(BC |Z ∈ A) · τ |C | ≤
Z⊆E\C

τ 2t−2
.
(4(∆ − 1))2t−2

Putting everything together, it is enough to find a constant τ ∈ [1; +∞) such that
τ ≥1+

∞
X

(∆ − 1)2t−2 ·

t=3

4

τ 2t−2
τ
τ
(τ /4)
+ =1+
2 + 2,
(4(∆ − 1))2t−2
2
1 − (τ /4)

√
where the last equality is valid if τ /4 < 1. Setting τ = 2( 5 − 1) completes the proof.



Further applications of the LCL to acyclic edge coloring can be found in [8].

3.6

Color-critical hypergraphs

A hypergraph H is (k+1)-critical if it is not k-colorable, but each of its proper subhypergraphs is. Call a hypergraph
H true if all its edges have size at least 3. It is interesting to know what the least possible number of edges in a
(k + 1)-critical true hypergraph on n vertices is. The best known constructions due to Abbott and Hare [1] and
Abbott, Hare, and Zhou [2] contain roughly (k − 1)n edges. This bound is asymptotically tight for k → ∞, as the
following theorem due to Kostochka and Stiebitz asserts.
Theorem 3.8 (Kostochka–Stiebitz [24]). Every (k + 1)-critical true hypergraph with n vertices contains at least
(k − 3k 2/3 )n edges.
Here we improve this result, obtaining the following new bound.
Theorem 3.9. Every (k + 1)-critical true hypergraph with n vertices contains at least (k − 4

√

k)n edges.

Proof. Our proof is essentially the same as the proof of Theorem 3.8 given in [24]. The only difference is that we
replace the application of the LLL by an application of the LCL (in the form of Theorem 3.1).
√
Let H be a (k + 1)-critical true hypergraph with n vertices. Denote V B V (H) and E B E(H). Let c B 4 k.
Fix some positive constant z (to be determined later). Let g : Z≥1 → R be given by
(
1 − z −1 if t = 1;
g(t) B
21−t z −1 if t > 1.
Inductively construct a sequence {Vi }m
i=0 , where 0 ≤ m ≤ n, of subsets of V according to the following rule. Let
V0 B V . If there is a vertex v ∈ Vi such that
X
g(|H ∩ Vi |) ≥ k − c,
(3.6.1)
H∈E:
H3v

then select one such vertex, denote it by vi , and let Vi+1 B Vi \ {vi }. Otherwise let m B i and stop.

14

If m = n, then
X

|E| =

1>

H∈E

|H|
XX

g(j) =

H∈E j=1

n−1
X

X

g(|H ∩ Vi |) ≥ (k − c)n,

i=0 H∈E:
H3vi

as desired.
Now suppose that m < n. We will prove that this cannot happen. Let V 0 B Vm . Since V 0 is nonempty, the
hypergraph H − V 0 obtained from H by deleting the vertices in V 0 is k-colorable. Fix a proper k-coloring ψ of
H − V 0 and extend it to a k-coloring ϕ of H by choosing a color for each vertex in V 0 uniformly and independently
from all other vertices.
Let A ⊆ Pow(V 0 ) be given by
A B {S ⊆ V 0 : there is no ϕ-monochromatic edge H ⊆ (V \ V 0 ) ∪ S}.
Note that A is downwards-closed and Pr(∅ ∈ A) = 1 (because the coloring ψ of V \ V 0 is proper). We will use
Theorem 3.1 to prove that Pr(V 0 ∈ A) > 0, which will be a contradiction since H is not k-colorable.
For v ∈ V 0 , let
B(v) B {BH : v ∈ H ∈ E},
where the event BH happens if and only if H is ϕ-monochromatic. Clearly, if v ∈ ∂A, then at least one of the
events BH ∈ B(v) holds.
Let τ (v) = τ ∈ [1; +∞) be a constant function. Consider some BH ∈ B(v). There are two cases. First suppose
that H * V 0 . Note that such H is ϕ-monochromatic if and only if H \V 0 is ψ-monochromatic and ϕ(u) = ψ(w) for all
0
u ∈ H ∩ V 0 and w ∈ H \ V 0 . Therefore, for each such H and for Z ⊆ V 0 \ H, Pr(BH |Z ∈ A) ≤ Pr(BH ) ≤ 1/k |H∩V | .
Thus,
0
τ |H∩V |
A
A
0
|H∩V 0 |
στ (BH , v) ≤ στ (BH , H ∩ V ) = max
Pr(BH |Z ∈ A) · τ
≤ |H∩V 0 | .
Z⊆V 0 \H
k
If, on the other hand, H ⊆ V 0 , then choose an arbitrary vertex u ∈ H \ {v} and consider Z ⊆ (V 0 \ H) ∪ {u}.
(This idea is analogous to the one we discussed in Subsection 3.3.) Since fixing the color of u does not change the
probability that H is monochromatic, we have Pr(BH |Z ∈ A) ≤ 1/k |H|−1 , so
στA (BH , v) ≤ στA (BH , E \ {u}) =

max
0

Z⊆(V \H)∪{u}

Pr(BH |Z ∈ A) · τ |H\{u}| ≤

τ |H|−1
.
k |H|−1

For a vertex v ∈ V 0 , let
at (v) B |{H ∈ E : v ∈ H * V 0 , |H ∩ V 0 | = t}|;
bt (v) B |{H ∈ E : v ∈ H ⊆ V 0 , |H| = t}|.
To apply Theorem 3.1, it is enough to guarantee that there exists a constant τ ∈ [1; +∞) such that for all v ∈ V 0 ,
τ ≥1+

∞
X

∞

at (v)

t=1

τt X
τ t−1
+
bt (v) t−1 .
t
k
k
t=3

(3.6.2)

0
0
Since V 0 is the last set in the sequence {Vi }m
i=0 , no vertex in V satisfies (3.6.1). In other words, for all v ∈ V ,
∞
X

at (v)g(t) +

t=1

∞
X

bt (v)g(t) < k − c.

t=3

Let
αt (v) B at (v)g(t);
βt (v) B bt (v)g(t).
Then (3.6.3) can be rewritten as
γ(v) B

∞
X
t=1

αt (v) +

∞
X
t=3

15

βt (v) < k − c,

(3.6.3)

and (3.6.2) turns into
τ ≥1+

∞
X
t=1

αt (v) ·

∞
1  τ t X
1  τ t−1
+
,
βt (v) ·
g(t) k
g(t) k
t=3

which, after substituting the actual values for g, becomes
∞

τ ≥ 1 + α1 (v) ·

z τ X
1
+
αt (v) · z
z − 1 k t=2
2



2τ
k

t
+

∞
X


βt (v) · z

t=3

2τ
k

t−1
.

(3.6.4)

We can view the right-hand side of (3.6.4) as a linear combination of variables αt (v), βt (v). If we assume that
4τ
1
≥
,
k
z−1
2

then the largest coefficient in this linear combination is z (2τ /k) (the coefficient of β3 (v)). Thus, it is enough to
find τ , z satisfying the following two inequalities:
1
4τ
≥
;
k
z−1

(3.6.5)

4zτ 2 (k − c)
.
(3.6.6)
k2
(Inequality (3.6.6) is obtained by replacing all coefficients on the right hand side of (3.6.4) by the largest one and
using the fact that γ(v) < k − c.) If we choose
k
+ 1,
z=
4τ
then (3.6.5) is satisfied, while (3.6.6) becomes


4τ 2 (k − c) k
k−c
4(k − c) 2
τ ≥1+
+1 =1+
τ+
τ .
2
k
4τ
k
k2
τ ≥1+

Thus, we just have to make sure that the following inequality has a solution τ :
4(k − c) 2 c
τ − τ + 1 ≤ 0.
k2
k
√
This is true if and only if c2 ≥ 16(k − c); in particular, c = 4 k works. Therefore, ϕ is a proper k-coloring of H
with positive probability. This contradiction completes the proof.


3.7

Choice functions

Our last example is a probabilistic corollary of the
SnLCL. Let U1 , . . . , Un be a collection of pairwise disjoint nonempty
finite sets. A choice function
F
is
a
subset
of
i=1 Ui such that for all 1 ≤ i ≤ n, |F ∩ Ui | = 1. A partial choice
Sn
function P is a subset of i=1 Ui such that for all 1 ≤ i ≤ n, |P ∩ Ui | ≤ 1. For a partial choice function P , let
dom(P ) B {i : P ∩ Ui , ∅}.
Thus, a choice function F is a partial choice function with dom(F ) = {1, . . . , n}.
Let F be a choice function and let P be a partial choice function. We say that P occurs in F if P ⊆ F , and
we say that F avoids P if P does not occur in F . Many natural combinatorial problems (especially ones related
to coloring) can be stated using the language of choice functions. For instance, consider a graph G with vertex set
{1, . . . , n}. Fix a positive integer k and let Ui B {(i, c) : 1 ≤ c ≤ k} for each 1 ≤ i ≤ n. For each edge ij ∈ E(G)
and 1 ≤ c ≤ k, define a partial choice function Pijc B {(i, c), (j, c)}. Then a proper vertex k-coloring of G can be
identified with a choice function F such that none of {Pijc }ij∈E(G),1≤c≤k occur in F . Another problem that has
a straightforward formulation using choice functions is the k-SAT (which also serves as a standard example of a
problem that can be approached with the LLL). S
n
A multichoice function M is simply a subset of i=1 Ui (one should think of it as a generalized choice function
where one is allowed to choose multiple or zero elements from each set). For a multichoice function M , let Mi B
M ∩ Ui . Again, we say that a partial choice function P occurs in a multichoice function M if P ⊆ M . Suppose that
16

we are given a family P1 , . . . , Pm of nonempty “forbidden” partial choice functions. For a multichoice function M ,
the ith defect of M (notation: def i (M )) is the number of indices j such that i ∈ dom(Pj ) and Pj occurs in M .
Observe that there exists a choice function F that avoids all of P1 , . . . , Pm if and only if there exists a multichoice
function M such that for all 1 ≤ i ≤ n,
|Mi | ≥ 1 + def i (M ).
(3.7.1)
Indeed, if F avoids all of P1 , . . . , Pm , then F itself satisfies (3.7.1). On the other hand, if M satisfies (3.7.1), then,
for every i, there is an element xi ∈ Mi that does not belong to any Pj occurring in M . Therefore, {xi }ni=1 is a
choice function that avoids all of P1 , . . . , Pm , as desired.
The main result of this subsection is that, in fact, it is enough to establish (3.7.1) on average for some random
multichoice function M .
Theorem 3.10. Let U1 , . . . , Un be a collection of pairwise disjoint nonempty finite sets and let P1 , . . . , Pm be a
family of nonempty partial choice functions. Let Ω be a probability
Snspace and let Mi : Ω → Pow(Ui ), 1 ≤ i ≤ n, be
a collection of mutually independent random variables. Set M B i=1 Mi . If for all 1 ≤ i ≤ n,
E|Mi | ≥ 1 + E def i (M ),

(3.7.2)

then there exists a choice function F that avoids all of P1 , . . . , Pm .
Sn
Proof. For x ∈ i=1 Ui , let p(x) B Pr(x ∈ M ). Then
X
E|Mi | =
p(x).
x∈Ui

Since the variables

{Mi }ni=1

are independent,
Pr(Pj ⊆ M ) =

Y

p(x).

x∈Pj

Therefore, if Ni B {j : i ∈ dom(Pj )},
E def i (M ) =

X

X Y

Pr(Pj ⊆ M ) =

j∈Ni

p(x).

j∈Ni x∈Pj

Thus, (3.7.2) is equivalent to
X
x∈Ui

Let τ (i) B

P

x∈Ui

X Y

p(x) ≥ 1 +

p(x).

(3.7.3)

j∈Ni x∈Pj

p(x) and let q(x) B p(x)/τ (i) for all x ∈ Ui . Then (3.7.3) can be rewritten as
X Y
τ (i) ≥ 1 +
q(x) · τ (dom(Pj )).

(3.7.4)

j∈Ni x∈Pj

We will only use the numerical condition (3.7.4), ignoring its probabilistic meaning. Construct a random choice
function F (in a new probability space) as follows: Choose an element P
x ∈ Ui with probability q(x), making the
choices for different Ui ’s independently (this definition is correct, since x∈Ui q(x) = 1). Set I B {1, . . . , n} and
define a random subset A ⊆ Pow(I) as follows:
A B {S ⊆ I : no Pj with dom(Pj ) ⊆ S occurs in F }.
Then A is a nonempty downwards-closed family of subsets of I, and I ∈ A if and only if F avoids all of P1 , . . . , Pm .
For i ∈ I, let
B(i) B {Bj : j ∈ Ni },
where the event Bj happens if and only if Pj ⊆ F . Clearly, if i ∈ ∂A, then there is some j ∈ Ni such that Pj ⊆ F ,
so we can apply Theorem 3.1.
Q
Consider any i ∈ I and j ∈ Ni . Since Pr(Bj ) = x∈Pj q(x), we have
στA (Bj , i) ≤ στA (Bj , dom(Pj )) =

Pr(Bj |Z ∈ A) · τ (dom(Pj ))
Y
≤ Pr(Bj ) · τ (dom(Pj )) =
q(x) · τ (dom(Pj )).
max

Z⊆I\dom(Pj )

x∈Pj

Therefore, in this case (3.7.4) implies (3.1.1), yielding Pr (I ∈ A) > 0, as desired.
17



Theorem 3.10 can be used, for instance, to obtain condition (3.3.3) for 2-colorability of uniform hypergraphs,
or to prove that a0 (G) ≤ d9.53(∆(G) − 1)e (this bound, although considerably weaker than the one given by
Theorem 3.7, is still an improvement over the previous results derived using the LLL). Another application of
Theorem 3.10 can be found in [9].
Acknowledgments. This work is supported by the Illinois Distinguished Fellowship. I am grateful to Alexandr
Kostochka for his helpful conversations and encouragement and to the anonymous referees for their valuable comments.

References
[1] H.L. Abbott, D.R. Hare. Sparse color-critical hypergraphs, Combinatorica, Volume 9, 1989. Pages 233–243.
[2] H.L. Abbott, D.R. Hare, and B. Zhou, Sparse color-critical graphs and hypergraphs with no short cycles, J.
Graph Theory, Volume 18, 1994. Pages 373–388.
[3] D. Achlioptas, F. Iliopoulos. Random Walks That Find Perfect Objects and the Lovász Local Lemma. FOCS ’14
Proceedings of the 55th Annual Symposium on Foundations of Computer Science, 2014. Pages 494–503.
[4] N. Alon, J. Grytczuk, M. Hałuszczak, and O. Riordan. Nonrepetitive colorings of graphs. Random Structures
& Algorithms, Volume 21, Issue 3–4, 2002. Pages 336–346.
[5] N. Alon, C. McDiarmid, and B. Reed. Acyclic coloring of graphs. Random structures and algorithms, Volume
2, No. 3, 1991. Pages 277–288.
[6] N. Alon, J.H. Spencer. The Probabilistic Method. Wiley, New York, 1992.
[7] N. Alon, B. Sudakov, and A. Zaks. Acyclic edge colorings of graphs. J. Graph Theory, Volume 37, 2001. Pages
157–167.
[8] A. Bernshteyn. New bounds for the acyclic chromatic index. Discrete Mathematics, Volume 339, Issue 10, 2016.
Pages 2543–2552.
[9] A. Bernshteyn. The asymptotic behavior of the correspondence chromatic number. Discrete Mathematics, Volume 339, Issue 11, 2016. Pages 2680–2692.
[10] R. Bissacot, R. Fernández, A. Procacci, and B. Scoppola. An improvement of the Lovász Local Lemma via
cluster expansion. J. Combinatorics, Probability and Computing, Volume 20, Issue 5, 2011. Pages 709–719.
[11] K. Chandrasekaran, N. Goyal, and B. Haeupler. Deterministic Algorithms for the Lovasz Local Lemma. SIAM
J. Comput., Volume 42, No. 6, 2013. Pages 2132–2155.
[12] V. Dujmović, G. Joret, J. Kozik, and D.R. Wood. Nonrepetitive Colouring via Entropy Compression. Combinatorica, 2015. Pages 1–26.
[13] P. Erdős, L. Lovász. Problems and results on 3-chromatic hypergraphs and some related questions. Infinite and
finite sets, A. Hajnal, R. Rado, and V.T. Sós, editors, Colloq. Math. Soc. J. Bolyai, North Holland, 1975. Pages
609–627.
[14] P. Erdős, J. Spencer. Lopsided Lovász Local Lemma and latin transversals. Discrete Applied Mathematics,
Volume 30, Issue 2–3, 1991. Pages 151–154.
[15] L. Esperet, A. Parreau. Acyclic edge-coloring using entropy compression. European J. Combin., Volume 34,
Issue 6, 2013. Pages 1019–1027.
[16] J. Fiamčik. The acyclic chromatic class of a graph (in Russian). Math. Slovaca, Volume 28, 1978. Pages 139–145.
[17] D. Gonçalves, M. Montassier, and A. Pinlou. Entropy compression method applied to graph colorings.
arXiv:1406.4380.
[18] B. Grünbaum. Acyclic colorings of planar graphs. Israel Journal of Mathematics, Volume 14, Issue 4, 1973.
Pages 390–408.
[19] J. Grytczuk. Nonrepetitive colorings of graphs—a survey. International Journal of Mathematics and Mathematical Sciences, Volume 2007, 2007.
[20] J. Grytczuk, J. Przybyło, and X. Zhu. Nonrepetitive list colourings of paths, Random Structures & Algorithms,
Volume 38, Issue 1–2, 2011. Pages 162–173.
18

[21] J. Grytczuk, J. Kozik, and P. Micek. New approach to nonrepetitive sequences. Random Structures & Algorithms, Volume 42, Issue 2, 2013. Pages 214–225.
[22] J. Harant, S. Jendrol’. Nonrepetitive vertex colorings of graphs. Discrete Mathematics, Volume 312, Issue 2,
2012. Pages 374–380.
[23] K. Kolipaka, M. Szegedy. Moser and Tardos meet Lovász. STOC ’11 Proceedings of the forty-third annual
ACM symposium on Theory of computing, 2011. Pages 235–244.
[24] A.V. Kostochka, M. Stiebitz. On the number of edges in colour-critical graphs and hypergraphs, Combinatorica,
Volume 20, 2000. Pages 521–530.
[25] M. Molloy, B. Reed. Further algorithmic aspects of the Local Lemma. Proceedings of the 30th Annual ACM
Symposium on Theory of Computing, 1998. Pages 524–529.
[26] R. Moser, G. Tardos. A constructive proof of the general Lovász Local Lemma. J. ACM, Volume 57, Issue 2,
2010.
[27] S. Ndreca, A. Procacci, and B. Scoppola. Improved bounds on coloring of graphs. European J. Combin., Volume
33, Issue 4, 2012. Pages 592–609.
[28] W. Pegden. An extension of the Moser–Tardos Algorithmic Local Lemma. SIAM J. Discrete Math., Volume
28, Issue 2, 2014. Pages 911–917.
[29] J. Radhakrishnan, A. Srinivasan. Improved bounds and algorithms for hypergraph two-coloring, Random Structures and Algorithms, Volume 16, 2000. Pages 4–32.
[30] T. Tao. Moser’s entropy compression argument, What’s New, 2009.
[31] A. Thue. Über unendliche Zeichenreichen. Norske Vid. Selsk. Skr., I Mat. Nat. Kl., 1906. Pages 1–22.

19

