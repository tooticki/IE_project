GENERALIZATIONS OF LOCAL BIJECTIVITY OF KELLER MAPS
AND A PROOF OF 2-DIMENSIONAL JACOBIAN CONJECTURE

arXiv:1603.01867v29 [math.AG] 26 Sep 2018

YUCAI SU
School of Mathematical Science, Tongji University, Shanghai, 200092, China
ycsu@tongji.edu.cn
Abstract. Let (F, G) ∈ C[x, y]2 be a Jacobian pair and σ : (a, b) 7→ (F (a, b), G(a, b)) for (a, b) ∈
C2 the corresponding Keller map. The local bijectivity of Keller maps tells that for p ∈ C2 , there
exist neighborhoods Op of p and Oσ(p) of σ(p) such that σp = σ|Op : Op → Oσ(p) is a bijection.
Thus if there exist p0 , p1 ∈ C2 with p0 6= p1 , σ(p0 ) = σ(p1 ), then the local bijectivity implies that
σp−1
σp0 : Op0 → Op1 is a bijection between some neighborhoods of p0 and p1 . We generalize this
1
result in various aspects, which lead us to give a proof of injectivity of Keller maps and thus the
2-dimensional Jacobian conjecture. Among those generalizations, one is the following (cf. Theorem

1.5): For any (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ C2 ×C2 satisfying p0 6= p1 , σ(p0 ) = σ(p1 ), κ0 ≤ |x1 | ≤
κ1 |x0 |κ2 + κ3 ≤ κ4 |x1 | + κ5 , ℓp0 ,p1 :=
2

|y1 |
|x1 |κ6

≥ κ7 for some preassigned κi ∈ R>0 , there exists

2

(q0 , q1 ) ∈ C × C satisfying the same conditions, and furthermore ℓq0 ,q1 > ℓp0 ,p1 .

Contents
1. Main theorem
2. Some preparations

1
5

3. Proof of Theorem 1.3
4. Proof of Theorem 1.4
5. Proof of Theorem 1.5 (1)

9
15
18

6. Proof of Theorem 1.5 (2)

25

7. Proofs of Theorems 1.1 and 1.2
References

28
29

1. Main theorem
Let us start with an arbitrary Jacobian pair (F, G) ∈ C[x, y]2 , i.e., a pair of polynomials on two
variables x, y with a nonzero constant Jacobian determinant


 ∂F ∂F 


 ∂x ∂y 
 ∈ C6=0 .

(1.1)
J(F, G) := 

 ∂G ∂G 
 ∂x ∂y 
Date: September 27, 2018
Supported by NSF grant 11431010 of China
Mathematics Subject Classification (2000): 14R15, 14E20, 13B10, 13B25, 17B63.
1

Assume that the corresponding Keller map σ : C2 → C2 sending, for p = (a, b) ∈ C2 ,
p 7→ (F (p), G(p)) := (F (a, b), G(a, b)),

(1.2)

is not injective, namely, for some p0 = (x0 , y0 ), p1 = (x1 , y1 ) ∈ C2 ,
σ(p0 ) = σ(p1 ), p0 6= p1 .

(1.3)

The local bijectivity of Keller maps says that for p ∈ C2 , there exist neighborhoods Op of p and
Oσ(p) of σ(p) such that σp = σ|Op is a bijection between these two neighborhoods. This implies that
σp−1
σp0 : Op0 → Op1 is a bijection between some neighborhoods Op0 of p0 and Op1 of p1 (we may
1

assume Op0 and Op1 are disjoint), i.e., any q0 ∈ Op0 is in 1–1 correspondence with q1 ∈ Op1 such

that σ(q0 ) = σ(q1 ) and q0 6= q1 . In this paper we generalize this result in various aspects, which
lead us to present a proof of injectivity of Keller maps, which implies the well-known Jacobian
conjecture (see, e.g., the References).

Theorem 1.1. (Main Theorem) Let (F, G) ∈ C[x, y]2 be a Jacobian pair. Then the Keller map
σ is injective. In particular, the 2-dimensional Jacobian conjecture holds, i.e., F, G are generators
of C[x, y].
First we give some formulations. Fix (once and for all) a sufficiently large ℓ ∈ R>0 . Applying
the following variable change,

(x, y) 7→ x + (x + y)ℓ , x + y ,
(1.4)

and rescaling F, G, we can assume

Supp F ⊂ ∆0,ξ,η ,

FL = (x + y)m ,

J(F, G) = 1,

(1.5)

where

	
• Supp F := (i, j) ∈ Z2≥0 | Coeff (F, xi y j ) 6= 0 is the support of F [cf. Convention 2.1 (2) (iv)
for notation Coeff (F, xi y j ) ],

• ∆0,ξ,η is the triangular with vertices 0 = (0, 0), ξ = (m, 0), η = (0, m) for some m ∈ Z>0 ,
• L is the edge of Supp F linking vertices ξ, η,

• FL , which we refer to as the leading part of F , is the part of F corresponding to the edge
L (which means that Supp FL = L ∩ Supp F ).

The reason we take the variable change (1.4) is to use the leading part FL of F to control F in
some sense [cf. (3.11) ], which guides us to obtain Theorem 1.3.
Throughout the paper, we use the following notations,

(p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ C2 × C2 ∼
= C4 ,


	


V = (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ C4  σ(p0 ) = σ(p1 ), p0 6= p1 ,

	


Vξ0 ,ξ1 = (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V  x0 = ξ0 , x1 = ξ1 ,

(1.6)
(1.7)
(1.8)

for any ξ0 , ξ1 ∈ C. Then V 6= ∅ by assumption (1.3). The main result used in the proof of Theorem
1.1 is the following.
Theorem 1.2.

(i) There exist ξ0 , ξ1 ∈ C such that Vξ0 ,ξ1 = ∅.
2


(ii) Fix any ξ0 , ξ1 ∈ C satisfying (i). Denote, for (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V ,
dp0 ,p1 = |x0 − ξ0 |2 + |x1 − ξ1 |2 .


Then for any (p0 , p1 ) ∈ V , there exists (q0 , q1 ) = (ẋ0 , ẏ0 ), (ẋ1 , ẏ1 ) ∈ V such that
dq0 ,q1 < dp0 ,p1 .

(1.9)

(1.10)

After a proof of this result, it is then not surprising that it can be used to give a proof of Theorem
1.1 by taking some kind of “limit” [cf. (7.2) ], which can guide us to derive a contradiction. We
would like to mention that at a first sight, Theorem 1.2 (i) seems to be obvious, however its proof
is highly nontrivial to us, it needs several results, which we state below. Here is the first one.

Theorem 1.3. Denote, for (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V ,

	
hp0 ,p1 = max |x1 |, |y1 |, |x0 |, |y0 | ,
(1.11)
and call hp0 ,p1 the height of (p0 , p1 ). There exists s0 ∈ R>0 (depending on m = deg F, deg G and

coeﬃcients of F and G ) satisfying the following: For any (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V with
hp0 ,p1 ≥ s0 ,

(1.12)

we must have
m
m+1

m
m+1

In particular if hp0 ,p1

|x1 + y1 | < hp0 ,p1 .
|x0 + y0 | < hp0 ,p1 ,

	
= max |xt |, |yt | (for some t ∈ {0, 1} ), then
m+1
m+2

|a − b| < nt

	
where nt = min |xt |, |yt | .

(1.13)


	
for any a, b ∈ |xt |, |yt |, hp0 ,p1 ,

(1.14)

To prove Theorem 1.2 (i), we assume conversely that
Vξ0 ,ξ1 6= ∅ for all ξ0 , ξ1 ∈ C.

(1.15)

Then we are able to obtain the following.
Theorem 1.4. Under the assumption (1.15), we have the following.
(i) The following subset of V is a nonempty closed bounded subset of C4 for any k0 , k1 ∈ R≥0 ,

	


(1.16)
Ak0 ,k1 = (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V  |x0 | = k0 , |x1 | = k1 .

(ii) The following is a well-deﬁned function on k0 , k1 ∈ R≥0 ,



γ
= max |y1 |  (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ Ak
k0 ,k1

0 ,k1

	
.

(1.17)

(iii) The γ k0 ,k1 is an “almost strictly” increasing function on both variables k0 , k1 ∈ R≥0 in the
following sense,

(a)

γ k0′ ,k1 > γ k0,k1

if k0′ > k0 ≥ 0, k1 ≥ 0,

(b)

γ k0,k1′ > γ k0,k1

if k0 > 0, k1′ > k1 ≥ 0.

This result is then used to prove the following.
3

(1.18)

Theorem 1.5.

(1) There exist κi ∈ R>0 such that the following hold.


(i) Denote by V0 the subset of V such that all its elements (p0 , p1 ) = (x0 , y0 ), (x1 , y1 )
simultaneously satisfy one of (1.19) or (1.20) [cf. (5.27) ]. Then V0 6= ∅.

(a) κ0 ≤ |x1 | ≤ κ1 |x0 |κ2 + κ3 ≤ κ4 |x1 | + κ5 , (b) ℓp0 ,p1 :=

|y1 |
≥ κ7 ,
|x1 |κ6

(1.19)

(a) 1 ≤ κ1 |x30 x1 y1 |κ2 ≤ κ3 |x0 x31 y12 | ≤ κ4 |x30 x1 y1 |κ5 ≤ κ6 ,
(b) κ7 ≤ |x1 | ≤ κ8 ,
where we require

(c) ℓp0 ,p1 := |x1 |2

 |x3 y |κ9

1 1
+
κ
11 ≥ κ12 ,
|x0 |κ10

κ4 < 1, κ3 < min{κ0 , κ5 } in case (1.19),

(1.20)

(1.21)

and in any case, κi will be chosen such that there exists θi ∈ R>0 satisfying: when
conditions hold, we have
θ0 ≤ |x0 |, |x1 | ≤ θ1 , and |y1 | ≥ θ0 .

(1.22)

(ii) For any (p0 , p1 ) ∈ V0 , at most only one equality can hold in (1.19) (a) or (1.20) (a); furthermore, none of the ﬁrst or last equality of (1.20) (a) or any equalities of (1.20) (b)
can occur.

(2) For any (p0 , p1 ) ∈ V0 , there exists (q0 , q1 ) = (ẋ0 , ẏ0 ), (ẋ1 , ẏ1 ) ∈ V0 such that
(1.23)

ℓq0 ,q1 > ℓp0 ,p1 .

Remark 1.6.
(1) We wish to mention that Theorem 1.5 is the most important and difficult
part of the paper. Throughout the paper we will frequently use the local bijectivity of
Keller maps. Theorem 1.5 (2) says that [assume for example, we have case (1.19) ]
|ẏ1 |
|y1 |
>
,
κ
6
|ẋ1 |
|x1 |κ6

(a) κ0 ≤ |ẋ1 | ≤ κ1 |ẋ0 |κ2 + κ3 ≤ κ4 |ẋ1 | + κ5 ,

(b)

(c) σ(q0 ) = σ(q1 ),

(d) q0 6= q1 .

(1.24)
(1.25)

If we regard ẋ0 , ẏ0 , ẋ1 , ẏ1 as 4 free variables, then the local bijectivity always allows us to
obtain (1.24) (c), which imposes two restrictions on 4 variables. We can impose at most
two more “nontrivial” restrictions on them [we regard (1.24) (d) as a trivial restriction, see
below]. The main difficulty for us is how to impose two more “solvable” restrictions on
variables [see (3) below] to control ẋ0 , ẏ0 , ẋ1 , ẏ1 in order to achieve our goal of “deriving a
contradiction”. However, it seems to us that two more restrictions are always insufficient
to achieve the goal. Here, condition (1.24) (b) imposes one more restriction, and we have
one free variable left. However there are 3 restrictions in (1.24) (a), thus in general there
will be no solutions. Thanks to Theorem 1.5 (1) (ii) [see (2) below], we only need to take
care of one restriction in (1.24) (a) each time [cf. (6.5) ] since we are always under a “local”
situation (i.e., we are only concerned with a small neighborhood of some points each time),
and thus the inequation in (1.24) (a) is solvable [we do not need to consider condition
(1.24) (d) under the “local” situation, we only need to take care of it when we take some
kind of “limit”, cf. (7.2) ].
4

(2) Condition (1.24) (b) is not only used to control |ẋ1 | and |ẏ1 |, but also used to take the
“limit”; while (1.24) (a) is used to control |ẋ0 | and |ẋ1 |. We remark that the requirement
“ κ3 < κ5 ” in (1.19) (a) or respectively κ11 > 0 in (1.20) (c) will guarantee the correspondent
inequation
κ1 |ẋ0 |κ2 + κ3 ≤ κ4 |ẋ1 | + κ5 , or respectively,
|ẋ1 |2


 3 κ9

 |ẋ3 ẏ |κ9
2 |x1 y1 |
1 1
>
|x
|
,
+
κ
+
κ
1
11
11
|ẋ0 |κ10
|x0 |κ10

(1.26)

is solvable [see (3) below, Remark 6.2 and (6.18) ]. Finally we would like to mention that
to find conditions like the ones in (1.19) or (1.20) satisfying Theorem 1.5 (1) (ii) has been
extremely difficult for us, we achieve this by using Theorem 1.4 to prove several technical
lemmas (cf. Assumption 5.1 and Lemmas 5.2–5.13).
(3) One may expect to have some statements such as one of the following:
(i) For any (p0 , p1 ) ∈ V with |x0 |θ0 + |x1 |θ1 ≤ s (for some θi , s ∈ R>0 ), there exists
(q0 , q1 ) ∈ V such that
(a) |ẋ0 |θ0 + |ẋ1 |θ1 ≤ s,

(b) |ẏ1 |θ2 > |y1 |θ2 .

(1.27)

(ii) For any (p0 , p1 ) ∈ V with |x1 |θ1 ≤ |y1 |θ2 + s, there exists (q0 , q1 ) ∈ V such that
(a) |ẋ1 |θ1 ≤ |ẏ1 |θ2 + s,

(b) |ẏ0 |θ3 − |ẋ0 |θ4 > |y0 |θ3 − |x0 |θ4 .

(1.28)

If a statement such as one of the above could be obtained, then a proof of Theorem 1.1
would be easier. At a first sight, the condition (1.27) (a) [or (1.10) ] only imposes one
restriction on variables, however it in fact contains 2 hidden restrictions [see arguments
after (7.7) ] simply because the left-hand side of “ < ” has 2 positive terms with absolute
values containing variables. The second condition in (1.28) is unsolvable as will be explained
in Remark 6.2. We would also like to point out that to obtain Theorem 1.1, we always
need to take some kind of “limit” [cf. (7.2) ] to derive a contradiction. Thus some condition
such as (1.10), (1.24) (b), (1.27) (b) or (1.28) (b) is necessary in order to take the “limit”.

2. Some preparations
We need some conventions and notations, which, for easy reference, are listed as follows.
Convention 2.1.
where i =

√

(1) A complex number is written as a = are + aim i for some are , aim ∈ R,

−1. If ab appears in an expression, then we assume b ∈ R, and in case a 6= 0,

we interpret ab as the unique complex number r b ebθi by writing a = reθi for some r ∈ R>0 ,
−π < θ ≤ π and e is the natural number.
P
(2) Let P = i∈Z≥0 pi y α+i ∈ C(x)((y)) with α ∈ Z, pi ∈ C(x).
(i) Assume p0 = 1. For any β ∈ Q with αβ ∈ Z, we always interpret P β as
Pβ

=

y αβ

 
j 

∞
P
P
β
pi y i
∈ C(x)((y)),
1+
j=1 j
i∈Z>0
5

(2.1)

where in general,
Then
′


k
λ1 ,λ2 ,...,λi

is the multi-nomial coeﬃcient

k(k−1)···(k−(λ1 +λ2 +···+λi )+1)
.
λ1 !λ2 !···λi !

′

(P β )β = P ββ for any β, β ′ ∈ Q with αβ, αββ ′ ∈ Z.

(2.2)

If p0 6= 1, then pβ0 is in general a multi-valued function, and if we fix a choice of pβ0 ,

then (2.2) only holds when β ′ ∈ Z [fortunately we will only encounter this situation,
cf. (3.23) and statements after it].
(ii) For Q1 , Q2 ∈ C(x)((y)), we use the following notation [as long as it is algebraically a
well-defined element in C(x)((y)) ]
P (Q1 , Q2 ) = P |(x,y)=(Q1 ,Q2 ) =

P
i

pi (Q1 )Qα+i
2 .

(2.3)

(iii) If Q1 , Q2 ∈ C with Q2 6= 0, we also use (2.3) to denote a well-defined complex number
as long as pi (Q1 ) exists for all posible i and the series (2.3) converges absolutely.
P
(iv) For Q = i∈Z≥0 qi y β+i ∈ C(x)((y)), by comparing coefficients of y β+i for i ≥ 0, there
exists uniquely bi ∈ C(x) such that
Q=

∞
P

bi P

β+i
α

(2.4)

.

i=0
β+i

We call bi the coeﬃcient of P α in Q, and denote by Coeff (Q, P
P
i j
i j
i,j qij x y with qij ∈ C, we also denote Coeff (Q, x y ) = qij .

β+i
α

).

If Q =

(3) Throughout the paper, we need two independent parameters k ≫ 1 (i.e., k → ∞) and
E → 0. We use the following convention: Symbols s, s j for j ≥ 0 always denote some
(sufficiently large) numbers independent of E , k . We use O(E i ) for i ∈ Q≥0 to denote any
element P in C(x)((y)) (or especially in C) such that P (ẋ, ẏ) converges absolutely and

|E −i P (ẋ, ẏ)| < s for some fixed s, where (ẋ, ẏ) is in some required region which will be
specified in the context.
pj y j ∈ C(x)((y)), pj ∈ C(x), and (x0 , y0 ) ∈ C2 with y0 6= 0. If pj (x0 ) exists for all
P
possible j, and z0 = j |pj (x0 )y0j | converges, then z0 is called the absolute converging value of P
Let P =

P

j

at (x0 , y0 ), denoted by A(x0 ,y0 ) (P ) (or by A(y0 ) (P ) if P does not depend on x).
Definition 2.2.
exists and

(1) Let P be as above and Q =

P

i qi y

i

∈ C((y)), qi ∈ R≥0 , x0 ∈ C. If pi (x0 )

|pi (x0 )| ≤ qi for all possible i,

(2.5)

then we say Q is a controlling function for P on y at point x0 , and denote
P Exy 0 Q or Q Dxy 0 P ,

(2.6)

or P Ey Q or Q Dy P when there is no confusion. In particular if P, Q do not depend on
y then we write P Ex0 Q or Q Dx0 P (thus a E b for a, b ∈ C simply means |a| ≤ b).
(2) An element in C((y)) with non-negative coefficients (such as Q above) is called a controlling
function on y.
6

(3) If Q = q0 y α +

P

j>0 qj y

α+j

∈ C((y)) is a controlling function on y with qi ∈ R≥0 and

q0 > 0, then we always use the same symbol with subscripts “ igo ” and “ neg ” to denote
the elements


P
P
(2.7)
qj y j = q0 y α (1 − Qigo ).
qj y j , Qneg = q0 y α 1 − q0−1
Qigo = q0−1
j>0

j>0

We call Qigo the ignored part of Q, and Qneg the negative correspondence of Q [in sense of

(2.9) and (2.10), where a, −k are nonpositive].
Lemma 2.3.

(1) If
P = p0 y α +

P

j>0

pj y α+j ∈ C(x)((y)),

Q = q0 y α +

j>0

with P Exy 0 Q, x0 ∈ C and |p0 (x0 )| = q0 ∈ R>0 , then
(a)

∂P
dQ
Eyx0 ±
,
∂y
dy

P

qj y α+j ∈ C((y)),

(b) P a Exy 0 Qaneg Ey (q0 y α )−b Qa+b
neg for a, b ∈ Q− ,

Qk Ey (q0 y α )2k Q−k
neg Ey







(q0 y α )k
if k ∈ Z≥1 ,
1 − kQigo


kQigo 

α k

if k ∈ Q≥0 with k < 1.
 (q0 y ) 1 +
1 − Qigo

(2.8)

(2.9)

(2.10)

where (2.9) (a) holds under the condition: either both P and Q are power series of y (in
this case the sign is “ + ”), or else both are polynomials on y −1 (in this case the sign is
“ − ”).
(2) If x0 , y0 ∈ C with y0 6= 0, and P1 Exy 0 Q1 , P2 Exy 0 Q2 , then
A(x0 ,y0 ) (P1 P2 ) ≤ A(y0 ) (Q1 )A(y0 ) (Q2 ) = Q1 (|y0 |)Q2 (|y0 |).

(2.11)

Proof. (2) and (2.9) (a) are obvious, (2.9) (b) and (2.10) are obtained by noting that for a, b ∈ Q−
and i ∈ Z>0 , one has
    


     ( i
k if k ∈ Z≥1 ,
a
a
a
+
b
a
+
b
k




 −k 
(−1)i
=
,
≤
≤
 = (−1)i
≤
i
i
i
i
i
i

k if 0 < k ∈ Q<1 .
Take

F̃ = f˜1 y +

∞
P
f˜i y i ∈ C(x)[[y]],

(2.12)

i=2

with f˜i ∈ C(x) and f˜1 6= 0. Regarding F̃ as a function on y (with fixed x), we have the formal

inverse function denoted by yF̃ ∈ C(x)[[F̃ ]] such that [cf. (2.4) ]
y = yF̃ (F̃ ) = b 1 F̃ +

∞
P

b i F̃ i ,

(2.13)

i=2

with b i = Coeff (y, F̃ i ) ∈ C(x) being determined by b 1 = f˜1−1 ∈ C(x) and
 


j
i−1
P ˜j−i P
P
j
ℓ
λn
b i = − b j f1
f˜1−λ1 −λ2 −···−λn f˜2λ1 f˜3λ2 · · · f˜n+1
, (2.14)
ℓ
λ
,
λ
,
...,
λ
1 2
n
j=1
ℓ=0
n∈Z≥0 , λ1 ,λ2 ,...,λn ≥0
λ1 +2λ2 +···+nλn = i−j

7

for i ≥ 2, which is obtained by comparing the coefficients of y i in (2.13).
Lemma 2.4. Let (with âi ∈ R≥0 , â1 > 0 ),
F̂ = â1 y +

∞
P

i=2

âi y i ∈ C[[y]] and F̂ neg = â1 y −

∞
P

âi y i ,

(2.15)

i=2

be a controlling function on y and its negative correspendence [cf. (2.7) ], and let
y = ŷneg (F̂ neg ) = b̂1 F̂ neg +

∞
P

i=2

i

(2.16)

b̂i F̂ neg ,
i

be the formal inverse function of F̂ neg , where b̂1 = â−1
1 and b̂i = Coeff (y, F̂ neg ) ∈ C. Then
(1) ŷneg (F̂ neg ) is a controlling function on F̂ neg , i.e.,
i

b̂i = Coeff (y, F̂ neg ) ≥ 0 for i ≥ 1.

(2.17)

(2) If F̃ Exy 0 F̂ with F̃ as in (2.12) and f˜i (x0 ) exists for all possible i and |f˜1 (x0 )| = â1 , then
y = yF̃ (F̃ ) ExF̃0 ŷneg (F̃ ), i.e.,

bi Ex0 b̂i ,

(2.18)

where bi = Coeff (y, F̃ i ) is as in (2.13), and bi Ex0 b̂i means that |bi (x0 )| ≤ b̂i . In particular
y Ey ŷneg (F̂ ),

(2.19)

where the right side of “ Ey ” is regarded as a function of y by substituting F̂ by (2.15).
Proof. Note that (1) follows from (2) by simply taking F̃ = â1 y. Thus we prove (2). We want
to prove
∂ i y x0 di y
for i ≥ 1,
Ey
∂ F̃ i
dF̂ ineg

(2.20)

where the left-hand side is understood as that we first use (2.13) to regard y as a function on F̃
(with parameter x) and apply

∂i
∂ F̃ i

to it, then regard the result as a function on y (and the like for

the right-hand side, which does not contain the parameter x). By (2.9), we have

∂ F̃
∂y

Exy 0

dF̂
dy

, and

thus
∂ F̃
∂y
i.e.,

∂y
∂ F̃

Exy 0

dy
dF̂ neg

!−1

Exy 0

 dF̂ 
dy

neg

!−1

=

dF̂ neg
dy

!−1

,

and (2.20) holds for i = 1. Inductively, by Lemma 2.3,
∂iy
∂ F̃ i

=

∂  ∂ i−1 y  ∂ F̃ −1
∂  ∂ i−1 y 
=
∂y ∂ F̃ i−1
∂y
∂ F̃ ∂ F̃ i−1

Exy 0

d  di−1 y  dF̂ neg −1
di y
.
=
dy dF̂ i−1
dy
dF̂ ineg
neg
8

(2.21)

This proves (2.20). Using (2.20) and noting from (2.13) and (2.16), we have
1 ∂ i y 
1 ∂ i y 
=


i! ∂ F̃ i F̃ =0 i! ∂ F̃ i y=0
.

i
1 di y 
x0 1 d y 
= b̂ i
=
E


i! dF̂ ineg y=0 i! dF̂ ineg F̂ neg =0

bi =

This proves (2.18). Since F̃ Exy 0 F̂ and ŷneg is a controlling function, we have ŷneg (F̃ ) Exy 0 ŷneg (F̂ ).
This together with (2.18) proves (2.19).



3. Proof of Theorem 1.3
First we use (1.13) to prove (1.14): By exchanging x and y if necessary, we may assume hp0 ,p1 =
|yt |, nt = |xt |. Then the only nontrivial case in (1.14) is the case when a = |yt |, b = |xt |. In this
case, we have
m


m+1
|a − b| = |yt | − |xt | ≤ |yt + xt | < hp0 ,p1
m+1
m+2

m+1

m

= |yt | m+1 < |xt | m+2 = nt

(3.1)

,

where the last inequality follows from the fact that by (1.13), we have (when |yt | = hp0 ,p1 ≥ s 0 is

sufficiently large)

m
m+1

m

m(m+2)

|xt | > |yt | − hp0 ,p1 = |yt | − |yt | m+1 > |yt | (m+1)2 .

(3.2)


To prove (1.13), assume conversely that there exists (p0i , p1i ) = (x0i , y0i ), (x1i , y1i ) ∈ V for any
i ∈ Z>0 satisfying

hp0i ,p1i ≥ i,

(3.3)

such that at least one of the following does not hold:
m
m+1

m
m+1

(i) |x0i + y0i | < hp0i ,p1i ,

(ii) |x1i + y1i | < hp0i ,p1i .

(3.4)

Thus we obtain a sequence (p0i , p1i ), i = 1, 2, ... Since at least one of the conditions in (3.4) cannot
hold for infinite many i’s. If necessary by replacing the sequence by a subsequence [if the sequence
(p0i , p1i ) is replaced by the subsequence (p0,ij , p1,ij ), then we always have ij ≥ j; thus (3.3) still
holds after the replacement], we may assume one of the conditions in (3.4) does not hold for all i.
If necessary by switching p0i and p1i , we can assume (3.4) (i) cannot hold for all i, i.e.,
m
m+1

|x0i + y0i | ≥ hp0i ,p1i → ∞ for all i ≫ 1.

(3.5)

We need to use the following notations:
a i ∼ bi , a i ≺ bi , a i  bi ,
means respectively
a 
 i
s 1 <   < s 2,
bi

a 
ai
 i
= 0,   ≤ s 1 ,
i→∞ bi
bi
lim

9

(3.6)

for some fixed s 1 , s 2 ∈ R>0 . By (1.5), we can write, for some fjk ∈ C,
F = FL + F1 with F1 =

m−1
P

y m−1−j

j=0

j
P

fjk xk .

(3.7)

k=0

Since |x0i |, |y0i | ≤ hp0i ,p1i , by (3.5) and (3.7), we have
m−1

F1 (p0i )  hp0i ,p1i ≺ (x0i + y0i )m = FL (p0i ),

(3.8)

m

and thus [we remark that although it is possible that (x0i + y0i )m ≺ hp0i ,p1i , it is very crucial that

we have (3.9) ]

F (p0i ) ∼ FL (p0i ) = (x0i + y0i )m .

m−1

(3.9)

Similarly, F1 (p1i )  hp0i ,p1i ≺ (x0i + y0i )m = FL (p0i ). We obtain the following important fact:
1=

F (p1i )
F (p1i )
= lim
= lim
F (p0i ) i→∞ F (p0i ) i→∞

F1 (p1i )
FL (p1i )
FL (p0i ) + FL (p0i )
F1 (p0i )
FL (p0i ) + 1

FL (p1i )
(x1i + y1i )m
= lim
.
i→∞ FL (p0i )
i→∞ (x0i + y0i )m

= lim

(3.10)

Therefore, by replacing the sequence by a subsequence, we have
x1i + y1i
= ω,
i→∞ x0i + y0i
lim

(3.11)

where ω is some m-th root of unity. Furthermore, when i ≫ 1, by (3.5) we have [cf. Convention
2.1 (3)]
m−1

E

:=

hp0i ,p1i
β0m

→ 0, where β0 := x0i + y0i .

(3.12)

Set
β1 :=

x1i + y1i
− 1 → ω − 1.
x0i + y0i

(3.13)

Remark 3.1. Before continuing, we would like to remark that our idea is to take some variable
change [cf. (3.17) ] to send the leading part FL of F to a “leading term” [cf. (3.20) ], which has the
highest absolute value when (x, y) is set to p0i or p1i [cf. (3.22) ] so that when we expand it as a
power series of y, it converges absolutely [cf. (3.25) ], and further, the inverse function converges
absolutely (cf. Lemma 3.3). Then we can derive a contradiction [cf. (3.44) ].
Proof of Theorem 1.3. Now we begin our proof of (1.13) in Theorem 1.3 as follows. Since either
x0i 6= x1i or y0i 6= y1i for all i, replacing the sequence by a subsequence and/or exchanging x and y
√
if necessary, we may assume y0i 6= y1i for all i. Set [where i = −1, cf. the statement after (3.21)
to see why we need to choose such a β2 ]
(
0 if ω 6= −1,
u1 = 1 + β1 x + β2 x(1 − x) ∈ C[x], where β2 =
(3.14)
i else.
We have
10

Lemma 3.2. There exists some δ > 0 independent of E such that
|u1 (a)| > δ for 0 ≤ a ≤ 1 (when i ≫ 1).

(3.15)

Proof. Fix δ1 ∈ R>0 to be sufficiently small.
• First assume ω = 1 (then β2 = 0). By (3.13), we can then assume |β1 | < δ1 . Then for
0 ≤ a ≤ 1, we have |u1 (a)| ≥ 1 − |β1 |a ≥ 1 − δ1 .

• Next assume ω = −1 (then β2 = i ). We can then assume |β1 im | < δ12 [cf. Convention
2.1 (1)] and 2 − δ12 ≤ |β1 re | ≤ 2 + δ12 by (3.13). For δ1 ≤ a ≤ 1 − δ1 , we have

|u1 (a)| ≥ |u1 (a)im | = |β1 im a + β2 im a(1 − a)| ≥ a(1 − a) − |β1 im |a ≥ δ1 (1 − δ1 ) − δ12 . (3.16)
If 0 ≤ a ≤ δ1 , we have |u1 (a)| ≥ |u1 (a)re | = |1 + β1 re x| ≥ 1 − (2 + δ12 )δ1 . If 1 − δ1 ≤ a ≤ 1,
then |u1 (a)| ≥ |u1 (a)re | = |1 + β1 re x| ≥ (2 − δ1 )(1 − δ1 ) − 1.
• Now assume ω 6= ±1 (then β2 = 0). We can then assume |β1 im | ≥ δ1 and |β1 | ≤ 2 + δ1 .
If 0 ≤ a ≤ δ1 , we have |u1 (a)| ≥ 1 − |β1 |δ1 ≥ 1 − (2 + δ1 )δ1 . If δ1 ≤ a ≤ 1, then
|u1 (a)| ≥ |u1 (a)im | = |β1 im |δ1 ≥ δ12 .

In any case we can choose δ > 0 such that (3.15) holds.



We set [cf. Remark 3.1, our purpose is to use the variable change (3.18) to send the leading part
FL of F to the element (3.20) which is a term (the “leading term”) with the lowest degree of y in
F̂ , cf. (3.21) ]
u = β0 u1 y −1 − v,

v = yi0 + β3 x,

F̂ = β0−m F (u, v),

−1
±1
Ĝ = β0m−1 β3−1 G(u, v) ∈ C[x, u−1
1 , y ] ⊂ C(x)[y ].

Then one can verify that J(u, v) = − ∂u
∂y
J(F̂ , Ĝ) = u1 y −2 ,

dv
dx

β3 = y1i − y0i ,

(3.17)
(3.18)

= β0 β3 u1 y −2 and



F̂ (q0 ), Ĝ(q0 ) = F̂ (q1 ), Ĝ(q1 ) , where q0 = (0, 1), q1 = (1, 1).

(3.19)

Note that the leading part FL of F contributes to F̂ the following element (which is the only term
in F̂ with the lowest y-degree −m, referred to as the leading term of F̂ ):
−m .
β0−m (u + v)m = um
1 y

(3.20)

Since all coefficients of x and y −1 in u or v have absolute values being  the height hp0i ,p1i

[cf. (3.17) ], due to the factor β0−m in F̂ [cf. (3.18) ], we see from (3.7) and (3.12) that other terms
of F (i.e., terms in F1 ) can only contribute O(E 1 ) elements to F̂ [cf. Convention 2.1 (3) for notation
O(E j )]. Thus we can write, for some fj = O(E 1 ) ∈ C[x, u−1
1 ] ⊂ C(x),


m
P
−m
j
1
+
.
y
F̂ = um
f
y
j
1

(3.21)

j=1

By (3.15), we see that fj (a) for 0 ≤ a ≤ 1 is well-defined for any j and fj (a) = O(E 1 ) [this is why

we need to choose some β2 to satisfy (3.15) ]. Set


	
s 1 = max |fj (a)|  1 ≤ j ≤ m, 0 ≤ a ≤ 1 = O(E 1 ).
11

(3.22)

Let 0 ≤ a ≤ 1. Take [here we choose an m-th root of um
1 to be u1 , this choice will not cause any
problem since we will only encounter integral powers of u1 below, cf. (2.2) ]
1

2
P := F̂ − m ∈ u−1
1 y + y C(x)[[y]],

F̂ = |u1 (a)|m y −m (1 + F̂− ), where F̂− = s 1
We have (cf. Definition 2.2)

(3.23)
m
P

y j = O(E 1 ).

(3.24)

j=1

1

P Eay P̂ := |u1 (a)|−1 y(1 − F̂− )− m .

F̂ Eay F̂ ,

(3.25)

Thus F̂ , P converges absolutely [by Lemma 2.3 (3)] when setting x = a and y = 1. Let
P0 := P |(x,y)=(0,1) = 1 + O(E 1 ),

(3.26)

where the last equality can be easily seen from (3.21) and (3.23) by noting that u1 (0) = 1. Write
[cf. (2.4) and (2.13); assume that Ĝ has the lowest y-degree −mG ]
y = u1 P +

∞
P

b i P i for some b i ∈ C(x),

(3.27)

i=2

Ĝ =

∞
P

i=−mG

ci P i for some ci ∈ C(x).

(3.28)

To continue the proof of Theorem 1.3, we need the following lemma. First, let 0 ≤ a ≤ 1.
Lemma 3.3.

(1) The series in (3.27) converges absolutely when setting (x, P ) to (a, P0 ), and
Y0 (a) := y|(x,P )=(a,P0 ) = u1 (a) + O(E 1 ).

(2) Regarding


∂ F̂ −1
∂y

(3.29)

as a series of P , it converges absolutely when setting (x, P ) to (a, P0 ).

Furthermore,

 ∂ F̂ −1 

= −m−1 u1 (a) + O(E 1 ).

∂y
(x,P )=(a,P0 )

(3.30)

(3) The series in (3.28) converges absolutely when setting (x, P ) to (a, P0 ).
Proof. (1) (cf. Remark 3.4) Note that the negative correspondence of P̂ is [cf. (2.7) ]
1

P̂ neg := 2|u1 (a)|−1 y − P̂ = 2|u1 (a)|−1 y − |u1 (a)|−1 y(1 − F− )− m .

(3.31)

Let yneg = yneg (P̂ neg ) be the inverse function of P̂ neg [cf. (2.16) ]. Then Lemma 2.4 shows that
y(P ) EaP yneg (P ).

(3.32)

Thus to see whether the series in (3.27) [which is the left-hand side of (3.32) ] converges absolutely
when setting (x, P ) to (a, P0 ), it suffices to see if the series yneg (P ) [which is the right-hand side
of (3.32) ] converges when setting P to |P0 |. The latter is equivalent to whether (3.31) has the

solution for y when P̂ neg is set to |P0 | (note that the solution, if exists, must be unique by noting
that a controlling function which is a nontrivial power series of y must be a strictly increasing
function). Note from (3.26) that
|P0 | = 1 + w for some w ∈ R such that −s 2 E ≤ w ≤ s 3 E ,
12

(3.33)

for some s 2 , s 3 . Consider the right-hand side of (3.31):
• if we set y to |u1 (a)| − s 4 E for some sufficiently large s 4 , then it obviously has some value
1 + w1 with w1 < −s 2 E ≤ w;
• if we set y to |u1 (a)| + s 5 E for some sufficiently large s 5 , then it has some value 1 + w2
with w2 > s 3 E ≥ w.
Since the right-hand side of (3.31) is a continuous function on y, this shows that there exists
(unique) y0 ∈ R>0 such that
P̂ neg |y=y0 = |P0 |,

and obviously, y0 = |u1 (a)| + O(E 1 ),

(3.34)

i.e., (3.31) has the solution y = y0 when P̂ neg is set to |P0 |, and thus the first part of (1) follows.

As for (3.29), note that Y0 (a) is the solution of y in the equation P0 = P |x=a . Using (3.29) in this
equation, we see it holds up to O(E 1 ).

(2) By Lemmas 2.3 and 2.4, using (3.23)–(3.25), we have
 ∂ F̂ −1
∂y

where Q− = s 1

Pm

j=1

Eay


y m+1
y m+1

E
,

P
m
m
m|u1 (a)| (1 − Q− )
m|u1 (a)| (1 − Q− ) y=yneg (P )

m−j j
m y

(3.35)

= O(E 1 ) [cf. (3.24) ]. The right-hand side of (3.35) (a controlling

function) converges obviously when setting P to |P0 | since by (3.34), we have yneg (|P0 |) = y0 =

|u1 (a)| + O(E 1 ) and so


0 ≤ Q− y=yneg (|P0 |) = O(E 1 ) < 1.

(3.36)

This proves the first statement of (2) [cf. (2.11) ]. As for the second statement, note that setting

(x, P ) to (a, P0 ) is equivalent to setting (x, y) to a, Y0 (a) . Then (3.30) follows from (3.21) and
(3.29).

(3) follows from (1) since Ĝ|x=a is a polynomial on y ±1 . This proves Lemma 3.3.



Remark 3.4. By (3.21),
F̂ = the leading term + O(E 1 ),

(3.37)

where O(E 1 ) is a finite combination of powers of y ±1 . In this case, we can in fact easily choose a
simpler controlling function P̂ for P [cf. (3.25) ]:
P̂ = |u1 (a)|−1 y

∞
P

E δ1 i y i

=

i=0

|u1 (a)|−1 y
,
1 − E δ1 y

(3.38)

where δ1 ∈ R>0 is some fixed sufficiently small number. Then

P̂ neg = |u(a)|−1 y 1 −

E δ1 y

1 − E δ1 y



=

|u(a)|−1 y(1 − 2E δ1 y)
,
1 − E δ1 y

(3.39)

and we can explicitly write down the inverse function of P̂ neg by solving y from (3.39) to obtain
yneg (P̂ neg ) [which, by Lemma 2.4 (1), must be a controlling function on P̂ neg (although it is not
13

obvious to see)]
yneg (P̂ neg ) =

1 + E δ1 |u(a)|P̂ neg − A
, where
4E δ1

(3.40)

1

2
2
A = 1 − 6E δ1 |u(a)|P̂ neg + E 2δ1 |u(a)|2 P̂ neg .

From this, one easily sees that the right-hand side of (3.32) converges when P is set to |P0 |, i.e.,

(3.40) converges when P̂ neg is set to |P0 | [if we expand A as a power series of P̂ neg , it converges

absolutely when P̂ neg is set to |P0 | simply because there appear the factors E δ1 and E 2δ1 ]. Thus
the proof of Lemma 3.3 (1) is easier (we have used the above proof as it can be adapted in some
more general situation).
Now we return to our proof of Theorem 1.3. By Lemma 3.3 (3), we are now safe to set (x, y) to
(0, 1) and (1, 1) [which is equivalent to setting (x, P ) to (0, P0 ) and (1, P0 ) respectively] in (3.28)
to obtain
0 = Ĝ(1, 1) − Ĝ(0, 1) =
Denote

∞
P

i=−mG


ci (1) − ci (0) P0i .

 ∂ F̂ −1
 ∂ F̂ −1
Q := −J(F̂ , Ĝ)
= −u1 y −2
,
∂y
∂y

(3.41)

(3.42)

where the last equality follows from (3.19). Take the Jacobian of F̂ with (3.28), by (3.19) and
(3.42), we obtain [by regarding Q as in C(x)((y))]
Q=

∞ dc
P
i i
P .
dx
i=−mG

(3.43)

By (3.42) and the proof of Lemma 3.3, we see that when P is set to P0 , the series in (3.43)
converges absolutely and in fact uniformly for x ∈ [0, 1] := {x ∈ R | 0 ≤ x ≤ 1}. This together
with (3.41) and (3.43) implies
Z 1
∞
∞
P
P
dci i
i
P0 dx
0=
(ci (1) − ci (0))P0 =
i=−mG
i=−mG 0 dx
=

Z

1
0

=m

∞ dc
P
i i
P0 dx =
dx
G
i=−m

−1

Z

1

Z

1
0


Q

dx =
P =P0

dx + O(E 1 ) = m−1 + O(E 1 ),

Z

1
0


Q y=Y0 (x) dx
(3.44)

0

which is a contradiction, where the sixth equality of (3.44) follows from (3.42), (3.29) and (3.30),

and the fifth follows by noting that QP =P0 means that we need to express Q as an element in

C(x)[[P ]] [i.e., use (3.27) to substitute y, that is exactly the equation (3.43) ] then set P to P0 ,
which is equivalent to directly setting y to Y0 (x) in Q [cf. (3.29) ]. The contradiction means that
if (3.3) holds, then we must have (3.4). The proof of Theorem 1.3 is now completed.

14

4. Proof of Theorem 1.4
Proof of Theorem 1.4. To prove the boundness of Ak0 ,k1 defined in (1.16), assume

(p0i , p1i ) = (x0i , y0i ), (x1i , y1i ) ∈ Ak0 ,k1 , i = 1, 2, ...,

(4.1)

is a sequence such that the height hp0i ,p1i → ∞. By definition, we have |x0i | = k0 , |x1i | = k1 . Thus
|y0i | = hp0i ,p1i or |y1i | = hp0i ,p1i , in any case, at least one inequation of (1.13) is violated. Hence

Ak0 ,k1 is bounded. To prove the closeness of Ak0 ,k1 , let (4.1) be a sequence converging to some

(p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ C4 . Then σ(p0 ) = σ(p1 ) and |x0 | = k0 , |x1 | = k1 . We must have
p0 6= p1 [otherwise, the local bijectivity of σ does not hold at the point p0 , cf. arguments after

(7.3) ], i.e., (p0 , p1 ) ∈ Ak0 ,k1 , and so Ak0 ,k1 is a closed set in C4 , namely, we have Theorem 1.4 (i).
From this, we see that γ k0 ,k1 in (1.17) is well-defined.

Now we prove Theorem 1.4 (iii). We will prove (1.18) (b) [the proof for (1.18) (a) is similar, but
simpler, cf. Remark 4.2]. First we claim that

γ 0,0 > 0.

(4.2)


To see this, by definition, there exists (0, ỹ0 ), (0, ỹ1 ) ∈ A0,0 for some ỹ0 , ỹ1 ∈ C with ỹ0 6= ỹ1 ,

thus also (0, ỹ1 ), (0, ỹ0 ) ∈ A0,0 . By definition, γ 0,0 ≥ max{|ỹ0 |, |ỹ1 |} > 0, i.e., we have (4.2).
Fix k0 > 0. For any given k1′ > 0, let

β = max{γ k0 ,k1 | k1 ≤ k1′ }



	
= max |y1 |  (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V, |x0 | = k0 , |x1 | ≤ k1′ .

(4.3)

Assume conversely that there exists k1 < k1′ with γ k0 ,k1 = β. We want to use the local bijectivity
of Keller maps to obtain a contradiction. Let E > 0 be a parameter such that E → 0 [cf. Convention
2.1 (3)]. Let

(p̃0 , p̃1 ) = (x̃0 , ỹ0 ), (x̃1 , ỹ1 ) ∈ V with |x̃0 | = k0 , |x̃1 | = k1 , |ỹ1 | = β.
(4.4)
Set (and define G0 , G1 similarly)

F0 = F (x̃0 + x, ỹ0 + y),

F1 = F (x̃1 + x, ỹ1 + y).

(4.5)

Denote
ã0 = Coeff (F0 , x1 y 0 ),

b̃0 = Coeff (F0 , x0 y 1 ),

ã = Coeff (F1 , x1 y 0 ),

b̃ = Coeff (F1 , x0 y 1 ).

We use c̃0 , d˜0 , c̃, d˜ to denote the corresponding elements for G0 , G1 . Then A0 = (ã0

c̃0
), A
b̃0 d˜0

(4.6)
= (b̃ã dc̃˜)

are invertible 2 × 2 matrices such that det A0 = det A = J(F, G) = 1. For the purpose of proving

Theorem 1.4 (iii), we can replace (F, G) by (F, G)A−1
0 , then A0 becomes A0 = I2 (the 2 × 2 identity

matrix), and AA−1
0 becomes the new A, which is in fact the following matrix,
!
!
Fx (p̃1 )Gy (p̃0 ) − Gx (p̃1 )Fy (p̃0 ) Gx (p̃1 )Fx (p̃0 ) − Fx (p̃1 )Gx (p̃0 )
ã c̃
=
,
A=
b̃ d˜
Fy (p̃1 )Gy (p̃0 ) − Gy (p̃1 )Fy (p̃0 ) Gy (p̃1 )Fx (p̃0 ) − Fy (p̃1 )Gx (p̃0 )
where the subscript “ x ” (resp., “ y ”) stands for the partial derivative

∂
∂x

(resp.,

∂
∂y ),

(4.7)

and F, G are

original F, G [i.e., before replaced by (F, G)A−1
0 ]. From this, for later use, we obtain the following:
15

There exist s 1 ∈ R>0 (depending on degrees and coefficients of F, G) such that for any (p̃1 , p̃2 ) ∈ V ,
we have
˜ ≤ hs 1 , (ii) either |ã| ≥ h−s 1 or |b̃| ≥ h−s 1 ,
(4.8)
(i) |ã|, |b̃|, |c̃|, |d|
p̃0 ,p̃1

p̃0 ,p̃1

p̃0 ,p̃1

where (ii) follows from (i) and the fact that ãc̃ − b̃d˜ = 1. We can write (here “ ≡ ” means equal
modulo terms with degrees ≥ 3 by defining deg x = deg y = 1)
F0 ≡ αF + x + a1 x2 + a2 xy + a3 y 2 ,

F1 ≡ αF + ãx + b̃y + a4 x2 + a5 xy + a6 y 2 ,

G0 ≡ αG + y + a7 x2 + a8 xy + a9 y 2 ,

˜ + a10 x2 + a11 xy + a12 y 2 ,
G1 ≡ αG + c̃x + dy

(4.9)
(4.10)

for some ai ∈ C, where αF = F (x̃0 , ỹ0 ), αG = G(x̃0 , ỹ0 ). For any s, t, u, v ∈ C, denote
q0 := (ẋ0 , ẏ0 ) = (x̃0 + sE , ỹ0 + tE ), q1 := (ẋ1 , ẏ1 ) = (x̃1 + uE , ỹ1 + v E ).

(4.11)

The local bijectivity of Keller maps says that for any u, v ∈ C (cf. Remark 4.1), there exist s, t ∈ C
such that (q0 , q1 ) ∈ V .
Remark 4.1. When we consider the local bijectivity of Keller maps, we always assume u, v ∈ C
are bounded by some fixed s ∈ R>0 (which is independent of E , and we can assume E as small as
s

we wish, for instance E < s −s ).

In fact we can use (4.9) and (4.10) to solve s, t up to E 2 ; for instance,
s = s0 + O(E 2 ),

s0 = ãu + b̃v + (α1 u2 + α2 uv + α3 v 2 )E ,

(4.12)

for some αi ∈ C. We want to choose suitable u, v such that
(I) |ẋ0 | = |x̃0 + sE | = |x̃0 | ( = k0 > 0 ) ,

(II) |ẏ1 | = |ỹ1 + v E | > |ỹ1 | ( = β ) .

(4.13)

If ã 6= 0 in (4.12), then we can easily first choose v to satisfy (II), then choose u to satisfy (I)

[cf. (4.12); we can also regard s as a free variable and solve u = ã−1 (s − b̃v) + O(E 1 ) from (4.12),
and then using the fact that x0 6= 0 we can solve s from (4.13) (I) as in (4.19) below]. Since
|x1 | = k1 < k1′ , we also have |ẋ1 | < k1′ [since E → 0, cf. (4.11) ]. This means that we can choose
(q0 , q1 ) ∈ V with |ẋ0 | = k0 , |ẋ1 | < k1′ , but |ẏ1 | > β, which is a contradiction with the definition of
β in (4.3). Now assume ã = 0 (and so b̃ 6= 0, c̃ 6= 0). In this case the situation is more complicated.

Remark 4.2. Before continuing, we remark that the proof of (1.18) (a) is easier: in that case
condition (4.13) (I) should be replaced by the condition |x̃1 + uE | = |x̃1 |, which can be easily
satisfied even in case k1 = 0 (i.e., x̃1 = 0). Thus (1.18) (a) holds.
Now we continue our proof. Since |x̃0 | = k0 > 0, and |ỹ1 | = β ≥ γ k0 ,0 > γ 0,0 > 0 [where the

first inequality follows from the definition of β in (4.3), the second from (1.18) (a), and the last
from (4.2) ], we can rewrite (4.13) as [cf. (4.12) ]
(I)′ |1 + ŝE | = 1, (II)′ |1 + v̂ E | > 1, where v̂ = ỹ1−1 v, ŝ = x̃−1
0 s,

(4.14)

and regard v̂ as a new variable. Set [see also arguments after (5.7) ],
−1
−1
−1
F̂0 = x̃0 F0 (x̃−1
0 x, y), Ĝ0 = G0 (x̃0 x, y), F̂1 = x̃0 F1 (x, ỹ1 y), Ĝ1 = G1 (x, ỹ1 y),
16

(4.15)

and rewrite [cf. (4.9) and (4.10); by subtracting Fi , Gi by some constants we may assume αF =
αG = 0; we now use b, c, d, which are different from b̃, c̃, d˜ in (4.9) and (4.10), to denote the
coefficients of linear parts of F̂1 , Ĝ1 ]




P
P
P
P
bi z i + by 1 +
b̄i z i + · · · ,
ai y i + x 1 +
āi y i + · · · , F̂1 =
F̂0 =
i≥2

Ĝ0 = y +

i≥2

i≥2

P

i≥2

ci y i + · · · ,

(4.16)

i≥2

Ĝ1 = z +

P

i≥2

di z i + · · · ,

where z = cx + dy,

(4.17)

for some ai , āi , bi , b̄i , ci , di ∈ C, and where we regard F̂1 , Ĝ1 as polynomials on y, z and we omit

terms with x-degree ≥ 2 in F̂0 (or ≥ 1 in Ĝ0 , and the likes for F̂1 , Ĝ1 ), which will be irrelevant to
our computations below. In this case, by (4.16), we have
ŝ = bv̂ + O(E 1 ).

(4.18)

If bim 6= 0 [cf. Convention 2.1 (1)], we can always choose suitable v̂ ∈ C with v̂re > 0 such that
both (I)′ and (II)′ in (4.14) hold. Alteratively, we can also regard ŝ as a free variable [and solve
v̂ = b−1 ŝ + O(E 1 ) from (4.18) ] and determine ŝ by solving ŝre from (4.14) (I)′ to obtain
1

ŝre =

−1 + (1 − ŝ2im E 2 ) 2
ŝ2 E
= − im + O(E 3 ),
2
2

(4.19)

then choose ŝim [with (b−1 ŝ)re > 0] to satisfy (4.14) (II)′ .
Now assume b ∈ R6=0 . We claim
(ai , ci ) 6= (bi , di ) for at least one i ≥ 2,

(4.20)

otherwise we would in particular obtain (and the like for G)


−1
−1


F (x̃0 , ỹ0 + k ) = x̃−1
0 F̂0 (x,y)=(0,k ) = x̃0 F̂1 (x,y)=(k c−1 ,0) = F (x̃1 + k c , ỹ1 ), i.e.,
σ(p̄0 ) = σ(p̄1 ),

(4.21)
(4.22)

with p̄0 = (x̄0 , ȳ0 ) = (x̃0 , ỹ0 + k ), p̄1 = (x̄1 , ȳ1 ) = (x̃1 + k c−1 , ỹ1 ) for all k ≫ 1 [cf. Convention
m
m+1

2.1 (3)]. Then hp̄0 ,p̄1 ∼ k [when k ≫ 1, cf. (3.6) ], and |x̄0 + ȳ0 | ∼ k ≻ hp̄

0 ,p̄1

, a contradiction with

(1.13). Thus (4.20) holds. Then, if necessary by replacing Ĝi by Ĝi + F̂i2 for i = 0, 1 (which does
not change the linear parts of F̂0 , F̂1 , Ĝ0 , Ĝ1 ), we may assume
ci0 6= di0 for some minimal i0 ≥ 2.
By replacing F̂j by F̂j +
can then suppose

P2i0

i
i=2 βi Ĝj

(4.23)

for some βi ∈ C and j = 0, 1, thanks to the term y in Ĝ0 , we
ai = 0 for 2 ≤ i ≤ 2i0 .

(4.24)

Now we need to consider two cases.
Case 1: Assume bk 6= 0 for some k ≤ 2i0 . Take minimal such k ≥ 2. Setting [the second equation
amounts to setting z = wE in (4.17) ],
v̂ = v̌ E k−1 , u = c−1 w − c−1 d v̌ E k−1 ,
17

(4.25)

and regarding v̌, w as new variables, we can then solve from (4.16) and (4.17) [cf. (4.12), (4.14)
and (4.18); observe that all omitted terms and all coefficients āi ’s, b̄i ’s do not contribute to our
solution of ŝ up to E k ] to obtain, for some nonzero b′ ∈ C,
ŝ = (bv̌ + b′ wk )E k−1 + O(E k ).

(4.26)

Using this and the first equation of (4.25) in (4.14), one can then easily see that (4.13) have
solutions [by taking, for example, v̌ > 0 so that (II)′ holds and then choosing w to satisfy (I)′ ].
Case 2: Assume bi = 0 for 0 ≤ i ≤ 2i0 . By computing the coefficients


Coeff J(F0 , G0 ), x0 y i = 0 = Coeff J(F1 , G1 ), x0 y i , i ≥ 1,

(4.27)

and induction on i for 1 ≤ i < i0 , one can easily obtain that āi = b̄i for i < i0 and āi0 6= b̄i0 by
(4.23) and (4.24). In this case, by setting [the first equation below means that v̌ E contributes a
positive O(E 2i0 ) element to the left-hand side of (4.14) (II)′ since it does not have a real part, in
particular (II)′ holds],
v̂ = v1 i E i0 −1 for v1 ∈ R6=0 ,

u = c−1 w − c−1 dv1 i E i0 −1 ,

(4.28)

we can then solve from (4.16) and (4.17) to obtain, for some nonzero b′′ ∈ C (all omitted terms do
not contribute to our solution of ŝ up to E 2i0 ),

ŝE = bv1 i E i0 + b′′ v1 i wi0 E 2i0 + O(E 2i0 +1 ).

(4.29)

Since b ∈ R6=0 , we see that (4.29) can only contribute an O(E 2i0 ) element to (4.14) (I)′ . Using

(4.29) and the first equation of (4.28) in (4.14), one can again see that (4.13) have solutions by
choosing suitable w. This proves Theorem 1.4.


5. Proof of Theorem 1.5 (1)
To prove Theorem 1.5 (1), let us make the following assumption [cf. Remark 1.6 (3)].
Assumption 5.1. Assume Theorem 1.5 (1) is not true.
Under this assumption, we have
Lemma 5.2. For any δ, k, k0 , k1 ∈ R>0 with k > 1, δ <

1
m,

we have γ k1+δ k0 ,kk1 < kγ k0 ,k1 .

Proof. Assume the result is not true, then by choosing δ′ with δ < δ′ <

1
m

and by Theorem 1.4 (iii),

we may assume γ k̄1+δ′ k0 ,k̄k1 > k̄γ k0 ,k1 for some k̄, k0 , k1 ∈ R>0 with k̄ > 1. Thus we can choose a

sufficiently small δ1 ∈ R>0 satisfying (the following holds when δ1 = 0 thus also hold when δ1 > 0
is sufficiently small)
k11+δ1γ k̄1+δ′ k0 ,k̄k1
(k̄k1 )1+δ1
18

> γ k0 ,k1 .

(5.1)


Take k ≫ 1. We define V0 to be the subset of V consisting of elements (p0 , p1 ) = (x0 , y0 ), (x1 , y1 )
satisfying [our aim is to design the following to satisfy Theorem 1.5 (1) ]
(a) k1 ≤ |x1 | ≤
(b)

k1
1
1+δ ′

k0

1

(1 − k −3 )|x0 | 1+δ′ + k1 (k −1 − k −2 + k −3 ) ≤ (1 − k −2 )|x1 | + k1 k −1 ,

γ k̄1+δ′ k0,k̄k1
|y1 |
.
≥
|x1 |1+δ1
(k̄k1 )1+δ1

(5.2)

Then we can rewrite the above as the form in (1.19), obviously we have (1.22) [note from the
second and last inequalities of (5.2) (a) that |x1 | ≤ k1 k ]. Further, by definition, there exists

′
(5.3)
(p̌0 , p̌1 ) = (x̌0 , y̌0 ), (x̌1 , y̌1 ) ∈ V with |x̌0 | = k̄1+δ k0 , |x̌1 | = k̄k1 , |y̌1 | = γ k̄1+δ′ k0 ,k̄k1 .
Then one can easily see that (p̌0 , p̌1 ) ∈ V0 , i.e., V0 6= ∅.

Let (p0 , p1 ) ∈ V0 . If the first two equalities, or the first and last equalities, hold in (5.2) (a), then
we obtain that |x1 | = k1 , |x0 | ≤ k0 , but by (5.1) and (5.2) (b), |y1 | > γ k0 ,k1 , a contradiction with

the definition of γ k0 ,k1 and/or Theorem 1.4 (iii).

′

If the last two equalities hold in (5.2) (a), then one obtains that |x1 | ∼ k , |x0 | ∼ k 1+δ [when
k ≫ 1, cf. (3.6); see Remark 5.3 ]. Note that (1.14) in particular implies that either hp0 ,p1 ∼
′

|x0 | ∼ |y0 | or hp0 ,p1 ∼ |x1 | ∼ |y1 |, in any case we obtain that hp0 ,p1  k 1+δ . By (5.2) (b), we

have |y1 |  |x1 |1+δ1 ∼ k 1+δ1 , and so (where the part “ ≻ ” follows by noting from δ′ <
|y1 |  k 1+δ1 ≻ k  k

(1+δ ′ )m
m+1

1
m

that

)

|x1 + y1 | ≥ |y1 | − |x1 | ∼ |y1 | ≻ k

(1+δ ′ )m
m+1

m
m+1

 hp0 ,p1 ,

(5.4)

a contradiction with (1.13). This shows that Theorem 1.5 (1) holds, a contradiction with Assumption 5.1. The lemma is proven.

Remark 5.3. Note that when we design the system (5.2), k is simply some fixed positive real
number. When we say k ≫ 1, it means that we may need to choose sufficiently large k such that
the system (5.2) can satisfy our requirement. This will also apply to some similar situations later.
Lemma 5.4. For any k0 , k1 ∈ R>0 , we have γ k0 ,k1 > k1 .
Proof. Assume the result is not true, then by choosing k0′ ∈ R>0 with k0′ < k0 , we may assume

γ k0′ ,k1 < k1 for some k0′ , k1 > 0.
Denote α =

γk′ ,k
0

k1

1

(5.5)

< 1. By (5.5) and Lemma 5.2, we have γ k k′ ,k k1 < kγ k′ ,k1 = k k1 α for all k ≫ 1.
0

0

Let (p0 , p1 ) ∈ V with |x0 | = k k0′ , |x1 | = k k1 , |y1 | = γ k k′ ,k k1 ≤ k k1 α. Then as in the proof of the
0

previous lemma, we have hp0 ,p1 ∼ k when k ≫ 1, but then

m
m+1

|x1 + y1 | ≥ |x1 | − |y1 | ≥ (1 − α)k k1 > hp0 ,p1 ,
which is a contradiction with (1.13). This proves Lemma 5.4.
19

(5.6)


Let k ≫ 1. We take


(p̄0 , p̄1 ) = (x̄0 , ȳ0 ), (x̄1 , ȳ1 ) ∈ Ak ,k with |x̄0 | = |x̄1 | = k , |ȳ1 | = γ k ,k > k ,

(5.7)

where the inequalities follow from Lemma 5.4. Similar to (4.5) (but not exactly), we define


(5.8)
F0 = F x̄0 (1 + x), ȳ0 + y , F1 = F x̄1 (1 + x), ȳ1 (1 + y) ,

and define G0 , G1 similarly [thus the matrices A0 , A defined after (4.6) now have determinant
det A0 = x̄0 J(F, G) 6= 0, det A = x̄1 ȳ1 J(F, G) 6= 0, and again by replacing (Fi , Gi ) by (Fi , Gi )A−1
0
for i = 0, 1, we can assume A0 = I2 ]. Define q0 , q1 accordingly [similar to, but a slightly different
from, (4.11), simply due to the different definitions in (5.8) and (4.5); note that E may depend on
k : in general the larger k is, the smaller E ; but any in case once k is chosen we can always choose
sufficiently small E , cf. also Remark 4.1],


q0 := (ẋ0 , ẏ0 ) = x̄0 (1 + sE ), ȳ0 + tE , q1 := (ẋ1 , ẏ1 ) = x̄1 (1 + uE ), ȳ1 (1 + v E ) .
(5.9)
In particular, we have (4.9), (4.10), and as in (4.12),

s = −ak u + bk v + O(E 1 ),

(5.10)

where we have written the coefficients of u, v as −ak , bk to emphasis that they may depend on k
and that they are in fact positive as shown in the next lemma. First to avoid confusion we remark
that if we still use ã, b̃ to denote the elements defined in (4.7) [with (p̃0 , p̃1 ) replaced by (p̄0 , p̄1 )],
then −ak , bk in (5.10) are not ã, b̃ simply because of the different definition of (5.8) from (4.5); in
fact, we have the following relations:
ak = −x̄−1
0 ãx̄1 ,

bk = x̄−1
0 b̃ȳ1 .

(5.11)

Therefore, by (4.8) there exists some fixed s 0 ∈ R>0 such that
|ak |, |bk | ≤ k s 0 .

(5.12)

Lemma 5.5. We have ak > 0, bk > 0.
Proof. First assume ak im 6= 0 or ak re < 0 or bk im 6= 0 or bk re < 0 [cf. Convention 2.1 (1)]. Then
from (5.10) one can easily choose u, v [with uim 6= 0, ure < 0, vim 6= 0, vre > 0 such that either
(ak u)re > 0 or (bk v)re < 0, and so sre < 0] satisfying [cf. (5.9) and (5.10) ]
0 < k0 := |ẋ0 | = k |1 + sE | < k , 0 < k1 := |ẋ1 | = k |1 + uE | < k ,
|ẏ1 | = γ k ,k |1 + v E | > γ k ,k ,

(5.13)

i.e., 0 < k0 < k , 0 < k1 < k with γ k0 ,k1 ≥ |ẏ1 | > γ k ,k , a contradiction with Theorem 1.4 (iii).

Thus ak ≥ 0, bk ≥ 0. If ak = 0, similar to arguments after (4.14) [see also arguments after (7.7) ],
we have two possible cases [cf. (4.25), (4.26) and (4.28), (4.29) ]:
v = v̂ E k−1 ,

u = c−1 w − c−1 d v̂ E k−1 ,

s = (bk v̂ + b′ wk )E k−1 + O(E k ),

v = v1 i E i0 −1 , u = c−1 w − c−1 dv1 i E i0 −1 , sE = bk v1 i E i0 + b′′ v1 i wi0 E 2i0 + O(E 2i0 +1 ),

(5.14)
(5.15)

where v̂, w ∈ C, v1 ∈ R6=0 , b′ , b′′ ∈ C6=0 , k, i0 ∈ Z≥2 . Assume we have the case (5.14) [the case

(5.15) is similar], we can first choose v̂ with v̂re > 0 so that the last inequation of (5.13) holds, then
choose w with (c−1 w)re < −1 (sufficiently smaller than −1) and (b′ wk )re < 0 (sufficiently smaller
20

than −1, such w can be always chosen since k ≥ 2) such that the first two inequations of (5.13)
hold. Thus (5.13) holds, and as before we obtain a contradiction. Therefore ak > 0. Similarly
bk > 0. The lemma is proven.

Lemma 5.6. For any ﬁxed δ ∈ R>0 , we have k < γ k,k < (1 + δ4 )k.
m

m
m+1

Proof. Otherwise we would then obtain that |x̄1 + ȳ1 | ≥ |ȳ1 | − |x̄1 | ≥ δ4 k ≻ k m+1 ∼ hp̄

0 ,p̄1

k ≫ 1), a contradiction with (1.13).

(when


Lemma 5.7. For any ﬁxed δ ∈ R>0 with δ <

1
m,

we have bk ≥ 1 + δ + ak for all k > 0.

Proof. Assume the lemma does not hold, then we can choose sufficiently small δ1 > 0 (which can
depend on k ) such that
(1 + δ1 )bk < 1 + δ − δ1 + ak .

(5.16)

Let ℓ ≫ k (we can assume E < ℓ−ℓ , cf. Remark 4.1). We define V0 to be the subset of V consisting

of elements (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) satisfying [again our purpose is to design the following to
satisfy Theorem 1.5 (1) ]

δ

1

(i) k ≤ |x1 | ≤ (1 − ℓ−3 )k 1+δ |x0 | 1+δ + k (ℓ−1 − ℓ−2 + ℓ−3 ) ≤ (1 − ℓ−2 )|x1 | + k ℓ−1 ,
(ii)

γ k ,k
|y1 |
≥
(1 + E 2 ).
1+δ
|x1 | 1
k 1+δ1

(5.17)

Then we have (1.19) and (1.22) [using the second and last inequalities of (5.17) (i)].
Remark 5.8. Recall from statements inside the bracket before (5.9) and Remark 4.1 that when
k is fixed, E can be fixed, and we can assume E < k −k . We here emphasis that the E used in the
above design of the system of inequations in (5.27) is exactly the same as that used in the local
bijectivity of Keller maps in (5.9). There is no any problem in doing this since our design does not
need to use the local bijectivity of Keller maps, we only use the local bijectivity of Keller maps
to show that the set V0 is nonempty [in the sense of defining the system (5.17), ℓ, k , E are simply
some chosen positive real numbers, cf. Remark 5.3 ].
For any (p0 , p1 ) ∈ V0 , if the first two equalities, or the first and last equalities, hold in (5.17) (i),
then |x1 | = k , |x0 | ≤ k , but by (5.17) (ii), |y1 | > γ k ,k , a contradiction with the definition of γ 1,1

and/or Theorem 1.4 (iii).

If the last two equalities hold in (5.17) (i), then we can obtain |x1 | ∼ ℓ (when ℓ ≫ k and k is

regarded as fixed; cf. Remarks 5.3 and 5.8 ), |x0 |  ℓ1+δ , but by (5.17) (ii), |y1 |  ℓ1+δ1 ≻ |x1 |.
Again by (1.14), we must have either hp0 ,p1 ∼ |x0 | ∼ |y0 | or hp0 ,p1 ∼ |x1 | ∼ |y1 |, in any case we
m
m+1

1

have hp0 ,p1  ℓ1+δ < ℓ1+ m . But then |x1 + y1 | ≥ |y1 | − |x1 | ∼ |y1 | ≻ hp0 ,p1 , a contradiction with
(1.13). Hence Theorem 1.5 (1) (ii) holds.

21

Next, we want to choose suitable u, v such that (5.17) holds for (q0 , q1 ) [defined in (5.9) ], i.e.,
1

(i) 1 ≤ |1 + uE | ≤ (1 − ℓ−3 )|1 + sE | 1+δ + ℓ−1 − ℓ−2 + ℓ−3 ≤ (1 − ℓ−2 )|1 + uE | + ℓ−1 ,
(ii)

|1 + v E |
≥ 1 + E 2.
|1 + uE |1+δ1

(5.18)

The second strict inequality automatically holds in (5.18) (i) (we can assume E < ℓ−ℓ , cf. Remark
4.1). If we take
u = 1,

v=

ak + 1 + δ − δ1
, and so s = 1 + δ − δ1 + O(E 1 ) by (5.10),
bk

(5.19)

by comparing the coefficients of E 1 , we see that all strict inequalities hold in (5.18) (i). Further,
the coefficient of E 1 in the left hand-side of (5.18) (ii) is

ak +1+δ−δ1
bk

− (1 + δ1 ) > 0 by (5.16). We

see that (q0 , q1 ) ∈ V0 , i.e., V0 6= ∅, a contradiction with Assumption 5.1, We have Lemma 5.7.



Lemma 5.9. For any ﬁxed δ ∈ R>0 , we have (1 − δ5 )bk ≤ 1 + ak for all k ≫ 1.
Proof. Let k ≫ 1 and we assume E < k −k (cf. Remark 4.1). Define V0 to be the subset of V

consisting of elements (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) satisfying [again our purpose is to design the
following to satisfy Theorem 1.5 (1); cf. Remarks 5.3 and 5.8 ]

(i) (1 − δ5 )k ≤ |x1 | ≤ (1 − k −3 )|x0 | + k −2 ≤ (1 − k −2 )|x1 | + k −1 ,
(ii)

γ k ,k
|y1 |
≥
(1 + E 2 ).
5
k
|x1 |1−δ

(5.20)

We have (1.19) and (1.22). For any (p0 , p1 ) ∈ V0 , if the first two equalities, or the first and last

equalities, hold in (5.20) (i), then we can obtain |x1 | = (1 − δ5 )k , |x0 | ≤ k , and by (5.20) (ii), we
have


5
|y1 | > (1 − δ5 )1−δ γ k ,k ≥ 1 − δ5 + δ10 + O(δ15 ) k > |x1 |.
(5.21)
m

m
m+1

As before, we would obtain that |x1 + y1 | ≥ |y1 | − |x1 | ∼ |y1 | ∼ k ≻ k m+1 ∼ hp0 ,p1 (when k ≫ 1,

cf. Remarks 5.3 and 5.8 ), a contradiction with with (1.13).

If the last two equalities hold in (5.20) (i), then |x1 | = |x0 | = k , but by (5.20) (ii), |y1 | > γ k ,k , a

contradiction with definition (1.17). Hence Theorem 1.5 (1) (ii) holds.

Next, we want to choose suitable u, v such that (5.17) holds for (q0 , q1 ) [defined in (5.9) ], i.e.,
(i) 1 − δ5 ≤ |1 + uE | ≤ (1 − k −3 )|1 + sE | + k −3 ≤ (1 − k −2 )|1 + uE | + k −2 ,
(ii)

|1 + v E |
≥ 1 + E 2.
|1 + uE |1−δ5

(5.22)

The first strict inequality automatically holds in (5.22) (i). If we take
u = −1,

v=−

1 + ak
,
bk

and so s = −1 + O(E 1 ) by (5.10),
22

(5.23)

by comparing the coefficients of E 1 , we see that all strict inequalities hold in (5.22) (i). Further,
the coefficient of E 1 in the left hand-side of (5.22) (ii) is 1 − δ5 −

1+ak
bk

, which is positive if the

assertion of the lemma is not true; in this case, we see that (q0 , q1 ) ∈ V0 , i.e., V0 6= ∅, and we
obtain a contradiction with Assumption 5.1, namely, we have Lemma 5.9.

The above two lemmas show that ak ≥

1−δ4 (1+δ)
.
δ4

Since δ is arbitrarily sufficiently small number,

we see that ak (thus also bk ) is unbounded, i.e.,
lim ak = lim bk = ∞, and in fact, lim

k →∞

k →∞

k →∞

ak
= 1.
bk

(5.24)

Remark 5.10.
(i) We wish to emphasis that the following design (5.27) has been the hardest
part for us to obtain [from the proof below we will see why we have to design such a
complicated system of inequations in (5.27) ].
(ii) From our proof above, one can see that in order to achieve our task, we must choose the
power (denoted as α0 ) of |x1 | in (5.2) (b), (5.17) (ii) and (5.20) (ii) to be different from
one, and in case α0 < 1 we must choose α0 to be independent of k as in (5.20) (ii), and
therefore we have to choose v to be different from u [as in (5.19) and (5.23) ] so that
(5.18) (ii) and (5.22) (ii) can hold. However because of (5.24), our task becomes extremely
difficult, simply because of the fact that any choice of v 6= u (and in case α0 < 1, v, u
must be negative), with v to be differ from u by a number which is independent of k , will
possibly force s = −ak u + bk v + O(E 1 ) to be too large [by (5.24) ]; thus we have to try in
some other way as shown below.
(iii) We wish to mention that in C5 of (5.27) (iii), we add the term E 4 in order for the technical
reason that the inequation corresponding to (1.23) is solvable [cf. (6.15) (i) ].
Let as before k ≫ 1 and δ be sufficiently small (and assume E ≪ k −k , cf. Remark 4.1 ). Denote

[note from Lemmas 5.7, 5.9 and (5.24) that v0 > 0 and we can assume 0 < v0 < δN for any fixed
N ∈ R>0 ; we define the following in order to have (5.35) ],
v0 :=

bk − a k − 1
= O(δN ).
bk

(5.25)

For convenience, we simply denote [cf. (5.7) for notations x̄i , ȳ1 ],
Y1 = ȳ1−1 y1 , Xi = x̄−1
i xi , i = 0, 1.

(5.26)

Define V0 to be the subset of V consisting of elements (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) satisfying [again
our purpose is to design the following to satisfy Theorem 1.5 (1); cf. Remarks 5.3 and 5.8 ]
1

−v05

1

5

(i) 1 ≤ C1 := |X03 X1 Y1 | 5−v0
≤ C3 :=

+v
|X03 X1 Y1 | 5−v0 0

(ii) E ≤ |X1 | ≤ E

−1

,

1

≤ C2 := |X0 X13 Y12 | 6−2v0
1
 1  10
v
0
where ℓ =
,
v0

≤ C4 := ℓ,

3
+v05

 |X 3 X Y 2 | 6−2v
0
4
1 0 1
+
E
≥ 1 + v05 E .
(iii) C5 := |X1 |
|X0 |5

2

Obviously we can rewrite (5.27) as the form in (1.20).
23

(5.27)

Remark 5.11. We emphasis once again (cf. Remarks 5.3 and 5.8 ) that there is no problem to
use the k , E in our design of the system (5.27). In the sense of defining the system (5.27), k , E are
only some chosen numbers (however in order for the system to satisfy our requirement, we may
need to choose these numbers to satisfy the condition E −1 ≫ k ≫ 1 ).
Lemma 5.12. When conditions (5.27) hold we have the following [in particular we have (1.22) ].
(a) E ≤ |X1 | ≤ E −1 , (b) E ≤ |X0 | ≤ E −1 , (c) (1−δ5 )|X1 | ≤ |Y1 | ≤ (1+δ5 )|X1 |.

(5.28)

Proof. Equ. (5.28) (a) is simply (5.27) (ii). If |X0 | < E , using that fact that 1 ≤ C1 ≤ C4 and

Equ. (5.28) (a), we see that |Y1 |  E −2 ≻ |X0 | when E −1 ≫ k [cf. Remark 5.11 ]. Thus by (1.13),
(1.14) and notation (5.26), we must have hp0 ,p1 ∼ |x1 | ∼ |y1 | ≫ E −1 , a contradiction with (5.28) (a).
Similarly, if |X0 | > E −1 , then |Y1 |  E 2 . By (5.27) (iii), we have
9

7

1

1

|X0 | 2 ≤ |X1 | 2 +O(v0 ) |Y1 |1+O(v0 ) ,
13

(5.29)

1

thus |X1 |  E − 7 +O(v0 ) ≫ E −1 , again a contradiction with (5.28) (a). Thus we have (5.28) (b). We
claim
max{|X1 |, |Y1 |} ≥ δ.
(5.30)
Otherwise, by the fact that 1 ≤ C2 , we obtain that |X0 | > δ−5 , a contradiction with (5.29). Thus
we have (5.30), which together with (5.29) [and notation (5.26) ] shows that k  max{|x1 |, |y1 |}
when k ≫ 1 [cf. Remark 5.11 ], and |x0 |  max{|x1 |1+δ , |y1 |1+δ } [cf. (5.25) ]. Thus (1.13), (1.14)

and notation (5.26) imply that we must have hp0 ,p1  |x1 |1+δ and |x1 | ∼ |y1 |, from this we obtain
(5.28) (c) as in the proof of Lemma 5.6.



Lemma 5.13. Theorem 1.5 (1) holds.
Proof. For any (p0 , p1 ) ∈ V0 , if the first equality holds, or the second and third equalities hold, in

(5.27) (i), i.e., C1 = C2 = C3 = 1. Then |X03 X1 Y1 | = |X13 X0 Y12 | = 1 and so |X1 |2 = |X0 |5 , but by
(5.27) (iii), we have |X0 |5 < |X1 |2 , a contradiction.

Assume the last equality holds in (5.27) (i). Then
5

5

(5.31)
|X03 X1 Y1 | = ℓ5−v0 +O(v0 ) , |X13 X0 Y12 | = ℓ6−2v0 +O(v0 ) .


5
By (5.28) (c), we can write |X1 | = |Y1 | 1 + O(δ5 ) . Then |X03 Y12 | 1 + O(δ5 ) = ℓ5−v0 +O(v0 ) ,

5
|X0 Y15 | 1 + O(δ5 ) = ℓ6−2v0 +O(v0 ) , i.e.,


5v0
v0
5
5
|X0 | = ℓ1− 13 +O(v0 ) 1 + O(δ5 ) , |Y1 | = ℓ1− 13 +O(v0 ) 1 + O(δ5 ) .

Thus, |X1 | = ℓ1−

5v0
+O(v05 )
13

2ℓ

C5 = |X1 |

(5.32)


5
1 + O(δ5 ) . Then up to E 4 , we have (by noting that C2 = ℓ1+O(v0 ) ),

3+O(v05 )

|X0 |5

= ℓ−

5v0
+O(v05 )
13


1 + O(δ5 ) ≪ 1 [since ℓ =

1
v0

1
 v10
0

],

(5.33)

a contradiction.
If the first equality holds in (5.27) (ii), i.e., |X1 | = E , then |Y1 | ∼ E when E −1 ≫ k by (5.28) (c).

Then |X0 | ∼ E −5 by the fact that 1 ≤ C2 ≤ C4 , but then C1 ∼ E −13 ≫ C4 , a contradiction.
24

Similarly, if the last equality holds in (5.27) (ii), i.e., |X1 | = E −1 , then |Y1 | ∼ E −1 , |X0 | ∼ E 5 , and
C1 ∼ E 13 ≪ 1, again a contradiction. Hence Theorem 1.5 (1) (ii) holds.

Next, we want to choose suitable u, v such that (5.27) holds for (q0 , q1 ) [defined in (5.9) ], namely,
1

−v05

1

+v05

(i) 1 ≤ C1 := |(1 + sE )3 (1 + uE )(1 + v E )| 5−v0
≤ C3 := |(1 + sE )3 (1 + uE )(1 + v E )| 5−v0
2

(iii) C5 := |1 + uE |

1

≤ C2 := |(1 + sE )(1 + uE )2 (1 + v E )2 | 6−2v0
≤ C4 := ℓ,

3
+v05
 |(1 + uE )3 (1 + sE )(1 + v E )2 | 6−2v
0

|1 + sE |5

(ii) E ≤ |1 + uE | ≤ E −1 ,


+ E 4 ≥ 1 + v05 E .

(5.34)

Note that (5.34) (ii) and the last strict inequality of (5.34) (i) automatically hold. Take
u = 1, v = 1 − v0 , and so, s = 1 + O(E 1 ) by (5.10) and (5.25).

(5.35)

Then the coefficients of E 1 in C1 , C2 and C3 are respectively
c1 := 1 − (5 − v0 )v05 ,

c2 := 1,

c3 := 1 + (5 − v0 )v05 ,

(5.36)

i.e., we have all strict inequalities in (5.34) (i). Further, the coefficient of E 1 in C5 is (6 − 2v0 )v05 >

v05 , i.e., (5.34) (ii) holds. Hence (q0 , q1 ) ∈ V0 , i.e., V0 6= ∅, and we obtain a contradiction with
Assumption 5.1. This shows that Assumption 5.1 must be wrong, namely, we have the lemma. 
6. Proof of Theorem 1.5 (2)


Proof of Theorem 1.5 (2). Now we prove Theorem 1.5 (2). Let (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V0 ,

i.e., (1.19) or (1.20) [cf. (5.27) ] holds. Note that (1.19)–(1.22) imply that x0 , x1 , y1 6= 0. Similar
to (4.5) and (5.8), we define


F0 = F x0 (1 + x), y0 + y , F1 = F x1 (1 + x), y1 (1 + y) ,
(6.1)

and define G0 , G1 similarly. Define q0 , q1 accordingly [similar to (4.11) and (5.9) ],


q0 := (ẋ0 , ẏ0 ) = x0 (1 + sE ), y0 + tE , q1 := (ẋ1 , ẏ1 ) = x1 (1 + uE ), y1 (1 + v E ) .

(6.2)

As in (4.12) and (5.10), we have, for some αi ∈ C,
s = s0 + O(E 2 ),

s0 = au + bv + (α1 u2 + α2 uv + α3 v 2 )E .

(6.3)

Remark 6.1. We remark that the E here shall be regarded to be different from that in the
previous results, here E may be much smaller than the previous E . If we denote the previous E as
E

−1

whenever necessary we can assume our new E satisfies that E < k −k , ℓ−ℓ , E 11 , where k , ℓ are
as before (cf. Remark 4.1).

E 1,

Now we consider two cases.
Case 1: Assume we have (1.19). If no equality (resp., the first equality) holds in (1.19) (a), we
only need to consider (1.24) (b) [resp., (1.24) (b) and the first inequality of (1.24) (a)], which can
be easily done. Thus by Theorem 1.5 (1) (ii), we may assume that the last equality of (1.19) (a)
holds [the proof for the case with the second equality of (1.19) (a) is exactly similar], i.e.,
κ1 |x0 |κ2 + κ3 = κ4 |x1 | + κ5 .
25

(6.4)

then we need to choose u, v so that (q0 , q1 ) satisfies (1.24) (b) and the last inequality of (1.24) (a),
namely
(i) C1 := |1 + v E | · |1 + uE |−κ6 − 1 > 0,
(ii) C2 := −|1 + sE |κ2 + κ′4 |1 + uE | + κ′5 ≥ 0,

(6.5)

where
κ′4 =

κ5 − κ3
κ4 |x1 |
> 0, κ′5 =
> 0 by (1.21), thus κ′4 + κ′5 − 1 = 0 by (6.4).
κ1 |x0 |κ2
|x0 |κ2

(6.6)

Set, for any fixed w ∈ C with wre > 0,
1
v = κ6 u + κ6 (κ6 − 1)u2 E + wE ,
2

(6.7)

then one can easily see that C1 = |1 + wE 2 | − 1 + O(E 3 ) = wre E 2 + O(E 3 ) > 0, i.e., (6.5) (i) holds.
Using (6.7) in (6.3), we obtain, for some α̃i ∈ C,
s = α̃0 u + (α̃1 u2 + α̃2 w)E + O(E 2 ) .

(6.8)

Using (6.7) and (6.8) in (6.5) (ii), we can then rewrite C2 as [by writing (1 + sE )κ2 = 1 + κ2 sE +
κ2 (κ2 −1) 2 2
s E
2

+ O(E 3 ) ]


C2 = −1 + α̃3 uE + (α̃4 u2 + α̃5 w)E 2  + κ′4 |1 + uE | + κ′5 + O(E 3 ) ≥ 0,

(6.9)

for some α̃i ∈ C. By comparing the coefficients of E 1 in (6.9), we immediately obtain that if

α̃3 6= κ′4 , then we can choose u [with (κ′4 − α̃3 )u re > 0 ] to satisfy (6.9).

Assume α̃3 = κ′4 . Then we see that C2 in (6.9) is an O(E 2 ) element. In this case, since we do not
know what are values of α̃4 , our strategy is to compute the following coefficient [cf. Convention
2.1 (1) (2) for notations “ re ’, “ im ” and Coeff ; also note that u2re = (ure )2 ],
β̃ = β̃1 + β̃2 with β̃1 = Coeff (C2 , u2re E 2 ) and β̃2 = Coeff (C2 , u2im E 2 ).

(6.10)

Observe that α̃4 does not contribute to β̃ by noting the following

(α̃4 u2 E 2 )re = α̃4 re (u2re − u2im ) + 2α̃4 im ure uim E 2 ,

(6.11)

and that the imaginary part of α̃4 u2 E 2 can only contribute an O(E 4 ) element to C2 in (6.9). Thus
for the purpose of computing β̃, we may assume α̃4 = α̃5 = 0 (then the computation becomes
much easier). Since α̃3 = κ′4 is real, it is straightforward to compute that
1
1
β̃ = (κ′4 − α̃23 ) = κ′4 (1 − κ′4 ) > 0,
2
2

(6.12)

by (6.9) and (6.6) [remark: the fact that β̃ is positive is very crucial for the inequation (6.9) being
solvable for any unknown α̃i ∈ C in (6.9), cf. Remark 6.2]. By (6.10) and (6.12), either β̃1 > 0
or β̃2 > 0, and we can then choose u with sufficiently large ure > 0 or respectively uim > 0 to
guarantee that (6.5) (ii) [i.e., (6.9) ] holds (when w is fixed). This completes the proof of Theorem
1.5 (2) for the case (1.19).
26

Case 2: Assume we have (1.20). By Theorem 1.5 (1) (ii), assume that we have the third equality
of (1.20) (a) [the arguments for the proof of the case with the second equality of (1.20) (a) is exactly
similar], namely,
κ′4 − 1 = 0,

where κ′4 =

κ4 |x30 x1 y1 |κ5
.
κ3 |x0 x31 y12 |

(6.13)

Then by writing [using (6.3) and (6.13) ]



 
κ4 |x30 x1 y1 |κ5 

= 1 + (3κ5 − 1)a + κ5 − 3 u + (3κ5 − 1)b + κ5 − 2 v E + · · · ,
3
2
κ3 |x0 x1 y1 |

(6.14)

we only need to find suitable u, v to satisfy, for some α̃i ∈ C [cf. (6.3) ],


(i) C1′ := 1 + (α̃3 u + α̃4 v)E + (α̃5 u2 + α̃6 uv + α̃7 v 2 )E 2  − 1 + O(E 3 ) ≥ 0

(ii) C2′ := 1 + (α̃8 u + α̃9 v)E + (α̃10 u2 + α̃11 uv + α̃12 v 2 )E 2 | + κ′11

− (1 + κ′11 )|1 − 2uE + 3u2 E 2  + O(E 3 ) > 0,

(6.15)

for some α̃i ∈ C, where κ′11 = κ11 |x31 y12 |−κ9 |x0 |κ10 , and (6.15) (ii) is obtained by rewriting (1.23) as

3 2 κ
|ẋ31 ẏ12 |κ9
−2 > 0. One can easily compute
2 |x1 y1 | 9 + κ
11 |ẋ1 |
|ẋ0 |κ10 + κ11 − |x0 |
|x0 |κ10
α̃4 = (3κ5 − 1)b + κ5 − 2,

α̃9 = 2κ9 − κ10 b.

(6.16)

First assume α̃4 6= 0 [cf. (6.15) (i) ]. Then we can set, for some α̃13 , w ∈ C with wre > 0 [cf. (6.3) ],


2 + w)E ,
v = α̃−1
−
α̃
u
+
(α̃
u
(6.17)
3
13
4

so that C1′ can become C1′ = |1 + wE 2 | − 1 + O(E 3 ) = wre E 2 + O(E 3 ) > 0, i.e., (6.15) (i) holds. Then
using (6.17), we can rewrite C2′ as (for some α̃i ∈ C)



C2′ = |1 + α̃14 uE + (α̃15 u2 + α̃16 w)E 2 | + κ′11 − (1 + κ′11 )1 − 2uE + 3u2 E 2  + O(E 3 ).

(6.18)

Observe the following.

• If c0 := α̃14 + 2(1 + κ′11 ) 6= 0, one can immediately choose u ∈ C with (c0 u)re > 0 to

guarantee that C2′ = (c0 u)re E + O(E 2 ) > 0.
• If c0 = 0 (then α̃14 is a real number), then as in Case 1 [cf. (6.10) ], we need to compute
β̃ = β̃1 + β̃2 with β̃1 = Coeff (C2′ , u2re E 2 ) and β̃2 = Coeff (C2′ , u2im E 2 ), and it is easy to obtain

that β̃ = 2κ′11 (1 + κ′11 ) > 0 (thus the fact that κ11 > 0 is very crucial in our proof). Then
we can choose u ∈ C with u2re > 0 in case β̃1 > 0 (or u2im > 0 in case β̃2 > 0) to be

sufficiently large to guarantee that C2′ > 0.

κ5 −2
Now assume α̃4 = 0, i.e., b = − 3κ
. We claim that α̃9 6= 0. To see this, using notations in
5 −1

(5.27), we in fact have [thus b =
κ5 =

4
13

+ O(v01 ) ]

6 − 2v0
6
+ O(v05 ) = + O(v01 ),
5 − v0
5

κ10 = 5 −

κ9 =

9
3
+ O(v05 ) = + O(v01 ).
6 − 2v0
2
27

3
1
+ O(v05 ) = + O(v01 ),
6 − 2v0
2
(6.19)

5
Thus α̃9 = 2κ9 − κ10 b = − 13
+ O(v01 ) 6= 0 [note that in case the second equality of (1.20) (a) holds

we still have no problem since κ2 = κ5 + O(v05 ) by (5.27) ]. We simply set u = 0. Then we have
the following.
• If C1′ is independent of v, then C1′ = 0, i.e., (6.15) (i) automatically holds, and we can easily
choose v ∈ C with (α̃9 v)re > 0 so that C2′ = (α̃9 v)re E + O(E 2 ) > 0, i.e., (6.15) (ii) holds.

• Otherwise, C1′ = |1 + b′ v k E k | − 1 + O(E k+1 ) for some b′ ∈ C6=0 and k ∈ Z≥2 , and we can

always choose v ∈ C with (b′ v k )re > 0 and (α̃9 v)re > 0 (such v always exists simply because
k ≥ 2) to guarantee that both of (6.15) hold.

This proves Theorem 1.5.



Remark 6.2. (cf. Remark 1.6) Assume that we have the following inequation on variable u, where
α1 , α2 , β1 , β2 ∈ R>0 , and a1 , a2 , a3 ∈ C are some unknown complex numbers:
α1 |1 + a1 uE + a2 u2 E 2 + a3 E 2 |β1 < α2 |1 + uE |β2 + α1 − α2 + O(E 3 ).

(6.20)

Then from the proof of (6.5), one can see that this inequation is solvable for any unknown
a1 , a2 , a3 ∈ C if and only if α1 > α2 [the reason that (6.15) (i) is solvable is that we have designed
(6.15) (i) to be compatible with (6.15) (ii) ].

7. Proofs of Theorems 1.1 and 1.2
Proof of Theorem 1.2. To prove Theorem 1.2 (i), we use Theorem 1.5. Denote [cf. (1.19), (1.20) ]
L = {ℓp0 ,p1 | (p0 , p1 ) ∈ V0 },

ℓ = sup L ∈ R>0 ∪ {+∞} (the supremum of L).

(7.1)


By definition, there exists a sequence (p0i , p1i ) := (x0i , y0i ), (x1i , y1i ) ∈ V0 , i = 1, 2, ..., i.e.,

p0i 6= p1i and [assume we have case (1.19) as the proof the case (1.20) is exactly similar],
σ(p0i ) = σ(p1i ), κ0 ≤ |x1i | ≤ κ1 |x0i |κ2 + κ3 ≤ κ4 |x1i | + κ5 , ℓi :=

|y1i |
≥ κ7 ,
|x1i |κ6

(7.2)

such that limi→∞ ℓi = ℓ (cf. Remark 1.6 ). By (1.22), |x0i |, |x1i | are bounded. By (1.13), we
see that |y0i |, |y1i | are also bounded [as in the proof of Theorem 1.4 (i) ]. Thus by replacing the
sequence by a subsequence, we may assume

lim (p0i , p1i ) = (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ C4 .

i→∞

(7.3)

First suppose p0 = p1 . Then by (7.3), for any neighborhood Op0 of p0 , there exists N0 such that

p0i , p1i ∈ Op0 when i > N0 , but p0i 6= p1i , σ(p0i ) = σ(p1i ), which is a contradiction with the

local bijectivity of Keller maps. Thus p0 6= p1 . By taking the limit i → ∞, we see that (1.22)
is satisfied by x0 , x1 , y1 (in particular x1 6= 0) and all conditions in (1.19) hold for (p0 , p1 ). Thus

(p0 , p1 ) ∈ V0 . Therefore by Theorem 1.5 (2), there exists (q0 , q1 ) = (ẋ0 , ẏ0 ), (ẋ1 , ẏ1 ) ∈ V0 such

that ℓq0 ,q1 > ℓp0 ,p1 = ℓ, a contradiction with (7.1). This proves that (1.15) is not true, i.e., we have
Theorem 1.2 (i).
28


To prove Theorem 1.2 (ii), as in (4.4) and (5.8), take (p0 , p1 ) = (x0 , y0 ), (x1 , y1 ) ∈ V and set

(and define G0 , G1 similarly)

F0 = F (x0 + α0 x, y0 + y),
α0 =

(

1

F1 = F (x1 + α1 x, y1 + y),

if x0 = ξ0 ,

α1 =

x0 − ξ0 else,

(

1

where

if x1 = ξ1 ,

(7.4)
(7.5)

x1 − ξ1 else.

Define q0 , q1 accordingly [cf. (4.11) and (5.9) ]. Then we have as in (4.12) and (6.3),
s = au + bv + O(E 1 ).

(7.6)

Note from Theorem 1.2 (i) that (x0 , x1 ) 6= (ξ0 , ξ1 ).

First suppose x0 6= ξ0 , x1 6= ξ1 (then α0 = x0 − ξ0 , α1 = x1 − ξ1 ). In this case, we need to choose
u, v such that,
C0 := β0 |1 + sE |2 + β1 |1 + uE |2 − (β0 + β1 ) < 0,

(7.7)

where β0 = |x0 − ξ0 |2 , β1 = |x1 − ξ1 |2 . Using (7.6) in (7.7), we immediately see (by comparing the

coefficients of E 1 ) that if b 6= 0 or a 6= −β0 β1−1 , then we have a solution for (7.7). Thus assume
b = 0, a = −β1 β0−1 [then d 6= 0 in (4.10) and a is real]. In this case, using arguments after (4.13),
we have the similar versions of either (4.25) and (4.26), or else (4.28) and (4.29), i.e.,
u = ûE k−1 ,

v = d−1 w − d−1 cûE k−1 ,

s = (aû + b′ wk )E k−1 + O(E k ),

u = u1 i E i0 −1 ,

v = d−1 w − d−1 cu1 i E i0 −1 ,

sE = au1 i E i0 + b′′ u1 i wi0 E 2i0 + O(E 2i0 +1 ),

or else

(7.8)
(7.9)

for some b′ , b′′ , u, w ∈ C6=0 , u1 ∈ R6=0 , k, i0 ∈ Z>0 , one can again find a solution for the inequation

(7.7).

Now if x0 = ξ0 (thus x1 6= ξ1 ), then the first term of C0 becomes |sE |2 = O(E 2 ) and we can
easily choose any u with ure < 0 to satisfy that C0 < 0. Similarly, if x1 = ξ1 (thus x0 6= ξ0 ), then

the second term of C0 becomes |uE |2 = O(E 2 ) and we can easily choose u with (au)re < 0 (in case
a 6= 0) or v with (bv)re < 0 (in case b 6= 0) to satisfy that C0 < 0. This proves Theorem 1.2.

Proof of Theorem 1.1. Finally we are able to prove Theorem 1.1. The second assertion of Theorem
1.1 follows from [8, 23]. To prove the first statement, assume conversely that there exists a Jacobian

pair (F, G) ∈ C[x, y]2 satisfying (1.5) such that (1.3) holds. Then we have Theorem 1.2. Similar to
the proof of Theorem 1.2, denote D = {d p0 ,p1 | (p0 , p1 ) ∈ V } [cf. (1.9) ], and set d = inf D ∈ R≥0

(the infimum of D). By definition, there exists a sequence (p0i , p1i ) := (x0i , y0i ), (x1i , y1i ) ∈ V ,

i = 1, 2, ..., such that limi→∞ d p0i ,p1i = d . Then {x0i , x1i | i = 1, 2, ...} is bounded by (1.9). Thus

{y0i , y1i | i = 1, 2, ...} is also bounded by (1.13). By replacing the sequence by a subsequence, we
can then assume (7.3). Now arguments after (7.3) show that (p0 , p1 ) ∈ V , but (x0 , x1 ) 6= (ξ0 , ξ1 )
by Theorem 1.2 (i), i.e., d > 0. Then by Theorem 1.2 (ii), we can then obtain a contradiction with
the definition of d . This proves Theorem 1.1.

References

[1] A. Abdesselam, The Jacobian conjecture as a problem of perturbative quantum field theory,
Ann. Henri Poincaré 4 (2003), 199–215.
29

[2] S. Abhyankar, Some thoughts on the Jacobian conjecture. I., J. Algebra 319 (2008), 493–548.
[3] H. Appelgate, H. Onishi, The Jacobian conjecture in two variables, J. Pure Appl. Algebra 37 (1985),
215–227.
[4] P.K. Adjamagbo, A. van den Essen, A proof of the equivalence of the Dixmier, Jacobian and Poisson
conjectures, Acta Math. Vietnam. 32 (2007), 205–214.
[5] H. Bass, The Jacobian conjecture, Algebra and its Applications (New Delhi, 1981), 1–8, Lecture Notes
in Pure and Appl. Math. 91, Dekker, New York, 1984.
[6] H. Bass, E.H. Connell, D. Wright, The Jacobian conjecture: reduction of degree and formal expansion
of the inverse, Bull. Amer. Math. Soc. 7 (1982), 287–330.
[7] A. Belov-Kanel, M. Kontsevich, The Jacobian Conjecture is stably equivalent to the Dixmier Conjecture, Mosc. Math. J. 7 (2007), 209–218.
[8] A. Bialynicki-Birula, M. Rosenlicht, Injective morphisms of real algebraic varieties, Proc. Amer.
Math. Soc. 13 (1962), 200–203.
[9] Z. Charzyński, J. Chadzyński, P. Skibiński, A contribution to Keller’s Jacobian conjecture. IV.
Bull. Soc. Sci. Lett. Lódź 39 (1989), no. 11, 6 pp.
[10] M. Chamberland, G. Meisters, A mountain pass to the Jacobian conjecture, Canad. Math. Bull. 41
(1998), 442–451.
[11] J. Dixmier, Sur les algebres de Weyl, Bull. Soc. Math. France 96 (1968), 209–242.
[12] L.M. Drużkowski, The Jacobian conjecture: survey of some results, Topics in Complex Analysis
(Warsaw, 1992), 163–171, Banach Center Publ., 31, Polish Acad. Sci., Warsaw, 1995.
[13] M. de Bondt, A. van den Essen, A reduction of the Jacobian conjecture to the symmetric case,
Proc. Amer. Math. Soc. 133 (2005), 2201–2205.
[14] G.P. Egorychev, V.A. Stepanenko, The combinatorial identity on the Jacobian conjecture, Acta
Appl. Math. 85 (2005), 111–120.
[15] E. Hamann, Algebraic observations on the Jacobian conjecture, J. Algebra 265 (2003), 539–561.
[16] Z. Jelonek, The Jacobian conjecture and the extensions of polynomial embeddings, Math. Ann. 294
(1992), 289–293.
[17] S. Kaliman, On the Jacobian conjecture, Proc. Amer. Math. Soc. 117 (1993), 45–51.
[18] T. Kambayashi, M. Miyanishi, On two recent views of the Jacobian conjecture, Aﬃne Algebraic
Geometry, 113–138, Contemp. Math. 369, Amer. Math. Soc., Providence, RI, 2005.
[19] M. Kirezci, The Jacobian conjecture. I, II. İstanbul Tek. Üniv. Bül. 43 (1990), 421–436, 451–457.
[20] L. Makar-Limanov, U. Turusbekova, U. Umirbaev, Automorphisms and derivations of free Poisson
algebras in two variables, J. Algebra 322 (2009), 3318–3330.
[21] T.T. Moh, On the Jacobian conjecture and the configurations of roots, J. Reine Angew. Math. 340
(1983), 140–212.
[22] M. Nagata, Some remarks on the two-dimensional Jacobian conjecture, Chinese J. Math. 17 (1989),
1–7.
[23] D.J. Newman, One-one polynomial maps, Proc. Amer. Math. Soc. 11 (1960), 867–870.
[24] A. Nowicki, On the Jacobian conjecture in two variables. J. Pure Appl. Algebra 50 (1988), 195–207.
[25] K. Rusek, A geometric approach to Keller’s Jacobian conjecture, Math. Ann. 264 (1983), 315–320.
[26] S. Smale, Mathematical problems for the next century, Math. Intelligencer 20 (1998), 7-15.
[27] M.H. Shih, J.W. Wu, On a discrete version of the Jacobian conjecture of dynamical systems, Nonlinear
Anal. 34 (1998), 779–789.
[28] V. Shpilrain, J.T. Yu, Polynomial retracts and the Jacobian conjecture, Trans. Amer. Math. Soc. 352
(2000), 477–484.
30

[29] Y. Su, Poisson algebras, Weyl algebras and Jacobi pairs, arXiv:1107.1115v9.
[30] Y. Su, X. Xu, Central simple Poisson algebras, Science in China A 47 (2004), 245–263.
[31] A. van den Essen, Polynomial automorphisms and the Jacobian conjecture, Progress in Mathematics
190, Birkhäuser Verlag, Basel, 2000.
[32] A. van den Essen, The sixtieth anniversary of the Jacobian conjecture: a new approach, Polynomial
automorphisms and related topics, Ann. Polon. Math. 76 (2001), 77–87.
[33] D. Wright, The Jacobian conjecture: ideal membership questions and recent advances, Aﬃne Algebraic Geometry, 261–276, Contemp. Math. 369, Amer. Math. Soc., Providence, RI, 2005.
[34] J.T. Yu, Remarks on the Jacobian conjecture, J. Algebra 188 (1997), 90–96.

31

