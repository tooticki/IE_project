arXiv:1611.06303v3 [math.HO] 20 Sep 2017

Hilbert’s Proof
of His Irreducibility Theorem
Mark B. Villarino, William Gasarch, and Kenneth W. Regan
September 25, 2018
Abstract
Hilbert’s irreducibility theorem is a cornerstone that joins areas of analysis and number theory. Both
the genesis and genius of its proof involved combining real analysis and combinatorics. We try to expose
the motivations that led Hilbert to this synthesis. His famous cube lemma anchored the proof but without
the analytical foundation and framework it would have had no purpose. We also assess this lemma as a
precursor of Ramsey theory.

1

Introduction.

In 1892, David Hilbert published what is known today as Hilbert’s irreducibility theorem. We give his
statement, using integral polynomial to mean a polynomial in any number of variables whose coefficients are
integers.
Theorem 1. If F (x, y, . . . , w; t, r, . . . , q) is an irreducible polynomial with integral coefficients in the variables
x, y, . . . , w and the parameters t, r, . . . , q, then it is always possible, and indeed in infinitely many ways, to
substitute integers for the parameters t, r, . . . , q such that the polynomial F (x, y, . . . , w; t, r, . . . , q) becomes an
irreducible polynomial in the variables x, y, . . . , w alone.
The statement of Theorem 1 is a direct translation from [14]. It falls short of modern precision. For
example, the irreducibility of F concerns the polynomial in the whole set of variables—parameters included—
but the statement is technically false if there are no variables but only parameters. Nor is it clear whether
one needs a lot of variables and parameters or whether proving the theorem for one or two of each suffices;
this is clarified below. One of our purposes is to lead readers to appreciate modern rigor and clarity compared
to 19th century standards.
To Hilbert, this theorem was not an end in itself but rather a tool to use for some remarkable applications.
A simple one is that if a polynomial f (x) over Z has values that are perfect squares for all sufficiently large
x, then f (x) must be the square of some other polynomial over Z. One of his most striking results was the
following.
Corollary 2. For every integer n > 1 there exist infinitely many polynomials p in Z[x] of degree n such that
p has the symmetric group Sn as its Galois group.
He began his paper [14] with a statement and proof of the two-variable case, which is the fundamental
step in the proof of the general theorem. Again in Hilbert’s own words, the statement is:
Theorem 3. If f (x, t) is an irreducible polynomial in the two variables x and t with integral coefficients
f (x, t) = T xn + T1 xn−1 + · · · + Tn ,

(1)

where T, T1 , . . . , Tn are integral polynomials in t, it is always possible, indeed in infinitely many ways, to
substitute an integer for t in f (x, t) such that the polynomial f (x, t) becomes an irreducible polynomial of the
single variable x.

This statement also has several issues. In just eight words of the last sentence, “t” is first a variable symbol,
then part of the name “f (x, t)” for f , and last a constant substituted into f (x, t). It is hard to avoid
the juggling of different meanings that Hilbert expected of his readers, but we will use “t0 ” and “t1 ” to
distinguish constants. Often t0 is a threshold and t1 > t0 . Second, the simpler statement does not clarify
what happens when there is no dependence on the variable x. The set Z[x] of polynomials f in one variable
x having coefficients in Z includes the constant polynomials f (x) = 0, f (x) = 1, f (x) = −1, and so on.
Likewise, f (x, t) = t2 + t + 2 counts as a member of Z[x, t]. It satisfies the hypotheses because it is irreducible
and because the choices T = T1 = · · · = Tn−1 = 0 and Tn = t2 + t + 2 count as “integral polynomials in t.”
But the conclusion is false because for every integer t1 , the constant t21 + t1 + 2 is an even number, so the
constant polynomial f ′ (x) = f (x, t1 ) = t21 + t1 + 2 is reducible as a member of Z[x].1
We will see at the start of Section 5 how the proof needs f (x, t1 ) to have at least one (complex) root for
all but finitely many t1 . For this it suffices that the two-variable polynomial f (x, t) is not independent of x,
so that x has degree at least 1. The crispest modern way we know to say this is “f ∈ Z[x, t] \ Z[t],” where \
means difference of sets. This yields the following statement.
Theorem 4. Let f (x, y) ∈ Z[x, y] \ Z[y]. For an infinite number of t1 ∈ Z, f (x, t1 ), as an element of Z[x],
is irreducible.
In fact, Hilbert proved the contrapositive, which can be formulated as follows.
Theorem 5. Let f (x, y) ∈ Z[x, y] \ Z[y]. If there exists t0 such that for every integer t1 ≥ t0 , f (x, t1 ) is
reducible in Z[x], then f (x, y) is reducible in Z[x, y].
Hilbert proved Theorem 5 by formulating what is today called Hilbert’s cube lemma. It can be viewed not
only as an enhanced form of Dirichlet’s pigeonhole principle but also as the first statement of a Ramsey-type
theorem.
In Section 2 we discuss Ramsey theory to illustrate why Hilbert’s cube lemma is regarded as belonging
to that field. In Section 3 we state and give a simple modern proof of the Hilbert’s cube lemma and describe
optimizations (we discuss Hilbert’s original proof in Section 13). It is easy to appraise the Hilbert cube
lemma as a gem in an isolated setting and forget the quest that led to it, which was was to find a polynomial
factor, ϕ(x, t) ∈ Z[x, t], of the polynomial f (x, t).
In Sections 4 through 11 we provide a motivated account of Hilbert’s beautiful proof of (ir)reducibility
by putting ourselves in his shoes and following the trail of ideas that we find in his 1892 paper. We have
tried to make it as self-contained and elementary as possible.
After Hilbert, many mathematicians offered other proofs of the irreducibility theorem. Many of these
proofs use so-called “density” arguments, a standard technique in today’s Diophantine approximation theory,
but a far cry from the natural idea of Hilbert to find a factor of a reducible polynomial. We will say more
about modern proofs in Section 12.
Hilbert remains one of the greatest mathematicians of all time. His original proof still contains insights
and arguments that are well worth study even today. We offer the reader a detailed exposition of this proof
in hope of saving it from the oblivion of history.

2

Ramsey Theory.

Theorems in Ramsey theory almost always follow this informally-stated pattern:
For any coloring of a large enough object
there is a nice monochromatic sub-object.
1 If this objection seems trivializing, consider instead the polynomial g(t) = t2 + 1, which is likewise irreducible. Whether
g(t) takes on infinitely many prime values is one of four problems presented by Edmund Landau to the 1912 International
Congress of Mathematicians—all still unsolved—and it must have been outside the boundary of what Hilbert’s words were
meant to embrace in 1892. Thus Hilbert’s theorem borders on matters of lasting depth.

2

We give three examples of such theorems along with some of the history. See [10, 16, 21] for more on
these theorems and also Alexander Soifer’s book [27] for more of the history.
In 1916, Issai Schur [24] proved the following statement. A c-coloring of a set S is formally a map from
S to {1, 2, . . . , c}.
Lemma 6. For all c there exists S = S(c) such that for all c-colorings of {1, . . . , S} there exists a monochromatic triple x, y, z such that x + y = z.
Schur viewed his lemma as a means to an end and so did not launch what is now called Ramsey theory.
He used it to prove the following theorem in number theory.
Theorem 7. Let n ≥ 1. There exists q such that, for all primes p ≥ q, there exists x, y, z ∈ {1, . . . , p − 1}
such that xn + y n ≡ z n (mod p).
Proof. Given n let q = S(n). Let p be a prime such that p ≥ S(n). Then Z∗p , which denotes the numbers
{1, . . . , p−1} together with the operation of multiplication modulo p, forms a group. All arithmetic henceforth
is in Z∗p .
p−1
Let H = {xn | x ∈ Z∗p }. Clearly H is a subgroup of Z∗p . It is known that |H| = gcd(n,p−1)
so the number
of cosets is c = p−1
|H| = gcd(n, p − 1) ≤ n. We denote the cosets by d1 H, . . . , dc H.
Consider the following c-coloring of {1, . . . , p − 1}: color x by i such that x ∈ di H. Since c ≤ n and
p − 1 ≥ S(n), by Schur’s lemma, there exists a monochromatic x1 , y1 , z1 such that x1 + y1 = z1 . Since they
are all in the same coset, there exists d such that x1 , y1 , z1 ∈ dH. Hence x1 = dxn , y1 = dy n , z1 = dz n .
Since dxn + dy n = dz n we get xn + y n = z n .

Theorem 7 refuted the idea of proving Fermat’s last theorem by showing that for all n ≥ 3 there are
arbitrarily large p such that xn + y n ≡ z n has no solution modulo p.
In 1927, Bartel van der Waerden [31] proved the following theorem which now bears his name.
Theorem 8. For all k, c there is a number W = W (k, c) such that, for all c-colorings of {1, . . . , W }, there
exists a monochromatic arithmetic sequence of length k.
The title of [31] credits Pierre Baudet with having conjectured this, but Soifer [27] gives evidence that
Schur had also done so. Even though van der Waerden did not have another goal in mind, he did not pursue
this line of research and so did not launch what is now called Ramsey theory.
Frank Ramsey [22] proved the following theorem that now bears his name. As others often do,we state
only the case for graphs, not hypergraphs. A graph consists of a set V of vertices and a set E ⊆ V2 (the set
of unordered pairs of elements of V ). The graph is complete if E includes all such pairs and is then denoted
by Kn , where n = |V |. We consider c-colorings of the edges, namely mappings f from E to {1, . . . , c}. A
monochromatic Km means a subset V ′ ⊆ V of size m and c′ 6 c such that for all distinct u, v ∈ V ′ , (u, v) is
an edge and f (u, v) = c′ .
Theorem 9. For all c, m there exists a number R such that for all c-colorings of the edges of KR there
exists a monochromatic Km .
The least such R satisfying the conditions of Theorem 9 is denoted by Rc (m). The folkloric example of
this theorem is that in any group of six people, at least three know each other or at least three are complete
strangers. If the six are the vertices of a K6 and each edge is colored green or blue (friends or strangers), then
the theorem says there is at least one monochromatic triangle. In fact, there are at least two such triangles,
whereas K5 has none when a green five-pointed star is inscribed in a blue pentagon, so that R2 (3) = 6.
Ramsey applied his lemma to problems in mathematical logic. He viewed it as a means to an end and
so did not launch what is now called Ramsey theory.
In 1892, before all of the results above, Hilbert [14] proved the lemma featured in the next section.
Like the three statements above (Lemma 6, Theorems 8 and 9), it applies to any c-coloring and yields a
monochromatic nice substructure. Hilbert viewed his lemma as a means to an end and so did not launch
3

what is now called Ramsey theory. He used it to prove the Hilbert irreducibility theorem, which is our main
topic.
Who did launch Ramsey theory? Speaking about his joint paper in 1935 with George Szekeres [5], Paul
Erdős said that it was Szekeres who rediscovered the statement and proof of Ramsey’s theorem. They used
it as a means to the following end.
Theorem 10. For all n ≥ 3 there exists m > n such that for any m points in the plane in general position
there exists n points that form a convex hull.
But they also attracted a clique of mostly Hungarians who developed the ideas, conjectures, and results that
grew into Ramsey theory as we know it.

3

The Cube Lemma.

Hilbert’s first paragraph in [14] crisply framed the problem of irreducibility under substitutions represented
by the statement of Theorem 1. Then he continued right away: “Our developments rest on the following
lemma.” We reproduce his words but change his a, µ to c, β and compress his displayed formulas using
variables b1 , . . . , bm that take only the values 0 or 1:
Given an infinite integer sequence a1 , a2 , a3 , . . . in which generally each
as denotes one of the c-many positive integers 1, 2, . . . , c, let m be
any positive integer. Then there are always m-many positive integers
µ(1) , µ(2) , . . . , µ(m) such that the 2m elements
aβ+Pm
(i)
i=1 bi µ
for infinitely many integers β are collectively the same number G, where
G is one of the numbers 1, 2, . . . , c.
Call those elements collectively the m-cube, which we can denote by C(β; µ1 , . . . , µm ). The sequence
a1 , a2 , a3 , . . . can be called a coloring of N+ using c colors. Thus the conclusion is that every coloring
gives rise to increments µ(1) , µ(2) , . . . , µ(m) that yield a monochromatic m-cube for infinitely many starting
points β. This is implied by the following finitistic statement, which we regard as Hilbert’s cube lemma
in the modern sense.
Lemma 11. For all m, c there is a number H such that, for all c-colorings of N+ and all intervals of length
H in N+ , there is a monochromatic m-cube within the interval.
Proof. We fix c. We will let Hm be a value of H that satisfies the theorem. We prove, by induction on
m, that Hm always exists. For the base case m = 1, we can take H1 = c + 1. This just says that for any
c-coloring of an interval of length c + 1 there will be two elements that are the same color. Taking β to be
the smaller one and β + µ1 the larger one, C(β; µ1 ) is a monochromatic 1-cube.
For the induction step, assume that h = Hm−1 exists. We show that, for any c-coloring of an interval of
length Hm = h·(1 + ch ), there is a monochromatic m-cube. Let COL be a c-coloring of an interval of length
Hm . Partition the interval into 1 + ch blocks of size h. By the pigeonhole principle, some two of those blocks
have the same sequence of h colors. By the induction hypothesis, the former has a monochromatic (m − 1)cube C(β; µ1 , . . . , µm−1 ), and since the color sequence of the latter is the same, it has C(β ′ ; µ1 , . . . , µm−1 )
with the same color and increments but β ′ > β. Take µm = β ′ − β. Then C(β; µ1 , . . . , µm ) is the required
monochromatic m-cube. This proves the lemma statement with H = Hm .
By analogy with Ramsey numbers, one can denote the least such H by H(m, c) and call it a “Hilbert
Cube Number.” The above proof embodies a recursive upper bound H(m, c) 6 H(m − 1, c)(1 + cH(m−1,c) ),
with basis H(1, c) = 1 for all c. This is far from best possible. When 2 6 m 6 c, one can improve the upper
4

bound to H(m, c) 6 h(1 + c(m − 1)h ), where h = H(m − 1, c), by a different counting argument. One can
further tweak this by using m−1
in place of (m − 1)h . These formulas are not bounded by any fixed tower
h
of exponents in c and m.
As observed by Brown et al. [2], Hilbert’s original proof yields bounds with (c + 1) rather than (m − 1)
in the base and the Fibonacci number F2m in the exponent, that is, H(m, c) 6 (c + 1)F2m , where F0 = 0,
F1 = 1, F2 = 1, F3 = 2, and so on. These bounds have doubly-exponential growth. Szemerédi [29] (see
also [10]) improved both the bounds and the nature of the result. Here is his more modern form of the
lemma:
Lemma 12. Let H, c > 0 and let A be a subset of [1, . . . , H] such that |A| > H/c. Then for some constant
C depending only on c, A contains an m-cube where m > log log(H) − C.

4

Monic polynomials.

Hilbert begins by reducing his general problem to the case of monic polynomials in one variable x with
rational coefficients. That is, he shows that the following statement suffices to prove Theorem 5.
Theorem 13. Let g(y, t) ∈ Z[y, t] \ Z[t]. If there exists t0 such that for all integers t1 > t0 , g(y, t1 ) is monic
and reducible in Z[y], then g(y, t) is reducible in Q[y, t].
Proving Theorem 13 will occupy the upcoming sections, but here we show the following.
Proposition 14. Theorem 13 implies Theorem 5.
The following transformation is used not only to prove the implication but also to motivate the machinery
for proving Theorem 13. Recall from (1) the integral polynomials T, T1 , . . . , Tn in t such that f (x, t) =
T xn + T1 xn−1 + · · · + Tn−1 x + Tn . Note that T and the Tj ’s become integer constants for any fixed value of
t. Define
g(y, t) = y n + S1 y n−1 + · · · + Sn−1 y + Sn ,
(2)
where for each j, 1 6 j 6 n, Sj = Tj T n−j . Then

y
g(y, t) = T n−1 f ( , t).
T
Thus g(y, t) is defined by rational transformation of the argument x in f (x, t) but still comes out integral.
To work with this, we preface four observations, of which the first is a famous result of Gauss called his
polynomial lemma.
Lemma 15.

(a) If a monic polynomial in Z[y] factors in Q[y], then it factors in Z[y].

(b) A polynomial ψ(y) divides a polynomial f ∈ Z[x, y] if and only if, upon writing
f (x, y) = a0 (y)xn + a1 (y)xn−1 + · · · + an−1 (y)x + an (y),
we have that ψ(y) is a factor of each aj (y).
(c) If ψ(y) is irreducible and divides f · g, where g ∈ Z[x, y] is written as
g(x, y) = b0 (y)xn + b1 (y)xn−1 + · · · + bn−1 (y)x + bn (y),
then either ψ(y) is a factor of all ai (y) or it is a factor of all bi (y).
(d) If f (x, y) can be factored into the product of two polynomials in x whose coefficients are rational
functions of y with integral coefficients, i.e., belong to Q(y)[x], then it can be factored into the product
of two polynomials in Z[x, y].
5

Proof. Part (a) can be understood as saying the product of two monic polynomials, each with at least one
rational noninteger coefficient, must have at least one rational noninteger coefficient. The intuition for (b)
and (c) is that since x occurs nowhere else, it cannot help ψ(y) divide f or f · g any other way than stated;
proofs may be found in Bôcher [1, pp. 203–204]. To prove (d), we write the given factorization in the form
f (x, y) =

f1 (x, y) f2 (x, y)
·
,
ϕ1 (y)
ϕ2 (y)

where f1 (x, y), f2 (x, y), ϕ1 (y) and ϕ2 (y) are integral polynomials such that f1 is not divisible by any factor
of ϕ1 (y) and f2 is not divisible by any factor of ϕ2 (y). By part (c), since f1 · f2 is divisible by ϕ1 · ϕ2 , f1
has the complete polynomial ϕ2 as a factor and f2 has the complete polynomial ϕ1 as a factor. By (b) we
can cancel ϕ2 from the coefficients of f1 and we can cancel ϕ1 from the coefficients of f2 . This gives us our
factorization into two polynomials in Z[x, y].
Proof of Proposition 14. Let t1 > t0 in the hypothesis of Theorem 13. Recall that g(y, t) = f ( Ty , t) for any
t. Since f (x, t1 ) factors in Z[x], g(y, t1 ) factors in Q[y]. But since g(y, t1 ) is an integral polynomial and is
monic in the one variable y, it factors in Z[y] by Gauss’s polynomial lemma.
Thus we have satisfied the hypothesis of Theorem 13—and with the same t0 as in Theorem 5. Assuming
its conclusion gives us
g(y, t) = Ψ(y, t)Ψ′ (y, t),
where Ψ(y, t) and Ψ′ (y, t) belong to Q[y, t]. Substituting back y = xT yields the following equation for our
original polynomial:
Φ(x, t)Φ′ (x, t)
f (x, t) =
,
AT n−1
where Φ(x, t) and Φ′ (x, t) both belong to Z[x, t], A ∈ Z, and T ∈ Z[t] . Now part (d) of our lemma completes
the proof.
Gauss used his lemma, which appeared on page 42 of his Disquisitiones [9], to give the first proof of the
irreducibility of the cyclotomic polynomial of prime degree over the rationals. As we’ve seen, Hilbert used
it to reduce the irreducibility theorem to the case of monic polynomials with rational coefficients. But to go
further and prove Theorem 13, a new tool is needed.

5

Puiseux series.

Let n be the maximum degree of g(y, t1 ) as a polynomial in y as t1 varies. It is possible that g(y, t1 )
has degree less than n for some values t1 owing to cancellations, but these values are isolated and we will
effectively be able to ignore them. The fundamental theorem of algebra shows that the equation g(y, t1 ) = 0
(for other values of t1 ) has n complex roots. Thus, thinking informally, we can postulate n functions of t,
say y1 (t), . . . , yn (t), that satisfy the equations. Hilbert brought this into reality by using a refined form of
the implicit function theorem, which we refer to as Puiseux’s theorem (see discussion of origins below). It
says that the n root functions y1 (t), . . . , yn (t) can be expressed in a concrete way by means of fractional
power series in decreasing powers of the variable. These are the so-called Puiseux series at infinity, defined
as follows.
Definition 1. A Puiseux series at infinity is an expression of the form
u(x1/k ) +

∞
X
Bi
,
xi/k
i=1

where u is a polynomial with possibly complex coefficients, k is a positive integer, and B1 , B2 , . . . ∈ C.
We adopt the next theorem statement from [30, pp. 80–81] with slight alterations in notation and formatting.
Its power series are called Puiseux expansions at infinity.
6

Theorem 16 (Puiseux’s Theorem). Given g(y, t) as above, there are n distinct power series
B11
B13
B12
+ 2 + 3 + ···
τ
τ
τ
B
B
B
23
22
21
+ 2 + 3 + ···
y2 (t) = A21 τ h + A22 τ h−1 + · · · + A2,h+1 +
τ
τ
τ
..
.
Bn3
Bn2
Bn1
+ 2 + 3 + ···
yn (t) = An1 τ h + An2 τ h−1 + · · · + An,h+1 +
τ
τ
τ
y1 (t) = A11 τ h + A12 τ h−1 + · · · + A1,h+1 +

(3)

which are all convergent for τ greater than some constant, where the following hold:
(a) For a certain positive integer k, τ = t1/k , where the positive real value of the root is meant;
(b) The given number h is the highest positive exponent of τ that occurs.
(c) All coefficients Ai,j and Bi,j are well-defined uniquely determined complex numbers;
(d) Any formal power series y(t) satisfying the formal identity g{y(t), t} ≡ 0 and having properties analogous to those of the series (3) necessarily coincides with one of the n series above.
(e) The following formal identity holds:
g(y, t) ≡

n
Y

i=1

{y − yi (t)}.

Hilbert [14] ascribed the idea of employing Puiseux series to Runge in a work that had appeared three
years earlier, and cited it in a footnote exactly like this.2 In order for the idea to get off the ground,
however, we need to have at least one series, i.e., n > 1. This is where the condition g(y, t) ∈ Z[y, t] \ Z[t] in
Theorem 13, reflecting emendations in Section 1, is used.
Hilbert then notes—and this is the reason to reduce the problem to monic polynomials—the relation
between the elementary symmetric functions of the roots y1 , y2 , . . . , yn and the coefficient polynomials
S1 , S2 , . . . , Sn , namely:
S1 = −(y1 + y2 + · · · + yn )

S2 = (−1)2 (y1 y2 + y1 y3 + · · · + yn−1 yn )
..
.
Sn = (−1)n (y1 y2 y3 · · · yn−1 yn ).

(4)

The insight is that by Puiseux’s theorem, when we plug the expansions (3) into the symmetric functions
(4), the resulting fractional power series for the coefficients all collapse down to integral polynomials in t.
And those must be the polynomials Sk in t from (2). For later reference, it will be convenient to state the
former observation as a theorem, calling the part of the expansion with positive exponents the polynomial
part.
Theorem 17. For any g(y, t) ∈ C[y, t] the elementary symmetric functions of n Puiseux expansions (3)
parameterizing the roots for any t collapse down to polynomials in Z[t] if (and only if ):
2 The original work of Puiseux can be found in Liouville’s Journal, vols. 15, 16 (1850, 1851). These expansions have already
been used by C. Runge to derive necessary conditions that an equation between two unknowns have infinitely many integral
solutions. See this Journal, vol. 100, p. 425. [Footnote by Hilbert]

7

(a) The coefficients of the negative powers of τ in the resulting fractional power series for the coefficients
are all equal to zero.
(b) The numerical coefficients of the “polynomial part” of the resulting fractional power series for the
coefficients are all integers.
(c) The numerical coefficients of the positive fractional powers of τ in the resulting fractional power series
for the coefficients are all equal to zero.
These three conditions will, with appropriate changes, characterize the coefficients of any polynomial factor
in Z[y, t] of g(y, t). Lemma 15 above shows that it suffices to write “rational numbers” instead of “integers”
in condition (b).

6

The formal factors.

Any nontrivial formal polynomial factor of g(y, t) is a polynomial of the form
Y
πA (y, t) :=
(y − yj ),

(5)

yj ∈A


where A is a nonempty
proper subset of the roots {y1 , y2, . . . , yn }. As Hilbert points out, there are n2

quadratic factors, n3 cubic factors, n4 quartic factors, n5 quintic factors, and finally n factors of degree
n − 1. Additionally, we count the n linear factors but exclude the two trivial ones, giving a grand total of
   


n
n
n
+
+ ···+
+ n = 2n − 2
2
3
n−1
possible factors. So, if g(y, t) is reducible, some πA (y, t) must be an integral polynomial factor. Sometimes
we prefer to think of A as a single item rather than a set, so we assign it a unique index a where a =
1, 2, . . . , 2n − 2. Then πa (y, t) means the same as πA (y, t). These items will become the “colors” in the cube
lemma.
Let’s look at a simple example of a reducible integral polynomial:
g(y, t) := y 3 − t3 .
Then the roots of g(y, t) = 0 are y1 = t, y2 = ωt, y3 = ω 2 t where ω 3 = 1, ω 6= 1.3 When n = 3 there are
23 − 2 = 6 formal factors. Thus the sets A are
{y1 },

{y2 },

{y3 },

{y1 , y2 },

{y1 , y3 },

{y2 , y3 },

and we (arbitrarily) assign the indices a = 1, 2, 3, 4, 5, 6 to them, respectively. Then, by (5), these formal
factors are:
π{y1 } ≡ π1 (y, t) = y − y1 = y − t,
π{y2 } ≡ π2 (y, t) = y − y2 = y − ωt,

π{y3 } ≡ π3 (y, t) = y − y3 = y − ω 2 t,

π{y1 ,y2 } ≡ π4 (y, t) = (y − y1 )(y − y2 ) = y 2 + ωty + ω 2 t2 ,

π{y1 ,y3 } ≡ π5 (y, t) = (y − y1 )(y − y3 ) = y 2 + ω 2 ty + ωt2 ,
π{y2 ,y3 } ≡ π6 (y, t) = (y − y2 )(y − y3 ) = y 2 + ty + t2 .

We observe that π1 (y, t) and π6 (y, t) are integral polynomial factors, whereas the other four are not.
3 Moreover,

y1 = t, y2 = ωt, y3 = ω 2 t where ω 3 = 1, ω 6= 1 are also the Puiseux expansions of the roots.

8

7

Using the pigeonhole principle.

Our problem now is to discover at least one formal factor πα that is an integral polynomial. (We note that
its complementary factor is also an integral polynomial.) We begin our search by applying our hypothesis.
Take t0 from the hypothesis of Theorem 13 and τ0 to be the positive kth root of t0 . Usually, τ0 will be
irrational. By hypothesis, if we substitute τ0 into all of the coefficient series of the formal factors πa (y, t), at
least one of them will be an integral polynomial in y.
Now, along with Hilbert, we observe that if we substitute 2τ0 into all of the coefficient series of the
formal factors πa (y, t), then at least one of them will be an integral polynomial in y, by the assumption that
g(y, 2k t0 ) is reducible.
Again, if we substitute 3τ0 into all of the coefficient series of the formal factors πa (y, t) at least one of
them will be an integral polynomial in y, by the assumption that g(y, 3k t0 ) is reducible. The same is true of
4τ0 , 5τ0 , and indeed, of στ0 for σ = 1, 2, 3, . . . .
Therefore, we obtain an infinite sequence of integral polynomial factors πa (y, σ k t0 ) in y. Each of them
has a unique index a ∈ {1, 2, . . . , 2n − 2}. Let these indices be a1 , a2 , a3 , . . . , as , . . . . Then, by the pigeonhole
principle, at least one index as occurs infinitely often. In our example above, we can take as = 1 or as = 6
and our sequence of indices contains 1 or 6 or both infinitely often. The point is the following.
The corresponding formal polynomial πas (y, t) is a
natural candidate for our integral polynomial factor.
To prove that it is our integral polynomial factor, we must verify that its Puiseux expansions satisfy the
three conditions of Theorem 17. The rest of Hilbert’s paper (and ours) is about pinning down a formal
factor πas (y, t) that satisfies these three conditions.

8

Framing the cube lemma.

Let’s consider the first condition of Theorem 16: The coefficients of all the negative powers of τ0 in the
resulting fractional power series for the coefficients of πas (y, σ k t0 ) are all equal to zero. Without loss of
generality we may suppose as indexes {y1 , . . . , yν } where ν < n is the degree of πas . Suppose the following
system of coefficient power series for πas (y, (σ k t0 )) has as as its index:
y1 + y2 + · · · + yν = C11 (στ0 )h + C12 (στ0 )h−1 + · · · + C1,h+1
D12
D13
D11
+
+
+ ···
+
στ0
(στ0 )2
(στ0 )3
..
.
y1 y2 · · · yν = Cν1 (στ0 )hν + Cν2 (στ0 )hν−1 + · · · + Cν,hν+1
Dν2
Dν3
Dν1
+
+
+ ··· .
+
στ0
(στ0 )2
(στ0 )3
The coefficients Cij , Dij are all completely determined as rational or irrational, real or complex numbers.
Some of them must be zero because the positive exponents of τ0 in general will be smaller than (n − 1)h.
The variable quantity here is the integer σ. This suggests that we rewrite the above fractional series as

9

series in σ and then obtain
y1 + y2 + · · · + yν = C11 σ h + C12 σ h−1 + · · · + C1,h+1
D11
D13
D12
+
+ 2 + 3 + ···
σ
σ
σ
..
.
y1 y2 · · · yν = Cν1 σ hν + Cν2 σ hν−1 + · · · + Cν,hν+1
Dν3
Dν2
Dν1
+ 2 + 3 + ···
+
σ
σ
σ
where the new coefficients Cij , Dij are again determinate numerical quantities. Suppose that the index of
the first occurrence of our infinitely repeated polynomial factor is s = σ = µ. Then every repetition of the
index µ produces the same ν power series in σ, but with a larger value of σ. Thus, since there are an infinite
number of such indices, there are infinitely many larger and larger values of σ substituted into the power
series.
If we look at the series of negative powers for any particular coefficient, we see that for sufficiently large
σ it becomes arbitrarily small in absolute value. Yet, the total power series takes integral values for all of
these values of σ. That suggests that the total contribution of the negative powers, for large σ, is an integer
of arbitrarily small absolute value, i.e., zero.
Thus we might try to argue by contradiction as follows: Assume that there are nonzero coefficients of
negative powers and deduce an absurd conclusion. The possible hitch is that this inference ignores the
“polynomial part” of the coefficient series—which could exactly compensate for a tiny nonzero contribution
of the negative powers.
To show that this is not the case we would like to somehow “eliminate” the polynomial part of the
coefficient series without losing the property of being an integer for infinitely many values of σ. This suggests
forming suitable linear combinations of the coefficient series that successively subtract off the principal terms
of the polynomial parts, and leaving finally only linear combinations of integer-valued series with negative
coefficients.
To see how this would work, let’s look at a typical coefficient series. Let us choose any of the ν power
series in the system under consideration, say the power series
P(σ) = C11 σ m−1 + C12 σ m−2 + · · · + C1m +

D13
D12
D11
+ 2 + 3 + ··· ,
σ
σ
σ

where we have written m − 1 for the highest power of σ.
Now comes a new insight. This is the insight that is key to the whole proof. Its simplicity belies the
brilliance it took to think of it. Professional mathematicians are aware of this phenomenon: the deepest
ideas, in the end, are based on a simple observation. The observation can be counterfactual and act as a
catalyst. Here is Hilbert’s:
Let us suppose that the series P(σ) takes on integral values, not
only for infinitely many values of σ, but also for all the infinitely
many values of σ + µ(1) , where µ(1) is a fixed increment independent of σ.
To set it in motion, we form the linear combination
P (1) (σ) := P(σ) − P(σ + µ(1) )
and put the polynomial part equal to
ϕm−1 (σ) := C11 σ m−1 + C12 σ m−2 + · · · + C1m
for brevity. We now start the argument-by-contradiction.
10

Suppose now that the other coefficients D11 , D12 , D13 , . . . of the power series P(σ) are not all zero and
let D1v /σ v be the first term whose coefficient D1v does not vanish. Then


1
1
(1)
(1)
P (σ) = ϕm−1 (σ) − ϕm−1 (σ + µ ) + D1v v −
+ ··· .
σ
(σ + µ(1) )v
Here the first difference on the right-hand side is a polynomial of degree m − 2 in σ; we put
ϕm−2 (σ) = ϕm−1 (σ) − ϕm−1 (σ + µ(1) ).
We expand the remaining terms on the right-hand side in decreasing powers of σ; then we obtain4
P (1) (σ) = ϕm−2 (σ) + µ(1) v

D1v
+ ··· .
σ v+1

We have reduced the maximum degree of the polynomial part by one unit. Moreover, P (1) (σ) takes on integral
values for infinitely many σ.
We have not proved that such an increment µ(1) exists, but if we could, then we could make a first step
in reaching our goal of producing a series of negative powers of σ that evaluates to an integer for infinitely
many values of σ.
To carry out a similar program to reduce the maximum degree of the polynomial part to m − 3, then to
m − 4, and so on until finally to zero, we would have to have to prove the existence of m fixed increments
µ(k) , k = 1, 2, . . . , m whose values are all independent of σ and such that if we substitute any of the integers
µ
µ+µ(1)
µ+µ(2) µ+µ(1) +µ(2)
µ+µ(3) µ+µ(1) +µ(3) µ+µ(2) +µ(3) µ+µ(1) +µ(2) +µ(3)

..
.

..
.

..
.

µ+µ(m) µ+µ(1) +µ(m) µ+µ(2) +µ(m)

..
.
···

···
···

..

.

µ+µ(1) +···+µ(m)

for σ in P(σ), the values will all be integers.
Note that the proof of the existence of the increment µ(1) amounts to proving that aµ and aµ+µ(1) are
both the same number in the set of indices as . A similar property holds for the set of all the above sums
of fixed increments µ(k) (for k = 1, 2, . . . , m) with µ, namely that they all are the subscripts of the same
number in the set of indices as . In our running example they are all equal to 1 or they are all equal to 6.
The proof of the existence of these increments is the content of the cube lemma. To serve the context of
Hilbert’s proof, we restate it using his formulas much as he visualized them in his paper.
Theorem 18. Let a1 , a2 , a3 , . . . be an infinite sequence in which the general term, as , is one of the a positive
numbers 1, 2, . . . , a. Moreover, let m be any positive integer. Then we can always find m positive integers
4 The

details, with simplified notation, are:




1
1
D1v
1
=
1
−
D1v ν −
µ
σ
(σ + µ)ν
σν
(1 + σ )ν



−ν  µ −ν  µ 2
D1v
= ν 1− 1+
+ ···
+
2
1 σ
σ
σ

 

ν(ν + 1) µ 2
D1v µν
+ ···
−
= ν
σ
σ
2
σ
 


ν +1 µ
µνD1v
+ ··· ,
= ν+1 1 −
σ
2
σ

and this last expression on the right-hand side is equivalent to that in the main body of the paper.

11

µ(1) , µ(2) , . . . , µ(m) such that for infinitely many integers µ the 2m elements
aµ
aµ+µ(1)
aµ+µ(2) aµ+µ(1) +µ(2)
aµ+µ(3) aµ+µ(1) +µ(3) aµ+µ(2) +µ(3) aµ+µ(1) +µ(2) +µ(3)
..
..
..
..
..
.
.
.
.
.
···
aµ+µ(m) aµ+µ(1) +µ(m) aµ+µ(2) +µ(m)
···
···
aµ+µ(1) +µ(2) +···+µ(m)
are all equal to the same number G, where G is one of the numbers 1, 2, . . . , a.
Thus we see that the statement arises naturally from the necessity of proving that the coefficients of the
negative powers of σ must be all equal to zero. It is the strengthened form of the pigeonhole principle we
mentioned earlier. It is stronger because it imposes a structure on the distribution of infinitely many common
values as whereas the pigeonhole principle only implies their existence.

9

The Coefficients of the Negative Powers of σ are Zero.

Employing the idea above, we form the following m linear combinations:
P (1) (σ) = P(σ) − P(σ + µ(1) ),

P (2) (σ) = P (1) (σ) − P (1) (σ + µ(2) ),
..
.
P (m) (σ) = P (m−1) (σ) − P (m−1) (σ + µ(m) ).
It follows from what we proved earlier that each of these m power series also assumes integer values for
infinitely many integral arguments σ = µ.
As we indicated, assuming the cube lemma, we obtain
D1v
+ ··· ,
σ v+2
where ϕm−3 (σ) is a polynomial in σ of degree m − 3. After m steps we finally arrive at the formula
P (2) (σ) = ϕm−3 (σ) + µ(1) µ(2) v(v + 1)

D1v
+ ··· .
σ v+m
Since this power series begins with negative powers of σ, we can find a positive number Γ such that for
all values of σ that exceed Γ the absolute value of the power series will be smaller than one. On the other
hand, the power series P (m) (σ) is itself equal to an integer for infinitely many arguments σ and since an
integer whose absolute value is less than one is necessarily equal to zero, it follows that there are infinitely
many integers σ for which the power series vanishes.
But, our last formula shows us that
h
i
lim σ v+m P (m) (σ) = µ(1) µ(2) · · · µ(m) v(v + 1) · · · (v + m − 1)D1v ,
P (m) (σ) = µ(1) µ(2) · · · µ(m) v(v + 1) · · · (v + m − 1)

σ→∞

where the expression on the right-hand side represents a quantity different from zero. This last result stands
in contradiction with the conclusion proved above, and therefore it is impossible that a nonzero coefficient
D1v occurs among the coefficients D11 , D12 , D13 , . . . . It follows in the same way that also the coefficients
D2i , D3i , D4i , . . . , Dνi must all be equal to zero.
This completes the proof of the first condition of Theorem 17 about the Puiseux expansions of the
coefficients of πas (y, t).
This step was the heart of Hilbert’s proof and his paper’s most brilliant insight. The other parts are
clever too, but in our opinion this best shows his penetrating originality.
12

10

The Coefficients of the Polynomial Part are Rational Numbers.

The next condition of Theorem 17 to be verified is: the numerical coefficients in the polynomial part of the
Puiseux expansions of the coefficients of πas (y, t) are rational numbers. Our expansion has collapsed to the
polynomial part, i.e.
P(σ) = C11 σ m−1 + C12 σ m−2 + · · · + C1m ,
(6)
where the right-hand side assumes integer values for infinitely many values of σ. If we set the right-hand side
equal to these integers for m values of σ, we obtain m linear equations in m unknowns C11 , C1,2 , . . . , C1m
which have a rational solution by Cramer’s rule. By Proposition 14, getting “rational” suffices to prove the
condition.

11

Only Integral Powers of t .

The final condition of Theorem 17 to be verified is: the only nonzero terms in the polynomial part of the
Puiseux expansions of the coefficients of πas (y, t) are those with integral powers of t.
Take τ0 to be a prime number larger than t0 in the statement of Theorem 13 and recall that στ0 = τ.
We now select 2n − 2 distinct prime numbers pℓ all greater than τ0 . For each of τ0 and the pℓ , at least one
among the 2n − 2 formal factors has coefficients in the above polynomial form (6). However, since we have
2n − 1 primes and only 2n − 2 formal factors, there must exist at least one formal factor admitting a double
representation by these polynomials (6). That is to say, there are distinct primes p, p′ > t0 such that
y1 + y2 + · · · + yν = A11 p−(m−1)/k τ m−1 + A12 p−(m−2)/k τ m−2 + · · · + A1m
..
.
y1 y2 · · · yν = Aν1 p−(m−1)/k τ m−1 + Aν2 p−(m−2)/k τ m−2 + · · · + Aνm ,
and simultaneously,
y1 + y2 + · · · + yν = A′11 (p′ )−(m−1)/k τ m−1 + A′12 (p′ )−(m−2)/k τ m−2 + · · · + A′1m
..
.
y1 y2 · · · yν = A′ν1 (p′ )−(m−1)/k τ m−1 + A′ν2 (p′ )−(m−2)/k τ m−2 + · · · + A′νm .
Since, by Puiseux’s theorem, the coefficients of the powers of τ are unique, if we equate coefficients of equal
powers of τ on the right-hand sides we obtain:
A11 p−(m−1)/k = A′11 (p′ )−(m−1)/k , · · ·

A12 p−(m−2)/k = A′12 (p′ )−(m−2)/k , · · ·
..
.
A1m = A′1m ,

Aν1 p−(m−1)/k = A′ν1 (p′ )−(m−1)/k
Aν2 p−(m−2)/k = A′ν2 (p′ )−(m−2)/k
..
.
Aνm = A′νm .

The final numerical point is that for any rational number r that is not an integer, and distinct primes p and
p′ , the ratio pr /p′r is irrational. Suppose the ratio were equal to the rational number c/d in lowest terms,
and let us also put r = k/ℓ in lowest terms. Cross-multiplying then gives
dℓ pk = cℓ p′k .
For this to happen, p must divide c. Let a be the largest integer such that pa divides c. Then we must have
ℓ = ak in order to cancel out all factors of p. This means that ℓ/k must be an integer, contradicting the
condition on r.
13

We can apply this where ℓ is a numerator of one of the exponents of p and p′ , such as ℓ = m − 1, because
we established in Section 10 that the coefficients Ai,j of the polynomial part are all rational. We conclude
that the only coefficients that can be different from zero are those for which the corresponding exponent of τ
must be an integer divisible by k.
It follows that the power series of our system are polynomials in τ k with rational coefficients, and if we
put τ k = t, we obtain
y1 + y2 + · · · + yν = F1 (t)
..
.
y1 y2 · · · yν = Fν (t),
where F1 (t), . . . , Fν (t) are polynomials in t with rational coefficients.
This completes the proof of the third condition of Theorem 17 of the Puiseux expansions of the coefficients
of some formal factor πas (y, t).
We note that the final formal factor πas (y, t) is not necessarily the same one that we started with. All
we needed was that it fulfills the three conditions of Theorem 17, and therefore the proof of Theorem 13 is
complete.

12

Later Proofs of the Irreducibility Theorem.

After Hilbert, many mathematicians offered other proofs of the irreducibility theorem.
Most of the modern proofs of the (two-variable) irreducibility theorem are based on that of Karl Dörge [4],
which sharpened an idea of Thoralf Skolem [26]. Dörge proved it without using the cube lemma and
obtained a stronger result. To begin contrasting his and Hilbert’s results, recall Hilbert’s statement that
if f ∈ Z[x, y1 , . . . , ys ] is irreducible, then for infinity many t1 , . . . , ts ∈ Z, f (x, t1 , . . . , ts ) is irreducible as a
member of Z[x].
Now let |f | be the maximum of 8 and the absolute values of the coefficients of f . (The reason for insisting
|f | ≥ 8 is technical.) A simplified statement of Dörge’s theorem is the following.
Theorem 19. There is a function c(d, s) such that the following holds. Let f ∈ Z[x, y1 , . . . , ys ] be irreducible
of degree d. Let N > |f |c(d,s) . Then the number of (t1 , . . . , ts ) ∈ {−N, . . . , N }s such that f (x, t1 , . . . , ts ) is
not irreducible is at most |f |c(d,s) N s−(1/2) log N .
Note that the number of such (t1 , . . . , ts ) has density 0. Dörge actually presented a generalization of this
theorem where he replaces Z with the integers of a finite extension of a number field.
Dörge also showed (in fact, this was his primary interest) that if f , viewed as an element of Z[y1 , . . . , ys ][x],
has Galois group G, then the number of (t1 , . . . , ts ) ∈ {−N, . . . , N }s such that f (x, t1 , . . . , ts ) does not have
Galois group G is at most |f |c(d,s) N s−(1/2) log N . And again, he actually presented a generalization of this
theorem that replaces Z with the integers of a finite extension of a number field.
Lang [17, 18] and Prasolov [20] have expositions of Dörge’s proof. Franz [7] also gave a proof that does
not use the cube lemma, and this is expounded further by Schinzel [25]. There is a another proof by Fried [8].
Serre [28] recasts these results in geometric terms and presents results about which groups can be Galois
groups.

13

Conclusion: Hilbert’s World.

We have shown the significance of the cube lemma in the context of Hilbert’s original paper. We return to the
questions of how Hilbert might have expanded it in the direction of Ramsey theory and why he didn’t. That
Hilbert was the world’s master in the relationship between number theory and logic until Gödel emerged,
while Ramsey was motivated by a problem in logic, gives more reason to ask. We close with a speculative
14

answer: The world in which Hilbert was immersed was and remains at least one level of exponentiation
higher than the ground floor of Ramsey theory.
Recall from Section 3 that we defined the “Hilbert Cube Numbers” H(m, c) to be the least H such
that every c-coloring of {1, . . . , H} has a monochromatic m-cube. The best known upper and lower bounds
appear still to be those of Gunderson and Rödl [11]:
m

c(1−ǫc )(2

−1)/m

m−1

6 H(m, c) 6 (2c)2

,

where ǫc → 0 as c → ∞.5 This establishes doubly-exponential growth of H(m, c) in m for any fixed c, in
contrast to the singly-exponential growth of the Ramsey numbers, in particular


4m
2m − 2
R2 (m) 6
6 √ .
m−1
m
Moreover, while Erdős and Turán [6] proved that H(2, c) is asymptotic to c2 , much less is known about
H(m, c) for fixed m > 3 (see remarks in [2] which appear still in force), and in [3] it is noted that H(m, 2)
depends on unknown properties of van der Waerden numbers. This all puts H(m, c) on a higher and harder
plane than analogous cases of Rc (m) in the Ramsey world. So what world was Hilbert in?
The years 1890–1893 saw the publication of Hilbert’s great foundational works in commutative algebra,
including his basis theorem and Nullstellensatz [13, 15]. A common thread is the notion of regularity: given
a finitely-specified system of elements that may have arbitrarily large values of some parameter t (such as
the degrees of certain polynomials over a ring), there is some integer t0 such that, for all t > t0 , the system
conforms to a simple description. Hilbert first proved his basis theorem nonconstructively. Later was it
shown that the growth of the relevant t0 (in terms of the degrees d of basis elements or the n-variable
n
equations in the Nullstellensatz ) is doubly-exponential, of order up to d2 . We could try to equate the
growth of H(m, c) with that of Ramsey numbers by regarding the cube as a graph of size M = 2m and
saying H(m, c) is “singly exponential in M .” But m, not M , is still the natural parameter, just as with n,
not 2n , in the Nullstellensatz.
Hence our answer is simply that Hilbert was occupied with more rarefied levels of algebra and analysis
where nonconstructive methods were often more salient than double-exponential effective ones. Irreducibility of polynomials plays into irreducible varieties and primary decompositions of polynomial ideals, which
Hilbert’s student Emanuel Lasker (the world chess champion) and colleague Emmy Noether built upon for
some great work in the next two decades that became more algorithmic. In the meantime, Hilbert swooped
down to the ground-level task of formalizing Euclid’s geometry in the later 1890s, which presaged his work
on formal logic.
The divide in purpose and growth rate does not ward us off from appreciating the cube numbers and
seeking other uses for them. That is why we have devoted this paper to expounding their original use and
context. We have highlighted how the cube lemma completed an insight about estimates by infinite series.
We hope that our exposition will foster a greater appreciation of combinatorial underpinnings of more
“analytical” areas of mathematics.
Acknowledgements. We thank Joseph P. Varilly for formatting help and the referees for helpful
comments that greatly improved the exposition and clarity.

References
[1] M. Bôcher, Introduction to Higher Algebra. Dover, New York, 2004.
[2] T. C. Brown, F. R. K. Chung, P. Erdős, R. L. Graham, Quantitative forms of a theorem of Hilbert. J.
Combin. Theory Ser. A 38 (1985) 210–216.
5 The same upper bound was recently ascribed to [12] by Conlon, Fox, and Sudakov [3] but see also Sándor [23] with different
asymptotics.

15

[3] D. Conlon, J. Fox, B. Sudakov, Short proofs of some extremal results, Combin. Probab. Comput. 23
(2014) 8–28.
[4] K. Dörge, Einfacher Beweis des Hilbertschen Irreduzibilitätssatzes, Math. Ann. 96 (1927) 176–182.
[5] P. Erdős and G. Szekeres, A combinatorial problem in geometry, Compositio Math. 2 (1935) 463-470.
[6] P. Erdős, P. Turán, On a problem of Sidon in additive number theory, and on some related problems,
J. London Math. Soc. 16 (1941) 212–215.
[7] W. Franz, Untersuchungen zum Hilbertschen Irreduzibilitätssatz, Math. Z. 33 (1931) 275–293.
[8] D. Fried, On Hilbert’s irreducibility theorem, J. Number Theory 6 (1974) 211–231.
[9] C. F. Gauss, Disquisitiones Arithmeticae. Arthur A. Clarke, tr. Yale University Press, New York, 1965.
[10] R. Graham, B. Rothschild, J. Spencer. Ramsey Theory. Wiley, New York, 1990.
[11] D. S. Gunderson, V. Rödl, Extremal problems for affine cubes of integers, Combin. Probab. Comput. 7
(1998) 65–79.
[12] D. S. Gunderson, V. Rödl, A. Sidorenko, Extremal problems for sets forming Boolean algebras and
complete partite hypergraphs, J. Combin. Theory Ser. A 88 (1999) 342–367.
[13] D. Hilbert, Über die Theorie der algebraischen Formen, Math. Ann. 36 (1890) 473–534.
[14] D. Hilbert Über die Irreducibilität ganzer rationaler Functionen mit ganzzahligen Coefficienten, J. reine
angew. Math. 110 (1892) 104–129.
[15] D Hilbert, Über die vollen Invariantensysteme. Math. Ann. 42 (1893) 313–373.
[16] B. Landman, A. Robertson, Ramsey Theory on the Integers. American Mathematical Society, Providence, 2004.
[17] S. Lang, Diophantine Geometry. Wiley, New York, 1962.
[18] S. Lang, Fundamentals of Diophantine Geometry. Springer, New York, 1983.
[19] K. Nowak, Some elementary proofs of Puiseux’s theorems, Univ. Iagel. Acta Math. 38 (2000) 279–282.
[20] V. Prasolov, Polynomials. Springer, New York, 2004.
[21] H. J. Promel, Ramsey Theory for Discrete Structures. Springer, New York, 2013.
[22] F. P. Ramsey, On a problem in formal logic, Proc. London Math. Soc. 30 (1930) 264–286.
[23] C. Sándor, An upper bound for Hilbert cubes, J. Combin. Theory Ser. A 114 (2007) 1157–1159.
[24] I. Schur, Uber die Kongruenz of xm + y m ≡ z m (mod p), Jahresbericht der Deutschen MathematikerVereinigung 24 (1916) 114-116.
[25] A. Schinzel, Selected Topics on Polynomials. Univ. of Michigan Press, Ann Arbor, 1982.
[26] T. Skolem, Untersuchungen über die moeglichen Verteilungen ganzzahliger Lösungen gewisser Gleichungen, Kristiania Vid. Selsk. Skr. 17, 1921; 57 pp.
[27] A. Soifer, The Mathematical Coloring Book: Mathematics of Coloring and the Colorful Life of Its
Creators, Springer, Berlin, 2009.
[28] J.-P. Serre, Topics in Galois Theory, A.K. Peters-CRC Press, New York, 2008.
16

[29] E. Szemerédi, On sets of integers containing no four elements in arithmetic progression, Acta. Math.
Hungar. 20 (1969) 89–104.
[30] N. Tzanakos. Elliptic Diophantine Equations. De Gruyter, Berlin, 2013.
[31] B. van der Waerden, Beweis einer Baudetschen Vermutung, Nieuw Arch. Wisk. 15 (1927) 212-216.

17

