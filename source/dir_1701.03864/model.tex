%!TEX root = AppM2_MultiD.tex
\section{3D $B_2$ Model}
\label{sec:approx}
For second order models, which are the subject of this paper, 
the set of realizable moments as given in \cite{kershaw1976flux} is
\begin{equation}\label{eq:realizablity-region}
  \begin{split}
    \cM =  \Big\{ &  \left(E^0, \bE^1, \bbrE^2\right) 
    \in \bbR \times \bbR^3 \times \bbR^{3\times3}, 
    ~~\text{s.t.}~~0 < E^0 = \Trace(\bbrE^2),\\  
    &  \|\bE^1\| \leq E^0, \,
    ~~\text{and}~~E^0 \bbrE^2 - \bE^1 \otimes \bE^1 
  ~~\text{symmetric non-negative} \Big\}.
\end{split}
\end{equation}
It is also referred to as the realizability domain. 
Our goal is to reconstruct an ansatz of the specific intensity
given moments within $\cM$.

We take the summation of three axisymmetric distributions as the
ansatz for the specific intensity:
\begin{equation}\label{eq:B2-ansatz}
  \bansatz(\bOmega) = \sum_{i = 1}^3 \dfrac1{2\pi} w_i 
  f(\bOmega\cdot\bR_i; \gamma_i, \delta_i),
\end{equation}
where $\bR_i$ are three mutually orthogonal unit vectors. We assume that the matrix
$\bbrR = \left[\bR_1, \bR_2, \bR_3\right]$ satisfy $\det(\bbrR) = 1$.
It is also
assumed that $f(\mu; \gamma, \delta)$ is a non-negative function of
$\mu$ with two shape parameters $\gamma$ and $\delta$, and
$\displaystyle \int_{-1}^1 f(\mu; \gamma, \delta) \dd\mu = 1$. All the
parameters in the ansatz, including $\bR_i$, $w_i$, $\gamma_i$, and
$\delta_i$, $i=1,2,3$, are functions of known moments and are
independent of $\bOmega$. We first discuss the properties of
\eqref{eq:B2-ansatz} for any arbitrary non-negative function
$f(\mu;\gamma,\delta)$ whose integral over $\mu\in[-1,1]$ is one.
To simplify the computing process in discussing the consistency conditions, we
first make the following observation which will be used later.
\begin{lemma}\label{lem:integral-orthogonal}
  For any permutation $l, m, k$ of $1, 2, 3$, $\forall
  n_l,n_m, n_k\in \mathbb{N}$, we have
  \[
    \begin{aligned}
      & \Vint{(\bOmega\cdot\bR_l)^{n_l} (\bOmega\cdot\bR_m)^{n_m} 
      (\bOmega\cdot\bR_k)^{n_k} f(\bOmega\cdot\bR_k; \gamma_k,
    \delta_k)} = \\ & \qquad \qquad \qquad \left
      \{
        \begin{array}{l}
          0, ~~\text{if either }~n_l \text{ or } n_m \text{ is odd}, \\
          [4mm]

          2 \pi \int_{-1}^1 \mu^{n_k} f(\mu;\gamma_k, \delta_k) \dd\mu, 
          ~~\text{if } n_l = n_m = 0, \\
          [4mm]

          \pi \int_{-1}^1 (1 - \mu^2) \mu^{n_k} f(\mu; \gamma_k,
          \delta_k) \dd\mu, ~~\text{if } n_l = 2, ~n_m = 0.
        \end{array}\right.
      \end{aligned}
    \]
  \end{lemma}
\begin{proof}
  Note that $f(\bOmega\cdot\bR_k; \gamma_k, \delta_k)$ is an 
  axisymmetric function with $\bR_k$ as its symmetric axis.
  Once $\bR_i$, $i=1,2,3$, are given, the value of
  \[
    \int_{\bbS^2} (\bOmega\cdot\bR_l)^{n_l} (\bOmega\cdot\bR_m)^{n_m}
    (\bsOmega \cdot \bR_k)^{n_k}
    f(\bOmega\cdot\bR_k; \gamma_k, \delta_k)
    \dd\bOmega,
  \]
  can be calculated conveniently by setting $\bR_k$ as coordinate
  axes. Below, we will repeatedly use this method to compute the moments. 

  Set the $z$-axis to be aligned to $\bR_k$, the $x$-axis to 
  be aligned to $\bR_l$, and the $y$-axis aligned to $\bR_m$.
  Then
\[
  \begin{split}
    & \int_{\bbS^2} (\bOmega\cdot\bR_l)^{n_l} (\bOmega\cdot\bR_m)^{n_m}
    (\bOmega\cdot\bR_k)^{n_k}
    f(\bOmega\cdot\bR_k; \gamma_k, \delta_k)
    \dd\bOmega \\
    = &  \int_0^\pi \left(\int_0^{2\pi} 
    (\sin\theta \cos\phi)^{n_l} (\sin\theta \sin\phi)^{n_m}
    (\cos\theta)^{n_k} f(\cos\theta; 
  \gamma_k,\delta_k) \dd\phi\right) \sin\theta \dd\theta \\
  = &  \int_0^\pi (\sin\theta )^{n_l + n_m} (\cos\theta)^{n_k}
  f(\cos\theta; \gamma_k,\delta_k) \sin\theta \dd\theta
  \int_0^{2\pi} (\cos\phi)^{n_l} (\sin\phi)^{n_m} \dd\phi. 
\end{split}
  \]
  Assume that $n_l$ is odd, let $n_l = 2 j + 1$.
  Then
  \[
    \begin{split}
      & \int_0^{2\pi} (\cos\phi)^{n_l} (\sin\phi)^{n_m} \dd\phi \\
      = & \int_0^{2\pi} (\cos\phi)^{2 j + 1} (\sin\phi)^{n_m} \dd\phi \\
      = & \int_0^{2\pi} (1-(\sin\phi)^2)^j (\sin\phi)^{n_m} \dd\sin\phi \\
      = & ~0.
    \end{split}
  \]
  Other cases are proved similarily.

  To calculate
  \[
    \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_k)^{n_k}
    f(\bOmega\cdot\bR_k; \gamma_k, \delta_k) \dd\bOmega,
  \]
  we set up the coordinate system such that $\bR_k$ is aligned to the
  $z$-axis. Let $\mu = \bOmega\cdot\bR_k$, then
  \[
    \begin{split}
      & \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_k)^{n_k}  
      f(\bOmega\cdot\bR_k; \gamma_k, \delta_k) \dd\bOmega \\
      = & \dfrac1{2\pi} \int_0^\pi \left( \int_0^{2\pi} 
    (\cos\theta)^{n_k} f(\cos\theta; \gamma_k, \delta_k) \dd\phi \right)
    \sin\theta \dd\theta \\
    = & \int_0^{\pi} (\cos\theta)^{n_k} f(\cos\theta; \gamma_k, \delta_k)   
    \sin\theta \dd\theta \\
    = & \int_{-1}^1 \mu^{n_k} f(\mu; \gamma_k, \delta_k) \dd\mu. 
  \end{split}
\]
If we let the $z$-axis to be aligned to $\bR_k$ and the $y$-axis
to be aligned to $\bR_l$, we have
\[
  \begin{split}
    & \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_l)^2
    (\bsOmega \cdot \bR_k)^{n_k}
    f(\bOmega\cdot\bR_k; \gamma_k, \delta_k) \dd\bOmega \\
    = & \dfrac1{2\pi} \int_0^\pi \left( \int_0^{2\pi}
    (\sin\theta\sin\phi)^2 (\cos\theta)^{n_k} f(\cos\theta; \gamma_k, \delta_k)
  \dd\phi \right) \sin\theta \dd\theta, \\
  = & \dfrac1{2\pi} \int_0^\pi (\sin\theta)^2 (\cos\theta)^{n_k} 
  f(\cos\theta; \gamma_k, \delta_k) \sin\theta \dd\theta
  \int_0^{2\pi} (\sin\phi)^2 \dd\phi \\
  = & \dfrac12 \int_{-1}^1 (1-\mu^2) \mu^{n_k} f(\mu; \gamma_k,
  \delta_k) \dd\mu. 
\end{split}
  \]
  Summarizing the results from the above three cases completes the proof of 
  this lemma.
\end{proof}
Take $\bv$ as defined in \eqref{eq:v-def}, the moments of interest are
\[
    \bE = [ E^0,E^1_1,E^1_2,E^1_3, E^2_{11},E^2_{12},E^2_{13},
    E^2_{22},E^2_{23} ]^T = \int_{\bbS^2} \bv \bansatz \dd\bOmega.
\]
The moment system based on the ansatz
\eqref{eq:B2-ansatz} is derived as
\begin{equation}\label{eq:moment_model}
  \pd{\bE}{t} + \pd{\bff_x(\bE)}{x} + \pd{\bff_y(\bE)}{y} +
  \pd{\bff_z(\bE)}{z} = \br(\bE),
\end{equation}
where
\[
  \begin{split}
    & \bff_x = [E^1_1, E^2_{11}, E^2_{12}, E^2_{13}, E^3_{111},
    E^3_{112}, E^3_{113}, E^3_{122}, E^3_{123}]^T = \int_{\bbS^2}
    (\bOmega\cdot\be_x) \bv \bansatz \dd\bOmega,\\
    & \bff_y = [E^1_2, E^2_{21}, E^2_{22}, E^2_{23}, E^3_{211},
    E^3_{212}, E^3_{213}, E^3_{222}, E^3_{223}]^T = \int_{\bbS^2}
    (\bOmega\cdot\be_y) \bv \bansatz \dd\bOmega,\\
    & \bff_z = [E^1_3, E^2_{31}, E^2_{32}, E^2_{33}, E^3_{311},
    E^3_{312}, E^3_{313}, E^3_{322}, E^3_{323}]^T = \int_{\bbS^2}
    (\bOmega\cdot\be_z) \bv \bansatz \dd\bOmega,
  \end{split}
\]
and $\br(\bE)$ is calculated from the scattering term, which is out of
the scope of our interests in this paper.

The parameters $\bR_i$, $w_i$, $\gamma_i$, and $\delta_i$ have to satisfy the 
consistency conditions: 
\begin{equation}\label{eq:consistency}
  E^0 = \Vint{\bansatz}, \quad
  \bE^1 = \Vint{\bOmega \bansatz}, \quand
  \bbrE^2 = \Vint{\bOmega \otimes \bOmega \bansatz}.
\end{equation}

The vectors $\bR_i$ in \eqref{eq:B2-ansatz} are determined by the consistency conditions
\eqref{eq:consistency} instantly, as shown in the following lemma. 
\begin{lemma}\label{lem:Rj}
  The consistency constraints \eqref{eq:consistency} require that
  $\bR_j$, $j=1,2,3$, be the eigenvectors of $\bbrE^2$.
\end{lemma}
\begin{proof}
  Let 
  $\bbrR = \left[\bR_1, \bR_2, \bR_3\right]$. As $\bbrR$ is an orthogonal 
  matrix, we have $\bbrR^{-1} = \bbrR^T$. To prove the lemma, it suffices to show that
  \begin{equation}\label{eq:consistency-Rj}
    \bR_j^T\bbrE^2\bR_i = \Vint{(\bOmega\cdot\bR_j)
    (\bOmega\cdot\bR_i)\bansatz} = 0,\quad \text{if}~j\not=i.
  \end{equation}
  The reason is that \eqref{eq:consistency-Rj} would indicate that
  $\bbrR^{-1}\bbrE^2\bbrR$ is a diagonal matrix, and therefore $\bR_j$,
  $j=1,2,3$, are the eigenvectors of $\bbrE^2$.
  
  In order to prove \eqref{eq:consistency-Rj}, consider the case $j=1$, $i=2$,
  \[
    \bR_1^T\bbrE^2\bR_2  = \Vint{(\bOmega\cdot\bR_1)
    (\bOmega\cdot\bR_2) \bansatz}
    = \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_1) (\bOmega\cdot\bR_2) 
    \sum_{i = 1}^3 w_i f(\bOmega\cdot\bR_i; 
    \gamma_i, \delta_i) \dd\bOmega.
  \]
  By Lemma \ref{lem:integral-orthogonal},
  \[
    \int_{\bbS^2} (\bOmega\cdot\bR_1) (\bOmega\cdot\bR_2) 
    w_k f(\bOmega\cdot\bR_k; \gamma_k, \delta_k)
    \dd\bOmega = 0, \quad k = 1,2,3.
  \]
  Therefore $\bR_1^T\bbrE^2\bR_2 = 0$. Similar arguments
  show that $\bR_1^T\bbrE^2\bR_3 = \bR_2^T\bbrE^2\bR_3 = 0$. 
\end{proof}

With the parameters $\bR_i$ determined, we now consider the consistency requirements under the coordinate
system $(\bR_1,\bR_2,\bR_3)$. In this coordinate system, $\bbrE^2$ is
a diagonal matrix. Also, as Lemma \ref{lem:Rj} specify $\bR_j$, 
$j=1,2,3$, to be the eigenvectors of $\bbrE^2$, consistency of all 
the non-diagonal elements of $\bbrE^2$ are naturally satisfied. 
Therefore we only need to look at the consistency of $E^0$, $\bE^1$, and all
the eigenvalues of $\bbrE^2$. This leaves us with 6 constraints. On the 
other hand, with $\bR_j$, $j = 1,2,3$ fixed, there are 9 parameters in the 
ansatz \eqref{eq:B2-ansatz}.
Denote
\begin{equation}\label{eq:sigma-def}
  \sigma_i = w_i \int_{-1}^1 \mu^2 f(\mu;\gamma_i,\delta_i)
  \dd\mu.
\end{equation}
The following lemma shows that once $\sigma_i$, $i = 1,2,3$ are specified, then $w_i$ 
for $i = 1,2,3$ would be determined by consistency constraints.
\begin{lemma}
  Let $\lambda_i$ be the eigenvalue corresponding to $\bR_i$. Then
  $w_i$, $\sigma_i$ and $\lambda_i$ satisfy the following constraints:
  \begin{equation}\label{eq:w-cond}
  \begin{split}
    & w_1 = 2\sigma_1 - (\sigma_2 + \sigma_3) -\lambda_1
    +\lambda_2 + \lambda_3,\\
    & w_2 = 2\sigma_2 - (\sigma_1 + \sigma_3) - \lambda_2
    +\lambda_1 + \lambda_3,\\
    & w_3 = 2\sigma_3 - (\sigma_1 + \sigma_2) - \lambda_3
    +\lambda_1 + \lambda_2.
  \end{split}
\end{equation}
\end{lemma}
\begin{proof}
  Firstly, 
  \[
  \lambda_1 = \Vint{(\bOmega\cdot\bR_1)^2 \bansatz} = \dfrac1{2\pi}
  \int_{\bbS^2} (\bOmega\cdot\bR_1)^2 \sum\limits_{i = 1}^3 w_i 
  f(\bOmega\cdot\bR_i; \gamma_i, \delta_i) \dd\bOmega.
  \]
  By Lemma \ref{lem:integral-orthogonal},
  \[
    \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_1)^2 w_1 
    f(\bOmega\cdot\bR_1; \gamma_1, \delta_1) \dd\bOmega 
    = w_1 \int_{-1}^1 \mu^2 f(\mu; \gamma_1, 
    \delta_1) \dd\mu 
    = \sigma_1.
  \]
  For $k = 2,3$, again by Lemma \ref{lem:integral-orthogonal},
  \[
    \begin{split}
      & \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_1)^2 w_k
      f(\bOmega\cdot\bR_k; \gamma_k, \delta_k) \dd\bOmega  \\
      = & \dfrac12 w_k \int_{-1}^1 (1-\mu^2) f(\mu; \gamma_k,
      \delta_k) \dd\mu 
      = \dfrac12 (w_k - \sigma_k).
    \end{split}
  \]
  Therefore, 
  \begin{equation}\label{eq:lambda1-consistency}
    \lambda_1 = \sigma_1 + \dfrac12 (w_2 - \sigma_2) + 
    \dfrac12 (w_3 - \sigma_3).
  \end{equation}
  By symmetry, we have
  \begin{equation}\label{eq:lambda23-consistency}
    \begin{split}
      & \lambda_2 = \sigma_2 + \dfrac12 (w_1 - \sigma_1) + 
      \dfrac12 (w_3 - \sigma_3), \\
      & \lambda_3 = \sigma_3 + \dfrac12 (w_1 - \sigma_1) + 
      \dfrac12 (w_2 - \sigma_2).
    \end{split}
  \end{equation}
  Rewriting \eqref{eq:lambda1-consistency} and
  \eqref{eq:lambda23-consistency} by solving the equations as a linear
  system of $w_i$ yields the final results \eqref{eq:w-cond}.
\end{proof}
Once $w_i$, $i=1,2,3$, are given, consistency
requires that $\gamma_i$ and $\delta_i$ satisfy
\begin{equation}\label{eq:moment-problem-1D}
  w_i \int_{-1}^1 \mu f(\mu;\gamma_i,\delta_i)
  \dd\mu = F_i,
\end{equation}
where $F_i = \bE^1\cdot\bR_i$. If $w_i = 0$, then the term $w_i 
f(\bOmega \cdot \bR_i; \gamma_i, \delta_i)$
does not appear in the ansatz \eqref{eq:B2-ansatz}. From now on we
assume $w_i \not= 0$. Recall that by definition, the function $f(\mu; \gamma, \delta)$ 
is a non-negative distribution on $\mu \in [-1,1]$, and its zeroth moment is $1$. Moreover,
the first and second-order moments of $f$ are respectively 
$\dfrac{F_i}{w_i}$ and $\dfrac{\sigma_i}{w_i}$. So,
combining \eqref{eq:sigma-def} and \eqref{eq:moment-problem-1D} define
a 1D moment problem. This means that once the value of the three parameters $\sigma_i$, 
$i = 1,2,3$ are specified, the consistency condition \eqref{eq:consistency} could 
be decomposed into three decoupled 1D moment problems
\begin{equation}\label{eq:consistency-decoupled}
  \left\{
  \begin{array}{l}
     \int_{-1}^1 \mu f(\mu;\gamma_i,\delta_i)
     \dd\mu = \dfrac{F_i}{w_i}, \\ [5mm]
     \int_{-1}^1 \mu^2 f(\mu;\gamma_i,\delta_i)
    \dd\mu = \dfrac{\sigma_i}{w_i},
  \end{array}\right.
\end{equation}
for $i = 1,2,3$.
According to \cite{CurFial91}, the realizability domains
of the 1D moment problems in \eqref{eq:consistency-decoupled}
are: 
\begin{equation}\label{eq:condition-realizable}
  \left(\dfrac{F_i}{w_i}\right)^2
  \leq\dfrac{\sigma_i}{w_i}\leq 1, \quad i = 1,2,3.
\end{equation}

A sufficient condition for the existence of non-negative
ansatz $\bansatz$ is $w_i \geq 0$, $i = 1,2,3$. It follows that 
a non-negative ansatz $\bansatz$ exists under the following conditions:
\begin{equation}\label{eq:condition-positive-ansatz}
  \left(\dfrac{F_i}{w_i}\right)^2
  \leq\dfrac{\sigma_i}{w_i}\leq 1, \quad
  w_i \geq 0, \quad i = 1,2,3.
\end{equation}
One would like to give a non-negative ansatz for as large a part of
the realizability domain as possible to have a realizable closure.
Before examining the non-negativity of the ansatz
\eqref{eq:B2-ansatz}, we give the following result, which is an
alternative characterization of the realizable moments:

\begin{lemma}\label{proposition-realizability}
  Let $\{\lambda_j,\bR_j\}$, $j=1,2,3$, be the eigenpairs of
  $\bbrE^2$, and $F_j = \bE^1\cdot\bR_j$. Then the realizability domain $\cM$
  given by \eqref{eq:realizablity-region} is
  \begin{equation}\label{eq:realizability-region-alternative}
    \cM = \left\{ \left(E^0, \bE^1, \bbrE^2\right) \, \left| \,
      0 < \sum\limits_{i=1}^3 \lambda_i = E^0,\, 
      \sum\limits_{i=1}^3 \dfrac{F_i^2}{\lambda_i} \leq
    E^0 \right.\right\}.
  \end{equation}
  In \eqref{eq:realizability-region-alternative},
the term $\dfrac{F_i^2}{\lambda_i} = 0$ is taken to be zero if $\lambda_i = 0$.
\end{lemma}
\begin{proof}
Denote the normalized first and second-order moments by
$\hat{\bE}^1 = \dfrac{\bE^1}{E^0}$ and $\hat{\bbrE}^2 = \dfrac{\bbrE^2}{E^0}$.
Let
\[
  \Lambda = \diag\left\{\dfrac{\lambda_1}{E^0}, \dfrac{\lambda_2}{E^0}, 
  \dfrac{\lambda_3}{E^0}\right\}, \quad
  \Lambda^{\frac12} = \diag\left\{\sqrt{\dfrac{\lambda_1}{E^0}}, \sqrt{\dfrac{\lambda_2}{E^0}}, 
  \sqrt{\dfrac{\lambda_3}{E^0}} \right\},
\]
and denote
\[
  \bbrR = [\bR_1, \bR_2, \bR_3], \quad \bbrT = \Lambda^{\frac12} \bbrR.
\]
Then
\[
  \hat{\bbrE}^2 = \bbrR^T \Lambda \bbrR = \bbrT^T \bbrT. 
\]
Assuming that $\lambda_i \not= 0$, $i = 1,2,3$. Then non-negativity of the matrix 
$\hat{\bbrE}^2 - \hat{\bE}^1 \otimes \hat{\bE}^1$
is equivalent to the non-negativity of the matrix $
  \Identity - \bbrT^{-T} \hat{\bE}^1 (\hat{\bE}^1)^T \bbrT^{-1}$,
which, in turn, is equivalent to 
$\|(\hat{\bE}^1)^T \bbrT^{-1}\|_2 \leq 1$, and therefore equivalent to
\begin{equation}\label{eq:realizable-cond}
  \sum\limits_{i = 1}^3 \dfrac{F_i^2}{\lambda_i} \leq E^0.
\end{equation}
The cases when there exists $i$ for which $\lambda_i = 0$ can be proved by entirely similar arguments.
\end{proof}
\begin{remark}
The above lemma could also be proved by applying the method for solving modified
eigenvalue problems proposed in \cite{yu1991recursive}. 
\end{remark}
Making use of Lemma \ref{proposition-realizability},
the realizability domain can be visualized as: take any point inside 
a triangle and let $\left(\dfrac{\lambda_1}{E^0}, \dfrac{\lambda_2}{E^0},
\dfrac{\lambda_3}{E^0}\right)$ be its barycentric coordinates.  
Then the corresponding $(F_1,F_2,F_3)$ lie in the ellipsoid 
\eqref{eq:realizable-cond}. 
Each side of the triangle corresponds to the cases where at least 
one eigenvalue of $\bbrE^2$ vanishes. In such cases non-negativity of
$\bansatz$ given in \eqref{eq:B2-ansatz} would impose the following
constraints on the first and second-order moments:
\begin{lemma}\label{lem:lambda2sigma}
  The non-negativity of the ansatz $\bansatz$ requires
  that if there exists $i = 1,2$ or $3$ such that $\lambda_i = 0$, then
  \[
  \left\{
    \begin{array}{l}
      F_i=0 \text{ and } \sigma_i = 0, \\
      |F_j| \leq \sigma_j \leq \lambda_j,
      \quad \text{for}~~\forall j \not= i.
    \end{array}\right.
  \]
  \end{lemma}
\begin{proof}
  Consider the case $i=1$. Since
  \begin{equation}\label{eq:cond-lambda-zero}
    0 = \lambda_1 = \int_{\bbS^2} (\bOmega \cdot \bR_1)^2
    \bansatz(\bOmega) \dd \bOmega,
  \end{equation}
  then $\bansatz$ can only be non-zero when $\bOmega \cdot \bR_1 = 0$.
  This gives
  \[
    F_1 = \int_{\bbS^2} (\bOmega \cdot \bR_1) \bansatz(\bOmega)
    \dd \bOmega = 0.
  \]
  To prove $\sigma_1 = 0$, let us study two cases.  
  \begin{enumerate}
    \item For $w_1 = 0$, it can be seen from \eqref{eq:sigma-def} 
      that $\sigma_1 = 0$.
    \item If $w_1 \not= 0$. Recall that $\bansatz$ can only be non-zero when 
      $\bOmega \cdot \bR_1 = 0$. Then \eqref{eq:sigma-def} shows $\sigma_1 = 0$. 
  \end{enumerate}
  
  Next, we show that $\sigma_j \geq |F_j|$, $j = 2,3$. We look at 
  two cases.
  \begin{enumerate}
    \item In the case that $w_j = 0$, by \eqref{eq:moment-problem-1D} we
      have $F_j = 0$, and by \eqref{eq:sigma-def} we see that $\sigma_j = 0$.
      Hence $\sigma_j \geq |F_j|$.
    \item If $w_j \not= 0$. Again, note that $\bansatz$ can only be non-zero 
      when $\bOmega \cdot \bR_1 = 0$, therefore for $j \not= 1$,
      the function $f(\bOmega\cdot\bR_j; \gamma_j, \delta_j)$
      has the form 
      $$f(\bOmega\cdot\bR_j; \gamma_j, \delta_j) = \alpha_j^-
      \delta(\bOmega \cdot \bR_j + 1) + \alpha_j^+ \delta(\bOmega \cdot \bR_j - 1).$$
      From \eqref{eq:sigma-def} we know that in such cases $\sigma_j = w_j$. 
      Combine this with the left inequality in 
      \eqref{eq:condition-positive-ansatz}, and we have $\sigma_j \geq |F_j|$.
  \end{enumerate}

  Finally, we prove $\sigma_j \leq \lambda_j$, $j = 2,3$. 
  Plugging $\sigma_1 = \lambda_1 = 0$ into \eqref{eq:w-cond} gives
  \[
    \sigma_2 - \sigma_3 = \lambda_2 - \lambda_3,
  \]
  and
  \[
    \sigma_2 + \sigma_3 = \lambda_2 + \lambda_3 - w_1,
  \]
  If $\bansatz$ is non-negative, then $w_1 \geq 0$. Combine the above and notice
  that $\lambda_2 + \lambda_3 = E^0$, we have
  \[
    \sigma_j \leq \lambda_j, \quad j = 2,3.
  \]
  The proofs for $i=2,3$, follows in a similar manner.
\end{proof}
\begin{remark}
As a special case of Lemma \ref{lem:lambda2sigma}, if there exists $j$ such that 
$\lambda_j = E^0$, and $\lambda_i = 0$ for $i \not= j$, then 
  \[
    \left\{
      \begin{array}{l}
        |F_j| \leq \sigma_j \leq \lambda_j = E^0, \\
        F_i=0 \text{ and } \sigma_i = 0,\quad\text{for}~~\forall i \not= j. 
      \end{array}\right.
    \]
  \end{remark}
From Lemma \ref{lem:lambda2sigma}, it is clear that when $\lambda_i = 0$ is the only zero
eigenvalue of $\bbrE^2$, the region for which the ansatz \eqref{eq:B2-ansatz} 
admits a non-negative distribution is limited to the rectangle $|F_j| \leq \lambda_j$,
$j\not=i$. We point out that this rectangle can cover only 4 points for the boundary of
the realizability domain in \eqref{eq:realizable-cond}, which in this case 
becomes the ellipse
\[
  \dfrac{F_j^2}{\lambda_j} + \dfrac{F_k^2}{\lambda_k} = E^0,
  \quad j \not= k.
\]


For other boundary moments, we have the following result:
\begin{lemma}\label{lem:realizable-bound}
  Suppose $\lambda_i > 0$, $i = 1,2,3$.
  Then on the boundary of the realizability domain, where
  \begin{equation}\label{eq:cond-boundary}
    \dfrac{F_1^2}{\lambda_1} + \dfrac{F_2^2}{\lambda_2}
    + \dfrac{F_3^2}{\lambda_3} = E^0,
  \end{equation}
  there are only two kinds of moments for which $\bansatz$ can be non-negative:
  \begin{enumerate}
    \item   $\exists i$, such that $\lambda_i = \dfrac{F_i^2}{E^0}$.
      Meanwhile for $j,k\not=i$, the relationships $\lambda_j = \lambda_k$  and
      $F_j = F_k = 0$ hold.
    \item $\forall j = 1,2,3$, the constraint $|F_j| = \lambda_j$ is satisfied. 
  \end{enumerate}
\end{lemma}
\begin{proof}
  Let the covariance matrix of the distribution function 
  be
  \[
    \bbrV = \dfrac{\bbrE^2}{E^0}-\left(\dfrac{\bE^1}{E^0}
    \right)\left(\dfrac{\bE^1}{E^0}\right)^T.
  \]
  If
  \[
    \dfrac{F_1^2}{\lambda_1} + \dfrac{F_2^2}{\lambda_2}
    + \dfrac{F_3^2}{\lambda_3} = E^0,
  \]
  then there exists at least one zero eigenvalue for $\bbrV$.
  Denote the corresponding eigenvector by $\bU$, and 
  \cite{kershaw1976flux} has shown that
  any non-negative distribution could be non-zero only when 
  $\bOmega \cdot \bU = \dfrac1{E^0}(\bE^1 \cdot \bU)$. We
  will repeatedly make use of this fact in the following 
  discussions.

  We study the two possible cases:
  \begin{enumerate}
    \item Suppose $\bU$ is aligned with some eigenvector of $\bbrE^2$. 
      Without loss of generality, we assume $\bR_3\slash\slash\bU$. 
      Then a non-negative distribution could be non-zero only on 
      $\bOmega\cdot\bR_3 = \dfrac{F_3}{E^0}$. In addition,
      \begin{equation}\label{eq:eigenvector-V}
        0 = \bU^T \bbrV \bU = \bR_3^T \left[\dfrac1{E^0} \bbrE^2 - 
          \left(\dfrac{\bE^1}{E^0} \right) \left(\dfrac{\bE^1}{E^0}
        \right)^T\right] \bR_3 = \dfrac{\lambda_3}{E^0} - \left(
        \dfrac{F_3}{E^0} \right)^2,
      \end{equation}
      which gives $\lambda_3 = \dfrac{F_3^2}{E^0}$.
      If $F_3 = 0$ then $\lambda_3 = 0$, which has been 
      ruled out in our assumptions. So $F_3 \not= 0$, which means a non-negative 
      distribution \eqref{eq:B2-ansatz} can only be
      \begin{equation}\label{eq:single-delta-dist}
        \bansatz = \dfrac{E^0}{2 \pi}
        \delta\left(\bOmega\cdot\bR_3 - \dfrac{F_3}{E^0}\right).
      \end{equation}
      Therefore $w_1 = w_2 = 0$, and by \eqref{eq:sigma-def} and 
      \eqref{eq:moment-problem-1D} we would have
      $\sigma_1 = \sigma_2 = F_1 = F_2 = 0$. Substituting this into \eqref{eq:w-cond}
      gives $\lambda_1 = \lambda_2 = \dfrac12(w_3 - \lambda_3)$.
      Conversely, moments satisfying $\lambda_1 = \lambda_2$ and $F_1 = F_2 = 0$
      in addition to $\lambda_3 = \dfrac{F_3^2}{E^0}$ could be generated by the ansatz 
      \eqref{eq:single-delta-dist}. 

    \item Consider the case when $\bU$ is not aligned to any $\bR_j$. 
      The only way to give a non-negative 
      distribution for \eqref{eq:B2-ansatz} in this case
      is
      \[
        \bansatz = \sum\limits_{i = 1}^3 [ \alpha_i^+ \delta(\bOmega \cdot \bR_i
        - 1) + \alpha_i^- \delta(\bOmega \cdot \bR_i + 1) ].
      \]
      Hence $\sigma_j = w_j $, $j=1,2,3$. Combining these with \eqref{eq:w-cond}
      gives $\sigma_j = \lambda_j$, $j = 1,2,3$.
      But condition \eqref{eq:condition-positive-ansatz} 
      require
      \begin{equation}
        \left|F_j\right| \leq \lambda_j,\quad
        j = 1,2,3.
      \end{equation}
      Recall assumption \eqref{eq:cond-boundary}, and
      notice  
      \begin{equation}
        E^0 = \dfrac{F_1^2}{\lambda_1}
        +\dfrac{F_2^2}{\lambda_2}
        +\dfrac{F_3^2}{\lambda_3}
        \leq\lambda_1+\lambda_2+\lambda_3=E^0.
      \end{equation}
      For all inequalities to hold, we need 
      \begin{equation}\label{cond-boundary-ellipsoid}
        \left|F_j\right|=\lambda_j,~~j=1,2,3.
      \end{equation}
      Conversely, for moments satisfying condition \eqref{cond-boundary-ellipsoid}, 
      choosing 
      \begin{equation}
        \sigma_j = \lambda_j,\quad j = 1,2,3.
      \end{equation}
      would give a non-negative ansatz.
  \end{enumerate}
  The proof is completed.
\end{proof}

We now turn to specifying the formula for $f$. We take $f$
to be the beta distribution used in the $B_2$ ansatz for slab geometry
\begin{equation}\label{eq:beta-dist}
  f(\mu; \gamma, \delta) = \mathcal{F}(\mu; \gamma, \delta),
  \quad 
  \xi  = \frac\gamma\delta, \quad
  \eta = \frac{1 - \gamma}\delta.
\end{equation}

Retaining only one term in \eqref{eq:B2-ansatz} would provide the same 
ansatz as the one-dimensional $B_2$ ansatz which we studied previously 
\cite{alldredge2016approximating}. Taking $\xi = \eta = 1$ in equation
\eqref{eq:beta-dist} would give $f$ as a constant function. If either $\xi$
or $\eta$ approach zero, the limit of the function $f$ is a Dirac function. 
If both of them go to zeros at a fixed rate, the function $f$ will become 
a combination of two Dirac functions. This capacity of \eqref{eq:beta-dist}
to interpolate between the constant function and Dirac functions is a 
feature it shares with the $M_2$ ansatz. Also, for slab geometry, the $B_2$ 
model possesses numerous nice properties similar to the $M_2$ model;
therefore, we use it as building blocks for three-dimensional ansatz.

If \eqref{eq:beta-dist} is the distribution function $f$ in 
\eqref{eq:sigma-def} and \eqref{eq:moment-problem-1D}, then for
$\sigma_i$, $w_i$ and $F_i$ satisfying the realizability condition 
\eqref{eq:condition-realizable}, we have  
\[
\xi_i \geq 0,\quad \eta_i \geq 0,
\]
which gives an integrable function for \eqref{eq:beta-dist}.
For the above cases, the parameters $\gamma_i$ and $\delta_i$ are given 
as follow:
\begin{lemma}\label{lem:gamma-delta}
  If \eqref{eq:condition-positive-ansatz} is fulfilled, we have
  \begin{equation}\label{eq:gamma-cond}
    \gamma_i = \frac{F_i  + w_i }{ 2 w_i} \quand 
    \delta_i = -\frac{ F_i^2 
      - \sigma_i w_i}{w_i^2 - \sigma_i w_i},\quad
    \forall i = 1,2,3.
  \end{equation}
\end{lemma}
\begin{proof}
  Note that the standard $\beta$ distribution
  $\dfrac1{\Beta(\xi,\eta)} x^{\xi - 1} (1 - x)^{\eta - 1}$ has the
  properties \cite{johnson1970discrete}:
  \[
  \begin{split}
    & \int_0^1 x \dfrac1{\Beta(\xi,\eta)} x^{\xi - 1}
    (1 - x)^{\eta - 1} = \dfrac{\xi}{\xi + \eta}, \\
    & \int_0^1 x^2 \dfrac1{\Beta(\xi,\eta)} x^{\xi - 1}
    (1 - x)^{\eta - 1} = \dfrac{\xi (\xi + 1)}
    {(\xi + \eta)(\xi + \eta + 1)}.
  \end{split}
  \]
  Therefore,
  \begin{equation}\label{eq:1D-1moment}
    \begin{split}
      & \int_{-1}^1 \mu f(\mu;\gamma_i,\delta_i)
      \dd\mu  
      \xlongequal{x = \frac12 (1 + \mu)} 
      \int_0^1 (2x - 1) \dfrac1{\Beta(\xi_i, \eta_i)} 
      x^{\xi_i - 1} (1-x)^{\eta_i - 1} \dd x\\
      = & 2\int_0^1 x \dfrac1{\Beta(\xi_i, \eta_i)}
      x^{\xi_i - 1} (1 - x)^{\eta_i - 1} \dd x
      - 1 
      = 2 \dfrac{\xi_i}{\xi_i + \eta_i} - 1 
      = 2 \gamma_i - 1.
    \end{split}
  \end{equation}
  Also,
  \begin{equation}\label{eq:1D-2moment}
    \begin{split}
      & \int_{-1}^1 \mu^2 f(\mu;\gamma_i,\delta_i)
      \dd\mu  
      \xlongequal{x = \frac12 (1 + \mu)} 
      \int_0^1 (2x - 1)^2 \dfrac1{\Beta(\xi_i, \eta_i)} 
      x^{\xi_i - 1} (1-x)^{\eta_i - 1} \dd x\\
      = & 4\int_0^1 x^2 \dfrac1{\Beta(\xi_i, \eta_i)}
      x^{\xi_i - 1} (1 - x)^{\eta_i - 1} \dd x
      - 4\int_0^1 x \dfrac1{\Beta(\xi_i, \eta_i)}
      x^{\xi_i - 1} (1 - x)^{\eta_i - 1} \dd x
      + 1 \\
      = & 4 \dfrac{\xi_i (\xi_i + 1)}{(\xi_i + \eta_i)
        (\xi_i + \eta_i + 1)} -4 \dfrac{\xi_i}{\xi_i + \eta_i}
      + 1 
      = 4 \dfrac{\gamma_i(\gamma_i - 1)}{1 + \delta_i} + 1.
    \end{split}
  \end{equation}
  Combining \eqref{eq:1D-1moment}, \eqref{eq:1D-2moment} with
  \eqref{eq:sigma-def}, \eqref{eq:moment-problem-1D}  
  gives us \eqref{eq:gamma-cond}.
\end{proof}
Note that \eqref{eq:sigma-def}, \eqref{eq:moment-problem-1D}, and
\eqref{eq:w-cond} together are the necessary and sufficient conditions 
for consistency constraints to all known
moments. This leaves $\sigma_i$, $i=1,2,3$, to be the three free
parameters. We shall return to the problem of determining $\sigma_i$
later. For the present, we assume $\sigma_i$, $i = 1,2,3$ are all given, and the
following lemma gives the closure relationship of the $B_2$ model.
\begin{lemma}\label{lem:E3}
  Let
  $\mathrm{\boldsymbol{R}} = [\bR_1, \bR_2, \bR_3] \in \bbR^{3\times
    3}$,
  and denote by $R_{ij}$ the entries of the matrix
  $\mathrm{\boldsymbol{R}}$, the flux closure is then given by
  $\bff(E^0, \bE^1, \bbrE^2)$, which relies on $\bE^1$, $\bbrE^2$ and
  $\bbrE^3$, with $\bbrE^3$ given as
\[
E^3_{ijk} =   \Vint{ (\bOmega\cdot\bR_l)
  (\bOmega\cdot\bR_m)
  (\bOmega\cdot\bR_n) \bansatz}
R_{il} R_{jm} R_{kn},
\]
where the Einstein summation convention is used.
  For distribution ansatz $\bansatz$ given by \eqref{eq:B2-ansatz},
  \begin{equation}\label{eq:B2-closure}
    \begin{aligned}
      &\Vint{ (\bOmega\cdot\bR_l) (\bOmega\cdot\bR_m)
    (\bOmega\cdot\bR_n) \bansatz} = \\ & \qquad \qquad \qquad \left
      \{
        \begin{array}{l}
          \dfrac{ F_l (\sigma_l^2 
          + 2 F_l^2 - 3 w_l \sigma_l)}
          {2 F_l^2 - w_l \sigma_l - w_l^2},
          ~~\text{if } l = m = n,\\ [4mm]
          \dfrac{ F_l }{2}\left(1-
            \dfrac{ \sigma_l^2 
            + 2 F_l^2 - 3 w_l \sigma_l }
            { 2 F_l^2 - w_l \sigma_l - w_l^2 }
          \right),~~\text{if }m=n,~m\not=l,\\ [4mm]
          0,~~\text{if}~l\not=m\not=n.
        \end{array}\right.
      \end{aligned}
    \end{equation}
  \end{lemma}
  \begin{proof}
    Consider the case when $l = m = n = 1$ at first.
    \[
      \Vint{ (\bOmega\cdot\bR_l) (\bOmega\cdot\bR_m)
      (\bOmega\cdot\bR_n) \bansatz} = 
      \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_1)^3  
      \sum_{i = 1}^3 w_i f(\bOmega\cdot\bR_i; 
      \gamma_i, \delta_i) \dd\bOmega.
    \]
    By Lemma \ref{lem:integral-orthogonal},
    \[
      \int_{\bbS^2} (\bOmega\cdot\bR_1)^3 w_2 f(\bOmega\cdot\bR_2;
      \gamma_2, \delta_2) \dd\bOmega = \int_{\bbS^2}
      (\bOmega\cdot\bR_1)^3 w_3 f(\bOmega\cdot\bR_3; \gamma_3, \delta_3)
      \dd\bOmega = 0,
    \]
    and
    \[
      \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_1)^3  
      w_1 f(\bOmega\cdot\bR_1; \gamma_1, \delta_1)
      \dd\bOmega = w_1 \int_{-1}^1
      \mu^3 f(\mu;\gamma_1,\delta_1) \dd\mu.
    \]
Note that the standard $\beta$ distribution
$\dfrac1{\Beta(\xi,\eta)} x^{\xi - 1} (1 - x)^{\eta - 1}$ has the
property \cite{johnson1970discrete}:
\[
  \int_0^1 x^3 \dfrac1{\Beta(\xi,\eta)} x^{\xi - 1}
  (1 - x)^{\eta - 1} = \dfrac{\xi (\xi + 1) (\xi + 2)}
  {(\xi + \eta)(\xi + \eta + 1)(\xi + \eta + 2)}.
\]
Therefore,
\[
  \begin{split}
    & \int_{-1}^1 \mu^3 f(\mu;\gamma_1,\delta_1)
    \dd\mu  
    \xlongequal{x = \frac12 (1 + \mu)} 
    \int_0^1 (2x - 1)^3 \dfrac1{\Beta(\xi_1, \eta_1)} 
    x^{\xi_1 - 1} (1-x)^{\eta_1 - 1} \dd x\\
    = & 8\int_0^1 x^3 \dfrac1{\Beta(\xi_1, \eta_1)}
    x^{\xi_1 - 1} (1 - x)^{\eta_1 - 1} \dd x
    - 12\int_0^1 x^2 \dfrac1{\Beta(\xi_1, \eta_1)}
    x^{\xi_1 - 1} (1 - x)^{\eta_1 - 1} \dd x\\
    & + 6\int_0^1 x \dfrac1{\Beta(\xi_1, \eta_1)}
    x^{\xi_1 - 1} (1 - x)^{\eta_1 - 1} \dd x
    - 1 \\
    = & \dfrac{8 \xi_1 (\xi_1 + 1) (\xi_1 + 2)}{(\xi_1 + \eta_1)
  (\xi_1 + \eta_1 + 1) (\xi_1 + \eta_1 + 2)} -  
  \dfrac{12 \xi_1 (\xi_1 + 1)}{(\xi_1 + \eta_1)
  (\xi_1 + \eta_1 + 1)} + \dfrac{6 \xi_1}{\xi_1 + \eta_1}
  - 1\\ 
  =  & \dfrac{(\xi_1 - \eta_1) (\xi_1^2 - 2 \xi_1 \eta_1 + 3 \xi_1
  + \eta_1^2 + 3 \eta_1 + 2)}{(\xi_1 + \eta_1) (\xi_1 + \eta_1 + 1)
  (\xi_1 + \eta_1 + 2)}.
\end{split}
  \]
  Recall \eqref{eq:beta-dist} and Lemma \ref{lem:gamma-delta}
  for the values of $\xi_1$ and $\eta_1$, we have
  \[
    \begin{split}
      & \int_{-1}^1 \mu^3 f(\mu;\gamma_1,\delta_1)
      \dd\mu \\
      = & \dfrac{(\xi_1 - \eta_1) (\xi_1^2 - 2 \xi_1 \eta_1 + 3 \xi_1
    + \eta_1^2 + 3 \eta_1 + 2)}{(\xi_1 + \eta_1) (\xi_1 + \eta_1 + 1)
    (\xi_1 + \eta_1 + 2)} \\
    = & \dfrac{ F_1 (\sigma_1^2 
  + 2 F_1^2 - 3 w_1 \sigma_1)}
  {2 F_1^2 - w_1 \sigma_1 - w_1^2}.
\end{split}
      \]
For $l = m = n = 2$ or $l = m = n = 3$ the computation is similar.

Now consider the case when $m = n$, $m\not=l$. Suppose $m = n = 1$ and $l = 2$.
Let us start by proving
\[
  \Vint{ (\bOmega\cdot\bR_1)^2 (\bOmega\cdot\bR_2) \bansatz }=  
  \Vint{ (\bOmega\cdot\bR_3)^2 (\bOmega\cdot\bR_2) \bansatz }.
\]
First, compute $\Vint{ (\bOmega\cdot\bR_1)^2 (\bOmega\cdot\bR_2) \bansatz }$.
\[
  \Vint{ (\bOmega\cdot\bR_1)^2 (\bOmega\cdot\bR_2)
  \bansatz} = 
  \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_1)^2
  (\bOmega\cdot\bR_2)
  \sum_{i = 1}^3 w_i f(\bOmega\cdot\bR_i; 
  \gamma_i, \delta_i) \dd\bOmega.
\]
Again by Lemma \ref{lem:integral-orthogonal},
\[
  \begin{split}
    & \int_{\bbS^2} (\bOmega\cdot\bR_1)^2
    (\bOmega\cdot\bR_2)
    w_3 f(\bOmega\cdot\bR_3; \gamma_3, \delta_3)
    \dd\bOmega \\
    = & \int_{\bbS^2} (\bOmega\cdot\bR_1)^2  
      (\bOmega\cdot\bR_2) w_1 f(\bOmega\cdot\bR_1; \gamma_1, \delta_1)
      \dd\bOmega \\
    = & 0,
\end{split}
  \]
  and
  \[
    \dfrac1{2\pi} \int_{\bbS^2} (\bOmega\cdot\bR_1)^2
    (\bOmega\cdot\bR_2)
    w_2 f(\bOmega\cdot\bR_2; \gamma_2, \delta_2)
    \dd\bOmega =  \frac 12 w_2 \int_{-1}^1
    (1 - \mu^2) \mu f(\mu;\gamma_2,\delta_2) \dd\mu.
  \]
Thus we have
\[
  \Vint{ (\bOmega\cdot\bR_1)^2 (\bOmega\cdot\bR_2)
  \bansatz} = \frac 12 w_2 \int_{-1}^1
  (1 - \mu^2) \mu f(\mu;\gamma_2,\delta_2) \dd\mu,
\]
and similarly,
\[
  \Vint{ (\bOmega\cdot\bR_3)^2 (\bOmega\cdot\bR_2)
  \bansatz} = \frac 12 w_2 \int_{-1}^1
  (1 - \mu^2) \mu f(\mu;\gamma_2,\delta_2) \dd\mu.
\]
Then we get
\[
  \Vint{ (\bOmega\cdot\bR_1)^2 (\bOmega\cdot\bR_2) \bansatz }=  
  \Vint{ (\bOmega\cdot\bR_3)^2 (\bOmega\cdot\bR_2) \bansatz }.
\]
On the other hand,
\[
  \Vint{ (\bOmega\cdot\bR_1)^2 (\bOmega\cdot\bR_2) \bansatz } +  
  \Vint{ (\bOmega\cdot\bR_3)^2 (\bOmega\cdot\bR_2) \bansatz } + 
  \Vint{ (\bOmega\cdot\bR_2)^3 \bansatz } = 
  \Vint{ (\bOmega\cdot\bR_2) \bansatz } = F_2.
\]
It follows that
\[
  \Vint{ (\bOmega\cdot\bR_1)^2 (\bOmega\cdot\bR_2) \bansatz } =   
  \Vint{ (\bOmega\cdot\bR_3)^2 (\bOmega\cdot\bR_2) \bansatz } = 
  \dfrac{ F_2 }{2}\left(1-
    \dfrac{ \sigma_2^2 
    + 2 F_2^2 - 3 w_2 \sigma_2 }
    { 2 F_2^2 - w_2 \sigma_2 - w_2^2 }
  \right).
\]

Now we look at $\Vint{ (\bOmega\cdot\bR_1) (\bOmega\cdot\bR_2)
(\bOmega\cdot\bR_3) \bansatz}$.
Once more by Lemma \ref{lem:integral-orthogonal},
\[
  \begin{split}
    & \int_{\bbS^2} (\bOmega\cdot\bR_1) (\bOmega\cdot\bR_2) 
    (\bOmega\cdot\bR_3) w_1 f(\bOmega\cdot\bR_1; 
    \gamma_1, \delta_1) \dd\bOmega \\
    = & \int_{\bbS^2} (\bOmega\cdot\bR_1) (\bOmega\cdot\bR_2) 
    (\bOmega\cdot\bR_3) w_2 f(\bOmega\cdot\bR_2; 
    \gamma_2, \delta_2) \dd\bOmega  \\
    = & \int_{\bbS^2} (\bOmega\cdot\bR_1) (\bOmega\cdot\bR_2) 
    (\bOmega\cdot\bR_3) w_3 f(\bOmega\cdot\bR_3; 
    \gamma_3, \delta_3) \dd\bOmega  \\
    = & ~0.
  \end{split}
\]
Therefore,
\[
  \Vint{ (\bOmega\cdot\bR_1) (\bOmega\cdot\bR_2)
  (\bOmega\cdot\bR_3) \bansatz} = 0.
\]
Summarizing the results from the above three cases completes the proof of this 
lemma.
\end{proof}

\tikzstyle{midpoint}=[circle,draw=black!50,fill=black,inner sep=1pt]
\begin{figure}[htbp]
  \centering
  \begin{tikzpicture}[font = \sansmath]
  \draw (0,0) coordinate (a)--+(3,0) coordinate (b)--+(60:3) coordinate (c) --cycle;
  \foreach\x[remember=\x as \lastx (initially c)] in{a,b,c}{
    \node[fill,circle,inner sep=1pt] at ($(\x)$) {};
  }
\node (pointP) at ( 1.2,1) [midpoint] {};
\node [black,above] at (pointP.east) {$P$};
\coordinate (Q) at (intersection of c--pointP and a--b);
\node (pointP1) at (Q) [midpoint] {};
\node [black,below] at (pointP1.east) {$P_1$};
\draw[dashed] (c) -- (Q);
\coordinate (U) at (intersection of a--pointP and b--c);
\node (pointP2) at (U) [midpoint] {};
\node [black,right] at (pointP2.east) {$P_2$};
\draw[dashed] (a) -- (U);
\coordinate (W) at (intersection of b--pointP and a--c);
\node (pointP3) at (W) [midpoint] {};
\node [black,left] at (pointP3.west) {$P_3$};
\draw[dashed] (b) -- (W);
\end{tikzpicture}
\caption{Schematic diagram of the interpolation}
\label{fig:schematic-interpolation}
\end{figure}

It remains to give $\sigma_i$, $i = 1,2,3$. Note that the trace of the
matrix $\bbrE^2$ equals $E^0$, so $\lambda_i$ satisfy the constraint
\[
\lambda_1 + \lambda_2 + \lambda_3 = E^0.
\]
And due to the positive semi-definiteness of $\bbrE^2$, we have
$\lambda_i\geq0$, $i=1,2,3$. This allows us to regard
$\left( \dfrac{\lambda_1}{E^0}, \dfrac{\lambda_2}{E^0},
  \dfrac{\lambda_3}{E^0} \right)$
as the barycentric coordinates of a point $\bP$ within a triangle (see
\figref{schematic-interpolation}). At the vertices of this triangle,
only one of the three eigenvalues of $\bbrE^2$ is non-zero. By the
similar arguments in the proof of Lemma \ref{lem:lambda2sigma}, a
non-negative $\bansatz$ in such cases retains only one of its three
terms. Combining this fact with \eqref{eq:w-cond} gives us the
closure at the vertices of the triangle:
\begin{center}
\begin{tabular}{ccc}
  $\left( \dfrac{\lambda_1}{E^0}, \dfrac{\lambda_2}{E^0},
  \dfrac{\lambda_3}{E^0} \right)$ & $\mapsto$ & 
  $(\sigma_1, \sigma_2, \sigma_3)$ \\
  $(1, 0, 0)$ & & $(E_0, 0, 0)$ \\
  $(0, 1, 0)$ & & $(0, E_0, 0)$ \\
  $(0, 0, 1)$ & & $(0, 0, E_0)$ \\
\end{tabular}
\end{center}
Now that the value of $(\sigma_1, \sigma_2, \sigma_3)$ at the vertices
are specified by the closure relation, we are to propose a smooth
extension of the functions $\sigma_i$ at the vertices to the whole
triangle, then a smooth extension of the closure relation is
achieved. A natural extension is a scaled identity map as
\[
\left( \dfrac{\lambda_1}{E^0}, \dfrac{\lambda_2}{E^0},
  \dfrac{\lambda_3}{E^0} \right) \mapsto \left( \lambda_1, \lambda_2,
  \lambda_3 \right),
\]
However, by \eqref{eq:w-cond} this extension results in
$w_j = \sigma_j$. As a consequence, the ansatz would always be linear
combinations of Dirac functions. It cannot include any smooth
functions, particularly it cannot recover a constant distribution at
the equilibrium. Moreover, such an extension does not depend on the
first-order moments $F_i$ at all, which is definitely not
appropriate. This motivates us to seek other ways of extending.

To figure out an appropriate extension, we assume it takes the following  
general but decomposed form
\begin{equation}\label{eq:sigma-decompose}
\sigma_i = \sum_{j=1}^3 s_j \sigma_i^j, \quad i = 1,2,3.
\end{equation}
It is assumed that $s_j$ is a weight function that relies only on $\lambda_j$, 
and $\sigma_i^j$ is a function that depends on both the first-order moments and the eigenvalues 
of the second-order moments but that is independent of $\lambda_j$. 

First, we determine the values of the weights, $s_j$. Our approach is 
motivated by geometric considerations. It is illustrated in
\figref{schematic-interpolation}. For the point $\bP$, we connect each 
vertex to $\bP$ and extend the line segment until it intersects with the
opposite side. Those three intersection points are denoted $\bP_j$,
$j = 1,2,3$, where the index $j$ indicates that $\bP_j$ lies on the side where
$\lambda_j = 0$. Denote the barycentric coordinates of $\bP_j$ by 
$\bP_j = \left( \dfrac{\lambda^j_1}{E^0}, \dfrac{\lambda^j_2}{E^0},
\dfrac{\lambda^j_3}{E^0} \right)$.
Therefore,
\[
  \lambda_i = \sum\limits_{j=1}^3 s_j \lambda^j_i,\quad
  j = 1,2,3,
\]
where
\begin{equation}\label{eq:weight-split} 
  s_1 = \frac12(\lambda_2+\lambda_3),\quad
  s_2 = \frac12(\lambda_1+\lambda_3),\quad
  s_3 = \frac12(\lambda_1+\lambda_2).
\end{equation}
The functions in \eqref{eq:weight-split} are used as the weights $s_j$, 
$j=1,2,3$.

The next thing is to specify $\sigma^j_i$.
Consider a $3 \times 3$ matrix with the nine functions,
$\sigma^j_i \left(\dfrac{\lambda_1}{E^0},
  \dfrac{\lambda_2}{E^0},\dfrac{\lambda_3}{E^0};
  \dfrac{F_1}{E^0},\dfrac{F_2}{E^0}, \dfrac{F_3}{E^0}\right)$,
$i, j = 1,2,3$, as its elements. Naturally, one would expect $\sigma^j_i$
to have symmetry in the permutation of indices. Precisely, if $\tau$ is a permutation on
the index set $\{1,2,3\}$, then for $\forall i, j = 1,2,3$,
\[
\sigma^j_i \left(\dfrac{\lambda_1}{E^0},
  \dfrac{\lambda_2}{E^0},\dfrac{\lambda_3}{E^0};
  \dfrac{F_1}{E^0},\dfrac{F_2}{E^0}, \dfrac{F_3}{E^0}\right) =
\sigma^{\tau(j)}_{\tau(i)} \left(\dfrac{\lambda_{\tau(1)}}{E^0},
  \dfrac{\lambda_{\tau(2)}}{E^0},\dfrac{\lambda_{\tau(3)}}{E^0};
  \dfrac{F_{\tau(1)}}{E^0},\dfrac{F_{\tau(2)}}{E^0},
  \dfrac{F_{\tau(3)}}{E^0}\right).
\]
Thus, we have only two functions for all $\sigma^j_i$:
\begin{itemize}
\item The three diagonal entries, $\sigma^i_i$, $i = 1,2,3$, have the
  same form;
\item All six off-diagonal entries, $\sigma^j_i$, $i \neq j$, have
  the same form.
\end{itemize}
Since $\sigma_i^j$ is assumed to be independent of $\lambda_j$, it
should be constant on the line segment ${\bP \bP_j}$. As an example, 
since $\sigma_i^1$ does not depend on $\lambda_1$, it should
be independent of $\lambda_2 + \lambda_3$. Therefore, one may use 
$\dfrac{\lambda_2} {\lambda_2 + \lambda_3}$ and
$\dfrac{\lambda_3}{\lambda_2 + \lambda_3}$ to replace $\lambda_2$ and $\lambda_3$
as variables in $\sigma_i^1$. Noticing that
$\left(0, \dfrac{\lambda_2} {\lambda_2 + \lambda_3},
\dfrac{\lambda_3}{\lambda_2 + \lambda_3}\right)$
is the barycentric
coordinate of $\bP_1$, we thus have
$\left. \sigma_i^1 \right|_{\bP} = \left. \sigma_i^1 \right|_{\bP_1}$,
and it is constant on line ${\bP \bP_1}$.

Moreover, this makes us assume $\sigma_i^j$ is also independent of $F_j$.
The reason is as follows. By Lemma \ref{lem:lambda2sigma}, the only region
in which \eqref{eq:B2-ansatz} might have a non-negative distribution when
$\lambda_j = 0$ is the rectangle $|F_k| \leq \lambda_k$, $k \neq j$.
Therefore, even when all three $\lambda_j$, $j = 1,2,3$, are positive,
we restrict our expected region to have a non-negative distribution 
inside the box $|F_k| \leq \lambda_k$, $k = 1,2,3$. Note that
this domain of $F_j$ depend on $\lambda_j$ while
$\sigma_i^j$ does not rely on $\lambda_j$, so we are induced to let 
$\sigma_i^j$ to be independent of $F_j$.

We proceed to specify $\sigma^j_i$ by constraints at vertices and
sides of the triangle. We first investigate the vertices to conclude
that
\begin{lemma}
With the assumptions above on $\sigma_i^j$, we have
\[
\sigma_i^i \equiv 0, \quad i = 1,2,3.
\]
\end{lemma}
\begin{proof}
  First, take the vertex in which $\lambda_1 = 1$ and
  $\lambda_2 = \lambda_3 = 0$. On this vertex one needs $\sigma_1 = 1$,
  and $\sigma_2 = \sigma_3 = 0$. We have
  \[
  \left.\sigma_1\right|_{\lambda_1 = 1} = \frac12(\left.\sigma^2_1\right|_{\lambda_1 = 1} 
  + \left.\sigma^3_1\right|_{\lambda_1 = 1}).
  \]
  Due to symmetry we know $\sigma^2_1 = \sigma^3_1$ on this vertex.
  Therefore, we have to let $\left.\sigma^2_1\right|_{\lambda_1 = 1}
  = \left.\sigma^3_1\right|_{\lambda_1 = 1} = 1$. Meanwhile, 
  \[
  \left.\sigma_2\right|_{\lambda_1 = 1} = \frac12(
  \left.\sigma^2_2\right|_{\lambda_1 = 1} + 
  \left.\sigma^3_2\right|_{\lambda_1 = 1}) = 0.
  \]
  This induces us to impose $\sigma^2_2 = \sigma^3_2 = 0$ on this vertex. 
  Next, consider the case on the side where $\lambda_1 = 0$. By Lemma
  \ref{lem:lambda2sigma}, $\sigma_1 = 0$. Recalling the consistency
  constraints \eqref{eq:w-cond}, we have
  \begin{equation}\label{eq:constraint-sigma23}
    \sigma_2 - \sigma_3 = \lambda_2 - \lambda_3.
  \end{equation}
  Consider any point $\bP$ on the side $\lambda_1 = 0$.
  Then, in \eqref{eq:sigma-decompose}, the function
  $\sigma^1_1$ takes its value at $\bP$ itself, while
  $\sigma^2_1$ is evaluated at the vertex $\lambda_3 = 1$, and 
  $\sigma^3_1$ is evaluated at the vertex $\lambda_2 = 1$.
  Then, on this side, we have
  \[
  \begin{split}
    \sigma_1 & = \frac12(\lambda_2 + \lambda_3) \sigma^1_1
    + \frac12(\lambda_1 + \lambda_3) \left.\sigma^2_1\right|_{\lambda_3 = 1}
    + \frac12(\lambda_1 + \lambda_2) \left.\sigma^3_1\right|_{\lambda_2 = 1} \\
    & = \frac12\sigma^1_1 + \frac12 \lambda_3 
    \left.\sigma^2_1\right|_{\lambda_3 = 1} + 
    \frac12 \lambda_2 \left.\sigma^3_1\right|_{\lambda_2 = 1} \\
    & = \frac12\sigma^1_1 = 0.
  \end{split}
  \]
  This proves that $\sigma^1_1 = 0$ on this side. 

  The above discussions show that $\sigma^i_i$ vanishes both at the vertex with 
  $\lambda_i = 1$ and on the side with $\lambda_i = 0$. Also, recall that $\sigma^i_i$ 
  is constant along straight lines passing through the vertex $\lambda_1 = 1$.
  Hence it is zero on the whole triangle. By symmetry, we have $\sigma_i^i
  \equiv 0$, $i=1,2,3$, on the whole triangle.

\end{proof}

We now turn to specifying $\sigma^j_i$ on the sides. 
On the side where $\lambda_1 = 0$, we also have
\[
  \begin{split}
    \sigma_2 = & \frac12(\lambda_2 + \lambda_3) \sigma^1_2 
    + \frac12(\lambda_1 + \lambda_3) 
    \left.\sigma^2_2\right|_{\lambda_3 = 1}
    + \frac12(\lambda_1 + \lambda_2) \left.\sigma^3_2\right|_{\lambda_2 = 1} \\
    = & \frac12 \sigma^1_2 + \frac12 \lambda_2 \left.\sigma^3_2\right|_{\lambda_2 = 1} 
    \qquad
  \text{notice } \sigma^3_2 = 1 \text{ on this vertex}\\
  = & \frac12 \sigma^1_2 + \frac12 \lambda_2,
\end{split}
\]
and
\[
  \sigma_3 = \frac12 \sigma^1_3 + \frac12 \lambda_3.
\]
Substracting these two equations yields
\[
  \sigma_2 - \sigma_3 = \frac12 (\sigma^1_2 - \sigma^1_3) + 
  \frac12 (\lambda_2 - \lambda_3).
\]
By \eqref{eq:constraint-sigma23}, we have
\[
\sigma^1_2 - \lambda_2 = \sigma^1_3 - \lambda_3.
\]
Recalling our previous assumption that $\sigma^1_2$ and $\sigma^1_3$ 
are independent of $\lambda_1$ and $F_1$, one has to set
\begin{equation}\label{eq:sigma-on-bound}
  \begin{split}
    & \sigma_2^1 = \lambda_2
    + h\left(\lambda_2, \lambda_3;
    F_2, F_3 \right),\\
    & \sigma_3^1 = \lambda_3
    + h\left(\lambda_2, \lambda_3;
    F_2, F_3\right),
  \end{split}
\end{equation}
where $h$ is a function with symmetry
\[
h(x,y;F_x,F_y) = h(y,x;F_y,F_x).
\]

The only thing remaining is to specify a particular
function $h$, so that all $\sigma_i^j$, $i \neq j$, would be assigned. In
choosing the function $h$, we have some constraints. For example:
\begin{enumerate}
\item On all three vertices, the values of $\sigma^j_k$ given by
  \eqref{eq:sigma-on-bound} are consistent with the discussions
  above.
\item The ansatz should cover the equilibrium distribution at the
  barycenter of the triangle.
\end{enumerate}
With these constraints, our objective is to find an $h$ for which the region
where $\bansatz$ is a non-negative integrable function is as large as 
possible. The requirements for $h$ can be summarized in the
following lemma:
\begin{lemma}\label{lem:requirements-h}
  Consider the case when $\lambda_1 = 0$.  For consistency with
  previous constraints on the vertices, the need to contain
  equilibrium, and to generate a non-negative ansatz for all moments
  within the region specified by Lemma \ref{lem:lambda2sigma}, $h$
  should satisfy the following:
  \begin{enumerate}
  \item \label{item:sign-h} $h(\lambda_2,\lambda_3; F_2, F_3) \leq 0$,
    within the rectangle $|F_j| \leq \lambda_j$, $j = 2,3$.
  \item \label{item:value-h} $-\frac12 h(\lambda_2,\lambda_3; F_2,F_3) \leq 
    \min\left\{\lambda_2 - |F_2|, \lambda_3 - |F_3|\right\}$.
  \item\label{item:vertex} $h(0,1; 0,F_y) = 0$, $h(1,0; F_x,0) = 0$.
  \item \label{item:equilibrium} $h(\frac12,\frac12,0,0) = -\frac13$.
  \item \label{item:boundary} $h(x, y; \pm x,\pm y) = 0$.
  \end{enumerate}
\end{lemma}
\begin{proof}
  Items \ref{item:sign-h} and \ref{item:value-h} come from requiring
  $\bansatz$ to be a non-negative distribution for the rectangle
  region in Lemma \ref{lem:lambda2sigma}.  Recalling that on the side
  $\lambda_1 = 0$, we have
  \begin{equation}\label{eq:sigma23}
    \sigma_j = \lambda_j + \frac12 h(\lambda_2,\lambda_3; F_2,F_3),
    \quad j = 2,3.
  \end{equation}
  From Lemma \ref{lem:lambda2sigma}, a non-negative distribution for
  \eqref{eq:B2-ansatz} in such cases require
  $|F_j| \leq \sigma_j \leq \lambda_j$, $j = 2,3$.  Hence
  \[
    h(\lambda_2,\lambda_3; F_2,F_3) \leq 0,
  \]
  and
  \[
    -\frac12 h(\lambda_2,\lambda_3; F_2,F_3) \leq 
    \min\left\{\lambda_2 - |F_2|, \lambda_3 - |F_3|\right\}.
  \]

  Item \ref{item:vertex} is due to consistency on vertices.  For
  instance, consider the case when $\lambda_2 = 1$, which should
  correspond to $\left.\sigma_2\right|_{\lambda_2 = 1} = 1$,
  $\left.\sigma_3\right|_{\lambda_2 = 1} = 0$. Plugging these into
  \eqref{eq:sigma23} gives item \ref{item:vertex}.

  Item \ref{item:equilibrium} comes from recovering equilibrium.  At
  equilibrium, $\lambda_j = \dfrac13$, $F_j = 0$, $j = 1,2,3$.  Direct
  calculation gives item \ref{item:equilibrium}.

  Item \ref{item:boundary} also derives from the non-negativity of
  the ansatz. It is a direct consequence of the discussions in Lemma
  \ref{lem:lambda2sigma}. In fact, it will naturally be satisfied if
  both requirements \ref{item:sign-h} and \ref{item:value-h} are
  satisfied. However, unlike either, it poses a direct constraint on the
  value of $h$ at certain points, which, therefore, is particularly
  useful when trying to propose a formula for $h$.

\end{proof}

In seeking $h(x,y; F_x,F_y)$, we start with item \ref{item:boundary}
in Lemma \ref{lem:requirements-h}, which suggests that $h(x,y; F_x,F_y)$
contains the factor
\begin{equation}\label{eq:h-factor}
  q(x,y; F_x,F_y) = \left(x - \dfrac{F_x^2}{x}\right) 
  \left(y - \dfrac{F_y^2}{y}\right).
\end{equation}
Note that as discussed in Lemma \ref{lem:lambda2sigma},
$\lambda_2 = 0$ would induce $F_2 = 0$, so this construction also
guarantees item \ref{item:vertex}. Also,
$q(\lambda_2,\lambda_3; F_2,F_3) \geq 0$ within the rectangle
$|F_j| \leq \lambda_j$, $j = 2,3$. Therefore, the remaining factor,
$ h(x,y; F_x, F_y) / q(x,y; F_x, F_y)$ is always
non-positive within $|F_j| \leq \lambda_j$, $j = 2,3$. We choose this
factor as a constant scaling of
\[
r(x,y;F_x,F_y) = -\left(1-\dfrac{F_x^2}{x} - \dfrac{F_y^2}{y}\right),
\]
which is always non-positive within the realizability domain.  The
constant factor is then given as $4/3$ based on item
\ref{item:equilibrium} in Lemma \ref{lem:requirements-h}. Therefore,
the function $h$ is set as
\begin{equation}\label{eq:h-formula}
  h(x,y;F_x,F_y) = \frac{4}{3} q(x,y;F_x,F_y) r(x,y;F_x,F_y).
\end{equation}
It is clear that it satisfies all items in Lemma
\ref{lem:requirements-h} except for item \ref{item:value-h}. The
precise depiction of the extent to which item \ref{item:value-h} is fulfilled
is deferred to the investigation of realizability in the next section.

With $h$ given, the whole model is closed. Direct
calculation gives us the closing relation of $\sigma_i$, $i = 1,2,3$, as
below:
\begin{equation}\label{eq:sigma-formula}
  \begin{split}
    & \sigma_1 = \lambda_1 - g(\lambda_1,\lambda_2; F_1, F_2)
    - g(\lambda_1,\lambda_3; F_1, F_3), \\
    & \sigma_2 = \lambda_2 - g(\lambda_2, \lambda_1; F_2, F_1)
    - g(\lambda_2,\lambda_3, F_2, F_3), \\
    & \sigma_3 = \lambda_3 - g(\lambda_3, \lambda_1; F_3, F_1)
    - g(\lambda_3, \lambda_2; F_3, F_2),
  \end{split}
\end{equation}
where
\[
g(x,y; F_x, F_y) = \dfrac{2 q(x,y;F_x,F_y) (x + y - 1 -
  r(x,y;F_x,F_y))} {3 (x + y)^2},
\]
satisfying $g(x,y; F_x,F_y) = g(y,x; F_y,F_x)$.

With $\sigma_j$ given as above, we substitute it into
\eqref{eq:w-cond} to give $w_i$, $i=1,2,3$, as
\begin{equation}\label{eq:w-formula}
  \begin{split}
    & w_1 = \sigma_1 + 2 g(\lambda_2, \lambda_3; F_2, F_3), \\
    & w_2 = \sigma_2 + 2 g(\lambda_1, \lambda_3; F_1, F_3), \\
    & w_3 = \sigma_3 + 2 g(\lambda_1, \lambda_2; F_1, F_2).
  \end{split}
\end{equation}
Then we plug $w_i$ and $\sigma_i$ into \eqref{eq:gamma-cond} to get
$\gamma_i$ and $\delta_i$. With formula for $w_i$, $\gamma_i$ and
$\delta_i$, $i = 1,2,3$, we now have the complete closed formula for
the ansatz $\bansatz$ in \eqref{eq:B2-ansatz}.


This closes our 3D $B_2$ model.  

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "AppM2_MultiD.tex"
%%% End: 
