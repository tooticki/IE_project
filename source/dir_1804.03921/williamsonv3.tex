\documentclass[12pt,a4paper,twoside]{article}
  %\documentclass{amsart}
  \usepackage{url}
  \usepackage{amsthm}
  \usepackage{amsmath}
  \usepackage{amsfonts}
  \usepackage{amssymb}
  \usepackage{amscd}
  \usepackage{authblk}
  \usepackage[mathscr]{eucal}
  \usepackage{mathtools} % for 'bsmallmatrix' environment
  \usepackage{enumitem}
  \usepackage{color}
 % \usepackage[affil-it]{authblk} % author affiliation etc.
  \usepackage{fancyhdr}
  \usepackage{hyperref}
  %\usepackage[colorlinks=true, linkcolor=blue]{hyperref}
  %\usepackage{showkeys}
  \usepackage[top=2.5cm, bottom=2.7cm,left=3.5cm, right=2.5cm]{geometry}
 \usepackage[noabbrev]{cleveref} %for numbering in align* use \cref{...} for refering

 %Code for numbering equations sectionwise
  \numberwithin{equation}{section}

 \allowdisplaybreaks[1] %If you prefer a strategy of letting page breaks fall where they may, even in the middle of a multi-line equation, then you might put \allowdisplaybreaks[1] in the preamble of your document. An optional argument 1?V4 can be used for finer control: [1] means allow page breaks, but avoid them as much as possible; values of 2,3,4 mean increasing permissiveness. When display breaks are enabled with \allowdisplaybreaks, the \\* command can be used to prohibit a pagebreak after a given line, as usual.

\pagestyle{plain}

  

  \theoremstyle{definition}  %Title and number in bold, body in normal font.
   \newtheorem{defn}{Definition}[section]
   \newtheorem{eg}[defn]{Example}
   \newtheorem{egs}[defn]{Examples}
   \newtheorem*{prblm}{Problem}
   \newtheorem*{ex}{Exercise}
   \newtheorem{exs}[defn]{Exercises}
   \newtheorem*{note}{Note}
   \newtheorem*{fact}{Fact}
   \newtheorem{rmk}[defn]{Remark}
   \newtheorem{rmks}[defn]{Remarks}

  \theoremstyle{plain}  %n Title and number in bold, body in italic (default).
   \newtheorem{thm}[defn]{Theorem}
   \newtheorem{lem}[defn]{Lemma}
   \newtheorem{prop}[defn]{Proposition}
   \newtheorem{cor}[defn]{Corollary}
   \newtheorem*{conj}{Conjecture}
   \newtheorem*{ackn}{Acknowledgment}

  \theoremstyle{remark} %Title and number in italic, body in normal font.
   \newtheorem*{notn}{Notation}
   \newtheorem*{summ}{Summary}
   \newtheorem*{concl}{Conclusion}
   \newtheorem*{claim}{Claim}
   \newtheorem*{pf}{Proof}

 \newcommand{\numberthis}{\refstepcounter{equation}\tag{\theequation}} % for numbering in  the align* environment

%\newcommand{\numberthis}{\tag{\addtocounter{equation}{1}\theequation}}
\renewcommand{\thesubsection}{\S~\arabic{section}.\arabic{subsection}}

\fontsize{12}{14}

\renewcommand\Authfont{\scshape\small}
\renewcommand\Affilfont{\itshape\small}
\setlength{\affilsep}{1em}

%\newcommand{\smalllineskip}{\baselineskip=15pt}
\newcommand{\keywords}[1]{{\footnotesize\hspace{0.68cm}{\textit{Keywords}: }#1\par
  \vskip.7\baselineskip}}
  \DeclareMathOperator{\spn}{span}
   \let\ker\relax % "undefine \ker"
   \DeclareMathOperator{\ker}{Ker}
   \DeclareMathOperator{\ran}{Ran}
   
%%%%% \renewenvironment{abstract}[0]{\small\rm
%%%%%         \begin{center}ABSTRACT
%%%%%         \\ \vspace{8pt}
%%%%%         \begin{minipage}{5.2in}\smalllineskip
%%%%%         \hspace{1pc}}{\end{minipage}\end{center}\vspace{-1pt}}
\newcommand{\emailaddress}[1]{\newline{\sf#1}}

% \let\LaTeXtitle\title
% \renewcommand{\title}[1]{\LaTeXtitle{\large\textsf{\textbf{#1}}}}

%%%TITLE
\title{Real Normal Operators and Williamson's Normal Form}
\date{}

%%AFFILIATIONS
\author[1]{B.V. Rajarama Bhat}
\author[2]{Tiju Cherian John}

\affil[1]{Indian Statistical Institute,  8th Mile Mysore Road, R.V. College Post, Bangalore-560059, India \emailaddress{bhat@isibang.ac.in}}
\affil[2]{Indian Statistical Institute,  8th Mile Mysore Road, R.V. College Post, Bangalore-560059, India \emailaddress{tijucherian@gmail.com}}


% \title{Real Normal Operators and Williamson's Normal Form}
% \author{B.V. Rajarama Bhat} %and Tiju Cherian John}
% \address{Indian Statistical Institute,  8th Mile Mysore Road, R.V. College Post, Bangalore-560059, India}
% \email{bvrajaramabhat@gmail.com}
% \author{Tiju Cherian John}
% \address{Indian Statistical Institute,  8th Mile Mysore Road, R.V. College Post, Bangalore-560059, India.}
% \email{tijucherian@gmail.com}
% \keywords{Spectral theorem, Real normal operator, Williamson's normal form, Infinite mode quantum systems}
% \subjclass[2010]{Primary 47A05; Secondary 81Q10}
% %\subjclass[2010]{47A05(Primary), and 81Q10(Secondary)}
\begin{document}
\maketitle
 \begin{abstract}

  A simple proof has been provided to show that any bounded normal operator on a real Hilbert space is orthogonally equivalent to its transpose(adjoint). This result and a lemma of Wong \cite{Wong69} allow a quick proof of the spectral theorem of real normal operators and lead naturally to some improvisations on the definition of spectral pair for normal operators as propounded by Goodrich \cite{Goo72}.  It also yields a structure theorem for skew-symmetric operators. 
  These tools are used to prove the main theorem of this article, which is a generalization of Williamson's normal form for bounded positive operators on infinite dimensional separable Hilbert spaces. This has applications in the study of infinite mode Gaussian states.\\
\textbf{Keywords:}
Spectral theorem, Real normal operator, Williamson's normal form, Infinite mode quantum systems\\
\textbf{2010 Mathematics Subject classification:}
Primary 47B15; Secondary 81S10
 \end{abstract}



%\emph{Conventions, terminologies and notations}: All the Hilbert spaces under consideration in this
% article are assumed to be separable. An inner product on a complex Hilbert space is always assumed to be conjugate
% linear in the first variable and linear in the second variable. In the discussion of real Hilbert spaces, we use the
% term \emph{transpose} as the corresponding term for \emph{adjoint} of an operator and in symbols we write $A^{T}$(or
% $A^{*}$ when there is no confusion) to denote the transpose of an operator $A$. An inner product preserving onto
% transformation between real Hilbert spaces will be called an \emph{orthogonal} transformation (or operator) instead o
% f a \emph{unitary} operator. Two real Hilbert spaces (or operators) are called \emph{orthogonally equivalent}, if
% there exists an orthogonal transformation which takes one to another. We use the symbols $\mathbb{C},\mathbb{R},
% \mathbb{Z}$ and $\mathbb{N}$ for denoting the set of complex numbers, real numbers, integers and natural numbers respectively. For an operator $A$ on a (real or complex) Hilbert space $\mathcal{H}$, $A^{0}$ denotes the identity operator on $\mathcal{H}$. If $X \subseteq \mathbb{C}$ then $\mathcal{B}(X)$ denote the Borel $\sigma$-algebra on $X$.
\section{Introduction}



 Williamson's  theorem characterizing positive definite
real matrices of even order is fairly well-known and is a very
useful result. We begin by stating this theorem, which we are going
to generalize. Let $n$ be a natural number. Suppose $A$ is a
strictly positive (hence invertible) real matrix of order $2n\times
2n$. Then there exists a symplectic matrix $L$ of order $2n\times 2n$
and a strictly positive diagonal matrix $P$ of order $n\times n$, such that
$$A= L^T
\begin{bmatrix}
  P &0\\
  0&P
\end{bmatrix}L,
$$  where $L^T$ denotes the transpose of $L.$ Here the matrix $P$ is uniquely determined up to permutation and the
diagonal entries are  known as symplectic eigenvalues of $A$.

This theorem was first proved by J. Williamson in \cite{Wil36}. It
has been extensively used to understand the symplectic geometry and
has applications in Harmonic Analysis and  Physics (See \cite{Gos11}).
 In recent years there is somewhat renewed interest in the field (\cite{BhJa15},\cite{IdGaWo17}) in
view of its relevance in quantum information theory and its
usefulness to understand symmetries of finite mode quantum Gaussian
states \cite{Par13}. We wish to extend some of the results of Parthasarathy 
\cite{Par13}, to infinite mode Gaussian systems  (see \cite{BhJoSr18}) and for the purpose we need a generalisation of the
Williamson's theorem to separable infinite dimensional Hilbert
spaces. Of course, such a generalization would be of independent
interest. Here we are precisely in the same situation as B\"ottcher and Pietsch \cite{Bot12}, namely we are unable to find any source in literature
where such a theorem has been worked out. The main goal of the present
paper is to fill this apparent gap. In the process we find shortcuts and simplifications of some known results on real normal operators.

In this subject it is necessary  to deal with real linear operators on real
Hilbert spaces and their complexifications. We know that non-real eigenvalues of real matrices
appear in conjugate pairs. We need appropriate generalization of
this result in infinite dimensions. In Theorem 3.1 we show that
every normal operator on a real Hilbert space is orthogonally
equivalent to its adjoint. This result is known \cite{Vis78}, however we
have an elementary direct proof of this fact. This is crucial for
our understanding of spectral theorem of real normal operators, for
which we refer to Wong \cite{Wong69}, Goodrich \cite{Goo72}, Viswanath \cite{Vis78}, Agrawal and Kulkarni \cite{AgKu94}. This acts as the  main tool for
obtaining infinite dimensional version of Williamson's theorem.
Applications of the theory can be seen in \cite{BhJoSr18}.

% We begin by reminding the reader that most of the basic facts
%about the geometry of a complex Hilbert space
% holds in the real case also. Naturally, the most important among them in an operator theoretic view are the
% so-called projection theorem and the Riesz representation theorem. In this work, we will be using them freely. It is also worth mentioning that there is a theory of bilinear functionals corresponding to the theory of sesquilinear functionals (some authors, for example, Halmos in \cite{Hal98}, call them bilinear functionals itself) on complex Hilbert spaces also holds in the real case.  By this, we mean the definitions and theorems about bilinear functionals and the connection between bilinear functionals and operators on the Hilbert space hold good in real field case also. The reader may refer Sections 2, 3, 18 and 22 of \cite{Hal98} and try to reformulate the theorems and definitions to the real Hilbert space situation when we use any of them in the sequel. In the real field case, the inner product is symmetric and linear in both the variables so the definition of a bilinear form should be taken as a symmetric form which is linear in both the variables.
 %\fbox{\parbox{\textwidth}
%{\textcolor{red}{Because it is real case should we give proof for some of the results  we use?}}}





\section{Preliminary definitions and observations}
  In this Section, we shall collect the basic definitions and observations relevant to our work on real Hilbert spaces. Much of the work in this section are similar to what is seen in \cite{Wong69} and \cite{Goo72}.
\begin{defn}
Let $A$ be a bounded operator on a real Hilbert space $(H,\left\langle \cdot,\cdot  \right\rangle)$. Its transpose $A^{T}$, is defined by $\left\langle Ax,y \right\rangle = \left\langle x,A^{T}y \right\rangle, \forall x,y \in H$. Such an $A^{T}$ exists uniquely as a bounded operator on $H$. $A$ is said to be normal if $AA^{T} = A^{T}A$.
\end{defn}
Often we use the term `\emph{real normal (self-adjoint, positive, invertible) operator}' for a normal (self-adjoint, positive, invertible) operator defined on a real Hilbert space. Following standard notation, for complex linear operators on complex Hilbert spaces  star ( $^*$ )  would denote the adjoint.
%We abuse the notation a little and obtain the following
\begin{defn}
  Let $H$ be a real Hilbert space. Then the complexification of $H$ is the complex Hilbert space $\mathcal{H} :=H+iH:= \{x+i \cdot y:x\in H,y\in H\}$ with  addition, complex-scalar product and inner product defined in the obvious way.
\end{defn}



For example, if $\left\langle \cdot,\cdot \right\rangle$ is the inner product on $H$ then the inner product on $\mathcal{H}$ is given by
 $\left\langle x_{1} + i\cdot y_{1}, x_{2} + i \cdot y_{2} \right\rangle_{\mathbb{C}} := \left\langle x_{1} ,x_{2} \right\rangle + \left\langle y_{1},y_{2} \right\rangle + i \left( \left\langle x_{1},y_{2} \right\rangle - \left\langle y_{1},x_{2} \right\rangle \right)$. Also note that the mapping $x \mapsto x+i \cdot0$ provides an embedding of $H$ into $\mathcal{H}$ as a real Hilbert space.


\begin{defn}\label{def:spectrum}
  Let $A$ be a bounded operator on the real Hilbert space $H$. Define an operator $\hat{A}$ on the complexification $\mathcal{H}$ of
  $H$ by $\hat{A} (x+iy) = Ax +iAy$. Then $\hat{A}$ is well defined, complex linear and bounded, with $({\hat{A})}^* (x+iy) = A^Tx +i\cdot A^Ty = \widehat{(A^T)}(x+iy)$ and $\|\hat{A}\| = \|A\|$. If $A$ is normal then $\hat{A}$ is also normal. $\hat{A}$ is called the complexification of $A$.
Define the spectrum of $A$, denoted by $\sigma(A)$, to be the
spectrum of $\hat{A}.$
\end{defn}
Note that the  definition above of spectrum matches with  the usual
notion of eigenvalues of a finite dimensional real matrix.

 The mapping $\mathcal{J} \colon \mathcal{H} \to \mathcal{H}$, defined by $\mathcal{J}(x + i\cdot y)= x-i\cdot y$  is such that $\mathcal{J} (a_{1}z_{1}+a_{2}z_{2})= \bar{a}_{1}\mathcal{J}(z_{1})+\bar{a}_{2}\mathcal{J}(z_{2})$, for $z_{1},z_{2} \in \mathcal{H}, a_{1}, a_{2} \in \mathbb{C}.$ In other words $\mathcal J$ is anti-linear. Moreover, $\mathcal{J}^{2}= I$, the identity operator on $\mathcal{H}$ and $\left\langle \mathcal{J}z_{1},\mathcal{J}z_{2} \right\rangle= \left\langle z_{2},z_{1} \right\rangle$. We observe that  $H = \{z \in \mathcal{H} \colon \mathcal{J}z = z\}$ and an operator $B$ on $\mathcal{H}$ is the complexification of some operator on $\mathcal H$ if and only if $B\mathcal{J}=\mathcal{J}B$.

%\begin{defn}\label{def:spectrum}
% Let $A$ be a bounded normal operator on a real Hilbert space $\mathcal{H}$ and let $\hat{A}$ be the corresponding complexified operator on $\hat{\mathcal{H}}$.


\begin{defn}\label{def:cyclic-vec}
   Let $A$ be a bounded normal operator on a real Hilbert space $H$. Then a vector $x\in H$ is is said to be  {\em transpose cyclic\/} for $A$, if
the  set $\{ A^n(A^T)^mx: m, n\geq 0\}$ is total in $H.$
It is said to by {\em cyclic\/} for $A$,  if $\{ A^nx: n\geq 0\}$ is total
in $H.$
\end{defn}
For the next two sections, $H$ denotes a real Hilbert space, $\mathcal{H}$ its complexification, $A$ denotes a bounded normal operator on $H$ and $\hat{A}$ its complexification on $\mathcal{H}$,
as described above.
\section {Symmetry of a real normal operator}
Here we prove that any normal operator on a real Hilbert space is orthogonally equivalent to its transpose (or adjoint). During the preparation of this manuscript we found that this result has appeared as Corollary 2.7 in Vishwanath \cite{Vis78}, but our proof is different and is very elementary. It just exploits the geometry of real Hilbert space. Moreover, this result is crucial to understand the spectral theroy of real normal operators.
\begin{thm} \label{thm:A similar A^T}
Let $H$ be a real Hilbert space and let $A\in B(H)$ be a normal operator. Then there exists an orthogonal transformation $U \in B(H)$, such that
\begin{equation} \label{eq: A similar A^T}
UAU^{T} = A^{T}.
\end{equation}
Further,  $U$ can be chosen such that $U^T = U$.
\end{thm}
\begin{proof}
Let us assume first that $A$ has a transpose cyclic vector \textit{i.e.}
there exists $x \in H$ such that $\mathcal{E} := \{
A^n({A^T})^mx: n, m \geq 0\}$ is total in $H$. Define $U$ on
$\mathcal{E}$ by
\begin{equation}
U(A^n({A^T})^mx) = ({A^T})^nA^mx, ~\textnormal{for }  n,m\geq 0.
\end{equation}
Then for $n,m,k,l\geq 0,$
\begin{align*}
               \langle A^n({A^T})^mx, A^k({A^T})^lx \rangle
               &= \langle ({A^T})^kA^lA^n({A^T})^mx, x \rangle \\
               &= \langle A^n({A^T})^m({A^T})^kA^lx, x \rangle \\
               &= \langle ({A^T})^kA^lx, ({A^T})^nA^mx \rangle \\
               &= \langle ({A^T})^nA^mx, ({A^T})^kA^lx \rangle \numberthis \label{eq:inner product} \\
               &= \langle U(A^n({A^T})^mx), U(A^k({A^T})^lx) \rangle , 
               \end{align*}
where the second equality follows from normality of $A$ and fourth equality because real inner product is symmetric. Since $U$ preserves the inner product on a total set $U$ can be extended as a bounded linear operator on $\overline{\textnormal{span}}\hspace{0.1cm} \mathcal{E}= H$. Note that the extended operator also preserves the inner product. We use the same symbol $U$ for the extended operator also. Thus $U$ is a real orthogonal transformation on $H$. Further by using (\ref{eq:inner product})
% \cref{eq:inner product}
note that
\begin{equation}
\langle U (A^m({A^T})^nx), A^k({A^T})^lx \rangle =  \langle ({A^T})^nA^mx, ({A^T})^kA^lx \rangle
=\langle A^m({A^T})^nx, U(A^k({A^T})^lx) \rangle .
\end{equation}
Therefore,
\begin{equation} \label{eq: U sa}
 U^T=U.
 \end{equation}
Also,
\begin{align*}
             UAU^T (A^n({A^T})^mx) &= UAU(A^n({A^T})^mx) \\
                                 &= UA(({A^T})^nA^mx) \\
                                 &= U(A^{m+1}({A^T})^nx) \\
                                 &= ({A^T})^{m+1}A^nx \\
                                 &= A^T(A^n({A^T})^mx).
\end{align*}
Thus (\ref{eq: A similar A^T}) is satisfied on a total set which in turn proves the required relation on $H$, in the special case when $A$ has a transpose cyclic vector. The general case follows by a familiar application of Zorn's lemma.
%\begin{equation}
 %UAU^* = A^*.
 %\end{equation}
%Let $\hat{U}$ be the complexification of $U$. Then a direct computation using \eqref{eq: U sa} and \eqref{eq: A similar A^*} proves \eqref{eq: A hat similar A hat *} for the case when $A$ has cyclic vector.
\end{proof}

\begin{cor}\label{cor:unitary-equi}
$\hat{A}$ is unitarily equivalent to $(\hat{A})^{*} =\widehat{(A^T)}.$
\end{cor}

\begin{proof}
Let $U$ be as in Theorem \ref{thm:A similar A^T}, then $\hat{U}$ is a unitary which does the job.
\end{proof}

\begin{cor} \label{cor:spectr-symmetry} For any real normal operator $A$,  
 $\sigma(A) =  \sigma(A^{T}) =\overline{\sigma(A)}$ and thus the spectrum is symmetric about the real axis.
\end{cor}

\begin{proof}
Immediate from Definition \ref{def:spectrum} and Corollary  \ref{cor:unitary-equi}
\end{proof}

 Note that Corollary \ref{cor:spectr-symmetry} is analogous to the fact that complex eigenvalues of a real matrix occur in pairs.


\section {The spectral theorem for  real normal operators}
Let $A$ be a bounded normal operator on a real Hilbert space
$H$. Consider its complexification $\hat{A}.$ By the
spectral theorem in the complex case, there exists a spectral
measure $\hat{E}$, such that $\hat{A} = \int
\limits_{\sigma(\hat{A})}\!\!\!\lambda \,d\hat{E}(\lambda)$. Notice that there is no reason why the spectral family $\hat{E}(\cdot )$ consists of complexification of real projections. It is just a notation for the spectral measure of $\hat{A}$. However the
following is true.
\begin{lem} \label{lem:wong}[Wong's lemma, \cite{Wong69}]
 $\mathcal{J}\hat{E}(e) = \hat{E}(\bar{e})\mathcal{J}$, for every Borel subset $e \subseteq \mathbb{C}$, where $\bar{e}$ denotes the set of all complex conjugates of elements of $e$.
\end{lem}
\begin{proof} Here is a sketch of the proof presented as
 Lemma 3.1 in \cite{Wong69}. For $\lambda \in \mathbb{C}, \epsilon >0$, let $\mathfrak{F}(\lambda,\epsilon)$ denote the subset $\{x \in H \colon \|(A-\lambda)^n x\| \leq \epsilon^n \|x\|\}$. For a Borel set $e\subseteq \mathbb{C}$, let $\mathfrak{F}(e,\epsilon ) = \underset{\lambda \in e}{\vee}\mathfrak{F}(\lambda,\epsilon )$ and $\mathfrak{F}(e)=\underset{\epsilon >0}{\cap}\mathfrak{F}(e,\epsilon )$.  We know that $\mathfrak{F}(e) = \ran \hat{E}(e)$ for any compact subset $e$ of $\mathbb{C}$ (Section 42 \cite{Hal98}). 
 
 
 Notice that $\langle \mathcal{J}z,w\rangle = \langle z,-\mathcal{J}w\rangle$. Therefore $\mathcal{J}\hat{E}(e)\mathcal{J}$ is a projection for any Borel subset $e$ of $\mathbb{C}$. Therefore, to prove the lemma it is enough to show that $\mathcal{J}\hat{E}(e)\mathcal{J}$ and $\hat{E}(\bar{e})$ have the same range for every Borel set $e$. To this end first notice that for $\lambda \in \mathbb{C}$ and $\epsilon >0$, if $x \in \mathfrak{F}(\lambda,\epsilon)$ then $\mathcal{J}x \in \mathfrak{F}(\bar{\lambda},\epsilon)$. From this it follows that  $x \in \mathfrak{F}(e)$ implies $\mathcal{J}x \in \mathfrak{F}(\bar{e})$ for any Borel set. Hence we get $\mathcal{J}\mathfrak{F}(e) \subseteq \mathfrak{F}(\bar{e})$. Therefore for a compact Borel set $e$  we have $\mathcal{J}\hat{E}(e)\mathcal{H} \subseteq \hat{E}(\bar{e})\mathcal{H}$. Now by regularity of the spectral measure  if $e$ is a Borel set we have $\mathcal{J}\hat{E}(e)\mathcal{H} \subseteq \hat{E}(\bar{e})\mathcal{H}$. Therefore we also have $\mathcal{J}\hat{E}(\bar{e})\mathcal{H} \subseteq \hat{E}(e)\mathcal{H}$. Applying $\mathcal{J}$ on both side we have $\hat{E}(\bar{e})\mathcal{H} \subseteq \mathcal{J}\hat{E}(e)\mathcal{H}$. Thus we see that $\mathcal{J}\hat{E}(e)\mathcal{H} = \hat{E}(\bar{e})\mathcal{H}$. Since $\mathcal{H} = \mathcal{J}\mathcal{H}$, we get  $\mathcal{J}\hat{E}(e)\mathcal{J}\mathcal{H} = \hat{E}(\bar{e})\mathcal{H}$
 
 %$\hat{E}(\bar{e})\mathcal{J}\hat{E}(e) = \mathcal{J}\hat{E}(e)$ 
\end{proof}

We use the notation $\mathcal{B}(D)$ to denote the Borel $\sigma$-algebra of a set $D$. Let  $e \subseteq \sigma(\hat{A})$(same as $\sigma(A)$) be any  Borel set, define $\hat{E_{1}}(e) :=  \frac{\hat{E}(e) + \hat{E}(\bar{e})}{2} $ and  $\hat{E_{2}}(e) :=  \frac{\hat{E}(e) - \hat{E}(\bar{e})}{2i}$. Then


\begin{equation} \label{eq:real-img-E-hat}
\hat{E}(e) = \hat{E_{1}}(e) + i\hat{E_{2}}(e).
\end{equation}

By Lemma \ref{lem:wong}, $\hat{E_{1}}(e)$ and $\hat{E_{2}}(e)$ both commute with $\mathcal{J}$. Therefore,  $\hat{E_{1}}(e)$ and $\hat{E_{2}}(e)$ are complexification of some operators $E_{1}(e)$ and $E_{2}(e)$, respectively on $H$. $E_{1}(e)$ is symmetric and $E_{2}(e)$ is skew symmetric for every Borel set $e$, because their complexifications are so. That is,
\begin{equation}\label{eq: spectr-pair1}
\begin{aligned}
  E_{1}(\bar{e}) &=  &E_{1}(e); \\
  E_{2}(\bar{e}) &= -\!\!\!\!\!&E_{2}(e),
\end{aligned}
\end{equation}
for every $e \in \mathcal{B}(\mathbb{C})$. Also note that by
Corollary \ref{cor:spectr-symmetry} and (\ref{eq: spectr-pair1}) we
have $E_{1}(\sigma(A)) = I$ and $E_{2}(\sigma(A))= 0$
\begin{prop}\label{prop:signed-measure}
For any fixed $x,y \in H$, define $\mu_{j}^{(x,y)}(e) := \left\langle x, E_{j}(e)y \right\rangle, j= 1,2$ for every Borel subset $e \subseteq \sigma(A)$. Then  $\mu_{j}^{(x,y)}$ is a regular  Borel (finite valued) signed measure on  $\sigma(A)$, for $j=1,2$. In particular, since $E_{2}(e)$ is skew symmetric,  $\mu_{2}^{(x,x)}(e)=\langle E_{2}(e)x,x\rangle = 0, \forall x$.
\end{prop}
\begin{proof}
  Clearly $\mu_{1}^{(x,y)}$ and $\mu_{2}^{(x,y)}$ are real valued functions defined on the Borel subsets of $\sigma(A)$. Let $e= \cup_{k}e_{k}$ be a countable disjoint union of Borel sets. By using the identification of $H$ inside $\mathcal{H}$, (\ref{eq:real-img-E-hat}) and properties of the spectral measure $\hat{E}$, we have
\begin{align*}
   \langle x, E_{1}(e)y\rangle +i\langle x, E_{2}(e)y\rangle
                    & = \langle x, \hat{E}(e)y \rangle_{\mathbb{C}} \numberthis \label{eqn:to-compute-mod-mu-j}  \\
                    & = \Sigma_{k}\langle x, \hat{E}(e_{k})y \rangle_{\mathbb{C}} \\
                    & = \Sigma_{k}\langle x, (\hat{E_{1}}(e_{k}) + i\hat{E_{2}}(e_{k}))y \rangle_{\mathbb{C}} \\
                    & = \Sigma_{k}\langle x, E_{1}(e_{k})y\rangle + i\Sigma_{k}\langle x, E_{2}(e_{k})\rangle .
  \end{align*}
This proves the countable additivity of $\mu_{j}^{(x,y)}, j= 1,2$. Regularity also follows by going to real and imaginary parts.
\end{proof}
\begin{cor}
$\mu_1^{(x,x)}$ is a positive measure. 
\end{cor}
\begin{rmk}
$E_1$ is a positive operator valued measure (POVM).
\end{rmk}
For a bounded Borel function $f$  on $\sigma(A)$, define a bilinear functional $\hat{\phi}$ by $$\hat{\phi}(z_{1}, z_{2}) := \int \! f(\lambda) \,d\langle z_{1}, \hat{E}(\lambda)z_{2}\rangle, \forall z_{1},z_{2} \in \mathcal{H}.$$
% \begin{equation*}
%   \hat{\phi}(z_{1}, z_{2}) := \int \! f(\lambda) \,d\langle z_{1}, \hat{E}(\lambda)z_{2}\rangle, \forall z_{1},z_{2} \in \hat{\mathcal{H}}
% \end{equation*}
 Then $\hat{\phi}$ is a bounded bilinear functional which provides the usual functional calculus for $\hat{A}$ (proof is easy and can be found in the Theorem 1, Section 37 of \cite{Hal98}).
\begin{thm}\label{thm:fnl-cal}
Let $f$ be a complex valued bounded Borel measurable function defined on $\sigma(A)$, then for the values $j=1,2$ there exists a unique bounded operator $A_{j}$ on $H$ such that
\begin{equation} \label{eq:fnl-cal}
 \langle x, A_{j}y\rangle = \int\! f(\lambda) \,d\langle x, E_{j}(\lambda)y\rangle
\end{equation}
for every pair of vectors $x$ and $y$. (This is denoted by $A_{j} = \int\! f \,dE_{j}= \int\! f(\lambda) \,dE_{j}(\lambda)$.)
\end{thm}


\begin{proof}
Proposition \ref{prop:signed-measure} and the boundedness of $f$ implies that the integral $\phi_{j}(x,y)= \int\!f(\lambda)\,d\langle x, E_{j}(\lambda)y\rangle$ may be formed for every pair of vectors $x$ and $y$. An easy computation shows that $\phi_{j}$ is a bilinear functional. Also, because of \ref{eqn:to-compute-mod-mu-j} we have $\lvert{\phi}_{j}(x,y)\rvert \leq \lvert\hat{\phi}(x,y)\rvert, \forall x,y \in H, j= 1,2$. Therefore, $\phi_{j}$ is a bounded bilinear functional  and so there exists a unique operator $A_{j}$  (see Section 22, \cite{Hal98}), satisfying (\ref{eq:fnl-cal}).
\end{proof}
\begin{cor}\label{cor:fnl-cal}
  $\int \textnormal{Im}(\lambda) \, dE_{1}(\lambda)= 0$ and $\int \textnormal{Re}(\lambda) \, dE_{2}(\lambda)= 0$, where $\textnormal{Im}$ denotes the function $\lambda=\lambda_{1}+ i\lambda_{2}\mapsto \lambda_{2}$ and $\textnormal{Re}$ denotes the function $\lambda_{1}+ i\lambda_{2}\mapsto \lambda_{1}$ defined on $\sigma(A)$.
\end{cor}
\begin{proof}
  Note that $\textnormal{Im}(\bar{\lambda}) = - \textnormal{Im}(\lambda)$ and $\textnormal{Re}(\bar{\lambda}) = \textnormal{Re}(\lambda)$. Now the result follows  from (\ref{eq: spectr-pair1}).
\end{proof}
Let  $\lambda= \lambda_{1} + i \lambda_{2}$, be an arbitrary element in $\sigma(A)$, by going to the definitions and using the Theorem \ref{thm:fnl-cal}, for $x\in H$  we have,
\begin{align*}
  A(x)&= \hat{A}(x) = \int\!\lambda \, d\hat{E}(\lambda)(x)\\
          &= \int\!\lambda \, dE_{1}(\lambda)(x)+ i\int\!\lambda \, dE_{2}(\lambda)(x)\\
          &=\int\!\lambda_{1} \, dE_{1}(\lambda)(x)-\int\!\lambda_{2} \, dE_{2}(\lambda)(x), \numberthis \label{eq:spectr-int1}
 %+i\left( \int\limits_{\sigma(A)}\!\!\! \lambda_{2} \, dE_{1}(\lambda_{2}) + \int\limits_{\sigma(A)}\!\!\! \lambda_{1} \, dE_{2}(\lambda_{1})\right)(x)
\end{align*}
where (\ref{eq:spectr-int1}) is obtained by using Corollary \ref{cor:fnl-cal} and the fact that there is no "imaginary" part for elements of $H$. By considering $\lambda_{1}$ as the function $r\cos\theta$ and $\lambda_{2}$ as $r\sin\theta$, we have
\begin{equation} \label{eq:spectr-int2}
   A =\int\! r\cos\theta \, dE_{1}-\int\! r\sin\theta \, dE_{2}.
\end{equation}
Similar to (\ref{eq:spectr-int2}), for $s,t \in \mathbb{N}$, we
obtain for future reference
\begin{equation}
  \label{eq:AA*-power}
  A^{s}{(A^{T})}^{t}(x)= \int\! r^{s+t}\cos (s-t)\theta \, dE_{1}(x)-\int\! r^{s+t}\sin(s-t)\theta \, dE_{2}(x).
\end{equation}
In particular, we have
\begin{align*}
 \left\langle A^{s}({A^T})^{t}x, x   \right\rangle
&= \int \limits_{\sigma(A)}\! r^{s+t}\cos (s-t)\theta \, d\mu_{1}^{(x,x)}-\int \limits_{\sigma(A)}\! r^{s+t}\sin(s-t)\theta \, d\mu_{2}^{(x,x)}\\
& = \int \limits_{\sigma(A)}\! r^{s+t}\cos (s-t)\theta \, d\mu_{1}^{(x,x)}, \numberthis \label{eq:spectr-int4}
\end{align*}
where (\ref{eq:spectr-int4}) is obtained by using the fact that
$\mu_{2}^{(x,x)}(e)=\langle E_{2}(e)x,x\rangle = 0, \forall e \in
\mathcal{B}(\mathbb{C})$.
\begin{defn}
Let $D$ be a compact subset of $\mathbb{C}$, which is symmetric
about the real axis.  A pair of operator valued functions $(E_{1},
E_{2})$ defined on the Borel $\sigma$-algebra of $D$ is called a
spectral pair if the following holds for every  $e\in
\mathcal{B}(D)$,
 \begin{enumerate}[label=\roman*)]
 \item  $E_{1}(e)$ is a bounded symmetric operator and $E_{2}(e)$ is a bounded skew symmetric operator.
 \item It satisfies (\ref{eq: spectr-pair1}):
   $E_{1}(\bar{e}) =  E_{1}(e); ~~
  E_{2}(\bar{e}) = -E_{2}(e).$ 
 \item If $\hat{E_{1}}(e)$ and $\hat{E_{2}}(e)$ denote the complexification of the corresponding operators, then the operator valued function defined by $\hat{E}(e):= \hat{E_{1}}(e) + i \hat{E_{2}}(e)$, is a spectral measure on $\mathcal{H}$.
 \end{enumerate}
\end{defn}
 Now we obtain the spectral theorem for a real normal operator.

\begin{thm}\label{thm:spectral-normal}
  If $A$ is a bounded normal operator on a real Hilbert space $H$, then there exists a unique spectral pair $(E_{1}, E_{2})$ such that (\ref{eq:spectr-int2}) holds.
\end{thm}
\begin{proof}
 We already proved everything except the uniqueness of the spectral pair. Suppose $(F_{1},F_{2})$ is another spectral pair satisfying
\begin{equation}\label{eq:spectr-int3}
A =\int\! r\cos\theta \, dF_{1}-\int\! r\sin\theta \, dF_{2} .
\end{equation}
  Let $\hat{F}(e)= \hat{F_{1}}(e)+ i\hat{F_{2}}(e)$, where $\hat{F_{1}}(e)$ and $\hat{F_{2}}(e)$ denotes the complexification of the corresponding operator. Then a direct computation of $\hat{A}(x+i\cdot y) = Ax + i \cdot Ay$ using (\ref{eq:spectr-int3}) and Corollary \ref{cor:fnl-cal} proves that $\hat{A} = \int\! \lambda \, d\hat{F}(\lambda)$. By uniqueness of spectral measure in the complex case we have $\hat{F}= \hat{E}$ this implies $F_{1} = E_{1}$ and $F_{2} = E_{2}$.
\end{proof}
 Observe that if $A$ was originally a self-adjoint operator then $E_{2} = 0$ in (\ref{eq:real-img-E-hat}) and we obtain the spectral theorem for a real bounded self adjoint operator exactly the same as that in complex case. The self adjoint case was already done in \cite{RiN90}.
 \begin{rmk}
 For a definition of the spectral pair which is independent of complexification, we refer to \cite{Goo72}. But we find going to the complexification easier. Further it should be noticed that our Corollary \ref{cor:spectr-symmetry} which is a consequence of the fact that a real normal operator orthogonally equivalent to its adjoint enables us to confine the definition of spectral pair  for subsets symmetric to the real axis. Also the definition of the spectral pair (and proof of Spectral Theorem) has been relatively simplified and made more operator theoretic in our approach.
 \end{rmk}
\begin{cor}
  If $A$ is a bounded self adjoint operator on a real Hilbert space $H$, then there exists a unique spectral measure $E$ on the real line such that $A= \int_{\sigma(A)}\lambda \,dE(\lambda).$
\end{cor}
For future reference, let us note that it makes sense to talk about the positive operators and square root of them in the real field case also.
\begin{defn}
  A bounded self adjoint operator $A$ on a real Hilbert space $H$, is called a positive operator if $\sigma(A) \subseteq [0, \infty)$, it is called strictly positive if it is positive and $0 \notin \sigma(A)$.
\end{defn}
\begin{cor}\label{cor:sqr-rt}
  If $A$ is a positive operator on a real Hilbert space then there exists a unique positive square root operator for $A$, i.e. there exists a unique operator $B$ such that $B^{2}= A$. We denote the positive square root of $A$ as $A^{1/2}$(or $\sqrt{A}$).
\end{cor}
\begin{proof}
  Take $B= \int_{\sigma(A)}\lambda^{1/2} \,dE(\lambda)$, where $E$ is the spectral measure associated with $A$ and $A= \int \lambda \,dE(\lambda)$. The proof is same as that of complex case.
\end{proof}
Even though the polar decomposition exists for general bounded linear operators between real Hilbert spaces, we give the following special case which will be sufficient for our purpose.
\begin{thm}
  Let $H$ and $K$ be two real Hilbert spaces and $A \colon H \rightarrow K$ be an invertible bounded linear operator, then there exists a unique orthogonal transformation $U \colon H \rightarrow K$ such that $A= U(A^{T}A)^{1/2}.$
\end{thm}
\begin{proof}
  Similar to the complex situation. For example one can imitate the proof of Theorem VI.10 in \cite{ReS80}.
\end{proof}
\subsection{Spectral Representation}
In the finite dimensional situation we have, any real normal operator is orthogonally equivalent to an operator of the form
\begin{equation*}
  \begin{bmatrix}
a_{1}  &        &        &        &        &        &        &\\
      & a_{2  } &        &        &        & &\mbox{\Huge 0} &\\
      &        & \ddots &        &        &        &        &\\
      &        &        & a_{k}   &        &       &         &\\
      &        &        &        & B_{1}   &       &         &\\
      &        &        &        &        & B_{2}  &         &\\
      &\mbox{\Huge 0}&  &        &        &       & \ddots  &\\
      &        &        &        &        &       &         & B_{m}
\end{bmatrix},
\end{equation*}
where $a_{1}, a_{2}, \cdots , a_{k} $ are the real eigenvalues (counting multiplicity) of the operator and $B_j$ is a $2\times2$ matrix of the form $B_{j} = \begin{bsmallmatrix}
          \alpha_{j} & \beta_{j}\\
         -\beta_{j} & \alpha_{j}
         \end{bsmallmatrix}, \alpha_j,\beta_j \in \mathbb{R}, j = 1,2,\dots,m$. $B_{j}$ corresponds to the complex eigenvalues $\alpha_{j}\pm i\beta_{j}$. Our next aim in this section is to obtain an analogous decomposition in the infinite dimensional situation. Note that in the finite dimensional situation a complex eigenvalue is prescribed by a 2-dimensional real subspace. A similar scenario  happens in the infinite dimensional case also. We present it here for reader's convenience as we couldn't find it in the literature.


   Let $\mu$ be a regular Borel measure on the Borel $\sigma$-algebra of a compact subset $E \subseteq \mathbb{C}$, which is symmetric about the real axis. Partition $E$ into a union of three disjoint sets, $E= I \cup K \cup \bar{K}$ where $I = E \cap \mathbb{R}, K = E \cap \mathbb{H^{+}}$, where $\mathbb{H^{+}} = \{\lambda \in \mathbb{C} \colon \textnormal{Im}(\lambda) > 0\}$. Let $L^{2}(E)$ denote the collection of all real valued, square integrable functions on $E$, with respect to the measure $\mu$. Then $L^{2}(E)$ is a real Hilbert space and $L^{2}(E) = L^{2}(I) \oplus L^{2}(K) \oplus L^{2}(\bar{K})$. Further, if $\mu$ is symmetric about the real axis i.e. $\mu(e)= \mu(\bar{e})$, for every Borel set $e$, then there exists an orthogonal transformation between $L^{2}(\bar{K})$ and $L^{2}(K)$, which maps $f \mapsto \bar{f}$, where $\bar{f}(z)= f(\bar{z})$ for all $f \in L^{2}(\bar{K})$. Therefore, $L^{2}(E)$ is orthogonally equivalent to $L^{2}(I) \oplus L^{2}(K) \oplus L^{2}(K)$. Considering this orthogonal equivalence, we will not distinguish between $L^{2}(E)$ and this direct sum decomposition in the case where $\mu$ is symmetric about the real axis. Define an operator $S$ on  $L^{2}(I) \oplus L^{2}(K) \oplus L^{2}(K)$ by

\begin{equation}
  \label{eq:basic-operator}
  S = \begin{bmatrix}
        M_{\lambda} &           0            &       0                \\
            0     & M_{\textnormal{Re}(\lambda)} & M_{\textnormal{Im}(\lambda)} \\
            0     &-M_{\textnormal{Im}(\lambda)} & M_{\textnormal{Re}(\lambda)}
      \end{bmatrix},
\end{equation}
where $M_{f}$ for a bounded Borel measurable function $f$ denotes
the multiplication operator $g \mapsto fg$,
$\textnormal{Re}(\lambda), \textnormal{Im}(\lambda)$ are as in
Corollary \ref{cor:fnl-cal}, defined on $K$ and $\lambda$ denotes
the function $\lambda(t) = t, \forall t$, on $I \subset \mathbb{R}$.
Then $S$ is a normal operator and we  will prove that every normal
operator is orthogonally equivalent to a direct sum of operators of
this form. We will need the following elementary lemma,
% * <tijucherian@gmail.com> 2018-04-10T19:21:15.293Z:
% 
% Such an explicit decomposition could not be found in the literature. So this part is new
% 
% ^.
\begin{lem} \label{lem:total-set}
  Let $\mu$ be a positive regular Borel measure on a compact set $E \subseteq \mathbb{C}$. Consider the real Hilbert space $L^{2}(E)$. By abuse of notation, for $n,m \geq 0$, let $r^{n+m}\cos (n-m)\theta$ denote the function $(r, \theta) \mapsto r^{n+m}\cos (n-m)\theta$ and $r^{n+m}\sin (n-m)\theta$ denote a function defined similarly. Then the set of functions $\{r^{n+m}\cos (n-m)\theta : n, m \geq 0 \} \cup \{r^{n+m}\sin (n-m)\theta: n, m \geq 0\}$ is a total set in $L^{2}(E)$.
\end{lem}

\begin{proof}
  Assume $f \in L^{2}(E)$ is such that $\left\langle f, r^{n+m}\cos (n-m)\theta \right\rangle $  $ = \left\langle f, r^{n+m}\sin (n-m)\theta \right\rangle $ $= 0$, for $n,m \geq 0$. By considering $f$ as  an element of the complex Hilbert space $(L^{2}(\mu), \langle \cdot, \cdot \rangle_{\mathbb{C}})$ and by going to polar coordinates, we have $\left\langle f, z^n \right\rangle_{\mathbb{C}} = \left\langle f, \bar{z}^{m} \right\rangle_{\mathbb{C}} = 0 $, for all $n,m \geq 0$. Similarly by expanding trigonometric identities we have $\left\langle f, z^{n}\bar{z}^{m} \right\rangle_{\mathbb{C}} = 0$. %for all $n,m \in \mathbb{N} \cup \{0\}$.
 Therefore, $\left\langle f, P(z, \bar{z}) \right\rangle_{\mathbb{C}}$, for every polynomial $P$ in $z$ and $\bar{z}$. Now by Stone-Weierstrass theorem we have $\left\langle f, g \right\rangle_{\mathbb{C}} = 0$, for every continuous function $g$ on $E$. This in turn implies that $f=0$, the zero element in $L^2(E)$.
\end{proof}
% \fbox{\parbox{\textwidth}
% {\textcolor{red}{Rest of this section is yet to be written, I want to write the spectral representation theorem here}}}

Recall from Corollary \ref{cor:spectr-symmetry} that the spectrum of a bounded real normal operator is symmetric about the real axis.
\begin{lem}\label{lem:spectr-theor-real}
Let $H$ be  a real Hilbert space and $A$ be a bounded normal operator on $H$ with $\sigma(A) = E$. Assume that $A$ has a transpose cyclic vector.  Then there exists a positive measure $\mu$ defined on $\mathcal{B}(E)$, with the following properties
\begin{enumerate}[label=\roman*)]
\item\label{item:1} $\mu$ is symmetric about the real axis.
\item \label{item:2}There exists  an orthogonal transformation $U \colon H \rightarrow  L^{2}(E,\mu)$ such that $U A U^{T} = S$, where $S$ on $L^2(E,\mu) $ is given by (\ref{eq:basic-operator}), via the identification described there.
\end{enumerate}
\end{lem}
\begin{proof}
Define $\mu = \mu_{1}^{(x,x)}$ as in Proposition
\ref{prop:signed-measure}. We look at the polar coordinates for
making the computations simpler. Let  $\mathcal{E} := \{A^n{(A^T)}^mx:
n, m \geq 0\}$. Define an operator $U :
\textnormal{span}\hspace{0.1cm}(\mathcal{E}) \rightarrow L^{2}(I)
\oplus L^{2}(K) \oplus L^{2}(K)$  by
  \begin{equation}
    \label{eq:Phi}
    \begin{split}
   U(\sum a_{nm}A^n{(A^T)}^mx) = \sum a_{nm}r^{n+m} &\oplus \sum a_{nm}r^{n+m}(\cos(n-m)\theta + \sin(n-m) \theta) \\ & \oplus \sum a_{nm}r^{n+m}(\cos(n-m)\theta - \sin(n-m) \theta).
    \end{split}
   \end{equation}
We set out to prove that $U$ is inner product preserving and can be extended as an onto map from $H$. Strictly as an element of $L^{2}(\sigma(A))$, $U(A^n{(A^T)}^mx)$ is the element $r^{n+m}(\cos(n-m)\theta + \sin(n-m) \theta)$. Therefore,we have
\begin{align*}
  &\langle U(A^k{(A^T)}^lx),U(A^n{(A^T)}^mx) \rangle \\
%\begin{split}
 = &\langle r^{k+l}(\cos(k-l)\theta + \sin(k-l) \theta), r^{n+m}(\cos(n-m)\theta + \sin(n-m) \theta) \rangle\\
%\end{split}\\
 = &\int \limits_{\sigma(A)} \!\!r^{k+l}(\cos(k-l)\theta + \sin(k-l) \theta) r^{n+m} (\cos(n-m)\theta + \sin(n-m) \theta) \,d\mu
  %\end{split} 
  \numberthis \label{eq:lem-inner-product1}\\
%&=\int \limits_{\sigma(A)} \!\!r^{k+l+n+m}\cos(k-l)-(n-m)\theta  \,d\mu .
\end{align*}
 Note that since $\sin(-\theta) = -\sin\theta$ and $\mu$ is symmetric about the real axis we have  $\int_{\sigma(A)} \sin q\theta \,d\mu = 0, \forall q \in \mathbb{Z}$. Therefore, by expanding (\ref{eq:lem-inner-product1}), using trigonometric identities, we have
\begin{equation}
  \label{eq:lem-inner-product1-1}
  \langle U(A^k{(A^T)}^lx),U(A^n{(A^T)}^mx) \rangle =  \int \limits_{\sigma(A)} \!\!r^{k+l+n+m}\cos((k-l)-(n-m))\theta  \,d\mu .
\end{equation}
So for proving that $U$ is inner product preserving, we just need to prove
\begin{equation} \label{eq:lem-innerproduct2}
%\begin{split}
  \langle A^k{(A^T)}^lx,A^n{(A^T)}^mx \rangle =  \int \limits_{\sigma(A)} \!\!r^{k+l+n+m}\cos((k-l)-(n-m))\theta  \,d\mu .
%\end{split}
\end{equation}
Write $k+m=s$ and $l+n=t$. Then by using elementary properties of normal operators and (\ref{eq:spectr-int4}) we have left hand side of (\ref{eq:lem-innerproduct2}) is same as
\begin{align*}
  \left\langle A^{s}x,A^{t}x   \right\rangle &= \left\langle A^{s}{(A^T)}^{t}x, x   \right\rangle\\
& = \int \limits_{\sigma(A)}\! r^{s+t}\cos (s-t)\theta \, d\mu_{1}^{(x,x)},
\end{align*}
which is now same as the right hand side of \ref{eq:lem-inner-product1-1} and thus $U$ is inner product preserving. Now we will show that $U$ extends as an orthogonal transformation of $H$ onto $L^{2}(I) \oplus L^{2}(K) \oplus L^{2}(K)$. To this end we show that the range of $U$ is dense.% in $L^{2}(\sigma(A))$.
 We have $U(\frac{1}{2}(A^{n}{(A^T)}^{m}+{(A^T)}^{n}A^{m})) = r^{n+m} \oplus r^{n+m}\cos(n-m)\theta  \oplus r^{n+m}\cos(n-m)\theta$, which is the element corresponding to $r^{n+m}\cos(n-m)\theta \in L^{2}(\sigma(A))$ and $U(\frac{1}{2}(A^{n}{(A^T)}^{m}-{(A^{T})}^{n}A^{m})) = r^{n+m} \oplus r^{n+m}\sin(n-m)\theta  \oplus -r^{n+m}\sin(n-m)\theta$,  which is the element corresponding to $r^{n+m}(\sin(n-m)\theta \in L^{2}(\sigma(A))$. We already know from Lemma~\ref{lem:total-set} that this collection is total. Thus we have proved that $U$ can be extended uniquely as an orthogonal transformation on $H$, we use the notation $U$ for denoting this extended operator also . Further, a direct computation using trigonometric identities shows that $U A U^{T} = S$ on vectors of the form $r^{n+m} \oplus r^{n+m}\cos(n-m)\theta  \oplus r^{n+m}\cos(n-m)\theta$ and $r^{n+m} \oplus r^{n+m}\sin(n-m)\theta  \oplus -r^{n+m}\sin(n-m)\theta$. This proves the lemma.
\end{proof}

\begin{thm}\label{thm:spectr-theor-real}
Let $A$ be a bounded normal operator on a real Hilbert space $H$.
% then there exists a countable family of  compact sets $E_i \subseteq \mathbb{C}$ and  positive measures $\mu_i$ symmetric to the real axis, on $\mathcal{B}(E_i)$ and a real orthogonal transformation $U \colon H \rightarrow \oplus_{i}  L^{2}(E_{i},\mu_{i})$ such that $UAU^{*} = \oplus_i{T_i}$, where $T_{i}$ on $L^2(E_{i},\mu_i) $
Then $A$ is orthogonally equivalent to a countable direct sum of
operators of the form  (\ref{eq:basic-operator}). ( \emph{ie. }there
exists a countable family of  compact sets $E_i \subseteq
\mathbb{C}$, positive measures $\mu_i$ symmetric to the real axis,
on $\mathcal{B}(E_i)$ and a real orthogonal transformation $U \colon
H \rightarrow \oplus_{i}  L^{2}(E_{i},\mu_{i})$ such that
$UAU^{T} = \oplus_i{S_i}$, where $S_{i}$ on $L^2(E_{i},\mu_i) $ is
as in (\ref{eq:basic-operator}) )
\end{thm}

\begin{proof}
  Use the previous lemma and apply Zorn's lemma.
\end{proof}

\begin{cor} \label{cor:skew}
 If $A$ is a skew symmetric operator on a real Hilbert space $H$, then there exists a countable family of compact subsets $F_j \subset [0, \infty)$ and positive measures $\mu_j$ on $\mathcal{B}(F_j)$ and a real orthogonal transformation $V \colon H \to \big(\oplus_{j}  L^{2}(\mu_{j}) \big) \bigoplus \big(\oplus_{j} L^{2}(\mu_{j}) \big) $ such that

  \begin{equation}
    \label{eq:skew}
    A = V^{T} \begin{bmatrix}
                          0            & \oplus_{j}(-M_{\lambda}^{j})   \\
              \oplus_{j}M_{\lambda}^{j} &        0
             \end{bmatrix} V,
  \end{equation}
where $M_{\lambda}^{j} \colon L^{2}(\mu_{j}) \to L^{2}(\mu_{j})$ is such that $f \mapsto \lambda f$ with $(\lambda f)(x)= xf(x), \forall x \in F_{j}$.
\end{cor}
\begin{proof}
Since $A$ is skew-symmetric $\sigma(A)$ is contained in the imaginary axis.  Use Theorem \ref{thm:spectr-theor-real} to get $L^{2}(E_{j})$, where $E_{j}$ subset of the positive imaginary axis. Take $F_{j} = -iE_{j}$. Use the obvious transformation to transfer measure to $F_{j}$.
\end{proof}
\begin{cor}\label{cor:invertible}
  If $A$ is a skew symmetric invertible operator on a real Hilbert space $H$, then there exists a real Hilbert space $K$, a positive invertible operator $P$ on $K$ and a real orthogonal transformation $V \colon H \to K \oplus K $ such that

  \begin{equation}
    \label{eq:skew}
    A = V^{T} \begin{bmatrix}
               0   & -P  \\
               P   & 0
             \end{bmatrix} V.
  \end{equation}
\end{cor}
We give two proofs for this result the second proof is very elementary and does not use the spectral measure.
\begin{proof}(1)
  If  $A$ is invertible then each $M_{\lambda}^j$ in Corollary \ref{cor:skew} is invertible. So take $P= \oplus_{j}M_{\lambda}^{j} . $
\end{proof}
\begin{proof}(2)
  Assume first that $A$ has a cyclic vector $x$.
 Note that if $A$ is skew-symmetric, $A^{2k+1}$ is skew-symmetric and $A^{2k}$ is symmetric for $k\in \mathbb{N}$. Therefore 
 \begin{equation}\label{eq:ip}
 \langle A^{2n}x, A^{2m+1}x\rangle = 0, \phantom{...}\forall n,m \geq 0, 
 \end{equation} 
 because  $A^{2k+1}$ being skew-symmetric $\langle x, A^{2k+1}x\rangle = 0$ for all $k\geq 0$ . Set $K = \overline{\spn}\{x, A^2x,A^4x, \dots\}$ and $N =  \overline{\spn}\{Ax, A^3x,A^5x, \dots\}$. Then $K \perp N$ by (\ref{eq:ip}) and since $x$ is cyclic $N=K^{\perp}$. Therefore, there exists an operator $R: K\rightarrow N$ such that 

 \begin{equation}\label{eq:A}
  A  = \begin{bmatrix}
   0 & -R^{T}\\
   R & 0
  \end{bmatrix},
  \end{equation}
  in the direct sum decomposition $H= K\oplus N$. Since $A(A^{2n}x) = A^{2n+1}x$, $R := A|_{K}$ maps $K$ onto $N$, since $A$ is invertible  $R$ is an invertible operator. Now we apply polar decomposition to $R$. If $R= UP$ then $U:K\rightarrow N$ and $P:K\rightarrow K$ are such that $U$ is orthogonal (because $R$ is invertible) and $P$ ($=\sqrt[]{R^{T}R}$) is positive definite and invertible. %Orthogonality of $U$ follows because $T$ is invertible. 
 
  Now we have \begin{equation}
 A = \begin{bmatrix}
  I_M & 0\\
  0 & U
 \end{bmatrix} \begin{bmatrix}
   0 & -P\\
   P & 0
  \end{bmatrix} \begin{bmatrix}
  I_M & 0\\
  0 & U^{\tau}
  \end{bmatrix}, 
  \end{equation}
  where $I_M $ is the identity operator on $M$ and $\begin{bsmallmatrix}
  I_M & 0\\
  0 & U
  \end{bsmallmatrix} : K\oplus K \rightarrow K\oplus N$ is orthogonal. %Note that by construction $P$ is invertible. 
 
  If $A$ doesn't have a cyclic vector then a usual argument using Zorn's lemma along with a permutation proves the result.
\end{proof}

\section{Williamson's Normal Form}

All the work we have done till now was to obtain the right machinery for a proof of Williamson's normal form in the infinite dimensional set up.  This was our main goal. We refer to Parthasarathy \cite{Par13} for an easy proof of this theorem in the finite dimensional setup. 
%  \fbox{\parbox{\textwidth}
% {\textcolor{red}{Need to address the uniqueness question, define real positive operators and write a lemma on the square root of a positive operator}}}
\begin{defn}\label{def:J-operator}
  Let $H$ be a real Hilbert space and $I$ be the identity operator on $H$. Define the involution operator $J$ on $H \oplus H$ by
$J = \begin{bmatrix}
         0 & -I\\
         I & 0
     \end{bmatrix}.$
\end{defn}

\begin{defn}
 Let $H$ and $K$ be two real Hilbert spaces. A bounded invertible linear operator $Q \colon H\oplus H \to K\oplus K $  is called a symplectic transformation if $Q^{T}JQ = J$, where $J$ on left side is the involution operator on $K\oplus K$ and that on the right side it is the involution operator on $ H\oplus H$.
\end{defn}

Here is the main Theorem.

\begin{thm}\label{sec:will-norm-form}
  Let $H$ be a real Hilbert space and $A$ be a strictly positive invertible operator on $H\oplus H$ then there exists
% a $\delta > 0$ and an atmost countable family of positive measures $\mu_i$ on the Borel $\sigma$-algebra of compact subsets $E_i \subseteq [\delta, \infty)$
a Hilbert space $K$, a positive invertible operator $P$ on $K$ and a symplectic transformation $ L\colon H\oplus H \rightarrow K \oplus K$
% \big(\oplus_{i}  L^{2}(\mu_{i}) \big) \bigoplus \big(\oplus_{i} L^{2}(\mu_{i}) \big)
 such that   \begin{equation}
    \label{eq:will-norm-form}
    A = L^{T} \begin{bmatrix}
              P & 0  \\
              0 & P
             \end{bmatrix} L.
  \end{equation}

  % \begin{equation}
  %   \label{eq:will-norm-form}
  %   A = L^{T} \begin{bmatrix}
  %             \oplus_{i}M_{\lambda}^{i} & 0  \\
  %              0                     & \oplus_{i}M_{\lambda}^{i}
  %            \end{bmatrix} L
  % \end{equation}
%where $M_{\lambda}^{i}$ are as in Corollary \ref{cor:skew}.
The decomposition is unique in the sense that if $M$ is any strictly positive invertible operator on a Hilbert space $\tilde{H}$ and $\tilde{L}\colon H\oplus H \rightarrow \tilde{H} \oplus \tilde{H}$ is a symplectic transformation such that
 \begin{equation}\label{eq:uniqueness}
    A = \tilde{L}^{T} \begin{bmatrix}
              M & 0  \\
              0 & M
             \end{bmatrix} \tilde{L},
  \end{equation}
then
%$\oplus_{i}M_{\lambda}^{i}$
$P$ and $M$ are orthogonally equivalent.
\end{thm}

\begin{proof}
  Define $B= A^{1/2}JA^{1/2}$, where $A^{1/2}$ is as described in Corollary \ref{cor:sqr-rt} and $J$ is given by Definition \ref{def:J-operator}. Then $B$ is a skew symmetric invertible operator on $H\oplus H$.
 Hence by Corollary (\ref{cor:invertible})  there exists a real Hilbert space $K$, an invertible positive operator $P$ and  a real orthogonal transformation $\Gamma \colon K\oplus K \to H$ such that
\begin{equation} \label{eq:B}
   \Gamma^{T} B \Gamma =  \begin{bmatrix}
                          0 & -P   \\
                          P & 0
                         \end{bmatrix}.
  \end{equation}
% Define $Q \colon  K\bigoplus K \to H\bigoplus H $
Define $L \colon  H\oplus H \to K\oplus K ,$ by 
 \begin{equation}
   L      = \begin{bmatrix}
                          P^{-1/2}  & 0  \\
                           0 &  P^{-1/2}
                         \end{bmatrix} \Gamma ^TA^{\frac{1}{2}}.
  \end{equation}

Then clearly \ref{eq:will-norm-form} is satisfied.  A direct computation using \ref{eq:B} shows that $L$ is symplectic, that is $
LJL^T = J$, where $J$ on the left side  is the involution operator on $H\oplus H$ and on the right side is the corresponding involution operator on $K\oplus K.$  
%Also note that
%\begin{equation}
% Q^{-1}A(Q^{-1})^{T}=
% \begin{bmatrix}
%  P& 0 \\
%  0 & P
% \end{bmatrix}
%\end{equation}
%
%By taking $L = Q^{T}$  we obtain (\ref{eq:will-norm-form}). \\


% To prove the uniqueness let
%  \begin{equation*}
%     A = L^{T} \begin{bmatrix}
%               P & 0  \\
%                0& P
%              \end{bmatrix} L
%       = \tilde{L}^{T} \begin{bmatrix}
%               M & 0  \\
%               0 & M
%              \end{bmatrix} \tilde{L}
%   \end{equation*}
% with the assumptions in the statement of the theorem. Putting $N=L\tilde{L}^{-1}$ we get a symplectic $N$ such that
% \begin{equation*}
%    N^{T} \begin{bmatrix}
%               P & 0  \\
%                0& P
%              \end{bmatrix} N
%       =  \begin{bmatrix}
%               M & 0  \\
%               0 & M
%              \end{bmatrix}
% \end{equation*}
% Substituting $N^{T} = JN^{-1}J^{-1}$ with appropriate $J$'s we get
% \begin{equation}\label{eq:2}
%   N^{-1}\begin{bmatrix}
%               0 &  P  \\
%                - P & 0
%              \end{bmatrix} N
%     = \begin{bmatrix}
%               0 & M  \\
%               -M & 0
%              \end{bmatrix}
% \end{equation}







 % Hence by Corollary (\ref{cor:skew})  there exists a family of positive measures  $\mu_i$ as described in the statement of the theorem and  a real orthogonal transformation $\Gamma \colon \big(\oplus_{i}  L^{2}(\mu_{i}) \big) \bigoplus \big(\oplus_{i} L^{2}(\mu_{i}) \big) \to \mathcal{H}$ such that
% \begin{equation}
%    \Gamma^{T} B \Gamma =  \begin{bmatrix}
%                           0           & \oplus_{i}-M_{\lambda}^{i}   \\
%                          \oplus_{i}M_{\lambda}^{i} &        0
%                          \end{bmatrix}
%   \end{equation}
% Note that since $B$ is invertible there exists $\delta > 0$ such that $E_{i}\subset [\delta, \infty), \forall i$. Define $Q \colon \big(\oplus_{i}  L^{2}(\mu_{i}) \big) \bigoplus \big(\oplus_{i} L^{2}(\mu_{i}) \big) \to \mathcal{H} $

%  \begin{equation}
%    Q      =A^{1/2} \Gamma \begin{bmatrix}
%                           \oplus_{i}M^{i}_{\frac{1}{\sqrt{\lambda}}}  & 0  \\
%                            0 &  \oplus_{i}M^{i}_{\frac{1}{\sqrt{\lambda}}}
%                          \end{bmatrix}
%   \end{equation}

% Note that $Q$ is a bounded invertible operator and  $Q^{T}JQ$ is a bounded operator on $\big(\oplus_{i}  L^{2}(\mu_{i}) \big) \bigoplus \big(\oplus_{i} L^{2}(\mu_{i}) \big)$. A direct computation shows $
% Q^{T}JQ = J$, where $J$ on right side is the corresponding involution operator on $\big(\oplus_{i}  L^{2}(\mu_{i}) \big) \bigoplus \big(\oplus_{i} L^{2}(\mu_{i}) \big)$ and on the left side it is the involution operator on $\mathcal{H}\bigoplus \mathcal{H}$ . Also note that
% \begin{equation}
%  Q^{-1}A(Q^{-1})^{T}=
%  \begin{bmatrix}
%    \oplus_{i}M_{\lambda}^{i} & 0 \\
%                      0 & \oplus_{i}M_{\lambda}^{i}
%  \end{bmatrix}
% \end{equation}

% By taking $L = Q^{T}$  we obtain (\ref{eq:will-norm-form}). \\

To prove the uniqueness,  let 
% To prove the uniqueness,  let us apply spectral theorem to $P$. Let $P = V^T(\oplus_{i}M_{\lambda}^{i})V$ where $M_{\lambda}^{i}$ is a multiplication operator on some $L^2(\mu_i)$ and $V\colon K \to \oplus_{i}L^2(\mu_i)$ is an orthogonal transformation. Put  $ L = \begin{bsmallmatrix}
%       V &0\\
%       0 & V
%     \end{bsmallmatrix} L$. Note that $L$ is also a symplectic transformation. Now we have
\begin{equation*}
    A =L^{T}\begin{bmatrix}
              P & 0  \\
               0  & P
             \end{bmatrix} L
      = \tilde{L}^{T} \begin{bmatrix}
              M & 0  \\
              0 & M
             \end{bmatrix} \tilde{L},
  \end{equation*} where $P$,  $M$ are two positive operators and $L$, $\tilde{L}$ are symplectic.
 Putting $N=L\tilde{L}^{-1}$ we get a symplectic $N$ such that
\begin{equation*}
   N^{T} \begin{bmatrix}
              P & 0  \\
               0                     & P
             \end{bmatrix} N
      =  \begin{bmatrix}
              M & 0  \\
              0 & M
             \end{bmatrix}.
\end{equation*}
Substituting $N^{T} = JN^{-1}J^{-1}$ with appropriate $J$'s we get

\begin{equation}\label{eq:2}
  N^{-1}\begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix} N
    = \begin{bmatrix}
              0 & M  \\
              -M & 0
             \end{bmatrix}.
\end{equation}

 Now we recall the fact that two similar normal operators are unitarily equivalent (this can be proved using Fuglede-Putnam theorem, see Theorem 12.36 in \cite{Rud91}). However, we continue with our proof without using this result. To this end, taking transpose on both sides of (\ref{eq:2}) we get

 \begin{equation*}
     N^{T}\begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix} (N^{T})^{-1}
    = \begin{bmatrix}
              0 & M  \\
              -M & 0
             \end{bmatrix}.
 \end{equation*}
Hence again by using (\ref{eq:2}) we get
\begin{equation*}
  N^{T}\begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix} (N^{T})^{-1}
  =  N^{-1}\begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix} N,
\end{equation*}
  or
\begin{equation*}
  \begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix} (N^{-1})^{T}N^{-1}
  =  (N^{-1})^{T}N^{-1}\begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix}.
\end{equation*}
This implies
\begin{equation}\label{eq:1}
   \begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix} \big((N^{-1})^{T}N^{-1}\big)^{1/2}
  = \big( (N^{-1})^{T}N^{-1}\big)^{1/2} \begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix},
\end{equation}
where the reasoning for (\ref{eq:1}) is same as that in the complex case. Let $N^{-1} = U\big( (N^{-1})^{T}N^{-1}\big)^{1/2}$ be the polar decomposition of $N^{-1}$. From (\ref{eq:2}) we get
\begin{equation*}
  U\big( (N^{-1})^{T}N^{-1}\big)^{1/2}\begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix}\big( (N^{-1})^{T}N^{-1}\big)^{-1/2} U^{T}
    = \begin{bmatrix}
              0 & M  \\
              -M & 0
             \end{bmatrix}.
\end{equation*}
Hence by (\ref{eq:1}) we have
\begin{equation}\label{eqW:skew-unitary2}
    U\begin{bmatrix}
              0 &  P   \\
               - P & 0
             \end{bmatrix}U^{T}
    = \begin{bmatrix}
              0 & M  \\
              -M & 0
             \end{bmatrix}.
\end{equation}
Now we will prove that (\ref{eqW:skew-unitary2}) implies  that $P$ and $M$ are orthogonally equivalent. Note that by taking squares, and getting rid of the negative sign,
\begin{equation*}
              U \begin{bmatrix}
              P^2 &  0   \\
                 0 & P^2
             \end{bmatrix}U^{T} =\begin{bmatrix}
              M^2 &  0   \\
                 0 &  M^2
             \end{bmatrix}.
\end{equation*} It is true that if $A$ and $B$ are self adjoint operators such that $A\oplus A$ and $B \oplus B$ are orthogonally equivalent then $A$ and $B$ are orthogonally equivalent. We will give a proof of this as a Lemma below. But if we assume this fact our proof is complete because we see that for the positive operators $P$ and $M$, $P^2$ and $M^2$ are orthogonally equivalent. Hence $P$ and $M$ are orthogonally equivalent.
%A^{\frac{1}{2}}JA^{\frac{1}{2}}
\end{proof}

Now we proceed to provide the proof of a lemma we promised. We depend on Hall \cite{Hall13} for notations and results used below. We write the following in the framework of complex Hilbert spaces, but as it was observed after Theorem \ref{thm:spectral-normal}, the spectral theory of a self-adjoint operator is identical on both real and complex Hilbert spaces and hence what we write below works on separable real Hilbert spaces also.

By the direct integral version of spectral theorem, any bounded self-adjoint operator $A$ on a separable Hilbert space is unitarily equivalent to the multiplication operator 
 $s\mapsto xs$  where $xs(\lambda) := \lambda s(\lambda ), \lambda \in \sigma(A)$ on $\int_{\sigma(A)}^{\oplus}\mathcal{H}_{\lambda}d\,\mu(\lambda)$ for some $\sigma$-finite measure $\mu$ with a measurable family  of Hilbert spaces $\{\mathcal{H}_{\lambda}\}$, satisfying dim$( \mathcal{H}_{\lambda})>0   $ almost everywhere $\mu .$ It is understood that we work with the Borel subsets of the spectrum $\sigma(A)$.  The function  $\lambda \mapsto \dim (\mathcal{H}_{\lambda})$ is called the multiplicity function associated with the direct integral representation of $A$.
By Proposition 7.24 from \cite{Hall13}, two bounded self-adjoint operators expressed as direct integrals on their spectrum are unitarily equivalent if and only if (i) the spectrum are same; (ii) the associated measures are equivalent in the sense that they are mutually absolutely continuous and (iii) the multiplicity functions coincide almost everywhere.


%characterizing the unitary equivalence class of a bounded self-adjoint operator. 
%\begin{thm}
%Suppose $A_1$ and $A_2$ are bounded self-adjoint operators on separable Hilbert spaces $\mathcal{H}_1$ and $\mathcal{H}_2$, respectively. Consider the direct integral representations for $A_1$ and $A_2$  with associated measures $\mu_1$ and $\mu_2$ (on Borel subsets of $\sigma(A_1)$ and $\sigma(A_2)$ respectively) chosen so that $\dim \mathcal{H}_{\lambda}^j > 0$ for $\mu_j$-almost everywhere $\lambda \in \sigma(A_j)$. Then $A_1$ and $A_2$ are unitarily equivalent if and only if the following conditions are satisfied.
%\begin{enumerate}
%\item $\sigma(A_1) = \sigma(A_2)$
%\item The measures $\mu_1$ and $\mu_2$ are mutually absolutely continuous.
%\item The multiplicity functions of $A_1$ and $A_2$ coincide up to a set of measure zero.
%\end{enumerate}
%\end{thm}
\begin{lem}\label{lem:direct-sum-unitary}
Let $A, B$ be self-adjoint operators on separable Hilbert space such that $A \oplus A$ and $B \oplus B$ are unitarily equivalent. Then $A$ and $B$ are unitarily equivalent.
\end{lem}
\begin{proof}
Let $A$ be unitarily equivalent to the multiplication operator 
for each section $s$, with respect to a measure $\mu$ on $\sigma (A)$ in the direct integral Hilbert space 
\[\int_{\sigma(A)}^{\oplus}\mathcal{H}_{\lambda}d\,\mu(\lambda).\] Then it can be seen that $A \oplus A$ is unitarily equivalent to the multiplication operator on the direct integral 
\[\int_{\sigma(A)}^{\oplus}\mathcal{K}_{\lambda}d\,\nu(\lambda) , \]  where 
$\mathcal{K}_{\lambda} = \mathcal{H}_{\lambda} \oplus \mathcal{H}_{\lambda}, \lambda \in \sigma(A)$ and $\nu = \frac{1}{2}\mu$. Since $A \oplus A$ and $B \oplus B$ are unitarily equivalent, by the uniqueness of integral representation mentioned above,  by comparing spectrum, measures and multiplicity functions it is easy to see that $A$ and $B$ are unitarily equivalent.
\end{proof}

\begin{rmk}
We observe that Lemma \ref{lem:direct-sum-unitary} can be proved using standard versions of Hahn-Hellinger theorem also, for example Theorem 7.6 in \cite{Par12} can also be used. We also note that if we take infinitely many copies of self-adjoint operators $A,B$ and $\oplus _{i=1}^{\infty} A$ is unitarily equivalent to 
$\oplus _{i=1}^{\infty} B$, does not mean that $A$ and $B$ are unitarily equivalent. So it is only natural that the multiplicity theory is required in the proof of last Lemma. 
\end{rmk}

\begin{rmk}
Under the situation of Theorem 5.3, in view of the uniqueness part of the theorem, the spectrum of $P$, can be defined as the symplectic spectrum of the positive invertible operator $A$.
\end{rmk}

\textbf{Acknowledgements:} We wish to thank Prof. K. R. Parthasarathy for introducing the subject to us during his 2015 lecture series at the Indian Statistical Institute, Bangalore centre. We also thank Prof. K. B. Sinha for the fruitful discussions we had with him on direct integrals. Bhat thanks J C Bose Fellowship for financial support.




% As promised in the proof of the previous theorem we will prove the following
% \begin{lem}

% \end{lem}

% New references:
% \begin{verbatim}

% [1] Rajendra Bhatia and Tanvi Jain. ?On symplectic eigenvalues of
% positive definite matrices?. In: Journal of Mathematical Physics
% 56.11, 112201 (2015). doi: 10.1063/1.4935852.

% [2] Martin Idel* , Sebatian Soto Gaona, Michael M. Wolf:,
% Perturbation Bounds for Williamson?s Symplectic Normal Form, Linear
% Algebra and its Applications 525 (2017) 45?58,
% https://linkinghub.elsevier.com/retrieve/pii/S0024379517301751

% [3] Maurice de Gosson, Symplectic Methods in Harmonic Analysis and
% Applications to Mathematical Physics; Birkh?user (2011)[23] ISBN
% 3-7643-9991-0 .
% \end{verbatim}

% \begin{thebibliography}{9}
% \bibitem{RKG} Goodrich, Robert Kent, \textit{The spectral theorem for real Hilbert Space}, Acta Sci. Math. (Szeged), 33, (1972), 123-127.
%\bibitem{RR} Radjavi H, Rosenthal P, \textit{Invariant Subspaces}, Springe-Verlag.
%\bibitem{PLD} Duren, P L, \textit{Theory of $H^p$ spaces}, Dover.
%\bibitem{RGD} Douglas R G, \textit{Banach Algebra Techniques in Operator Theory}, Graduate Texts in Mathematics, Vol. 179, Springer-Verlag.
% \end{thebibliography}




%\bibliographystyle{amsplain}
%\bibliography{williamsonv1}

% \noindent
%  \textsc{B. V. Rajarama Bhat}:
%  {\small\itshape Indian Statistical Institute Bangalore, 8th Mile Mysore Road, R.V. College Post, Bangalore-560059, India}.
%  {\small{\itshape\tt{E-mail:  bvrajaramabhat@gmail.com}}}.\\

% %
% %
%  \noindent
%  \textsc{Tiju Cherian John}:
%  {\small\itshape Indian Statistical Institute Bangalore, 8th Mile Mysore Road, R.V. College Post, Bangalore-560059, India}.
%  {\small{\itshape\tt{E-mail: tijucherian@gmail.com}}}.
\bibliographystyle{amsalpha}
\bibliography{bibliography}
\end{document}
