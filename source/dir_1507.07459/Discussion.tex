\chapter{Discussion}\label{chap:Discussion}

In this chapter we will discuss possible directions for further research. The LP and the SDP relaxations for the problem are discussed in Section \ref{sec:DiscLP}. Section \ref{sec:DiscBerman} considers possible ways in which the weighted approximation algorithm of Berman \cite{Berman} could be lightly changed. Section \ref{sec:IS} continues with a discussion about the difference in the results on the independent set problem in bounded degree graphs and the current results on $k$-set packing. Finally Section \ref{sec:WeightedVSUnweighted} discusses the problems arising when one tries to generalise the unweighted approximation algorithms with weights. Sections \ref{sec:DiscLP}, \ref{sec:IS} and \ref{sec:WeightedVSUnweighted} suggest future research directions and contain some conjectures. %and what makes the $\frac{k+2}{3}$-approximations so considerably easier than the $\frac{k+1}{3}$-approximations.

%In this chapter we will discuss possible directions for further research. We start with a discussion about the LP and the SDP relaxations for the problem. Next we consider possible ways in which the weighted approximation algorithm of Berman \cite{Berman} could be lightly changed. Then we discuss the difference in the results on the independent set problem in bounded degree graphs and the current results on $k$-set packing. We discuss the problems arising when one tries to generalize the unweighted approximation algorithms with weights and what makes the $\frac{k+2}{3}$-approximations so considerably easier than the $\frac{k+1}{3}$-approximations.

\section{LP and SDP relaxations}\label{sec:DiscLP}

Here is a summary of the current results.
%
\begin{enumerate}
  \item The standard LP relaxation for $k$-set packing has integrality gap $k - 1 + \frac{1}{k}$. In the case of $k$-dimensional matching (i.e. when the hypergraph is $k$-partite) the integrality gap equals $k - 1$. Chan and Lau \cite{LapChiLau} gave algorithms for these cases. These results and algorithms also extend to the weighted case.
  \item The intersecting family LP for $k$-set packing has integrality gap at most $\frac{k}{3} + 1 + \varepsilon$ (Theorem \ref{thm:IntegralityGap2}). It is not known whether this result also extends to the weighted case.
  \item By the results of \cite{LapChiLau}, there also exists a polynomially sized LP for $k$-set packing with integrality gap at most $\frac{k}{3} + 1 + \varepsilon$. We don't know whether this is also true for the weighted version either.
  \item Also by \cite{LapChiLau}, the Lov\'{a}sz Theta function is at least as strong as the intersecting family and therefore this SDP relaxation has integrality gap at most $\frac{k}{3} + 1 + \varepsilon$.
\end{enumerate}

\subsection{Extending results to the weighted case}\label{subsec:WeightedLP}

\paragraph{Unweighted versus weighted} While the results for the standard LP extend to the weighted case, the results for the intersecting family LP do not extend in an obvious way. This is for the same reason why the unweighted approximation algorithms for $k$-set packing do not easily generalise to the weighted case (c.f. Section \ref{sec:WeightedVSUnweighted}): the local search technique is relying crucially on cardinality. For example, $\mathcal{F}_1(e)$ in the proof of Theorem \ref{thm:IntegralityGap2} need not be an intersecting family in the weighted case: the objective function might increase even by adding less sets than are removed. We elaborate on this in Section \ref{sec:WeightedVSUnweighted}. %It is not obvious how to improve significantly on the integrality gap of the standard LP for weighted $k$-set packing.

\paragraph{Possible research directions} Perhaps there is another way to partition the hyperedges rather than in $\mathcal{F}_1$, $\mathcal{F}_2$ and $\mathcal{F}_{3+}$ that does provide a way to extend the result to the weighted case. For the weighted problem the setting of $\mathcal{F}_1$, $\mathcal{F}_2$ and $\mathcal{F}_{3+}$ does not make sense and nothing can be proved. In the weighted case it seems to make sense to define a $t$-locally optimal solution as a solution where adding at most $t$ new sets and losing any number of sets does not yield an improvement (instead of losing less than $t$ sets in the unweighted case). But perhaps in the weighted case it will prove to be worthwhile to consider the integral optimum solution rather than a $t$-locally optimum.

The proof of the existence of a polynomially sized LP in Theorem \ref{thm:LP2} depends on the existence of small kernels for every intersecting family. If a new result on the integrality gap of some LP for weighted $k$-set packing relies on intersecting families, this result still holds. The SDP relaxation still captures all intersecting family constraints in the weighted case (one can just add weights to the objective function and nonnegativity constraints on them), so if one proves a result for weighted $k$-set packing using these intersecting families, that result immediately extends to the polynomially sized LP and SDP relaxation.

\begin{prob}
Narrow the gap between the integrality gap for relaxations of the weighted and the unweighted $k$-set packing problem.
\end{prob}

\subsection{Smaller bound on integrality gap}\label{subsec:IntegralityGap}

Another way to improve upon the current results is to further decrease the upper bound on the integrality gap on LP relaxations like the intersecting family. This seems likely to be possible, because all unweighted approximation algorithms achieve bounds of $\frac{k+2}{3} + \varepsilon$ or $\frac{k+1}{3} + \varepsilon$ while the current result is $\frac{k}{3} + 1 + \varepsilon$. Perhaps some ideas from these algorithms can be extended to the integrality gap of the LP relaxation.

\begin{prob}
Improve the integrality gap of relaxations for the unweighted $k$-set packing to $\frac{k+2}{3} + \varepsilon$ or better.
\end{prob}

\paragraph{Towards a gap of $\frac{k+1}{3} + \varepsilon$} In particular we would like to point out that it may be worthwhile to see if the idea from the quasi-polynomial time $\frac{k+1}{3} + \varepsilon$ from $\cite{Mastrolilli}$ can be extended. The proof of this approximation guarantee also depends on Lemma \ref{lem:BermanMIS2} as did our new bound of $\frac{k}{3} + 1 + \varepsilon$. Their algorithm uses slightly more crafted ideas, but these do not seem to extend to the integrality gap of the LP in a straightforward way. Roughly speaking they are able to bound $\mathcal{F}_1$ by $\varepsilon |M|$ rather than $|M|$. This is then added twice like in the proof of Theorem \ref{thm:IntegralityGap2}. This effectively decreases the bound by $\frac{2}{3}|M|$ which is exactly the current difference between the results. Perhaps by altering the argument a little bit, one could use the idea of this proof to improve the bound for the integrality gap for the intersecting family LP to, say, $\frac{k+1}{3} + \varepsilon$.

\paragraph{Towards a gap of $\frac{k+2}{3} + \varepsilon$} Also the idea from the $\frac{k+2}{3}$-approximation by Sviridenko and Ward \cite{Sviridenko} might be interesting to take a closer look at. Very roughly speaking they bound $\mathcal{F}_2$ by $2 |M \setminus \mathcal{F}_1|$. This cancels against the bound for $\mathcal{F}_1$ and hence they obtain $3 |\mathcal{F}| \leq k|M| + 2|M|$. A similar idea could perhaps be used to bound the LP-values of the sets $\mathcal{F}_1$ and $\mathcal{F}_2$.

Since the local search techniques have reached their limits in terms of their approximation guarantee, other techniques have to be sought to improve the approximation guarantee. The results on the LP and SDP relaxations for $k$-set packing are scarce and we believe more research in this area could turn out to be fruitful. We make the following conjecture.

\begin{conjecture}
The integrality gap of relaxations for the unweighted $k$-set packing can be bounded by $\frac{k+1}{3} + \varepsilon$.
\end{conjecture}

\section{Improving Berman's weighted approximation}\label{sec:DiscBerman}

\subsection{Generalising $charge$ and claws}\label{subsec:DiscBerman1}

The analysis as presented in Section \ref{sec:ProofBerman} shows that slight changes to the algorithm do not simply constitute an improvement of the approximation guarantee to $\frac{k}{c}$ for some $c > 2$. Let us replace the $\frac{1}{2}$ in the definition of $charge(u,v)$ to $\frac{1}{c}$ and the $\frac{1}{2}$ in the definition of a nice (good) claw to $\frac{1}{c}$.

\paragraph{Approximation guarantee} Lemma \ref{lem:Berman1} can now be easily adapted to hold for any $c>2$. The proof remains exactly the same and \textsc{WishfulThinking} now has an approximation guarantee of $\frac{k}{c}$.

\paragraph{Nice claw improves $w^2(A)$} However, Lemma \ref{lem:Berman2} is no longer true and this can be seen from our simplified proof. In the proof that the talons of a nice claw improve $w^2(A)$ when the definitions of $charge(u,v)$ and of a nice claw have been altered, the analysis remains exactly the same except for the fact that in Equation \eqref{eighth}, the factor 2 in the right-hand side changes into a $c$:

\begin{equation}\label{eighth2}
w^2(u) + w^2(v) \geq cw(u)w(v),
\end{equation}

However, Equation \eqref{eighth2} is only true for all $u$ and $v$ for the values $c=0$ and $c=2$. Since $c=0$ is not possible because $c$ occurs in the denominator in the definition of $charge(u,v)$ and of a nice claw, $w^2(A)$ improves only when $c=2$ when following the current analysis.

It is possible to incorporate an extra constraint in the definition of a nice claw to make sure that Equation \eqref{eighth2} holds for some $c > 2$. Then Lemma \ref{lem:Berman2} is true because of the altered definition. However, the extra constraint now causes trouble in the proof of Lemma \ref{lem:Berman1}, which is then not necessarily true anymore.

\subsection{Generalising the weight function}\label{subsec:DiscBerman2}

Intuitively, what is the crucial point why $w^2$ might behave differently than $w$? In general, looking at the squared weight function (or at $w^c$ for any $c>1$) is slightly more biased towards larger weights. When a vertex has some weight $m$ and we add 1 to its weight, $w$ increases by 1 while $w^2$ increases by $2m+1$. Also the square of the weight of one vertex might be more than the weight of two vertices. $w^2$ prefers one vertex of weight 3 to two vertices of weight 2, while $w$ prefers the two vertices of weight 2 to the single vertex of weight 3. So by guiding the search by $w^2$ rather than $w$, an iteration might decrease the real objective function but it is more difficult to get stuck in an inferior locally optimal solution and hence a better result might be achieved in the end.

One could also try to improve $w^p$ for some $2 < p \in \mathbb{N}$ next to the use of the parameter $c$ rather than 2. Following the same analysis as in Section \ref{sec:ProofBerman}, Equation \eqref{eighth} then translates to
%
\begin{equation*}
w^p(u) + w^p(v) \geq c w(u) w^{p-1}(v).
\end{equation*}
%
This is trivially true for $c = 0$ and even $p$, for $p = c = 1$ and for $p = c = 2$. Again the first is not a real option, the second option gives an approximation guarantee of $\frac{k}{1}$ which is not an improvement and the third option is the one that leads to Berman's result. %One could try to choose $c = { p \choose 1 }$, so that the term on the right-hand side cancels when one applies that binomial theorem on $(w(u)+w(v))^p$.
%Using the binomial theorem on $(w(u)+w(v))^p$ cancels the term on the right-hand side by letting $c={p \choose 1}=p$, but yields some other terms that seem to hurt.
%Note that this is also true for $p = c = 1$, which gives the standard $d$-approximation back.
This shows that using the current analysis this is the best possible result, so to improve the approximation guarantee one really needs another analysis or another approach. See also \cite{BermanWeighted2} for other reasoning about generalising Berman's algorithm.

\section{Relation to the independent set problem}\label{sec:IS}

Here is a summary of the relation between $k$-set packing and the independent set problem.

\begin{enumerate}
  \item Finding a maximum set packing is equivalent to finding a maximum independent set in the conflict graph of the set packing instance.
  \item Finding a maximum $k$-set packing can be reduced to finding a maximum independent set in the $k+1$-claw free conflict graph of the $k$-set packing instance. %This last problem is more general than $k$-set packing as there are $k+1$-claw free graphs that do not correspond to any $k$-set packing instance.
  %\item $k$-set packing is a more general problem than the maximum independent set problem on bounded degree graphs.
\end{enumerate}

\subsection{Results on the independent set problem}\label{subsec:ResultsIS}

\paragraph{General graphs} The following results are known for the maximum independent set problem in general. Let $n$ be the number of vertices in the graph.
%
\begin{enumerate}
  \item The problem is NP-hard and it is hard to approximate within $n^{1 - \varepsilon}$ unless NP-hard problems have randomised polynomial time algorithms \cite{CliqueIsHard}.
  \item There is an approximation algorithm that achieves an approximation guarantee of $\Theta\left( \frac{n}{\log^2 n} \right)$ \cite{ApproxGeneralIS}.
  %\item There exists no constant factor approximation algorithm \cite{noPTAS1} if $\mathcal{P} \neq \mathcal{NP}$.
  %\item An $n^{\frac{1}{4}}$-approximation ratio is out of reach \cite{NoApproxGeneralIS}.
\end{enumerate}
%
\paragraph{Bounded degree graphs}
When the maximum degree of every vertex is assumed to be bounded by some $\Delta$, approximating the problem becomes considerably easier. The following results are known for the maximum independent set problem on bounded degree graphs.
%
\begin{enumerate}
  \item Assuming the Unique Games Conjecture \cite{UGC} it is hard to approximate within $O \left( \frac{\Delta}{\log^2 \Delta} \right)$ \cite{Bounded1}.
  %\item For all $\Delta > 3$ these exists an $\varepsilon > 1$ such that it is NP-hard to $(1 + \varepsilon)$-approximate the problem \cite{noPTAS1,NoPTAS3}.
  %\item There exists an $\varepsilon > 0$ such that it is NP-hard to $O \left( \Delta^\varepsilon \right)$-approximate the problem \cite{Communication}.
  \item %It is obvious the simple greedy algorithm finds an independent set of size at least $\frac{n}{\Delta}$.
  The greedy algorithm is an obvious $\Delta$-approximation. Hochbaum \cite{Hochbaum} was the first to give an approximation algorithm with approximation guarantee $\frac{\Delta}{2}$, which was improved to $\frac{\Delta+2}{3}$ \cite{GreedIsGood,HalldorssonLau}. Berman and F\"{u}rer \cite{BermanMIS} give a $\frac{\Delta+3}{5} + \varepsilon$-approximation for even $\Delta$ and a $\frac{\Delta+3.25}{5} + \varepsilon$-approximation for odd $\Delta$, which was slightly improved in \cite{BermanFujito}. Then a major jump came with an $O \left( \frac{\Delta}{ \log \log \Delta} \right)$-approximation, a $\frac{\Delta}{6}(1+o(1))$-approximation, a proof that greedy achieves $\frac{\Delta+2}{3}$ and that Berman and F\"{u}rer really achieved $\frac{\Delta+3}{4}$ \cite{Bounded2}. The currently best result is an $O \left( \frac{\Delta \log \log \Delta}{\log \Delta} \right)$-approximation in polynomial time that also extends to the weighted case \cite{Halperin,SpecialWeight,Vishwanathan}.
\end{enumerate}

\subsection{From bounded degree to claw-free graphs}\label{subsec:DiscIS2}

\paragraph{Comparison} The results on the maximum independent set problem in bounded degree graphs are much stronger than the results on $k$-set packing. For example, the gap between its hardness ($\Omega \left( \frac{\Delta}{\log^2 \Delta} \right)$) and its best approximation guarantee ($O \left( \frac{\Delta \log \log \Delta}{\log \Delta} \right)$) is much smaller ($\Omega(\frac{k}{\log k})$ versus $\frac{k+1}{3} + \varepsilon$). The constraint that the degree is bounded apparently allows much more arguments than the constraint that the size of an independent set in the neighbourhood of every vertex is bounded. %[TODO: What goes wrong if you try to use the SDP approach for d/log d here? What may be a way out?]

\begin{prob}
Narrow the gap between the approximation guarantee of $k$-set packing and the independent set problem on bounded degree graphs.
\end{prob}

\paragraph{Mimicking the bounded degree algorithm} As an example, consider the $O \left( \frac{\Delta \log \log \Delta}{\log \Delta} \right)$-approximation for weighted independent set in bounded degree graphs by Halperin \cite[Section 5]{Halperin}. In a nutshell this solves a semidefinite programming relaxation and partitions the resulting vectors in sets $S_0$, $S_1$ and $S_2$. It then uses the greedy approach on $S_0$ to find an independent set $I_0$, projects and normalises the vectors in $S_1$ and selects some of them to find $I_1$, and just sets $I_2 = S_2$. It then returns the largest weight independent set from $I_0$, $I_1$ and $I_2$. By a good choice of a parameter the approximation guarantee is achieved.

If one tries to use the same approach on the independent set problem in $k+1$-claw free graphs it is the set $S_0$ that is causing trouble. In the bounded degree case it is trivially true that the greedy algorithm produces an independent set $I_0$ of total weight at least $\frac{w(S_0)}{\Delta+1}$ where $w(S_0)$ is the sum of the weights of the vertices in $S_0$. %by just selecting the vertex with the lowest degree and removing it along with all its neighbours, and then iterating on the graph with $\Delta + 1$ vertices less.
Intuitively $S_0$ is already a good structured set so it is not needed to do anything smarter than the greedy algorithm.

However, in the $k+1$-claw free case the greedy algorithm does not have such a sufficient performance guarantee. It has a performance guarantee of $k$, %but a performance guarantee in terms of $w(S_0)$ (or $|S_0|$ in the unweighted case) is needed.
so the value of the greedy solution can be compared to the optimal independent set size in $S_0$. But it can not be compared to the weight (or the cardinality) of $S_0$.

\paragraph{Intuition and research direction} Morally it seems there should not be such a difference between the independent set problem in bounded degree graphs and claw-free graphs. Look at a vertex $v$ in a claw-free graph and at its neighbours $N(v)$. As the maximum size of an independent set in $N(v)$ is at most $k$, one could look at $N(v)$ as the union of $k$ cliques (in relation to the set packing instance: one clique for the sets that all share one of the $k$ elements, modulo some duplicates). And for the independent set problem, a clique is not that different from a vertex: it is only possible to pick one of the vertices. It would be an interesting research direction to see where exactly the analogy with the bounded degree graphs stops, or to somehow change the algorithm for the bounded degree graphs and achieve an improved approximation guarantee for claw-free graphs.

The intuition in this paragraph inclines us to believe the approximation guarantee for $k$-set packing can be brought down further. Perhaps it it not $\frac{k}{\log k}$, which is the best known hardness bound, but we make the following conjecture.

\begin{conjecture}
The approximation guarantee for $k$-set packing can be bounded by some function strictly smaller than $\frac{k}{3}$.
\end{conjecture}

%As such, the $k$-set packing problem generalizes the maximum independent set problem in bounded degree graphs. This is an NP-complete problem, it does not admit a polynomial time approximation scheme \cite{noPTAS1}, and assuming the Unique Games conjecture (see \cite{UGC}) the problem of finding a maximum independent set in a $d$-regular graph cannot be approximated within a factor $O\left(\frac{d}{\log^2{d}}\right)$ \cite{Bounded1}. On the positive side, the greedy approach for this problem was shown to have an approximation ratio of $\frac{d+2}{3}$ \cite{GreedIsGood}. The currently best approximation algorithm achieves an approximation guarantee of $O\left(\frac{d}{\log \log d}\right)$ \cite{Bounded2}. In Chapter \ref{chap:IS} we will elaborate more on the difference between the maximum independent set problem in bounded degree graphs and $k+1$-claw free graphs [TODO].

\section{Unweighted versus weighted $k$-set packing}\label{sec:WeightedVSUnweighted}

\paragraph{General extension} For most problems the weighted version is not much more difficult than the unweighted version. For example, also weighted matchings can be found in graphs in polynomial time, and for a lot of problems adding weights to the LP-formulation does not change anything significantly. However, for $k$-set packing the difference between the weighted version and the unweighted version is nontrivial.

\paragraph{Extending $k$-set packing} As noted in Section \ref{sec:Unweighted}, the analysis of the unweighted case hugely depends on the cardinality of every set. This is because the algorithms rely on local search and analyse a locally optimal solution. However, adding more sets than you remove from your current solution may not be advantageous in the weighted case, as the total weight might decrease while the cardinality of the solution increases. And in the weighted case, it could be the case that the total weight increases when you add less sets than you remove from your current solution. This proves hard to be incorporated in the analysis, and the weights of the sets cannot be handled in a straightforward way. This is why the results for the unweighted case do not easily extend to the weighted case. There have been less results on the weighted case and the algorithms do not immediately follow from the unweighted results, although they all use local search techniques.

\begin{prob}
Improve the approximation guarantee for weighted $k$-set packing.
\end{prob}

\paragraph{Research direction} The best weighted approximation algorithms reduce the problem to the independent set problem on $k+1$-claw free graphs. There are no indications so far that better results can be obtained in the weighted $k$-set packing problem by holding back from this reduction, so this seems a good way to look at the problem. These weighted approximation algorithms achieve approximation guarantees of approximately $\frac{2k}{3}$ \cite{Chandra} and $\frac{k}{2}$ \cite{Berman}. Section \ref{sec:DiscBerman} considered possible ways to improve upon this last algorithm by changing it a little bit, aided by the simplified proof from Chapter \ref{chap:Weighted}. Berman and Krysta \cite{BermanWeighted2} considered what values of $w^\alpha$ are the best for every $k$ when one searches a 2-locally optimal solution and achieve an approximation guarantee of about $\frac{2k}{3}$. A natural extension of this would be to use this alternate weight function in a search for $t$-locally optimal solutions for some $t>2$. Considering such larger improving sets proved to work for the unweighted problem and it trivially works for the weighted case when one searches for improving sets of size $n$; the question is, how large do the improving sets have to be to get an improved approximation guarantee of, say, about $\frac{k}{3}$? Perhaps a value of $t = O(k)$ or $t = O(\log n)$ works. We think it is fruitful to investigate this possibility and either find a better approximation algorithm or an indication that this might not be helpful after all.

We believe a better approximation guarantee could be obtained by increasing the search space and we make the following conjecture.

\begin{conjecture}
The approximation guarantee for weighted $k$-set packing can be bounded by $\frac{k+c}{3} + \varepsilon$ for some fixed $c \geq 0$.
\end{conjecture}

%[TODO done: What are the issues while trying to get k/3+c for the weighted case? May be you can conjecture some algorithm that might work, given the new developments for unweighted case]

%[TODO] discussion of what makes (k+2)/3 bound in Sviridenko et al paper easier than (k+1)/3.
%Is it for the same reason why (k+1)/2 is very easy with Hurken-Schrijver  but k/2 needs much more work. 