
In Section \ref{subsec:necessary} we derive the necessary conditions for exact support recovery for thresholding procedures. 
The role of thresholding procedures is then analyzed in Section \ref{subsec:optimality}. 

\subsection{Necessary conditions for exact support recovery under URS}
\label{subsec:necessary}

With the preparations from Section \ref{subsec:URS}, we are ready to state the converse of Theorem \ref{thm:sufficient}.
It turns out that under the general dependence structure characterized by URS, the boundary \eqref{eq:strong-classification-boundary} is tight for thresholding procedures.

\begin{theorem} \label{thm:necessary}
    Let ${\cal E}$ be a triangular array with AGG marginal $F$ with parameter $\nu > 0$, and the signals $\mu$ be as described in Theorem \ref{thm:sufficient}. 
    Assume further that the errors ${\cal E}$ have uniform relatively stable maxima and minima, i.e., ${\cal E}\in U(F)$, and $(-{\cal E}) = \{-\epsilon_{p}(j)\} \in U(F)$.
    If 
    \begin{equation} \label{eq:signal-below-boundary}
        \overline{r} < g(\beta) = \left(1+(1-\beta)^{1/\nu}\right)^\nu,
    \end{equation}
    then no thresholding procedure can succeed in the exact support recovery problem.
    That is, for any $\widehat{S}_p = \{j\in[p]\;|\;x(j)\ge t_p(x)\}$, where the threshold $t_p(x)$ may depend on the data, 
    \begin{equation} \label{eq:classification-impossible-dependent}
        \lim_{p\to\infty}\mathbb P[\widehat{S}_p = S_p] = 0. 
    \end{equation}
\end{theorem}

We shall first comment on the role of error dependence.

\begin{remark} \label{rmk:dependence-assumptions}
Paraphrasing Theorems \ref{thm:sufficient} and Theorem \ref{thm:necessary}: 
if we consider only thresholding procedures, then for a very large class of dependence structures, we cannot improve upon the Bonferroni procedure $\widetilde{S}_p$. 
Specifically, for all ${\cal E}\in U(F)$, and for all $S_p\in {\cal S}$, we have
\begin{equation}
    \lim_{p\to\infty} \P[\widetilde{S}_p\neq S_p]
    = \begin{cases}
    \inf_{\widehat{S}_p \in {\cal T}} \liminf_{p\to\infty} \P[\widehat{S}_p\neq S_p] = 1, & \text{if}\quad \overline{r} < g(\beta)\\
    \inf_{\widehat{S}_p \in {\cal T}} \limsup_{p\to\infty} \P[\widehat{S}_p\neq S_p] = 0, & \text{if}\quad \underline{r} > g(\beta),\\
    \end{cases}
\end{equation}
where $\cal T$ is the set of all thresholding procedures (recall \eqref{eq:thresholding-procedure}). 
% In contrast, \citet{butucea2018variable} state that (for Gaussian errors) a particular thresholding procedure $\widetilde{S}$ is minimax; see Section \ref{subsec:optimality} below. 

In view of Theorem \ref{thm:necessary}, we also answer the question raised in \citet{butucea2018variable}.
In particular, the authors of \citep{butucea2018variable} commented that independent error is the  `least favorable model' in the problem of support recovery, and conjectured that the support recovery problem may be easier to solve in the case of dependence, similar to how the problem of signal detection is easier under dependent errors (see \citep{hall2010innovated}).
Our results here state that asymptotically, \emph{all} error dependence structures in the URS class are equally difficult for thresholding procedures. 
Therefore, the phase-transition behavior is universal in the class of dependence structures characterized by URS.
\end{remark}

Returning to the more concrete example of Gaussian errors, Theorem \ref{thm:Gaussian-weak-dependence} yields the following corollary.

\begin{corollary} \label{cor:weakly-dependent-errors}
For UDD Gaussian errors, the conclusions in Theorem \ref{thm:necessary} hold.
\end{corollary}

Following Remark \ref{rmk:dependence-assumptions}, we will demonstrate the tightness of the dependence conditions in Theorem \ref{thm:necessary}.
Specifically, we demonstrate that if the URS dependence condition is violated, then it may be possible to recover the support of weaker signals below the boundary.

\begin{example} \label{exmp:counter-example}
Suppose ${\cal E} = \left(\epsilon_p(j)\right)_{j=1}^p$ is Gaussian, and is comprised of $\lfloor p^{1-\beta}\rfloor$ blocks, each of size at least $\lfloor p^\beta \rfloor$; 
let the elements of each block have correlation 1, and let elements from different blocks be independent. 
If $\underline{r} \ge 4(1-\beta)$, then the procedure $\widehat{S}^* = \left\{j:x(j)>\sqrt{2(1-\beta)\log{p}}\right\}$ yields $\mathbb P[\widehat{S}^* = S] \to 1$. 
This requirement on signal size is strictly weaker than that of the strong classification boundary, since $4(1-\beta) < (1 + \sqrt{1-\beta})^2$ on $\beta\in(0,1)$.

The above example shows that if the correlations of the Gaussian errors do not decay in a uniform fashion (UDD fails), then we can do substantially better in terms of support recovery.
\end{example} 

Proof of the claims in the example can be found in Appendix \ref{subsec:proofs-examples}; numerical simulations of this example can be found in Section \ref{sec:numerical}.

Our second comment is on the role of error tail assumptions.

\begin{remark} \label{rmk:tail-assumptions}
Theorems \ref{thm:sufficient} and \ref{thm:necessary} state that the phase-transition phenomenon is universal in all distributions in the AGG class for thresholding procedures.
We will see in Section \ref{subsec:optimality} that thresholding procedures are in fact \emph{sub-optimal} for AGG models with $\nu<1$. 
Therefore, the minimax optimality of the thresholding procedures $\widetilde{S}_p$ only applies to AGG models with $\nu\ge1$.

On the other hand, the phase-transition phenomenon for thresholding procedures is universal in all error models with rapidly varying tails, which includes AGG models {\it for all} $\nu>0$.
In contrast, errors with heavy (regularly varying) tails do not exhibit this phenomenon (see Appendix \ref{sec:heavy-tailed} Theorem \ref{thm:heavy-tails}).
We summarize the role of thresholding procedures in Table \ref{table:role-of-thresholding}.
\end{remark}

\begin{table}[ht]
    \caption{Properties of thresholding procedures under different error distributions (in brackets).}
    \begin{tabular}{p{35mm}p{32mm}p{32mm}} \toprule
        Thresholding procedure & Minimax-optimality &  Phase-transition \\ 
        (Error distributions) &  (Log-concave density) & (Rapidly-varying tails) \\ \midrule
        AGG($\nu$), $\nu\ge1$ & Yes (Yes) & Yes (Yes) \\ \cmidrule{1-3}
        AGG($\nu$), $0<\nu<1$ & No (No) & Yes (Yes) \\ \cmidrule{1-3}
        Power laws & No (No) & No (No) \\ \bottomrule
    \end{tabular}
  \label{table:role-of-thresholding}
\end{table}

We conclude this section with the proof of Theorem \ref{thm:necessary}.

\begin{proof} [Proof of Theorem \ref{thm:necessary}]
Suppose that \eqref{eq:classification-impossible-dependent} fails, then we have
\begin{equation} \label{eq:classification-possible-dependent}
    \limsup_{p\to\infty}\P[\widehat{S}_p = S_p] = c > 0. 
\end{equation}
Since the estimator $\widehat{S}_p = \{x(j) \ge t_p(x)\}$ is thresholding, the threshold must separate the signals and null part, i.e.,
\begin{equation*}
    \P[\widehat{S}_p = S_p] 
    = \P\left[\max_{j\in S^c}x(j) < t_p(x) \le \min_{j\in S}x(j)\right]
    \le \P\left[\max_{j\in S^c}x(j) < \min_{j\in S}x(j)\right].
\end{equation*}
Using the assumption that the signal sizes are no greater than $\overline{\Delta}$, we have
\begin{align}
\P\left[\max_{j\in S^c}x(j) < \min_{j\in S}x(j)\right]  
  &= \P\left[\frac{\max_{j\in S^c}x(j)}{u_p} < \frac{\min_{j\in S}x(j)}{u_p}\right] \nonumber \\
  &\le  \P\left[\frac{\max_{j\in S^c}\epsilon(j)}{u_p} < \frac{\min_{j\in S}\overline{\Delta} + \epsilon(j)}{u_p}\right] \nonumber \\
  &= \P\left[ \frac{M_{S^c}}{u_p} < \frac{\overline{\Delta} - m_S}{u_p} \right], \label{eq:classification-possible-dependent-proof-0}
\end{align}
where $M_{S^c} = \max_{j\in S^c}\epsilon(j)$ and $m_{S} = \max_{j\in S}\left(-\epsilon(j)\right)$.
Since the error arrays ${\cal E}$ and $(-{\cal E})$ are URS by assumption, using the expression for the AGG quantiles \eqref{eq:AGG-quantiles}, we have
\begin{equation} \label{eq:classification-possible-dependent-proof-1}
    \frac{M_{S^c}}{u_p} = \frac{M_{S^c}}{u_{|S^c|}} \frac{u_{|S^c|}}{u_p} \xrightarrow{\P} 1,
\quad \text{and} \quad
\frac{m_{S}}{u_p} = \frac{m_{S}}{u_{|S|}} \frac{u_{|S|}}{u_p} \xrightarrow{\P} (1-\beta)^{1/\nu},
\end{equation}
so that the two random terms in probability \eqref{eq:classification-possible-dependent-proof-0} converge to constants.

Since signal sizes are bounded above by $\overline{r} < \left(1 + (1-\beta)^{1/\nu}\right)^{\nu}$, we can write $\overline{r}^{1/\nu} = 1 + (1-\beta)^{1/\nu} - d$ for some $d > 0$, by our parametrization of $\overline{\Delta}$, we have
\begin{equation} \label{eq:classification-possible-dependent-proof-2}
    \frac{\overline{\Delta}}{u_p} = \left(1+(1-\beta)^{1/\nu}-d\right)(1+o(1)).
\end{equation}
Combining \eqref{eq:classification-possible-dependent-proof-1} and \eqref{eq:classification-possible-dependent-proof-2}, we conclude that the right-hand-side of the probability \eqref{eq:classification-possible-dependent-proof-0} converges in probability to a constant strictly less than 1, that is, 
\begin{equation}
    \frac{\overline{\Delta} - m_S}{u_p} \xrightarrow{\P} 1 - d.
\end{equation}
Therefore, the last probability in \eqref{eq:classification-possible-dependent-proof-0} must go to 0.
This contradicts the assumption in \eqref{eq:classification-possible-dependent}.
\end{proof}

% \begin{proof} [Proof of Theorem \ref{thm:necessary}]
% Denote $M_{S^c} = \max_{j\in S^c}\epsilon(j)$ and $m_{S} = \max_{j\in S}\left(-\epsilon(j)\right)$.
% Asymptotic perfect recovery requires both $\P[\widehat{S}\subseteq S]\to 1$ and $\P[\widehat{S}\supseteq S]\to 1$.
% We start with the first requirement:
% the probability of no false inclusion must go to 1
% \begin{equation} \label{eq:no-false-inclusion}
% \P\left[\max_{S^c}x(j) < t_p(x)\right] = \P\left[\frac{M_{S^c}}{u_{|S^c|}} < \frac{t_p(x)}{u_{|S^c|}}\right] \to 1, 
% \end{equation}
% where we emphasize that the thresholds $t_p(x)$ may be a random quantity that depends on $x$.
% By uniform relative stability of the $\epsilon$'s, for any $\delta>0$, we have
% $$
% \P\left[\frac{M_{S^c}}{u_{|S^c|}} < 1 - \delta\right] \to 0.
% $$
% Therefore, by \eqref{eq:no-false-inclusion}, we must have 
% \begin{equation} \label{eq:requirement-no-false-inclusion}
%     \P\left[\frac{t_p(x)}{u_{|S^c|}} < 1 - \delta\right] \to 0, 
% \end{equation}
% as well. For otherwise if we had $\liminf\P[\frac{t_{p}(x)}{u_{|S^c|}} < 1 - \delta] \ge \gamma$ for some $\gamma > 0$, then
% \begin{align*}
% \limsup_{p\to\infty} \P\left[\frac{M_{S^c}}{u_{|S^c|}} < \frac{t_p(x)}{u_{|S^c|}}\right] 
%     &\le \limsup_{p\to\infty} \P\left[\frac{M_{S^c}}{u_{|S^c|}} < 1 - \delta\right] 
%         + \limsup_{p\to\infty} \P\left[\frac{t_p(x)}{u_{|S^c|}} \ge 1 - \delta\right] \\
%     &= 0 + 1 - \liminf_{p\to\infty} \P\left[\frac{t_p(x)}{u_{|S^c|}} < 1 - \delta\right] \\
%     &\le 1 - \gamma,
% \end{align*}
% which contradicts the requirement in \eqref{eq:no-false-inclusion}.
% 
% Equation \eqref{eq:requirement-no-false-inclusion} implies that 
% \begin{align}
%     & \P\left[\frac{t_p(x)}{\left(\nu\log{(p-p^{1-\beta})}\right)^{1/\nu}}\left(1+o(1)\right) < 1-\delta\right] \to 0 \nonumber \\
%     %\iff& \P\left[\frac{t_p(x)}{\left(\nu\log{p}\right)^{1/\nu}}\left(1+o(1)\right) < (1-\delta)\left(1-p^{-\beta}\right)^{1/\nu}\left(1+o(1)\right)\right] \to 0 \nonumber \\
%     \iff& \P\left[\frac{t_p(x)}{\left(\nu\log{p}\right)^{1/\nu}} < (1-\delta)\left(1+o(1)\right)\right] \to 0, \label{eq:threshold-upper-bound}
% \end{align}
% where $o(1)$'s are sequences that converge to 0 as $p$ tends to infinity, and may vary from line to line.
% 
% On the other hand, the probability of no missed detection must also go to 1,  $\P[\widehat{S}\supseteq S]\to 1$.
% This implies
% \begin{align}
%     & \P\left[\min_{j\in S}x(j) > t_p(x)\right] = \P\left[\frac{\min_{j\in S}x(j)}{u_{|S|}} > \frac{t_p(x)}{u_{|S|}}\right] \to 1 \nonumber \\
%     \implies & \P\left[ \frac{m_S}{u_{|S|}} < \frac{- t_p(x) + \left(\nu\overline{r}\log{p}\right)^{1/\nu}}{u_{|S|}} \right] \to 1 \label{eq:no-missed-detection}
% \end{align}
% where we used the assumption that the signal sizes are no larger than $ \left(\nu\overline{r}\log{p}\right)^{1/\nu}$.
% Again, by uniform relative stability of the $(-\epsilon)$'s, we have for any $\delta>0$, we have
% $$
% \P\left[\frac{m_S}{u_{|S|}} < 1 - \delta\right] \to 0.
% $$
% Therefore by the same reasoning as the case of no-false-inclusion, from \eqref{eq:no-missed-detection}, we must have
% \begin{equation} \label{eq:requirement-no-missed-detection}
%     \P\left[\frac{-t_p(x)+\left(\nu\overline{r}\log{p}\right)^{1/\nu}}{u_{|S|}} < 1 - \delta\right] \to 0.
% \end{equation}
% Now, since $\overline{r} < \left(1 + (1-\beta)^{1/\nu}\right)^{\nu}$, we can write $\overline{r}^{1/\nu} = 1 + (1-\beta)^{1/\nu} - d$ for some $d > 0$. Hence \eqref{eq:requirement-no-missed-detection} is, after substituting the expression for $\overline{r}$, equivalent to 
% \begin{align}
%     & \P\left[-t_p(x) + \left[(1-d)+(1-\beta)^{1/\nu}\right]\left(\nu\log{p}\right)^{1/\nu} < (1-\delta) u_{|S|}\right] \to 0 \nonumber \\
%     %\iff& \P\left[\frac{t_p(x)}{\left(\nu\log{p}\right)^{1/\nu}} > \left[{1-d} + {(1-\beta)^{1/\nu}} - (1-\delta)(1-\beta)^{1/\nu}\right]\left(1+o(1)\right)\right] \to 0 \nonumber \\
%     \iff& \P\left[\frac{t_p(x)}{\left(\nu\log{p}\right)^{1/\nu}} > \left(1 - d + \delta(1-\beta)^{1/\nu}\right)\left(1+o(1)\right)\right] \to 0. \label{eq:threshold-lower-bound}
% \end{align}
% Finally, we show that \eqref{eq:threshold-lower-bound} stands in contradiction to \eqref{eq:threshold-upper-bound}. Since $\delta$ is arbitrary, we can pick $\delta\in \left(0, d/(1+(1-\beta)^{1/\nu})\right)$, so that 
% $$1 - d + \delta(1-\beta)^{1/\nu} < (1-\delta).$$
% However, probabilities in both \eqref{eq:threshold-lower-bound} and \eqref{eq:threshold-upper-bound} vanish, which implies $\P[t_p(x)\in \mathbb R] \to 0$; therefore $t_p(x)$ cannot be a well-defined random variable.
% \end{proof}




\subsection{On the (sub)optimality of thresholding procedures}
\label{subsec:optimality}

In support recovery problems under models such as \eqref{eq:model}, thresholding procedures seems to be the only ``reasonable'' choice for estimating the support set $S$.
In Theorem \ref{thm:sufficient} we saw that a (FWER-controlling) thresholding procedure is indeed consistent for support recovery, 
It is natural to ask if it will be sufficient to restrict attention to only thresholding procedures.
We will show that, perhaps surprisingly, for general error models, thresholding procedures are not always optimal.

We adopt here a Bayesian framework to measure statistical risks, where the support of signals are assumed to be random, although an equivalent minimax risk approach may be taken as in \cite{butucea2018variable} to allow for arbitrary support configuration as we did in previous sections.
For concreteness, we assume that the unknown signal support is distributed uniformly in the collection of all subsets of size $s$, denoted $$\mathcal{S} = \left\{S\subseteq\{1,\ldots,p\};|S|=\lfloor p^{1-\beta}\rfloor\right\}.$$ 
That is,
\begin{equation} \label{eq:uniform}
\pi(\{1,\ldots, n_s\}) := \mathbb P\left[S = \{1,\ldots, n_s\}\right] = \binom{p}{s}^{-1}\quad
\mbox{for all }1\le n_1<\ldots<n_s\le p.
\end{equation}
If we consider the 0-1 loss function,
$$
l(\widehat{S},S) = 1 - \mathbbm{1}[\widehat{S} = S] = \mathbbm{1}[\widehat{S} \neq S],
$$
then for a sequence of estimators $\widehat{S} = \widehat{S}_p$, the (asymptotically) optimal procedures should minimize the (asymptotic) Bayesian risk,
\begin{equation} \label{eq:Bayesian-risk}
    R(\widehat{S}) := \limsup_{p\to\infty} \mathbb E_{S,{\cal E}} [l(\widehat{S},S)] = \limsup_{p\to\infty} \mathbb P_{S,{\cal E}}[\widehat{S} \neq S],
\end{equation}
where the expectation is taken over all sets $\mathcal{S}$, with a uniform distribution $\pi$ as specified in \eqref{eq:uniform}, and over the errors ${\cal E}$.

On observing data $x$,
we can order our observations from largest to smallest
$x(j_1) \ge x(j_2)  \ge \ldots \ge x(j_p)$,
where $(j_1, \ldots, j_p)$ is a permutation of $\{1, \ldots, p\}$. 
If the sparsity $s = \lfloor p^{1-\beta}\rfloor$ of the problem is known, then a natural estimator for $S$ would be based on the set of top $s$ order statistics: $\widehat{S} = \{j_1, \ldots, j_s\}$.
This oracle estimator is indeed optimal, if the error densities are log-concave.

\begin{proposition} \label{prop:log-concave}
Let the errors in \eqref{eq:model} be independent with common distribution $F$.
Let the signals be uniformly distributed as in \eqref{eq:uniform}, and have equal magnitude $\delta>0$. 
If $F$ has log-concave density $f$, then the oracle thresholding procedure $\widehat{S}^* = \{j_1, \ldots, j_s\}$ is optimal in terms of asymptotic Bayesian risk.
\end{proposition} 

The assumption of log-concavity of the densities is compatible with the AGG model with $\nu\ge1$, as is demonstrated in the next example.

\begin{example}
The generalized Gaussian density $f(x)\propto \exp\{-|x|^\nu/\nu\}$ is log-concave for all $\nu\ge1$.
In this case, by Proposition \ref{prop:log-concave}, the oracle thresholding procedure is optimal for independent errors.
\end{example}

%(This also explains the $\gamma\ge 1$ condition in Theorem 1 of Arias-Castro and Chen)

Consider the Bayesian risk as defined in \eqref{eq:Bayesian-risk}, the statement for the necessary condition of support recovery,
with the help of Proposition \ref{prop:log-concave}, can be strengthened to include all procedures, regardless of whether they are thresholding.

\begin{theorem} \label{thm:necessary-strengthened}
In the context of Theorem \ref{thm:necessary}, where the signal is below the strong classification boundary \eqref{eq:signal-below-boundary},
if the $\epsilon_p(j)$'s are independent and identically distributed with log-concave densities, and the signals are uniformly distributed as in \eqref{eq:uniform}, then no procedure succeeds. That is, for any sequence of estimators $\widehat{S} = \widehat{S}_p$, we have $R(\widehat{S}) = 1.$
%    $$
%    \lim_{p\to\infty}\mathbb P[\widehat{S}_p = S_p] = 0. \label{eq:classification-impossible-minimax}
%    $$
\end{theorem}

\begin{proof}[Proof of Theorem \ref{thm:necessary-strengthened}]
When errors are independent with log-concave density, the oracle thresholding procedure, by Proposition \ref{prop:log-concave}, is optimal.
But all thresholding procedures fail according to Theorem \ref{thm:necessary}.
\end{proof}

\begin{remark}
In contrast with Theorem \ref{thm:necessary}, this strengthened necessary condition states that perfect recovery cannot be uniformly achieved, for \emph{any} estimator.
Consequently, the thresholding procedure $\widetilde{S}_p$ described in Theorem \ref{thm:sufficient} is an asymptotically minimax procedure over the class of error models $U(F)$, that is, in the class of errors with AGG($\nu$) marginals $F$ where $\nu>1$, we have
\begin{equation} \label{eq:minimax}
    \widetilde{S}_p = \argmin_{\widehat{S}_p} \sup_{{\cal E}\in U(F)} R(\widehat{S}_p),
\end{equation}
where $\widehat{S}_p$ is taken over \emph{all} procedures.
It can be shown that the supremum in \eqref{eq:minimax} may be taken over all set of locations as well (by, for example, applying Theorem 1.1 in the supplement of \citep{butucea2018variable});
we content ourselves with a Bayesian minimax result here.
\end{remark}

\begin{remark}
\citet{butucea2018variable} attempted to generalize their risk bound to non-Gaussian distributions with the \emph{monotone likelihood ratio} (MLR) property, where a family of distributions $\{f_\delta, \delta \in U\}$ is said to have the MLR property if, for all $\delta_0, \delta_1\in U\subseteq\R$ such that $\delta_0 < \delta_1$, the likelihood ratio $\left(f_{\delta_1}(x)/f_{\delta_0}(x)\right)$ is an increasing function of $x$.

It turns out that no generality is lost by restricting our attention to only log-concave densities: in the signal-plus-noise model \eqref{eq:model}, the MLR property is equivalent to the requirement of log-concavity of error densities. 
We characterize this equivalence in the next proposition.
\end{remark}

\begin{proposition} \label{prop:MLR-log-concavity}
Let $\delta$ be the magnitude of the non-zero signals in the signal-plus-noise model \eqref{eq:model}, hence $f_\delta(x) = f_0(x-\delta)$.
In this case, the family $\{f_\delta, \delta \in \R\}$ has the MLR property if and only if the error density $f_0$ is log-concave.
\end{proposition}

% In view of Proposition \ref{prop:log-concave} and Proposition \ref{prop:MLR-log-concavity}, the minimax optimality of thresholding procedures described in Theorem \ref{thm:necessary-strengthened} is really universal in all error models with log-concave densities.

\begin{proof}[Proof of Proposition \ref{prop:MLR-log-concavity}]
Since $f_0$ is log-concave, we write $f_0(t) = \exp\{\phi(t)\}$ for some concave function $\phi$.
By the assumption of MLR, for any $x_1 < x_2$, set $\delta_0 = 0$, and $\delta_1 = (x_2 - x_1)/2 > 0$, we have
\begin{align}
    &\phi\left(\frac{(x_1+x_2)}{2}\right)- \phi(x_1) \ge \phi(x_1)- \phi\left(\frac{(x_1+x_2)}{2}\right) \nonumber \\
    \iff 
    &\phi\left(\frac{(x_1+x_2)}{2}\right) \ge \frac{1}{2} \phi(x_1) + \frac{1}{2} \phi(x_2). \label{eq:midpoint-concave}
\end{align}
This shows that the log-density $\log{f_0}$ is midpoint-concave, i.e, \eqref{eq:midpoint-concave} holds for all $x_1$. $x_2$.
For Lebesgue measurable functions, midpoint concavity is equivalent to concavity by the Sierpinki Theorem (see, e.g., Sec I.3 in \citep{donoghue2014distributions}). This proves the `only-if' part.

For the `if' part, when  $\phi(t) = \log{(f_0(t))}$ is log-concave, then for any $\delta_0 < \delta_1$, and any $x<y$, we have
\begin{equation}
    \log{\frac{f_{\delta_1}(y)}{f_{\delta_0}(y)}} - \log{\frac{f_{\delta_1}(x)}{f_{\delta_0}(x)}}
    = \phi(y-\delta_1) - \phi(y-\delta_0) - \phi(x-\delta_1) + \phi(x-\delta_0) \ge 0,
\end{equation}
where the last inequality follows from Lemma \ref{lemma:four-point-concavity}.
Therefore log-concavity implies the MLR property as well.
\end{proof}

% \begin{proposition} \label{prop:log-convex}
% Suppose $f$ is log-concave on $(-\infty, -K]$ and $[K, +\infty)$, and log concave on $[-K, K]$. 
% Further, suppose that the mean shifts in model \eqref{eq:simple-model} are of the same magnitude $\Delta$,
% then the optimal procedure $\widehat{S}^*$ must satisfy the following:
% \begin{enumerate}
%     \item If $j\in\widehat{S}^*$, for some $x(j) > K+\Delta$, then $j'\in\widehat{S}^*$ for all $K\le x(j') < x(j)$.
%     \item If $j\in\widehat{S}^*$, for some $-K+\Delta < x(j) < K$, then $j'\in\widehat{S}^*$ for all $x(j) < x(j') \le K$.
%     \item If $j\in\widehat{S}^*$, for some $x(j) < -K$, then $j'\in\widehat{S}^*$ for all $x(j) < x(j') \le -K$.
% \end{enumerate}
% \end{proposition}

We present the proof of Proposition \ref{prop:log-concave}, followed by an analysis of an example where errors have super-exponential tails.

\begin{proof}[Proof of Proposition \ref{prop:log-concave}]
The problem of support recovery can be equivalently stated as a classification problem, where the discrete parameter space is $\mathcal{S} = \{S\subseteq[p]:|S|=s\}$, and observations $x \in\R^p$ has likelihood $f(x|S)$ indexed by support set $S$.

By optimality of Bayes classifier (see, e.g., \citep{domingos1997optimality}), the classifier that maximizes the probability of support recovery is therefore
$$
\widehat{S}^* = \argmax_{\widehat{S}\in \mathcal{S}} f(x|S) \Big/ \binom{p}{s},
$$
and the problem reduces to showing that 
\begin{equation}
    \widehat{S}^* = \left\{j\in[p]\;|\;x(j) \ge x_{[s]}\right\}. \label{eq:S-hat-star}
\end{equation}
maximizes the likelihood $f(x|S)$.

We show by contradiction that the optimal set $\widehat{S}$ must contain all top--s observations. 
Suppose $\widehat{S} \neq \widehat{S}^*$, then there must be indices $j_1 \in \widehat{S}$ and $j_2 \in \widehat{S}^c$ such that $x(j_1) < x(j_2)$ (note that there are no ties almost surely).
If we exchange the labels of $x(j_1)$ and $x(j_2)$, that is, we form a new estimate $\widetilde{S} = \left(\widehat{S}\setminus\{j_1\}\right)\cup\{j_2\}$,
comparing the log-likelihoods under $\widehat{S}$ and $\widetilde{S}$, we have
\begin{equation} \label{eq:improved-set-estimator}
    \log{f(x|\widehat{S})} - \log{f(x|\widetilde{S})} = \;\phi(x(j_1) - \delta) + \phi(x(j_2)) - \phi(x(j_2) - \delta) - \phi(x(j_1)).
\end{equation}
Since $\phi=\log{f_0}$ is a concave by assumption, Lemma \ref{lemma:four-point-concavity} implies that \eqref{eq:improved-set-estimator} is non-positive.
This implies that any estimator that is not $\widehat{S}^*$ may be improved, and the optimality of $\widehat{S}^*$ follows.
\end{proof}

As promised in Remark \ref{rmk:tail-assumptions}, we demonstrate with an example that thresholding procedures may \emph{not} be optimal when the error have super-exponential tails. 

\begin{example}[Sub-optimality of thresholding] \label{exmp:log-convex}
Let the errors have generalized Gaussian density with $\nu=1/2$, i.e., $\log{f_0(x)}\propto -x^{1/2}$. Let dimension $p=2$, sparsity $s=1$ with uniform prior, and signal size $\delta=1$.
If the observations take on values $x = (x_1, x_2)^\mathrm{T} = (1,2)^\mathrm{T}$, we see from a comparison of the likelihoods
$$
\log \frac{f(x|\{1\})}{f(x|\{2\})} = 2x_1^{1/2} + 2(x_2 - 1)^{1/2} - 2x_2^{1/2} - 2(x_1 - 1)^{1/2} = 4 - 2\sqrt{2} > 0,
$$
that even though $x_1<x_2$, the set $\{1\}$ is a better estimate of support than $\{2\}$, i.e., $\P[S=\{1\}|x] > \P[S=\{2\}|x]$.
\end{example}

It is in general true that top observations should not be selected when errors have super-exponential tails, and the optimal estimator is no longer thresholding.
We provide a (partial) characterization of the optimal procedure under this setting next.

\begin{proposition} \label{prop:log-convex}
Denote the optimal procedure for support recovery in model \eqref{eq:model} as $\widehat{S}^*$.
If the errors are iid, with density $f$ log-convex on $[K, +\infty)$, then whenever $j\in\widehat{S}^*$ for some $x(j) > K+\delta$, we must have $j'\in\widehat{S}^*$ for all $K+\delta \le x(j') < x(j)$.

In particular, if there are $m$ observations exceeding $K+\delta$, with $m>s$, then the top $m-s$ observations will \emph{not} be included in the optimal estimator $\widehat{S}^*$.
\end{proposition} 

\begin{proof}[Proof of Proposition \ref{prop:log-convex}]
Since both $f(t)$ and $f(t-\delta)$ are log-convex on $[K+\delta, \infty)$, 
by an argument similar to that in the proof of Proposition \ref{prop:log-concave}, for indices $j_1 \in \widehat{S}^c$ and $j_2 \in \widehat{S}$ such that $K+\delta < x(j_1) < x(j_2)$, we have
$$
\phi(x(j_1) - \delta) + \phi(x(j_2)) \ge \phi(x(j_1)) + \phi(x(j_2) - \delta),
$$
therefore likelihood can be increased by replacing $j_1$ in $\widehat{S}$ with $j_2$.
\end{proof}

It should be remarked that Proposition \ref{prop:log-convex} is valid when there is a known maximum signal size $\delta$. 
When maximum signal sizes are unknown a priori, a large observation may be attributed to either a truly large signal, or to the error with super-exponential tails.
Common practice has always been to attribute large observations to large signals, and not large errors.

As an example, consider the linear regression
\begin{equation} \label{eq:regression}
 Y = X\mu + \xi,
\end{equation}
where $\mu$ is a vector of regression coefficients of interest to be inferred from observations of $X$ and $Y$.
If the design matrix $X$ is of full column rank, then the OLS estimator of $\mu$ can be formed 
\begin{equation*}
    \widehat{\mu} = \left(X'X\right)^{-1}X'Y = \mu + \epsilon,
\end{equation*}
where $\epsilon := (X'X)^{-1}X'\xi$.
Hence we recover the generic problem \eqref{eq:model}. 
The support recovery problem is therefore equivalent to the fundamental model selection problem.
Often an investigator calculate the t-scores of each coefficient as 
\begin{equation} \label{eq:linear-model-selection}
    \widehat{\mu}(j) \Big/ \widehat{\mathrm{s.e.}}(\widehat{\mu}(j)),
\end{equation}
where $\widehat{\mathrm{s.e.}}(\widehat{\mu}(j))$ is the estimated standard error of $\widehat{\mu}(j)$.
The investigator then chooses indices with large t-scores to enter the model.
If the errors in model \eqref{eq:regression} are Gaussian, the expression \eqref{eq:linear-model-selection} is t-distributed and have power-law tails; the discussion above suggests that this commonplace procedure is sub-optimal for bounded signals.



