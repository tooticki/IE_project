\subsection{Proof of the claims in Examples \ref{exmp:FWER-controlling_procedures} and \ref{exmp:counter-example}}
\label{subsec:proofs-examples}

\begin{proof}[Proof of claims in Example \ref{exmp:FWER-controlling_procedures}]
By the Mill's ratio for the standard Gaussian distribution,
$$
\frac{t_p \P\left[Z>t_p\right]}{\phi(t_p)} \to 1,\quad \text{as}\quad p\to\infty,
$$
where $Z\sim \text{N}(0,1)$. 
Using the expression for $t_p = \sqrt{2\log{p}}$, we have
$$
p \;\P\left[Z>t_p\right] \sim \sqrt{2\pi}\left(2\log{p}\right)^{-1/2} \to 0,
$$
as desired. The rest of the claims follow from Corollary \ref{cor:FWER-controlling_procedures}.
\end{proof}

\begin{proof}[Proof of claims in Example \ref{exmp:counter-example}]
Recall that $\widehat{S}^* = \{j:x(j)>t_p^*\}$, where $t_p^* = \sqrt{2(1-\beta)\log{p}}$. 
Analogous to \eqref{eq:Bonferroni-FWER-control} in the proof of Theorem \ref{thm:sufficient}, we have
\begin{align*}
    \P\left[\widehat{S} \subseteq S\right] 
        &= 1 - \P\left[\max_{j\in S^c}x(j) > t_p^*\right] 
        = 1 - \P\left[\max_{j\in S^c}\epsilon(j) > t_p^*\right] \nonumber \\
      % \ge 1 - \P\left[\max_{j\in\{1,\ldots,p\}}\epsilon(j) > t_p\right] \nonumber \\
        &\ge 1 - \P\left[\max_{j\in[p]}\epsilon(j) > t_p^*\right] 
        \ge 1 - \P\left[\max_{j\in\{1,\ldots,\lfloor p^{1-\beta}\rfloor\}}\widetilde{\epsilon}(j) > t_p^*\right]
\end{align*}
where $\left(\widetilde{\epsilon}\right)_{j=1}^{\lfloor p^{1-\beta}\rfloor}$'s are independent Gaussian errors; in the last inequality we used the assumption that there are at most $\lfloor p^{1-\beta}\rfloor$ independently distributed Gaussian errors in $\left(\epsilon_p(j)\right)_{j=1}^p$.
By Example \ref{exmp:FWER-controlling_procedures} (with $\lfloor p^{1-\beta}\rfloor$ taking the role of $p$), we know that the FWER goes to 0 at a rate of 
$\left(2\log{\lfloor p^{1-\beta}\rfloor}\right)^{-1/2}$.
Therefore, the probability of no false inclusion converges to 1.


On the other hand, since the signal sizes are no smaller than $(\nu\underline{r}\log p)^{1/\nu}$, similar to \eqref{eq:sufficient-proof-eq1}, we obtain
\begin{align}
    \P\left[\widehat{S} \supseteq S\right] 
    &\ge \P\left[\min_{j\in S}\epsilon(j) > \sqrt{2(1-\beta)\log{p})} - \sqrt{2\underline{r}\log{p}} \right] \nonumber \\
    &= \P\left[\max_{j\in S}\left(-\epsilon(j)\right) < \sqrt{2\log{p})}\left(\sqrt{\underline{r}}-\sqrt{1-\beta}\right) \right] \nonumber \\
    &= \P\left[\frac{\max_{j\in S}(-\epsilon(j))}{u_{|S|}} < \frac{\sqrt{\underline{r}}-\sqrt{1-\beta}}{\sqrt{1-\beta}}\left(1+o(1)\right) \right], \label{eq:sufficient-proof-counter-example}
\end{align}
where in the last line we used the quantiles \eqref{eq:AGG-quantiles}.
Since the minimum signal size is bounded below by $\underline{r} > 4(1-\beta)$, the right-hand-side of the inequality in \eqref{eq:sufficient-proof-counter-example} converges to a constant strictly larger than 1. While the left-hand-side, by Slepian's Lemma \cite{slepian1962one}, is stochastically smaller than a r.v. going to 1, i.e.,
\begin{equation}
  \frac{1}{u_{|S|}} \max_{j\in S}(-\epsilon(j)) \stackrel{d}{\le} \frac{1}{u_{|S|}} \max_{j\in S)} \epsilon^*(j) \stackrel{\P}{\longrightarrow} 1,
\end{equation}
where $\left({\epsilon^*}\right)_{j=1}^{\lfloor p^{1-\beta}\rfloor}$'s are independent Gaussian errors.
Therefore the probability in \eqref{eq:sufficient-proof-counter-example} must also converge to 1.
\end{proof}
