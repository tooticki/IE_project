\section{Aging}
\label{sec:age}
\setcounter{equation}{0}


We will consider the following two aging functions of $(Y_t)$.
\begin{eqnarray}
\label{eq:br}
&\bar R(s,t)=\P(Y_t=Y_{t+s}),&\\
\label{eq:bpi}
&\bar \Pi(s,t)=\P(Y_t=Y_{t+r}\,\mbox{ for all }r\in[0,s]),&
\end{eqnarray}
with the following result.
\begin{theo}
\label{teo:age}
If $X$ is transient, then there exist non-trivial functions $R,\Pi:[0,\infty)\to(0,1]$ such that
\begin{eqnarray}
\label{eq:age_r}
&\lim_{t\to\infty}\bar R(\theta t,t)=R(\theta),&\\
\label{eq:age_pi}
&\lim_{t\to\infty}\bar \Pi(\theta t/q_{1/t},t)=\Pi(\theta).&
\end{eqnarray}
\end{theo}

\begin{rmk}
\label{rmk:trans}
We do not have any strong reason to believe that the result does not hold generally under Assumptions A and B.
The restriction to transient processes is technical. Our argument below requires, roughly speaking, that during 
time $t$ a {\em single} visit of  $Y$ to a deep trap lasts a length of time of order $t$, and this occurs only 
in the transient case. In this case, both assumptions A and B hold, with $\rho_n\sim n/q$, $r_n\sim 1/q$, and 
$q_{1/t}\sim q$, where $1<q<\infty$ is the same constant appearing in the statement of Theorem~\ref{teo:conv1}.

We state below a (weaker) version of this result for integrated versions of the aging functions, or equivalently,
for those functions looked at suitable random times.
\end{rmk}

\begin{rmk}
\label{rmk:age1}
Let $\tilde X_t=X_{I_t}$. In the literature one has rather considered the aging functions
\begin{eqnarray}
\label{eq:r}
&R(s,t)=\P(\tilde X_t=\tilde X_{t+s}),&\\
\label{eq:pi}
&\Pi(s,t)=\P(\tilde X_t=\tilde X_{t+r}\,\mbox{ for all }r\in[0,s]).&
\end{eqnarray}
In case $\tau_0$ is a continuous random variable, then we of course have the identities $R(\cdot,\cdot)=\bar R(\cdot,\cdot)$ 
and $\Pi(\cdot,\cdot)=\bar\Pi(\cdot,\cdot)$, but not otherwise. In any case, one can show that aging results like~(\ref{eq:age_r},\ref{eq:age_pi}) 
hold for $R(\cdot,\cdot)$ and $\Pi(\cdot,\cdot)$ as well, with $R(\cdot)$ and $\Pi(\cdot)$ as limiting aging functions, respectively.
\end{rmk}


\begin{rmk}
\label{rmk:age2}
$R$ and $\Pi$ turn out to be identical. We have
\begin{equation}
\label{eq:pir} 
R(\theta)=\Pi(\theta)=\frac{\sin(\pi\alpha)}{\pi}\int_{\theta/(1+\theta)}^1s^{-\a}(1-s)^{\a-1}\,ds.
\end{equation}
See~(\ref{eq:age2}, \ref{eq:h2}) and Remark~\ref{rmk:age3} below. 
\end{rmk}



In order to prove Theorem~\ref{teo:age}, we will naturally consider the rescaled version $\hye$ of $Y$ with the special strongly converging rescaled
environment (see~(\ref{eq:bye}) above). One ingredient of the proof of~(\ref{eq:age_r}) is a comparison to $\vyed$ (see~(\ref{eq:vyed}) above) as
follows.


\begin{lm}
\label{lm:comp}
For all $t>0$ fixed, if $X$ is transient, then we have that
\begin{equation}
\label{eq:comp1}
\lim_{\delta\to0}\limsup_{\eps\to0}P(\hye_t\ne\vyed_t)=0
\end{equation}
for a.e.~$\ups$.
\end{lm}

\noindent{\bf Proof}

As in previous arguments, we will leave implicit many times below that claims hold for a.e.~$\ups$.
$P$ and $E$ remain as notation for the probability and expectation with respect to the distribution
of the dynamical random variables ($X$ and the $\hat T_i^{(j)}$'s).
We first consider for $T>0$
\begin{equation}
\label{eq:comp2}
\int_0^TP(\hye_s\ne\vyed_s)\,ds=E\int_0^T\1\{\hye_s\ne\vyed_s\}\,ds.
\end{equation}

We will argue as in the proofs of Lemmas~\ref{lm:conv1} and~\ref{lm:conv2} above. Let us first fix an arbitrary $\eta>0$, and then choose 
$S$ as in the second point of Remark~\ref{rmk:conv2}. Then on the event that $\eps\bce_{\nu_\eps S}>T$ and outside an event of vanishing 
probability as $\eps\to0$, the integral on the right of~(\ref{eq:comp2}) is bounded above by
\begin{equation}
\label{eq:comp3}
\sum_{x\in\te\N\cap(\teps_\delta)^c\atop x\leq S+1}\mue(x) \,\bte(\te^{-1}x,\nu_\eps S).
\end{equation}
Using now~(\ref{eq:expcurly}) and the fact argued below~(\ref{eq:c3}), we have that the $\lim_{\delta\to0}\limsup_{\eps\to0}$
of the expectation of the integral is bounded above by $T\eta$. Since $\eta$ is arbitrary, we have that
\begin{equation}
\label{eq:comp4}
\lim_{\delta\to0}\limsup_{\eps\to0}\int_0^TP(\hye_s\ne\vyed_s)\,ds=0.
\end{equation}

We now fix $\delta'>\delta$ and define $I=\min\{i\geq1:\,x_i\in\t_{\delta'}\}$.  
Let $\ze$ be as in the proof of Lemma~\ref{lm:conv1} (see paragraph of~(\ref{eq:l1})). % and~(\ref{eq:xi1}) above).
%
Let $t>0$ be fixed and condition on 
\begin{equation}
\label{eq:barc}
\bar C^{(\eps)}:=\eps\bce_{\zeta^{(\eps)}_{I+1}-1}=\mue(x_I^{(\eps)})\hat T(\yep_I,\ze_I)+\Delta^{(\eps)},
\end{equation} 
where the latter summand, $\Delta^{(\eps)}$, is defined by this equality. % (and~(\ref{eq:cealt})). 
Note that the former summand is an exponential
random variable of mean $\mue(x_I^{(\eps)}) r_{\nu(\eps^{-1})}$, and that
given $X$  (and $\ups$) the summands are 
absolutely continuous random variables independent of each other. 

It thus follows that
\begin{eqnarray}\nn
P(\hye_t\ne\vyed_t|X)&\leq&
\int_0^t\left(\int_0^sb_\eps e^{-b_\eps(s-r)}f^{(\eps)}(r)\,dr\right)P(\hye_{t}\ne\vyed_{t}|\bar C^{(\eps)}=s,X)\,ds\\
\label{eq:comp5}
&+&P(\bar C^{(\eps)}\geq t|X),
\end{eqnarray}
where $b_\eps^{-1}=\mue(x_I^{(\eps)}) r_{\nu(\eps^{-1})}$ and $f^{(\eps)}$ is the density of $\Delta^{(\eps)}$ given $X$. 
The above integral is thus upper bounded by
\begin{equation}
\label{eq:comp6}
b_\eps\int_0^tP(\hye_{t}\ne\vyed_{t}|\bar C^{(\eps)}=s,X)\,ds.
\end{equation}
Now, by the independence of increments of $(\bce_n)$ given $X$, the probability inside the latter integral can be written as 
\begin{equation}
\label{eq:comp7}
P(\ddye_{t-s}\ne\bryed_{t-s}|X),
\end{equation}
where $(\ddye_t)$ and $(\bryed_t)$ are defined as $(\hye_{t})$ and $(\vyed_{t})$ respectively with 
$(\bce_{n+\xi^{(\eps)}_{I+1}-1}-\bce_{\xi^{(\eps)}_{I+1}-1})$ replacing $(\bce_n)$. We thus obtain 
(after integrating in $X$)
\begin{equation}
\label{eq:comp8} 
\lim_{\delta\to0}\limsup_{\eps\to0}\int_0^tP(\ddye_{t-s}\ne\bryed_{t-s})\,ds
=\lim_{\delta\to0}\limsup_{\eps\to0}\int_0^tP(\ddye_{s}\ne\bryed_{s})\,ds=0
\end{equation}
similarly as we did~(\ref{eq:comp4}). 
And we have that $\lim_{\delta\to0}\liminf_{\eps\to0}b_\eps^{-1}\geq \delta'/q>0$, 
since $x_I\in\t_{\delta'}$ and $\lim_{\eps\to0}r_{\nu(\eps^{-1})}=1/q>0$. 
We thus get that the 
$\lim_{\delta\to0}\limsup_{\eps\to0}$ of the 
first term in~(\ref{eq:comp5}) vanishes, and since $\delta'$ is arbitrary and 
$\lim_{\delta'\to0}\limsup_{\eps\to0}\bar C^{(\eps)}=0$ in probability, 
as can be readily checked, the result follows.
$\square$

\begin{rmk}
\label{rmk:trans2}
In the recurrent case $b_\eps$ is not bounded, and thus the above argument breaks down.
\end{rmk}

%\vspace{.5cm}

\noindent{\bf Proof of Theorem~\ref{teo:age}}



We will first replace $\hye$ by $\byed$ and then resort to Lemma~\ref{lm:comp} and Remark~\ref{rmk:byed}.
By Lemma~\ref{lm:conv1},
we have that
\begin{equation}
\label{eq:age1} 
\lim_{\delta\to0}\lim_{\eps\to0}\byed=Z
\end{equation}
in distribution on $(D,J_1)$. From that and Lemma~\ref{lm:comp} and Remark~\ref{rmk:byed} above, we claim that
\begin{equation}
\label{eq:age2} 
\lim_{\eps\to0}\bar R(\theta\eps^{-1},\eps^{-1})=\lim_{\delta\to0}\lim_{\eps\to0}\P(\byed_1=\byed_{1+\theta})=\P(Z_1=Z_{1+\theta}):=R(\theta).
\end{equation}
(\ref{eq:age_r}) then follows.  
The only point of the claim that needs arguing is the second equality. 
We first point out that from the construction of $\byed$ (see~(\ref{eq:c5})), since the $\mu(x_i)$'s are almost surely all distinct,
we have from~(\ref{eq:mu}) that, for all fixed $\delta$ and all small enough $\eps$, the probability in the second
term in~(\ref{eq:age2}) equals
\begin{equation}
\label{eq:age2a} 
\P(\byed_1=\byed_{1+r}\,\mbox{ for all }r\in[0,\theta])
\end{equation}
plus a small error, and the latter probability equals
\begin{equation}
\label{eq:age2aa} 
\P([1,1+\theta]\cap\mbox{range of }\bved=\emptyset).
\end{equation}

It readily follows from~(\ref{conv4}) and Remark~\ref{rmk:conv2}.1
that the second term in~(\ref{eq:age2}) equals
\begin{equation}
\label{eq:age2c} 
\P([1,1+\theta]\cap\mbox{range of }V=\emptyset)=\P(Z_1=Z_{1+r}\,\mbox{ for all }r\in[0,\theta]).
\end{equation}
Now the right hand side of~(\ref{eq:age2c}) equals that of~(\ref{eq:age2}) (since the $\mu(x_i)$'s are almost surely all distinct).
(\ref{eq:age_r}) is then settled.

In the above argument, we felt the need to go through~(\ref{eq:age2a}) and~(\ref{eq:age2aa}), since the (indicators of the) events in the 
the second probability in~(\ref{eq:age2}) and in~(\ref{eq:age2a}) are not almost surely continuous on $(D,J_1)$, but so is the event
in~(\ref{eq:age2aa}).

As regards~(\ref{eq:age_pi}), we have that
\begin{equation}
\label{eq:hpe}
\bar \Pi(\theta\eps^{-1}/q_\eps,\eps^{-1})=\P(Y_{\eps^{-1}}=Y_{\eps^{-1}+r}\,\mbox{ for all }r\in[0,\theta\eps^{-1}/q_\eps])
=\esp\left(e^{-\theta/(\eps q_\eps Y_{\eps^{-1}})}\right)=\esp\left(e^{-\theta/\hye_1}\right),
\end{equation}
and Lemma~\ref{lm:comp} implies that
\begin{equation}
\label{eq:h2}
\lim_{\eps\to0}\esp\left(e^{-\theta/\hye_1}\right)=\lim_{\d\to0}\lim_{\eps\to0}\esp\left(e^{-\theta/\vyed_1}\right)
=\esp\left(e^{-\theta/Z_1}\right)=:\Pi(\theta),
\end{equation}
where the second equality follows from~(\ref{eq:age1}), which implies marginal convergence
in distribution (since each fixed
deterministic time is almost surely a continuity point of $Z$).
$\square$

\begin{rmk}
\label{rmk:age3}
 One quickly checks that
\begin{equation}
\label{eq:age3} 
\P(Z_1=Z_{1+\theta})=\P(Z_1=Z_{1+r}\,\mbox{ for all }r\in[0,\theta]),
\end{equation}
which equals $\P([1,1+\theta]\cap\mbox{ range of }V=\emptyset)$, as noted in~~(\ref{eq:age2c}) above.
One can then obtain the right hand side of~(\ref{eq:pir})
%\begin{equation}
%\label{eq:age3a} 
%\frac{\sin(\pi\alpha)}{\pi}\int_{\theta/(1+\theta)}^1s^{-\a}(1-s)^{\a-1}\,ds
%\end{equation}
as an expresssion for the latter probability. (This may be readily seen to follow from Proposition 3.1 in~\cite{kn:B}, 
since $V$ is an $\a$-stable subordinator; see Remark~\ref{rmk:Z} above.)
We further notice that we can write
\begin{equation}
\label{eq:age4} 
\P(Z_1=Z_{1+\theta})=\esp\left(e^{-\theta/Z_1}\right).
\end{equation}
See Remark~\ref{rmk:age2} above.  (\ref{eq:age3}) and~(\ref{eq:age4}) give us the Laplace transform of $1/Z_1$. An expression for the density of
that variable can be found in (5.97) of~\cite{kn:FM}.
\end{rmk}



\begin{rmk}
\label{rmk:age4}
Another aging function which is natural on one side and not as considered in the literature as the above ones on the other side, and also 
fits well in the above picture, is the following one.
\begin{equation}
\label{eq:q}
\textstyle \Omega(s,t)=\P(\sup_{r\in[0,t]}Y_r<\sup_{r\in[0,t+s]}Y_{r})
\end{equation}
It was suggested in~\cite{kn:FIN} as a ``measure of the prospects for novelty in the system``. 
Since $\sup_{r\in[0,t]}\hye_r=\sup_{r\in[0,t]}\vyed_r$ if $\hye_t=\vyed_t$, from Lemma~\ref{lm:comp},~(\ref{eq:c8}), Lemma~\ref{lm:conv1}
and~(\ref{eq:c5a}),
we have that
\begin{equation}
\label{eq:qage}
\textstyle \lim_{t\to\infty}\Omega(\theta t,t)=\P(\sup_{r\in[0,1]}Z_r<\sup_{r\in[0,1+\theta]}Z_{r})=:\Omega(\theta).
\end{equation}
%CHANGE 
This is an example where the limiting aging function requires full use of the process $Z$; in the previous cases, 
the limits could be expressed in terms of the (clock) process $V$ alone. 
We could not find an explicit expression for the right hand side of~(\ref{eq:qage}).
\end{rmk}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Integrated aging results}
\label{ssec:iage}



By considering integrated aging functions, or equivalently aging functions looked at random times, we may circumvent
the difficulties exhibited by recurrence --- see Remarks~\ref{rmk:trans} and~\ref{rmk:trans2}
above. As an example, let us consider one such integrated aging function, and state the corresponding result.

Let
\begin{equation}
\label{eq:ir}
\bar{\mathfrak R}(\lambda,\mu)=\esp[\bar R(\lambda{\mathcal T},\mu {\mathcal T})]=\int_0^{\infty}e^{-t}\bar R(\lambda t,\mu t)\,dt,
\end{equation}
with $\bar R$ as in~(\ref{eq:br}) above, and ${\mathcal T}$ a mean one exponential random variable independent of every other
random variable in the problem.


\begin{theo}
\label{teo:iage}
If $X$ satisfies Assumptions  $A$ and $B$, then 
\begin{equation}
\label{eq:iage}
\lim_{\lambda,\mu\to\infty\atop{\lambda/\mu\to\theta}}\bar{\mathfrak R}(\lambda,\mu)=R(\theta),
\end{equation}
with $R$ as in Theorem~\ref{teo:age} above.
\end{theo}


\noindent{\bf Proof}

Let us for simplicity take $\lambda=\theta\mu$.
We may then write
\begin{equation}
\label{eq:ir1}
\bar{\mathfrak R}(\lambda,\mu)
=\esp\int_0^{\infty}e^{-t}\,{\mathbf 1}\{Y_{\mu t}=Y_{(\mu+\lambda) t}\}\,dt
=\esp\int_0^{\infty}e^{-t}\,{\mathbf 1}\{\hye_t=\hye_{(1+\theta)t}\}\,dt,
\end{equation}
where $\eps=\mu^{-1}$.


Given $0<\eta<1$,~(\ref{eq:c7}) allows us to bound the right hand side of~(\ref{eq:ir1}) above and below by $(1\pm\eta)$ times
\begin{equation}
\label{eq:ir2}
\lim_{\eps\to0}\esp\int_0^{\infty}e^{-t}\,{\mathbf 1}\{\byed_t=\byed_{(1+\theta)t}\}\,dt
=\esp\int_0^{\infty}e^{-t}\,{\mathbf 1}\{Z^{(\delta)}_t=Z^{(\delta)}_{(1+\theta)t}\}\,dt,
\end{equation}
respectively, as soon as $\delta$ is close enough to $0$, where the latter equality follows from Lemma~\ref{lm:conv1}. 
Since $\eta$ is arbitrary, by Lemma~\ref{rmk:conv_bvd} the left hand side of~(\ref{eq:ir1}) equals
\begin{equation}
\label{eq:ir3}
\esp\int_0^{\infty}e^{-t}\,{\mathbf 1}\{Z_t=Z_{(1+\theta)t}\}\,dt=\int_0^{\infty}e^{-t}\,\P(Z_t=Z_{(1+\theta)t})\,dt,
\end{equation}
since every fixed $t$ is almost surely a continuity point of $Z$. Now by the self similarity of index 1 exhibited by $Z$, 
the probability inside the integral does not depend on $t>0$, and the result follows, since
$\P(Z_1=Z_{(1+\theta)})=R(\theta)$. $\square$

\medskip

Similar results can be argued for integrated versions of the aging functions $\bar\Pi$ and $\Omega$ above.
























