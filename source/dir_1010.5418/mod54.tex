\section{Model and results}
\label{sec:mod}
\setcounter{equation}{0}


As in the introduction, let $\pi$ be a probability measure on $\Z^d\setminus\{0\}$, and let 
$\tau=(\tau_x\,,\, x\in\Z^d)$ be a collection of 
positive numbers attached to the points of $\Z^d$ 
%We assume that $\tau(x)\geq 1$ for all $x$. 
%Let us now specify the assumptions on $\tau$. 
chosen as follows.
Let $Q$ be a probability measure on $(0,\infty)$ that belongs to the domain of attraction of a 
stable law of index $\alpha\in (0,1)$. In other words we assume that 
\begin{equation}\label{eq:tail}
 Q(u,\infty)=\ell(u)\,u^{-\alpha},\,u>0
\end{equation}
where $\ell$ is a slowly varying function at infinity. 
We choose for 
\begin{equation}\label{eq:tau}
\tau=\{\tau_x\,,\, x\in\Z^d\} 
\end{equation} 
a family of independent random variables 
with law $Q$. More precisely we endow the product space $\Omega=(0,\infty)^{\Z^d}$ 
with the law $\Q=Q^{\Z^d}$.

We consider the Markov generator 
\begin{equation}\label{eq:df}
 {\cal L}^\tau f(x)=\frac 1{\tau_x}\sum_y (f(y)-f(x))\pi(y-x)\,.
\end{equation} 
Let $P^\tau_x$ be the law 
of the Markov process $\X$ generated by ${\cal L}^\tau$ and started at $x$ 
on path space ${\cal D}([0,\infty),\Z^d)$. 
We recall that $(\X_t\,,\, t\geq 0)$ denotes the canonical 
projections on ${\cal D}([0,\infty),\Z^d)$. 
We define the age process (as in the previous section): 
\begin{equation}\label{eq:en}
 \E=(\E_t=\tau_{\X_t}\,,\,t\geq 0)\,.
\end{equation}



The so-called {\it annealed law} of the process $\X$ 
is the semidirect product measure on $\Omega\times{\cal D}([0,\infty),\Z^d)$ 
defined by 
\begin{equation}\label{eq:joint}
\P(A\times B)=\int_A d\Q(\tau) P^\tau_0(B),
\end{equation} 
where $A$ and $B$ are measurable subsets of $\Omega$ and ${\cal D}([0,\infty),\Z^d)$ 
respectively. 

In order to state our assumptions we introduce an auxiliary random walk:  
let $\xi_1,\xi_2,\ldots$ be iid $\Z^d$-valued 
random vectors with distribution $\pi$ and define 
\begin{equation}\label{eq:rw}
 X_0=0,\quad X_n=\sum_{i=1}^n\xi_i,\quad n\geq1\,.
\end{equation}
$X=(X_n,\,n\geq0)$ is a version of the jump chain of $\X$.

Let us also define the {\em range} of $X$ ({\em up to time} $n$), 
\begin{equation}\label{eq:range}
\RR_n=\RR_n(X)=\{z\in\Z^d:\,X_i=z\mbox{ for some }i\leq n\},\quad n\geq0,
\end{equation}
and make 
\begin{equation}\label{eq:range1}
R_n=|\RR_n| \mbox{ and } \rho_n=\esp(R_n). 
\end{equation}
Also define for $n\geq1$
\begin{equation}\label{rn}
r_n=\P(X_1\ne0,\ldots,X_n\ne0)\,.
\end{equation}
We will at times think of $(r_n)$ as a function.

Our first result requires the following assumptions.

\noindent{\bf Assumption} $\mathbf A$ (law of large numbers for the range): 
\begin{equation}\label{llnr}
 \lim_{n\to\infty} \frac {R_n}{\rho_n}=1\,\mbox{ in probability}. 
\end{equation} 
	    
%{\sc In what sense: a.s. or in probability?} 

\noindent{\bf Assumption} $\mathbf B$ (slow variation of $r$): $r:\N\to[0,1]$ given in~(\ref{rn}) above
is slowly varying at infinity. \label{assb}


\begin{rmk}
 \label{rmk:lln}
All transient random walks in $\Z^d$, $d\geq1$, including all random walks in $d\geq3$, 
obviously satisfy Assumptions $A$ and $B$.
But all planar random walks~\cite{kn:JP1, kn:JP2}, and $1$-dimensional  $\beta$-stable 
random walks with  $\beta\leq1$~\cite{kn:LR} also satisfy Assumptions $A$ and $B$.
\end{rmk}


Before stating our first result, we describe the form of the scaling limit of $\E$: we introduce an $\a$-stable subordinator 
$\ups=(\ups_r)_{r\geq0}$ and a family of independent mean 1 exponential random variables $\{T_r;\,r\geq0\}$, and let 
\begin{equation}
\label{eq:V}
V_s=\int_0^sT_r\,d\ups_r,\quad s\geq0,
\end{equation}
and $W=V^{-1}$ be the inverse of $V$ (see Remark~\ref{rmk:inv} below). Let finally
\begin{equation}
\label{eq:Z}
Z_t=\ups_{W_t}-\ups_{W_t-},\quad t\geq0.
\end{equation}


 
\begin{rmk}
\label{rmk:Z}
Note that $V$ is itself an $\a$-stable subordinator. (This will be relevant in our discussion on aging in Section~\ref{sec:age}
below---see Remark~\ref{rmk:age3} in that section.)
We may regard $V$ and $Z$ as processes in the random environment $\ups$. In fact, given $\ups$, they are both Markovian.
We may think of $\ups$ as the scaling limit of the (relevant) environment of the trap model. %See discussion below.
The overall distribution of $Z$ (integrated over the joint distribution of $\ups$ and $\{T_r;\,r\geq0\}$) makes it a self similar 
process of index $1$.
\end{rmk}
 

\begin{rmk}
 \label{rmk:const}
Let $c>0$ be the constant such that $\esp(\exp\{-\l \ups_1\})=\exp\{-c\l^\a\}$. One readily checks that the distribution
of $Z$ does not depend on that constant. %For convenience, we will take it so that~(\ref{eq:auxconv}) below is satisfied.
Here and below we will denote also by $\P$ and $\esp$ the probability and expectation underlying the distributions of
$\ups$ and the $T_r$'s.
\end{rmk}

 

We are now ready to state our convergence 
result, but first some notation. For $\eps>0,\,t\geq0$, let 
\begin{equation}
\label{eq:ye}
\E^{(\eps)}_t=\eps q_\eps\E_{\eps^{-1}t}, 
\end{equation}
where $q_\eps$ is a slowly varying function at $0$ to be further specified below, %(see~(\ref{eq:ae})), 
and denote  $\E^{(\eps)}=(\E^{(\eps)}_t)$ and $Z=(Z_t)$. 
Let $D$, $D_T$ denote the spaces of c\`adl\`ag real functions defined on $[0,\infty)$, $[0,T]$ 
respectively. Let $d_T$ denote the $L_1$ distance in $D_T$, and $d=\sum_{n=1}^\infty2^{-n}(d_n\wedge1)$.


\begin{theo}
\label{teo:conv1}
Suppose Assumptions A and B are in force. 
Then as $\eps\searrow0$
\begin{equation}
\label{eq:conv1}
\E^{(\eps)}\to Z
\end{equation}
in distribution on $(D,d)$, where $(q_\eps)_{\eps>0}$ is nonincreasing, slowly varying at $0$ and satisfies
$1\leq q:=\lim_{\eps\to0}q_\eps\leq\infty$, with $q<\infty$ if and only if $X$ is transient.
\end{theo}
%

Notice that in the transient case we have linear scaling, and sublinear scaling in the recurrent case.
A more precise description of $q_\eps$ is given in~(\ref{eq:ae2}) below.

%\begin{rmk}
%\label{rmk:fd}
%Theorem~\ref{teo:conv1} implies that $\E^{(\eps)}_t\to Z_t$ in distribution for every fixed $t\geq0$, since the projection in coordinate $t$
%is continuous for almost every $Z$, as can be readily checked.
%\end{rmk}
Here is a rough evaluation on the form of the spatial scaling in~(\ref{eq:ye}) leading to~(\ref{eq:conv1}). 
After $n$ steps, the random walk $X$ has explored $R_n\sim\rho_n$ new sites, each
one visited of the order of $1/r_n$ times, so the walk should be visiting a trap of depth of order $s_{\rho_n}=:v_n$, 
where $s_n$ is of the order of the largest of $n$ independent copies of $\tau_0$. Under our assumptions, the main 
contributions to the total time spent by the process to give $n$ steps, namely the times spent at the deepest 
traps encountered up to that number of steps, are roughly independent, so that total time should be of order $v_n/r_n=:\phi_n$. 
Then to times of order $\eps^{-1}$ correspond energies of order $v_{\nu_\eps}$, where
\begin{equation}\label{eq:nue}
\nu_\eps=\phi^{-1}(\eps^{-1}),
\end{equation}
and $\phi^{-1}$ is the inverse of $\phi$.
We thus should take
\begin{equation}\label{eq:ae1}
\frac1{v_{\nu_\eps}}=\frac1{r_{\nu_\eps}\phi_{\nu_\eps}}\sim\frac{\eps}{r_{\nu_\eps}}
\end{equation} 
%and indeed will do that explicitly from now on.
as spatial scaling, where the latter aproximate equality follows from the inverse relation between $\phi$ and $\nu$.
From the assumptions on $r$ and the distribution of $\tau_0$, it follows that $\nu$ is nonincreasing, unbounded and regularly
varying at infinity. Since $r\in[0,1)$ is nonincreasing and slowly varying at infinity, we conclude that 
\begin{equation}\label{eq:ae2}
q_\eps=1/r_{\nu_\eps} 
\end{equation} 
has the stated properties.

%In all other cases, we have sublinear scaling (even if just barely, due to the 
%slowly varying decay of $r$). 
%Notice also that, in general, due to the slow variation of $r$ and polynomial growth 
%of $v$, $a_\eps$ may be also taken as $1/\nu'(\eps^{-1})$, where $\nu'$ is the inverse of $\phi'_n:=n/r_n$. 
%In the planar simple symmetric case, for example, one may take $a_\eps=\eps\,|\!\log\eps|$. 

The rough discussion of the last paragraph also gives rise to the form of the limiting process, once one realizes 
that (under our assumptions) the total times spent on the few contributing traps, when divided by the respective
means, and suitably scaled to account for the number of distinct visits, are approximately iid mean 1 exponentials.
A striking aspect is the universality of the limiting process even for cases where the scalings are distinct
(linear and sublinear as pointed out above).


A remark about the topology: small traps do not contribute to the limit, and were they to be completely disregarded 
the convergence would take place in the $J_1$/usual Skorohod topology, 
but they are there and mix up with large traps in a way which the $J_1$ topology 
(and other more usual ones, like the $M_1$ topology) is too fine to handle, and so we resort to a rougher topology.

One important technical aspect to consider in order to prove the scaling limit of an aging function like~(\ref{eq:af1}) 
is to show that for an arbitrary fixed time $t$, $\E^{(\eps)}_t$ converges to $Z_t$ as $\eps\to0$ in a strong enough form. 
This does not follow from Theorem~\ref{teo:conv1}, mainly due to the topological issue just discussed.
We state and prove such a convergence result, Lemma~\ref{lm:comp}, in Section~\ref{sec:age}, 
involving suitable versions of the relevant processes, 
before establishing the main results of that section, namely the aging results stated in 
Theorem~\ref{teo:age} (see also Remark~\ref{rmk:age4}). 
Our approach requires the strengthening of Assumptions A and B to transience of $X$. 
Scaling limit results for integrated versions of the aging functions herein considered, and potentially 
others, follow from Theorem 5, or rather the arguments in its proof, directly, under the original assumptions. 
See Subsection~\ref{ssec:iage}.

We close with a brief discussion on the stronger than annealed version for Theorem~\ref{teo:conv1}. Roughly, the annealed aspect of
Theorem~\ref{teo:conv1} follows from our approach of considering a version of the 
$\tau$ variables placed over the range of the underlying discrete random walk, thus fixing it, in such a way that they in a certain sense 
converge almost surely (to the increments of a stable subordinator, $\Upsilon$) --- see details in the proof of Theorem~\ref{teo:conv1} on
Section~\ref{sec:conv}. This turns out to be convenient for the analysis leading to Theorem~\ref{teo:conv1}, but when going back to the original
$\tau$'s, we only have an annealed result.
But of course, when we consider the distribution of the process given $\tau$, we integrate with respect to the underlying discrete random walk, 
and the averaging involved in this could lead to a stronger result. 
A condition is required, however --- annealed convergence is all we have in, say, the asymmetric simple one dimensional case. One is
introduced in Section~\ref{sec:str}, saying roughly that independent realizations of the trajectory of $X$ intersect little. With
that additional condition, we state
and prove stronger convergence results.