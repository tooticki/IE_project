\section{Preliminaries on random walks}
\label{sec:rw}
\setcounter{equation}{0}

In this section, we establish a few facts concerning discrete time random walks that follow from Assumptions  $A$ and  $B$ made in
Section~\ref{sec:mod}
above, as well as from other assumptions we will consider below. These results will be used later in the sections ahead.

Let $X=(X_n,\,n\geq0)$ be the random walk introduced in Section~\ref{sec:mod} above, and define 
\begin{equation}
\label{eq:run} 
u_n=\P(X_n=0),\quad U_n=\sum_{i=0}^nu_i,\quad L_n=\sum_{i=0}^n\1\{X_i=0\},\quad n\geq0.
\end{equation}
$L_n$ is the occupation time of the origin up to step $n$. We will also write $L_x$ for a positive real $x$, and it means $L_{\lf x\rf}$,
similarly for $U_x$ and $r_x$.

Our first remark is that 
\begin{equation}
\label{eq:ror} 
\rho_n=\sum_{k=0}^n r_k,
\end{equation}
with $\rho$ and $r$ defined in~(\ref{eq:range1},~\ref{rn}) above.
The formula is proved as follows (see~\cite{kn:S} page 36). First we have that
\begin{equation}\nn
R_n=\sum_{k=0}^n \1\{R_k=R_{k-1}+1\}\,, 
\end{equation}
where $R$ was defined in~(\ref{eq:range}) above. Upon noticing that 
\begin{equation}\nn
R_k=R_{k-1}+1\Leftrightarrow X_k-X_{k-1}\not=0 ; X_k-X_{k-2}\not=0,\ldots,X_k\not=0\,,
\end{equation}
we conclude that 
\begin{eqnarray*}%\nn
&\P(R_k=R_{k-1}+1)=&\\
&\P(\xi_k\not=0;\xi_k+\xi_{k-1}\not=0,\ldots,X_k\not=0)
=\P(X_1\not=0;X_2\not=0,\ldots,X_k\not=0)=r_k\,.&
\end{eqnarray*}%{equation} 
 It then follows from~(\ref{eq:ror}) and Assumption  $B$ that 
\begin{equation}
\label{eq:ronr} 
\lim_{n\to\infty}\frac{\rho_n}{nr_n}=1\,.
\end{equation}
(This readily follows from the first displayed equation on page 55 of~\cite{kn:Se}.)

Our second remark is the following result.

\begin{lm}
\label{lm:approx}
Under Assumption  $B$, and provided $\lim_{n\to\infty}r_n=0$ (that is, if $X$ is recurrent), the law of $r_n L_n$ approximates a mean 1 exponential
distribution as $n\to\infty$. 
\end{lm}

\noindent{\bf Proof} 

Given $u\geq0$, we have that
$$ \{r_n L_n>u\}=\{\eta_1+...+\eta_k\leq n\} $$ 
where the $\eta_j$, $j\geq1$, are the successive  increments of return times to the origin by $X$, and $k=\lf u/r_n\rf+1$. 

Therefore 
\begin{equation} \label{1}
\P(r_n L_n>u)=\P(\eta_1+...+\eta_k\leq n)=\P(\bar\eta_n\leq1),
\end{equation} 
where $\bar\eta_n=(\eta_1+...+\eta_k)/n$.

A straightforward computation of the Laplace transform of $\bar\eta_n$ yields
\begin{equation} \label{2}
\esp(e^{-\l\bar\eta_n})=\{\esp(e^{-\frac\l n\eta_1})\}^k=\left\{1-\frac\l n\int_0^\infty r(x)\,e^{-\frac\l n x}\,dx\right\}^k
=\left\{1-\int_0^\infty r(y n/\l)\,e^{-y}\,dy\right\}^k,
\end{equation} 
where  $r(x)=\P(\eta_1>x)=r_{\lf x\rf}$.

Assumption  $B$ and Theorems 2.6 and 2.7 of~\cite{kn:Se} imply that the integral on the right hand side of~(\ref{2}) is asymptotic
to $r_n$ as $n\to\infty$. This and the form of $k$ imply that
\begin{equation} \label{3}
\lim_{n\to\infty}\esp(e^{-\l\bar\eta_n})=e^{-u}
\end{equation} 
for all $\l>0$, and this implies that the law of $\bar\eta_n$ converges to that of a(n extended) random variable which takes the value $0$
with probability $e^{-u}$, and the value $\infty$ with the complementary probability. It follows that 
\begin{equation} \label{4}
\lim_{n\to\infty}\P(r_n L_n>u)=e^{-u}
\end{equation} 
for every $u>0$. $\square$

\begin{cor}
\label{cor:approx}
Under Assumption $B$, we have that
\begin{equation} \label{5}
\lim_{n\to\infty}r_n U_n=1.
\end{equation} 
\end{cor}

\noindent{\bf Proof}  

In the transient case, this follows from $r_n\to r_\infty>0$, $L_n\to L_\infty$, a Geometric random variable with mean $r_\infty^{-1}$, 
and monotone convergence.

In the recurrent case, from the first equality in~(\ref{1}), we find that
\begin{equation} \label{6}
\P(r_n L_n>u)\leq\P\!\left(\max_{1\leq j\leq k}\eta_j\leq n\!\right)=(1-r_n)^k.
\end{equation} 
From the form of $k$, and the fact that $\lim_{n\to\infty}(1-r_n)^{1/r_n}=e^{-1}$, we find that for every $c>e^{-1}$ and large enough $n$, the right
hand side of~(\ref{5}) is dominated by $c^u$ for all large enough $n$. Dominated convergence now yields
\begin{equation} \label{7}
r_n U_n=\int_0^\infty\P(r_n L_n>u)\,du\to\int_0^\infty e^{-u}\,du=1\,.
\end{equation} 
as $n\to\infty$, since, from~(\ref{eq:run}), $r_n U_n=r_n\esp(L_n)= \esp(r_nL_n)$. $\square$

\bigskip


Another corollary of Lemma~\ref{lm:approx} is as follows. For $x\in\Z^d$, let
\begin{equation} \label{71}
\ell(x,n)=\sum_{j=0}^n \1\{X_j=x\}\,T_j,
\end{equation}
where $T_1,T_2,\ldots$ are iid mean 1 exponential random variables independent of $X$.

\begin{cor}
\label{cor:approx1}
Under Assumption $B$, we have that $r_n\ell(0,n)$ converges weakly to a mean 1 exponential distribution.
\end{cor}

%\begin{rmk}
%This result holds also in the transient case; also if we replace $n$ by $an$, with an arbitrary constant $a>0$.
%\end{rmk}
\noindent{\bf Proof}  

In the recurrent case, the result follows immediately from Lemma~\ref{lm:approx} and the law of large numbers, 
once we observe that 
\begin{equation} \label{8}
\ell(0,n)=\sum_{i=1}^{L_n} T'_j ,
\end{equation} 
where $T'_1,T'_2,\ldots$ are iid mean 1 exponential random variables independent of $X$.  

In the transient case, $L_n$ converges as $n\to\infty$ to a geometrically distributed random variable, say $L_\infty$. 
Also $\lim_{n\to\infty}r_n=r_\infty>0$, and one readily checks that $r_\infty\sum_{i=1}^{L_\infty} T'_j$ is a mean 1 exponential 
random variable. 
$\square$

\bigskip




\begin{lm}
\label{lm:cp}
Under Assumption $B$, we have that for every $0<a<b<\infty$
\begin{equation}
\label{eq:labn}
L_{bn}-L_{an}\to0
\end{equation}
in probability as $n\to\infty$.
\end{lm}

\begin{rmk}
 \label{rmk:labn}
Since $L_{bn}-L_{an}$ is an integer, we have that the probability of no return to $0$ of $X$ during $[an,bn]$ goes to 1 as $n\to\infty$ for every
fixed $0<a<b<\infty$.
\end{rmk}


\noindent{\bf Proof}

Let $N=N_n(a,b)$ denote the random variable on the 
 left of~(\ref{eq:labn}). Using the Markov property, one readily checks that the conditional
distribution of $L_{(b+1)n}-L_{an}$ given $N\geq1$ dominates the unconditional one of $L_n$. 
We conclude that
\begin{eqnarray}\nn
U_{(b+1)n}-U_{an}\=\esp[L_{(b+1)n}-L_{an}]\geq\esp[L_{(b+1)n}-L_{an};\,N\geq1]\\
\label{eq:cp1}
&\geq&\esp[L_n]\,\P(N\geq1)=U_n\,\P(N\geq1).
\end{eqnarray}

We then have that $\P(N\geq1)\leq(U_{(b+1)n}-U_{an})/U_n$ and the result follows from Assumption $B$ and~(\ref{5}).
$\square$



