***
Definition 1.1 (Spread random variable). Let ξ be a complex random
***
Remark 1.2. It follows from the monotone convergence theorem that
***
Definition 1.3 (Structured random matrix). Let A = (aij ) and B =
***
Remark 1.4. The assumption that the entries of M are shifted scalings
***
Corollary 1.21 below is a key input for the proofs in [10]).
***
Theorem 1.12 below (see also Theorem 1.10 for the Gaussian case) shows
***
Theorem 1.6 (Shifted iid matrix [36]). Let X be an n × n matrix with
***
Proposition 1.7 (Matrix with entries having bounded density [6]). Let
***
Proposition 1.8 (Heavy-tailed matrix with non-degenerate entries [6]).
***
Definition 1.9 (Broad connectivity). Let A = (aij ) be an n×m matrix
***
Theorem 1.10 (Gaussian matrix with broadly connected proﬁle [30]).
***
Remark 1.11. Since the dependence of the bound (1.20) on the parameters δ and ν is not quantiﬁed, Theorem 1.10 only addresses Question B for
***
Theorem 1.12 (General matrix with broadly connected proﬁle). Let
***
Remark 1.13. While we have stated no moment assumptions on the
***
Remark 1.14 (Improving the probability bound). We expect that the
***
Remark 1.15 (Bounds on moderately small singular values). The methods used to prove Theorem 1.12 together with an idea of Tao and Vu
***
Corollary 1.16 (Shifted non-Hermitian band matrices). Let M = A ◦
***
Remark 1.17. It is possible to modify our argument for the above corollary to treat a band proﬁle that does not “wrap around”, i.e. only enforcing
***
Theorem 1.18 (Main result). Fix arbitrary r0 ∈ (0, 12 ], K0 ≥ 1, and let
***
Remark 1.19 (Moment assumption). The assumption of 4+ η moments
***
Remark 1.20 (Dependence of α, β on parameters). The proof gives
***
Corollary 1.21 (Scalar shift of a centered random matrix). Let X =
***
Conjecture 1.22. Theorem 1.18 continues to hold for B ∈ Mn (C) not
***
Definition 1.23 (Super-regularity). Let A be an n × m matrix with
***
Theorem 1.24 (Matrix with super-regular proﬁle). Let M = A ◦ X + B
***
Theorem 1.24 makes crucial use of a new “entropy reduction” argument,
***
Lemma 2.1 (Incompressible vectors are spread, cf. [28, Lemma 3.4]). Fix
***
Lemma 2.2 (Metric entropy of the sphere). Let V ⊂ Cm be a subspace
***
Definition 2.3 (Concentration probability).
***
Definition 2.4 (Controlled second moment, cf. [36, Deﬁnition 2.2]). Let
***
Lemma 2.5. Let ξ be a centered complex random variable with unit variance, and assume ξ is κ0 -spread for some κ0 ≥ 1 (see Definition 1.1). Then
***
Lemma 2.6 (Crude anti-concentration, cf. [39, Corollary 6.3]). Let ξ be
***
Lemma 2.7 (Improved anti-concentration). Let ξ be a complex random
***
Lemma 2.7 can be deduced from the Berry–Esséen theorem (which is the
***
Lemma 2.8 (Tensorization, cf. [28, Lemma 2.2]).
***
Lemma 2.9 (Crude anti-concentration for the image of a ﬁxed vector).
***
Lemma 2.10 (Improved anti-concentration for the image of a ﬁxed vector). Fix v ∈ Cm . Let α > 0 such that Iα (v) 6= ∅ and fix I0 ⊂ Iα (v)
***
Theorem 1.24 is well-invertible on the set of compressible vectors Comp(θ, ρ)
***
Proposition 3.1 (Compressible vectors: broadly connected proﬁle). Let
***
Proposition 3.2 (Compressible vectors: general proﬁle with large perturbation). Let M = A◦X + B be as in Definition 1.3 with n/2 ≤ m ≤ 2n.
***
Lemma 3.3 (Highly compressible vectors). Let M = A ◦ X + B be as in
***
Definition 1.3 with m ≤ 2n. Assume that ξ has κ-controlled second moment
***
Lemma 3.4 (Many good rows). Let A be an
***
Lemma 3.5 (Control by a random net of small cardinality). For every
***
Remark 3.6. We obtain the random set ΣI,J (ε) as the intersection of
***
Theorem 3.7 (Restricted
***
Corollary 3.8. Let M be an n × m matrix with n ≥ m, and assume
***
Remark 3.9. The original Restricted Invertibility Theorem of Bourgain
***
Proposition 3.1 from an iterative application of the following lemma:
***
Lemma 3.10 (Incrementing compressibility: broadly connected proﬁle).
***
Lemma 3.11 (Anti-concentration for the image of an incompressible vector). Let M be as in Proposition 3.2. Let v ∈ Incomp(θ, ρ) for some
***
Remark 3.12. Proceeding as in the proof of Lemma 3.10 would yield
***
Lemma 2.7 and the above estimates, for all t ≥ 0 we have
***
Lemma 3.13 (Incrementing compressibility: general proﬁle). Let M be
***
Lemma 3.3. Denoting ε = ρ′′ K 2 , the above bound rearranges to
***
Proposition 3.1 to show v has essential support of size (1 − δ/2)n, and hence
***
Proposition 3.2. In particular,
***
Lemma 4.1 (Good overlap on average). Recall the parameter ε from our
***
Lemma 3.11. Letting Lk = {j ∈ [n] : 2−(k+1) < |uj | ≤ 2−k , since
***
Definition 5.1 (Regular pair). Let A be an n × n matrix with nonnegative entries. For ε > 0, we say that a pair of vertex subsets I, J ⊂ [n] is
***
Lemma 5.2 (Regularity Lemma). Let ε > 0. There exists m0 ∈ N with
***
Remark 5.3. The dependence on ε of the bound m0 ≤ Oε (1) is very
***
Lemma 5.4 (Schur complement bound). Let M ∈ MN +n (C), which we
***
Lemma 5.5 (Control on the operator norm). Let ξ ∈ C be a centered
***
Remark 5.6. The probability bounds in the above lemma can be improved under higher moment assumptions on ξ, and improve to exponential
***
Theorem 5.7 (Latala [18]). Let n, m be sufficiently large and let Y be
***
Theorem 5.8 (Vershynin [42]). Let η ∈ (0, 1) and n, m, N sufficiently
***
Theorem 5.8 we have
***
Lemma 5.9. Let A be an n × n matrix with entries aij ∈ [0, 1]. Let
***
Lemma 5.10. Assume n1 := |Jfree | ≥ δ1/2 n. If σ0 , δ are sufficiently small
***
Lemma 5.11. Assume n2 := |Jcyc | ≥ δ1/2 n. Fix γ ≥ 1 and let W ∈
***
Remark 5.12. We note that in the proof of Lemma 5.11 we do not
***
Theorem 1.18 under the additional assumption that the standard deviation
***
Lemma 5.13. Let M = A ◦ X + B be an n × n matrix as in Definition
***
Remark 5.14. The proof gives an implied constant of order exp(−O(K/r0 )O(1) )
